{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome","text":"<p>Welcome to Marsh's totally unofficial documentation for the OpenAI Python library!</p> <ul> <li> OpenAI Python library reference</li> <li> Get started with the library</li> <li> Example code</li> <li> Library <code>CHANGELOG</code></li> </ul>"},{"location":"#about-these-docs","title":"About these docs","text":"<p>Though this documentation is officially unofficial, you're welcome to use and improve it until OpenAI brings up their own (1) or they ask me to take them down.</p> <ol> <li>When OpenAI publishes their own Python API reference, I might decommission this site.</li> </ol>"},{"location":"#unofficial","title":"Unofficial","text":"<p>Neither this site nor its contents are officially endorsed by OpenAI. Other than being a customer, I have no affiliation with OpenAI. I've published this documentation because I wanted full API reference for the Python library. You might find it useful, too.</p> <p>You might instead prefer to use OpenAI's official docs on OpenAI's official documentation site and in the upstream openai/openai-python repository on GitHub, however.</p>"},{"location":"#unsupported","title":"Unsupported","text":"<p>The documentation on this site is provided AS-IS with NO WARRANTY. The API reference is indeed generated from the OpenAI Python library's code, but I make no promises nor guarantee these docs reflect the current, past, or future state of the library.</p> <p>That said, I use these docs myself and thus intend to keep them (mostly) current. However, there's no automation pulling content from their repo to this fork. (1)</p> <ol> <li>That means you might encounter inaccuracies or you might not find what you think should be here. In either case, you should refer to openai/openai-python as the source of truth.</li> </ol> <p> Enjoy! \u2014Marsh</p>"},{"location":"advanced/","title":"Advanced configuration","text":"<p>You can directly override the httpx client to customize it for your use case, including:</p> <ul> <li>Support for proxies</li> <li>Custom transports</li> <li>Additional advanced functionality</li> </ul> <pre><code>import httpx\nfrom openai import OpenAI\n\nclient = OpenAI(\n    # Or use the `OPENAI_BASE_URL` env var\n    base_url=\"http://my.test.server.example.com:8083\",\n    http_client=httpx.Client(\n        proxies=\"http://my.test.proxy.example.com\",\n        transport=httpx.HTTPTransport(local_address=\"0.0.0.0\"),\n    ),\n)\n</code></pre>"},{"location":"advanced/#managing-http-resources","title":"Managing HTTP resources","text":"<p>By default, the library closes underlying HTTP connections whenever the client is garbage collected. You can manually close the client using the <code>.close()</code> method if desired, or with a context manager that closes when exiting.</p>"},{"location":"advanced/#microsoft-azure-openai","title":"Microsoft Azure OpenAI","text":"<p>To use this library with Azure OpenAI, use the <code>AzureOpenAI</code> class instead of the <code>OpenAI</code> class.</p> <p>Important</p> <p>The API surface of the Azure API differs from that of the core API. The static types for responses / params won't always be correct.</p> <pre><code>from openai import AzureOpenAI\n\n# gets the API Key from environment variable AZURE_OPENAI_API_KEY\nclient = AzureOpenAI(\n    # https://learn.microsoft.com/en-us/azure/ai-services/openai/reference#rest-api-versioning\n    api_version=\"2023-07-01-preview\",\n    # https://learn.microsoft.com/en-us/azure/cognitive-services/openai/how-to/create-resource?pivots=web-portal#create-a-resource\n    azure_endpoint=\"https://example-endpoint.openai.azure.com\",\n)\n\ncompletion = client.chat.completions.create(\n    model=\"deployment-name\",  # e.g. gpt-35-instant\n    messages=[\n        {\n            \"role\": \"user\",\n            \"content\": \"How do I output all files in a directory using Python?\",\n        },\n    ],\n)\nprint(completion.model_dump_json(indent=2))\n</code></pre> <p>In addition to the options provided in the base <code>OpenAI</code> client, the following options are provided:</p> <ul> <li><code>azure_endpoint</code> (or the <code>AZURE_OPENAI_ENDPOINT</code> environment variable)</li> <li><code>azure_deployment</code></li> <li><code>api_version</code> (or the <code>OPENAI_API_VERSION</code> environment variable)</li> <li><code>azure_ad_token</code> (or the <code>AZURE_OPENAI_AD_TOKEN</code> environment variable)</li> <li><code>azure_ad_token_provider</code></li> </ul> <p>An example of using the client with Azure Active Directory can be found here.</p>"},{"location":"advanced/#versioning","title":"Versioning","text":"<p>This package generally follows SemVer conventions, though certain backwards-incompatible changes may be released as minor versions:</p> <ol> <li>Changes that only affect static types, without breaking runtime behavior.</li> <li>Changes to library internals which are technically public but not intended or documented for external use. (Please open a GitHub issue to let us know if you are relying on such internals).</li> <li>Changes that we do not expect to impact the vast majority of users in practice.</li> </ol> <p>We take backwards-compatibility seriously and work hard to ensure you can rely on a smooth upgrade experience.</p> <p>We are keen for your feedback; please open an issue with questions, bugs, or suggestions.</p>"},{"location":"changelog/","title":"Library <code>CHANGELOG</code>","text":""},{"location":"changelog/#1134-2024-03-09","title":"1.13.4 (2024-03-09)","text":"<p>Full Changelog: v1.13.3...v1.13.4</p>"},{"location":"changelog/#bug-fixes","title":"Bug Fixes","text":"<ul> <li>streaming: improve error messages (#1218) (4f5ff29)</li> </ul>"},{"location":"changelog/#chores","title":"Chores","text":"<ul> <li>api: update docs (#1212) (71236e0)</li> <li>client: improve error message for invalid http_client argument (#1216) (d0c928a)</li> <li>docs: mention install from git repo (#1203) (3ab6f44)</li> <li>export NOT_GIVEN sentinel value (#1223) (8a4f76f)</li> <li>internal: add core support for deserializing into number response (#1219) (004bc92)</li> <li>internal: bump pyright (#1221) (3c2e815)</li> <li>internal: minor core client restructuring (#1199) (4314cdc)</li> <li>internal: split up transforms into sync / async (#1210) (7853a83)</li> <li>internal: support more input types (#1211) (d0e4baa)</li> <li>internal: support parsing Annotated types (#1222) (8598f81)</li> </ul>"},{"location":"changelog/#documentation","title":"Documentation","text":"<ul> <li>contributing: improve wording (#1201) (95a1e0e)</li> </ul>"},{"location":"changelog/#1133-2024-02-28","title":"1.13.3 (2024-02-28)","text":"<p>Full Changelog: v1.13.2...v1.13.3</p>"},{"location":"changelog/#features","title":"Features","text":"<ul> <li>api: add wav and pcm to response_format (#1189) (dbd20fc)</li> </ul>"},{"location":"changelog/#chores_1","title":"Chores","text":"<ul> <li>client: use anyio.sleep instead of asyncio.sleep (#1198) (b6d025b)</li> <li>internal: bump pyright (#1193) (9202e04)</li> <li>types: extract run status to a named type (#1178) (249ecbd)</li> </ul>"},{"location":"changelog/#documentation_1","title":"Documentation","text":"<ul> <li>add note in azure_deployment docstring (#1188) (96fa995)</li> <li>examples: add pyaudio streaming example (#1194) (3683c5e)</li> </ul>"},{"location":"changelog/#1132-2024-02-20","title":"1.13.2 (2024-02-20)","text":"<p>Full Changelog: v1.13.1...v1.13.2</p>"},{"location":"changelog/#bug-fixes_1","title":"Bug Fixes","text":"<ul> <li>ci: revert \"move github release logic to github app\" (#1170) (f1adc2e)</li> </ul>"},{"location":"changelog/#1131-2024-02-20","title":"1.13.1 (2024-02-20)","text":"<p>Full Changelog: v1.13.0...v1.13.1</p>"},{"location":"changelog/#chores_2","title":"Chores","text":"<ul> <li>internal: bump rye to v0.24.0 (#1168) (84c4256)</li> </ul>"},{"location":"changelog/#1130-2024-02-19","title":"1.13.0 (2024-02-19)","text":"<p>Full Changelog: v1.12.0...v1.13.0</p>"},{"location":"changelog/#features_1","title":"Features","text":"<ul> <li>api: updates (#1146) (79b7675)</li> </ul>"},{"location":"changelog/#bug-fixes_2","title":"Bug Fixes","text":"<ul> <li>api: remove non-GA instance_id param (#1164) (1abe139)</li> </ul>"},{"location":"changelog/#chores_3","title":"Chores","text":"<ul> <li>ci: move github release logic to github app (#1155) (67cfac2)</li> <li>client: use correct accept headers for binary data (#1161) (e536437)</li> <li>internal: refactor release environment script (#1158) (7fe8ec3)</li> </ul>"},{"location":"changelog/#1120-2024-02-08","title":"1.12.0 (2024-02-08)","text":"<p>Full Changelog: v1.11.1...v1.12.0</p>"},{"location":"changelog/#features_2","title":"Features","text":"<ul> <li>api: add <code>timestamp_granularities</code>, add <code>gpt-3.5-turbo-0125</code> model (#1125) (1ecf8f6)</li> <li>cli/images: add support for <code>--model</code> arg (#1132) (0d53866)</li> </ul>"},{"location":"changelog/#bug-fixes_3","title":"Bug Fixes","text":"<ul> <li>remove double brackets from timestamp_granularities param (#1140) (3db0222)</li> <li>types: loosen most List params types to Iterable (#1129) (bdb31a3)</li> </ul>"},{"location":"changelog/#chores_4","title":"Chores","text":"<ul> <li>internal: add lint command (#1128) (4c021c0)</li> <li>internal: support serialising iterable types (#1127) (98d4e59)</li> </ul>"},{"location":"changelog/#documentation_2","title":"Documentation","text":"<ul> <li>add CONTRIBUTING.md (#1138) (79c8f0e)</li> </ul>"},{"location":"changelog/#1111-2024-02-04","title":"1.11.1 (2024-02-04)","text":"<p>Full Changelog: v1.11.0...v1.11.1</p>"},{"location":"changelog/#bug-fixes_4","title":"Bug Fixes","text":"<ul> <li>prevent crash when platform.architecture() is not allowed (#1120) (9490554)</li> </ul>"},{"location":"changelog/#1110-2024-02-03","title":"1.11.0 (2024-02-03)","text":"<p>Full Changelog: v1.10.0...v1.11.0</p>"},{"location":"changelog/#features_3","title":"Features","text":"<ul> <li>client: support parsing custom response types (#1111) (da00fc3)</li> </ul>"},{"location":"changelog/#chores_5","title":"Chores","text":"<ul> <li>interal: make link to api.md relative (#1117) (4a10879)</li> <li>internal: cast type in mocked test (#1112) (99b21e1)</li> <li>internal: enable ruff type checking misuse lint rule (#1106) (fa63e60)</li> <li>internal: support multipart data with overlapping keys (#1104) (455bc9f)</li> <li>internal: support pre-release versioning (#1113) (dea5b08)</li> </ul>"},{"location":"changelog/#1100-2024-01-25","title":"1.10.0 (2024-01-25)","text":"<p>Full Changelog: v1.9.0...v1.10.0</p>"},{"location":"changelog/#features_4","title":"Features","text":"<ul> <li>api: add text embeddings dimensions param (#1103) (94abfa0)</li> <li>azure: proactively add audio/speech to deployment endpoints (#1099) (fdf8742)</li> <li>client: enable follow redirects by default (#1100) (d325b7c)</li> </ul>"},{"location":"changelog/#chores_6","title":"Chores","text":"<ul> <li>internal: add internal helpers (#1092) (629bde5)</li> </ul>"},{"location":"changelog/#refactors","title":"Refactors","text":"<ul> <li>remove unnecessary builtin import (#1094) (504b7d4)</li> </ul>"},{"location":"changelog/#190-2024-01-21","title":"1.9.0 (2024-01-21)","text":"<p>Full Changelog: v1.8.0...v1.9.0</p>"},{"location":"changelog/#features_5","title":"Features","text":"<ul> <li>api: add usage to runs and run steps (#1090) (6c116df)</li> </ul>"},{"location":"changelog/#chores_7","title":"Chores","text":"<ul> <li>internal: fix typing util function (#1083) (3e60db6)</li> <li>internal: remove redundant client test (#1085) (947974f)</li> <li>internal: share client instances between all tests (#1088) (05cd753)</li> <li>internal: speculative retry-after-ms support (#1086) (36a7576)</li> <li>lazy load raw resource class properties (#1087) (d307127)</li> </ul>"},{"location":"changelog/#180-2024-01-16","title":"1.8.0 (2024-01-16)","text":"<p>Full Changelog: v1.7.2...v1.8.0</p>"},{"location":"changelog/#features_6","title":"Features","text":"<ul> <li>client: add support for streaming raw responses (#1072) (0e93c3b)</li> </ul>"},{"location":"changelog/#bug-fixes_5","title":"Bug Fixes","text":"<ul> <li>client: ensure path params are non-empty (#1075) (9a25149)</li> <li>proxy: prevent recursion errors when debugging pycharm (#1076) (3d78798)</li> </ul>"},{"location":"changelog/#chores_8","title":"Chores","text":"<ul> <li>add write_to_file binary helper method (#1077) (c622c6a)</li> </ul>"},{"location":"changelog/#172-2024-01-12","title":"1.7.2 (2024-01-12)","text":"<p>Full Changelog: v1.7.1...v1.7.2</p>"},{"location":"changelog/#documentation_3","title":"Documentation","text":"<ul> <li>readme: improve api reference (#1065) (745b9e0)</li> </ul>"},{"location":"changelog/#refactors_1","title":"Refactors","text":"<ul> <li>api: remove deprecated endpoints (#1067) (199ddcd)</li> </ul>"},{"location":"changelog/#171-2024-01-10","title":"1.7.1 (2024-01-10)","text":"<p>Full Changelog: v1.7.0...v1.7.1</p>"},{"location":"changelog/#chores_9","title":"Chores","text":"<ul> <li>client: improve debug logging for failed requests (#1060) (cf9a651)</li> </ul>"},{"location":"changelog/#170-2024-01-08","title":"1.7.0 (2024-01-08)","text":"<p>Full Changelog: v1.6.1...v1.7.0</p>"},{"location":"changelog/#features_7","title":"Features","text":"<ul> <li>add <code>None</code> default value to nullable response properties (#1043) (d94b4d3)</li> </ul>"},{"location":"changelog/#bug-fixes_6","title":"Bug Fixes","text":"<ul> <li>client: correctly use custom http client auth (#1028) (3d7d93e)</li> </ul>"},{"location":"changelog/#chores_10","title":"Chores","text":"<ul> <li>add .keep files for examples and custom code directories (#1057) (7524097)</li> <li>internal: bump license (#1037) (d828527)</li> <li>internal: loosen type var restrictions (#1049) (e00876b)</li> <li>internal: replace isort with ruff (#1042) (f1fbc9c)</li> <li>internal: update formatting (#1041) (2e9ecee)</li> <li>src: fix typos (#988) (6a8b806)</li> <li>use property declarations for resource members (#1047) (131f6bc)</li> </ul>"},{"location":"changelog/#documentation_4","title":"Documentation","text":"<ul> <li>fix docstring typos (#1022) (ad3fd2c)</li> <li>improve audio example to show how to stream to a file (#1017) (d45ed7f)</li> </ul>"},{"location":"changelog/#161-2023-12-22","title":"1.6.1 (2023-12-22)","text":"<p>Full Changelog: v1.6.0...v1.6.1</p>"},{"location":"changelog/#chores_11","title":"Chores","text":"<ul> <li>internal: add bin script (#1001) (99ffbda)</li> <li>internal: use ruff instead of black for formatting (#1008) (ceaf9a0)</li> </ul>"},{"location":"changelog/#160-2023-12-19","title":"1.6.0 (2023-12-19)","text":"<p>Full Changelog: v1.5.0...v1.6.0</p>"},{"location":"changelog/#features_8","title":"Features","text":"<ul> <li>api: add additional instructions for runs (#995) (7bf9b75)</li> </ul>"},{"location":"changelog/#chores_12","title":"Chores","text":"<ul> <li>cli: fix typo in completions (#985) (d1e9e8f)</li> <li>cli: fix typo in completions (#986) (626bc34)</li> <li>internal: fix binary response tests (#983) (cfb7e30)</li> <li>internal: fix typos (#993) (3b338a4)</li> <li>internal: minor utils restructuring (#992) (5ba576a)</li> <li>package: bump minimum typing-extensions to 4.7 (#994) (0c2da84)</li> <li>streaming: update constructor to use direct client names (#991) (6c3427d)</li> </ul>"},{"location":"changelog/#documentation_5","title":"Documentation","text":"<ul> <li>upgrade models in examples to latest version (#989) (cedd574)</li> </ul>"},{"location":"changelog/#150-2023-12-17","title":"1.5.0 (2023-12-17)","text":"<p>Full Changelog: v1.4.0...v1.5.0</p>"},{"location":"changelog/#features_9","title":"Features","text":"<ul> <li>api: add token logprobs to chat completions (#980) (f50e962)</li> </ul>"},{"location":"changelog/#chores_13","title":"Chores","text":"<ul> <li>ci: run release workflow once per day (#978) (215476a)</li> </ul>"},{"location":"changelog/#140-2023-12-15","title":"1.4.0 (2023-12-15)","text":"<p>Full Changelog: v1.3.9...v1.4.0</p>"},{"location":"changelog/#features_10","title":"Features","text":"<ul> <li>api: add optional <code>name</code> argument + improve docs (#972) (7972010)</li> </ul>"},{"location":"changelog/#139-2023-12-12","title":"1.3.9 (2023-12-12)","text":"<p>Full Changelog: v1.3.8...v1.3.9</p>"},{"location":"changelog/#documentation_6","title":"Documentation","text":"<ul> <li>improve README timeout comment (#964) (3c3ed5e)</li> <li>small Improvement in the async chat response code (#959) (fb9d0a3)</li> <li>small streaming readme improvements (#962) (f3be2e5)</li> </ul>"},{"location":"changelog/#refactors_2","title":"Refactors","text":"<ul> <li>client: simplify cleanup (#966) (5c138f4)</li> <li>simplify internal error handling (#968) (d187f6b)</li> </ul>"},{"location":"changelog/#138-2023-12-08","title":"1.3.8 (2023-12-08)","text":"<p>Full Changelog: v1.3.7...v1.3.8</p>"},{"location":"changelog/#bug-fixes_7","title":"Bug Fixes","text":"<ul> <li>avoid leaking memory when Client.with_options is used (#956) (e37ecca)</li> <li>errors: properly assign APIError.body (#949) (c70e194)</li> <li>pagination: use correct type hint for .object (#943) (23fe7ee)</li> </ul>"},{"location":"changelog/#chores_14","title":"Chores","text":"<ul> <li>internal: enable more lint rules (#945) (2c8add6)</li> <li>internal: reformat imports (#939) (ec65124)</li> <li>internal: reformat imports (#944) (5290639)</li> <li>internal: update formatting (#941) (8e5a156)</li> <li>package: lift anyio v4 restriction (#927) (be0438a)</li> </ul>"},{"location":"changelog/#documentation_7","title":"Documentation","text":"<ul> <li>fix typo in example (#950) (54f0ce0)</li> </ul>"},{"location":"changelog/#137-2023-12-01","title":"1.3.7 (2023-12-01)","text":"<p>Full Changelog: v1.3.6...v1.3.7</p>"},{"location":"changelog/#bug-fixes_8","title":"Bug Fixes","text":"<ul> <li>client: correct base_url setter implementation (#919) (135d9cf)</li> <li>client: don't cause crashes when inspecting the module (#897) (db029a5)</li> <li>client: ensure retried requests are closed (#902) (e025e6b)</li> </ul>"},{"location":"changelog/#chores_15","title":"Chores","text":"<ul> <li>internal: add tests for proxy change (#899) (71a13d0)</li> <li>internal: remove unused type var (#915) (4233bcd)</li> <li>internal: replace string concatenation with f-strings (#908) (663a8f6)</li> <li>internal: replace string concatenation with f-strings (#909) (caab767)</li> </ul>"},{"location":"changelog/#documentation_8","title":"Documentation","text":"<ul> <li>fix typo in readme (#904) (472cd44)</li> <li>readme: update example snippets (#907) (bbb648e)</li> </ul>"},{"location":"changelog/#136-2023-11-28","title":"1.3.6 (2023-11-28)","text":"<p>Full Changelog: v1.3.5...v1.3.6</p>"},{"location":"changelog/#bug-fixes_9","title":"Bug Fixes","text":"<ul> <li>client: add support for streaming binary responses (#866) (2470d25)</li> </ul>"},{"location":"changelog/#chores_16","title":"Chores","text":"<ul> <li>deps: bump mypy to v1.7.1 (#891) (11fcb2a)</li> <li>internal: send more detailed x-stainless headers (#877) (69e0549)</li> <li>revert binary streaming change (#875) (0a06d6a)</li> </ul>"},{"location":"changelog/#documentation_9","title":"Documentation","text":"<ul> <li>readme: minor updates (#894) (5458457)</li> <li>readme: update examples (#893) (124da87)</li> <li>update readme code snippet (#890) (c522f21)</li> </ul>"},{"location":"changelog/#135-2023-11-21","title":"1.3.5 (2023-11-21)","text":"<p>Full Changelog: v1.3.4...v1.3.5</p>"},{"location":"changelog/#bug-fixes_10","title":"Bug Fixes","text":"<ul> <li>azure: ensure custom options can be passed to copy (#858) (05ca0d6)</li> </ul>"},{"location":"changelog/#chores_17","title":"Chores","text":"<ul> <li>package: add license classifier (#826) (bec004d)</li> <li>package: add license classifier metadata (#860) (80dffb1)</li> </ul>"},{"location":"changelog/#134-2023-11-21","title":"1.3.4 (2023-11-21)","text":"<p>Full Changelog: v1.3.3...v1.3.4</p>"},{"location":"changelog/#bug-fixes_11","title":"Bug Fixes","text":"<ul> <li>client: attempt to parse unknown json content types (#854) (ba50466)</li> </ul>"},{"location":"changelog/#chores_18","title":"Chores","text":"<ul> <li>examples: fix static types in assistants example (#852) (5b47b2c)</li> </ul>"},{"location":"changelog/#133-2023-11-17","title":"1.3.3 (2023-11-17)","text":"<p>Full Changelog: v1.3.2...v1.3.3</p>"},{"location":"changelog/#chores_19","title":"Chores","text":"<ul> <li>internal: update type hint for helper function (#846) (9a5966c)</li> </ul>"},{"location":"changelog/#132-2023-11-16","title":"1.3.2 (2023-11-16)","text":"<p>Full Changelog: v1.3.1...v1.3.2</p>"},{"location":"changelog/#documentation_10","title":"Documentation","text":"<ul> <li>readme: minor updates (#841) (7273ad1)</li> </ul>"},{"location":"changelog/#131-2023-11-16","title":"1.3.1 (2023-11-16)","text":"<p>Full Changelog: v1.3.0...v1.3.1</p>"},{"location":"changelog/#chores_20","title":"Chores","text":"<ul> <li>internal: add publish script (#838) (3ea41bc)</li> </ul>"},{"location":"changelog/#130-2023-11-15","title":"1.3.0 (2023-11-15)","text":"<p>Full Changelog: v1.2.4...v1.3.0</p>"},{"location":"changelog/#features_11","title":"Features","text":"<ul> <li>api: add gpt-3.5-turbo-1106 (#813) (9bb3c4e)</li> <li>client: support reading the base url from an env variable (#829) (ca5fdc6)</li> </ul>"},{"location":"changelog/#bug-fixes_12","title":"Bug Fixes","text":"<ul> <li>breaking!: correct broken type names in moderation categories  (#811) (0bc211f)</li> </ul>"},{"location":"changelog/#chores_21","title":"Chores","text":"<ul> <li>fix typo in docs and add request header for function calls (#807) (cbef703)</li> <li>internal: fix devcontainer interpeter path (#810) (0acc07d)</li> </ul>"},{"location":"changelog/#documentation_11","title":"Documentation","text":"<ul> <li>add azure env vars (#814) (bd8e32a)</li> <li>fix code comment typo (#790) (8407a27)</li> <li>readme: fix broken azure_ad notebook link (#781) (3b92cdf)</li> </ul>"},{"location":"changelog/#124-2023-11-13","title":"1.2.4 (2023-11-13)","text":"<p>Full Changelog: v1.2.3...v1.2.4</p>"},{"location":"changelog/#bug-fixes_13","title":"Bug Fixes","text":"<ul> <li>client: retry if SSLWantReadError occurs in the async client (#804) (be82288)</li> </ul>"},{"location":"changelog/#123-2023-11-10","title":"1.2.3 (2023-11-10)","text":"<p>Full Changelog: v1.2.2...v1.2.3</p>"},{"location":"changelog/#bug-fixes_14","title":"Bug Fixes","text":"<ul> <li>cli/audio: file format detection failing for whisper (#733) (01079d6)</li> <li>client: correctly flush the stream response body (#771) (0d52731)</li> <li>client: serialise pydantic v1 default fields correctly in params (#776) (d4c49ad)</li> <li>models: mark unknown fields as set in pydantic v1 (#772) (ae032a1)</li> <li>prevent IndexError in fine-tunes CLI (#768) (42f1633)</li> </ul>"},{"location":"changelog/#documentation_12","title":"Documentation","text":"<ul> <li>reword package description (#764) (9ff10df)</li> </ul>"},{"location":"changelog/#122-2023-11-09","title":"1.2.2 (2023-11-09)","text":"<p>Full Changelog: v1.2.1...v1.2.2</p>"},{"location":"changelog/#bug-fixes_15","title":"Bug Fixes","text":"<ul> <li>client: correctly assign error properties (#759) (ef264d2)</li> </ul>"},{"location":"changelog/#documentation_13","title":"Documentation","text":"<ul> <li>readme: link to migration guide (#761) (ddde839)</li> </ul>"},{"location":"changelog/#121-2023-11-09","title":"1.2.1 (2023-11-09)","text":"<p>Full Changelog: v1.2.0...v1.2.1</p>"},{"location":"changelog/#documentation_14","title":"Documentation","text":"<ul> <li>readme: fix nested params example (#756) (ffbe5ec)</li> </ul>"},{"location":"changelog/#refactors_3","title":"Refactors","text":"<ul> <li>client: deprecate files.retrieve_content in favour of files.content (#753) (eea5bc1)</li> </ul>"},{"location":"changelog/#120-2023-11-08","title":"1.2.0 (2023-11-08)","text":"<p>Full Changelog: v1.1.2...v1.2.0</p>"},{"location":"changelog/#features_12","title":"Features","text":"<ul> <li>api: unify function types (#741) (ed16c4d)</li> <li>client: support passing chunk size for binary responses (#747) (c0c89b7)</li> </ul>"},{"location":"changelog/#bug-fixes_16","title":"Bug Fixes","text":"<ul> <li>api: update embedding response object type (#739) (29182c4)</li> <li>client: show a helpful error message if the v0 API is used (#743) (920567c)</li> </ul>"},{"location":"changelog/#chores_22","title":"Chores","text":"<ul> <li>internal: improve github devcontainer setup (#737) (0ac1abb)</li> </ul>"},{"location":"changelog/#refactors_4","title":"Refactors","text":"<ul> <li>api: rename FunctionObject to FunctionDefinition (#746) (1afd138)</li> </ul>"},{"location":"changelog/#112-2023-11-08","title":"1.1.2 (2023-11-08)","text":"<p>Full Changelog: v1.1.1...v1.1.2</p>"},{"location":"changelog/#bug-fixes_17","title":"Bug Fixes","text":"<ul> <li>api: accidentally required params, add new models &amp; other fixes (#729) (03c3e03)</li> <li>asssitant_deleted -&gt; assistant_deleted (#711) (287b51e)</li> </ul>"},{"location":"changelog/#chores_23","title":"Chores","text":"<ul> <li>docs: fix github links (#719) (0cda8ca)</li> <li>internal: fix some typos (#718) (894ad87)</li> </ul>"},{"location":"connect/","title":"Connect","text":"<p>To connect to the OpenAI API:</p> <ol> <li>Populate an <code>OPENAI_API_KEY</code> environment variable with your OpenAI API key</li> <li>Create a synchronous or asynchronous <code>OpenAI</code> client object.</li> </ol> <p>Tip</p> <p>To reduce the risk of committing your OpenAI API key to source control, you can use python-dotenv and add <code>OPENAI_API_KEY=\"YOUR_API_KEY_HERE\"</code> to your <code>.env</code> file.</p>"},{"location":"connect/#synchronous-client","title":"Synchronous client","text":"<p>Create an instance of the OpenAI client:</p> <pre><code>import os\nfrom openai import OpenAI\n\nclient = OpenAI(\n    api_key=os.environ.get(\"OPENAI_API_KEY\"), # (1)\n)\n\nchat_completion = client.chat.completions.create(\n    messages=[\n        {\n            \"role\": \"user\",\n            \"content\": \"Say this is a test\",\n        }\n    ],\n    model=\"gpt-3.5-turbo\",\n)\n</code></pre> <ol> <li>You can omit this parameter if the <code>OPENAI_API_KEY</code> environment variable is set and contains a valid key. By default, the OpenAI() client attempts to read the <code>OPENAI_API_KEY</code> env var upon instantiation.</li> </ol> <p>To stream responses from the API, include <code>stream=True</code> in your call to Completions.create() method call:</p> <pre><code>from openai import OpenAI\n\nclient = OpenAI()\n\nstream = client.chat.completions.create(\n    model=\"gpt-4\",\n    messages=[{\"role\": \"user\", \"content\": \"Say this is a test\"}],\n    stream=True, # (1)\n)\nfor chunk in stream:\n    print(chunk.choices[0].delta.content or \"\", end=\"\")\n</code></pre> <ol> <li> This enables response streaming through Server Side Events (SSE).</li> </ol>"},{"location":"connect/#asynchronous-client","title":"Asynchronous client","text":"<p>Create an instance of the AsyncOpenAI client and <code>await</code> each API call. Functionality between the synchronous and asynchronous clients is otherwise identical.</p> <pre><code>import os\nimport asyncio\nfrom openai import AsyncOpenAI\n\nclient = AsyncOpenAI(\n    api_key=os.environ.get(\"OPENAI_API_KEY\"), # (1)\n)\n\n\nasync def main() -&gt; None:\n    chat_completion = await client.chat.completions.create(\n        messages=[\n            {\n                \"role\": \"user\",\n                \"content\": \"Say this is a test\",\n            }\n        ],\n        model=\"gpt-3.5-turbo\",\n    )\n\n\nasyncio.run(main())\n</code></pre> <ol> <li>You can omit this parameter if the <code>OPENAI_API_KEY</code> environment variable is set and contains a valid key. By default, the AsyncOpenAI() client attempts to read the <code>OPENAI_API_KEY</code> env var upon instantiation.</li> </ol> <p>You can enable response streaming in the async client by including <code>stream=True</code> to the AsyncCompletions.create() method:</p> <pre><code>from openai import AsyncOpenAI\n\nclient = AsyncOpenAI()\n\n\nasync def main():\n    stream = await client.chat.completions.create(\n        model=\"gpt-4\",\n        messages=[{\"role\": \"user\", \"content\": \"Say this is a test\"}],\n        stream=True, # (1)\n    )\n    async for chunk in stream:\n        print(chunk.choices[0].delta.content or \"\", end=\"\")\n\n\nasyncio.run(main())\n</code></pre> <ol> <li> This enables response streaming through Server Side Events (SSE).</li> </ol>"},{"location":"connect/#module-level-global-client","title":"Module-level global client","text":"<p>Similar to pre-v1 versions of the library, there is also a module-level client available for use in REPLs, notebooks, and other scenarios requiring quick \"local loop\" iteration.</p> <p>Do NOT use the module-level global client in production application code. Instead, create instances of OpenAI or AsyncOpenAI client objects as described earlier rather than relying on the global client.</p> <pre><code># WARNING: Use this client instantiation technique **only** in REPLs, notebooks,\n#          or other scenarios requiring quick local-loop iteration.\n\nimport openai\n\n# optional; defaults to `os.environ['OPENAI_API_KEY']`\nopenai.api_key = '...'\n\n# all client options can be configured just like the `OpenAI` instantiation counterpart\nopenai.base_url = \"https://...\"\nopenai.default_headers = {\"x-foo\": \"true\"}\n\ncompletion = openai.chat.completions.create(\n    model=\"gpt-4\",\n    messages=[\n        {\n            \"role\": \"user\",\n            \"content\": \"How do I output all files in a directory using Python?\",\n        },\n    ],\n)\nprint(completion.choices[0].message.content)\n</code></pre> <p>We recommend you avoid using this module-level client your application code because:</p> <ul> <li>It can be difficult to reason about where client options are configured.</li> <li>It's impossible to change certain client options without causing the potential for race conditions.</li> <li>It's harder to mock for testing purposes.</li> <li>It's impossible to control cleanup of network connections.</li> </ul>"},{"location":"connect/#examples","title":"Examples","text":"<pre><code>#!/usr/bin/env -S poetry run python\n\nfrom openai import OpenAI\n\n# gets API Key from environment variable OPENAI_API_KEY\nclient = OpenAI()\n\n# Non-streaming:\nprint(\"----- standard request -----\")\ncompletion = client.chat.completions.create(\n    model=\"gpt-4\",\n    messages=[\n        {\n            \"role\": \"user\",\n            \"content\": \"Say this is a test\",\n        },\n    ],\n)\nprint(completion.choices[0].message.content)\n\n# Streaming:\nprint(\"----- streaming request -----\")\nstream = client.chat.completions.create(\n    model=\"gpt-4\",\n    messages=[\n        {\n            \"role\": \"user\",\n            \"content\": \"How do I output all files in a directory using Python?\",\n        },\n    ],\n    stream=True,\n)\nfor chunk in stream:\n    if not chunk.choices:\n        continue\n\n    print(chunk.choices[0].delta.content, end=\"\")\nprint()\n</code></pre>"},{"location":"debugging/","title":"Logging and debugging","text":"<p>We use the standard library <code>logging</code> module.</p> <p>You can enable logging by setting the environment variable <code>OPENAI_LOG</code> to <code>debug</code>.</p> <pre><code>$ export OPENAI_LOG=debug\n</code></pre>"},{"location":"debugging/#how-to-tell-whether-none-means-null-or-missing","title":"How to tell whether <code>None</code> means <code>null</code> or missing","text":"<p>In an API response, a field may be explicitly <code>null</code>, or missing entirely; in either case, its value is <code>None</code> in this library. You can differentiate the two cases with <code>.model_fields_set</code>:</p> <pre><code>if response.my_field is None:\n  if 'my_field' not in response.model_fields_set:\n    print('Got json like {}, without a \"my_field\" key present at all.')\n  else:\n    print('Got json like {\"my_field\": null}.')\n</code></pre>"},{"location":"debugging/#accessing-raw-response-data-headers","title":"Accessing raw response data (headers)","text":"<p>The \"raw\" Response object can be accessed by prefixing <code>.with_raw_response.</code> to any HTTP method call, for example:</p> <pre><code>from openai import OpenAI\n\nclient = OpenAI()\nresponse = client.chat.completions.with_raw_response.create(\n    messages=[{\n        \"role\": \"user\",\n        \"content\": \"Say this is a test\",\n    }],\n    model=\"gpt-3.5-turbo\",\n)\nprint(response.headers.get('X-My-Header'))\n\ncompletion = response.parse()  # get the object that `chat.completions.create()` would have returned\nprint(completion)\n</code></pre> <p>These methods return an <code>LegacyAPIResponse</code> object. This is a legacy class as we're changing it slightly in the next major version.</p> <p>For the sync client this will mostly be the same with the exception of <code>content</code> &amp; <code>text</code> will be methods instead of properties. In the async client, all methods will be async.</p> <p>A migration script will be provided &amp; the migration in general should be smooth.</p>"},{"location":"debugging/#with_streaming_response","title":"<code>.with_streaming_response</code>","text":"<p>The above interface eagerly reads the full response body when you make the request, which may not always be what you want.</p> <p>To stream the response body, use <code>.with_streaming_response</code> instead, which requires a context manager and only reads the response body once you call <code>.read()</code>, <code>.text()</code>, <code>.json()</code>, <code>.iter_bytes()</code>, <code>.iter_text()</code>, <code>.iter_lines()</code> or <code>.parse()</code>. In the async client, these are async methods.</p> <p>As such, <code>.with_streaming_response</code> methods return a different <code>APIResponse</code> object, and the async client returns an <code>AsyncAPIResponse</code> object.</p> <pre><code>with client.chat.completions.with_streaming_response.create(\n    messages=[\n        {\n            \"role\": \"user\",\n            \"content\": \"Say this is a test\",\n        }\n    ],\n    model=\"gpt-3.5-turbo\",\n) as response:\n    print(response.headers.get(\"X-My-Header\"))\n\n    for line in response.iter_lines():\n        print(line)\n</code></pre> <p>The context manager is required so that the response will reliably be closed.</p>"},{"location":"error-handling/","title":"Error handling","text":"<p>When the library is unable to connect to the API (for example, due to network connection problems or a timeout), a subclass of <code>openai.APIConnectionError</code> is raised.</p> <p>When the API returns a non-success status code (that is, 4xx or 5xx response), a subclass of <code>openai.APIStatusError</code> is raised, containing <code>status_code</code> and <code>response</code> properties.</p> <p>All errors inherit from <code>openai.APIError</code>.</p> <pre><code>import openai\nfrom openai import OpenAI\n\nclient = OpenAI()\n\ntry:\n    client.fine_tuning.jobs.create(\n        model=\"gpt-3.5-turbo\",\n        training_file=\"file-abc123\",\n    )\nexcept openai.APIConnectionError as e:\n    print(\"The server could not be reached\")\n    print(e.__cause__)  # an underlying Exception, likely raised within httpx.\nexcept openai.RateLimitError as e:\n    print(\"A 429 status code was received; we should back off a bit.\")\nexcept openai.APIStatusError as e:\n    print(\"Another non-200-range status code was received\")\n    print(e.status_code)\n    print(e.response)\n</code></pre> <p>Error codes are as followed:</p> Status Code Error Type 400 <code>BadRequestError</code> 401 <code>AuthenticationError</code> 403 <code>PermissionDeniedError</code> 404 <code>NotFoundError</code> 409 <code>ConflictError</code> 422 <code>UnprocessableEntityError</code> 429 <code>RateLimitError</code> &gt;=500 <code>InternalServerError</code> N/A <code>APIConnectionError</code>"},{"location":"error-handling/#retries","title":"Retries","text":"<p>Certain errors are automatically retried 2 times by default, with a short exponential backoff.</p> <p>Connection errors (for example, due to a network connectivity problem), 408 Request Timeout, 409 Conflict, 429 Rate Limit, and &gt;=500 Internal errors are all retried by default.</p> <p>You can use the <code>max_retries</code> option to configure or disable retry settings:</p> <pre><code>from openai import OpenAI\n\n# Configure the default for all requests:\nclient = OpenAI(\n    # default is 2\n    max_retries=0,\n)\n\n# Or, configure per-request:\nclient.with_options(max_retries=5).chat.completions.create(\n    messages=[\n        {\n            \"role\": \"user\",\n            \"content\": \"How can I get the name of the current day in Node.js?\",\n        }\n    ],\n    model=\"gpt-3.5-turbo\",\n)\n</code></pre>"},{"location":"error-handling/#timeouts","title":"Timeouts","text":"<p>By default requests time out after 10 minutes. You can configure this with a <code>timeout</code> option, which accepts a float or an <code>httpx.Timeout</code> object:</p> <pre><code>from openai import OpenAI\n\n# Configure the default for all requests:\nclient = OpenAI(\n    # 20 seconds (default is 10 minutes)\n    timeout=20.0,\n)\n\n# More granular control:\nclient = OpenAI(\n    timeout=httpx.Timeout(60.0, read=5.0, write=10.0, connect=2.0),\n)\n\n# Override per-request:\nclient.with_options(timeout=5 * 1000).chat.completions.create(\n    messages=[\n        {\n            \"role\": \"user\",\n            \"content\": \"How can I list all files in a directory using Python?\",\n        }\n    ],\n    model=\"gpt-3.5-turbo\",\n)\n</code></pre> <p>On timeout, an <code>APITimeoutError</code> is thrown.</p> <p>Note that requests that time out are retried twice by default.</p>"},{"location":"get_started/","title":"Install","text":"Info <p>The pages in this Get started section are adapted from the sections in the README.md in the upstream repository.</p> <p>The OpenAI Python library provides access to the OpenAI REST API in Python applications. It includes type definitions for all request params and response fields and has clients for both synchronous and asynchronous operations powered by httpx.</p> <p>The OpenAI Python library is generated from OpenAI's OpenAPI specification with Stainless.</p>"},{"location":"get_started/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.7+</li> <li>OpenAI API key</li> </ul>"},{"location":"get_started/#install-the-package","title":"Install the package","text":"<p>You can the openai package from PyPi with <code>pip</code>:</p> <pre><code># Install the package\npip install openai\n</code></pre>"},{"location":"get_started/#migrate-from-earlier-versions","title":"Migrate from earlier versions","text":"<p>Released on November 6th 2023, the OpenAI Python library was rewritten for version <code>1.0.0</code>.</p> <p>If your project used a pre-v1 version of the library, see the v1 migration guide for information and scripts that can help you update your code.</p>"},{"location":"request-response/","title":"Request and response types","text":"<p>Nested request parameters are Python TypedDicts.</p> <p>For example, the user message in the following <code>chat.completions.create()</code> request is a <code>ChatCompletionUserMessageParam</code>, which has a base type of <code>TypedDict</code>:</p> <pre><code>from openai import OpenAI\n\nclient = OpenAI()\n\ncompletion = client.chat.completions.create(\n    messages=[\n        {\n            \"role\": \"user\",\n            \"content\": \"Can you generate an example JSON object describing a fruit?\",\n        }\n    ],\n    model=\"gpt-3.5-turbo-1106\",\n    response_format={\"type\": \"json_object\"},\n)\n</code></pre>"},{"location":"request-response/#file-upload-request-types","title":"File upload request types","text":"<p>Request parameters that correspond to file uploads can be passed as <code>bytes</code>, a <code>PathLike</code> instance, or a tuple of <code>(filename, contents, media type)</code>.</p> <pre><code>from pathlib import Path\nfrom openai import OpenAI\n\nclient = OpenAI()\n\nclient.files.create(\n    file=Path(\"input.jsonl\"),\n    purpose=\"fine-tune\",\n)\n</code></pre> <p>The async client uses the same interface. If you pass a <code>PathLike</code> instance, the file contents will be read asynchronously automatically.</p>"},{"location":"request-response/#response-types","title":"Response types","text":"<p>Responses are Pydantic models that include their helper methods for things like:</p> <ul> <li>Serializing the object to JSON: <code>example_response_object.model_dump_json</code><code>(indent=2, exclude_unset=True)</code></li> <li>Converting the object to a dictionary: <code>example_response_object.model_dump</code><code>(exclude_unset=True)</code></li> </ul> <p>Tip</p> <p>Typed requests and responses enable type checking, autocompletion, and hover-help documentation in editors that support those features. In Visual Studio Code, for example, you can enable type checking in Pylance by setting <code>python.analysis.typeCheckingMode</code> to <code>basic</code> as described in that article's Settings and Customization section.</p>"},{"location":"examples/","title":"Examples","text":"<p>The following examples are taken from the <code>examples/</code> directory in the root of the openai/openai-python repository.</p> <ul> <li>assistant.py</li> <li>async_demo.py</li> <li>audio.py</li> <li>azure.py</li> <li>azure_ad.py</li> <li>demo.py</li> <li>module_client.py</li> <li>picture.py</li> <li>streaming.py</li> </ul>"},{"location":"examples/assistant/","title":"assistant.py","text":"<pre><code>import time\n\nimport openai\n\n# gets API Key from environment variable OPENAI_API_KEY\nclient = openai.OpenAI()\n\nassistant = client.beta.assistants.create(\n    name=\"Math Tutor\",\n    instructions=\"You are a personal math tutor. Write and run code to answer math questions.\",\n    tools=[{\"type\": \"code_interpreter\"}],\n    model=\"gpt-4-1106-preview\",\n)\n\nthread = client.beta.threads.create()\n\nmessage = client.beta.threads.messages.create(\n    thread_id=thread.id,\n    role=\"user\",\n    content=\"I need to solve the equation `3x + 11 = 14`. Can you help me?\",\n)\n\nrun = client.beta.threads.runs.create(\n    thread_id=thread.id,\n    assistant_id=assistant.id,\n    instructions=\"Please address the user as Jane Doe. The user has a premium account.\",\n)\n\nprint(\"checking assistant status. \")\nwhile True:\n    run = client.beta.threads.runs.retrieve(thread_id=thread.id, run_id=run.id)\n\n    if run.status == \"completed\":\n        print(\"done!\")\n        messages = client.beta.threads.messages.list(thread_id=thread.id)\n\n        print(\"messages: \")\n        for message in messages:\n            assert message.content[0].type == \"text\"\n            print({\"role\": message.role, \"message\": message.content[0].text.value})\n\n        client.beta.assistants.delete(assistant.id)\n\n        break\n    else:\n        print(\"in progress...\")\n        time.sleep(5)\n</code></pre>"},{"location":"examples/async_demo/","title":"async_demo.py","text":"<pre><code>#!/usr/bin/env -S poetry run python\n\nimport asyncio\n\nfrom openai import AsyncOpenAI\n\n# gets API Key from environment variable OPENAI_API_KEY\nclient = AsyncOpenAI()\n\n\nasync def main() -&gt; None:\n    stream = await client.completions.create(\n        model=\"gpt-3.5-turbo-instruct\",\n        prompt=\"Say this is a test\",\n        stream=True,\n    )\n    async for completion in stream:\n        print(completion.choices[0].text, end=\"\")\n    print()\n\n\nasyncio.run(main())\n</code></pre>"},{"location":"examples/audio/","title":"audio.py","text":"<pre><code>#!/usr/bin/env rye run python\n\nimport time\nfrom pathlib import Path\n\nfrom openai import OpenAI\n\n# gets OPENAI_API_KEY from your environment variables\nopenai = OpenAI()\n\nspeech_file_path = Path(__file__).parent / \"speech.mp3\"\n\n\ndef main() -&gt; None:\n    stream_to_speakers()\n\n    # Create text-to-speech audio file\n    with openai.audio.speech.with_streaming_response.create(\n        model=\"tts-1\",\n        voice=\"alloy\",\n        input=\"the quick brown fox jumped over the lazy dogs\",\n    ) as response:\n        response.stream_to_file(speech_file_path)\n\n    # Create transcription from audio file\n    transcription = openai.audio.transcriptions.create(\n        model=\"whisper-1\",\n        file=speech_file_path,\n    )\n    print(transcription.text)\n\n    # Create translation from audio file\n    translation = openai.audio.translations.create(\n        model=\"whisper-1\",\n        file=speech_file_path,\n    )\n    print(translation.text)\n\n\ndef stream_to_speakers() -&gt; None:\n    import pyaudio\n\n    player_stream = pyaudio.PyAudio().open(format=pyaudio.paInt16, channels=1, rate=24000, output=True)\n\n    start_time = time.time()\n\n    with openai.audio.speech.with_streaming_response.create(\n        model=\"tts-1\",\n        voice=\"alloy\",\n        response_format=\"pcm\",  # similar to WAV, but without a header chunk at the start.\n        input=\"\"\"I see skies of blue and clouds of white\n                The bright blessed days, the dark sacred nights\n                And I think to myself\n                What a wonderful world\"\"\",\n    ) as response:\n        print(f\"Time to first byte: {int((time.time() - start_time) * 1000)}ms\")\n        for chunk in response.iter_bytes(chunk_size=1024):\n            player_stream.write(chunk)\n\n    print(f\"Done in {int((time.time() - start_time) * 1000)}ms.\")\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>"},{"location":"examples/azure/","title":"azure.py","text":"<pre><code>from openai import AzureOpenAI\n\n# may change in the future\n# https://learn.microsoft.com/en-us/azure/ai-services/openai/reference#rest-api-versioning\napi_version = \"2023-07-01-preview\"\n\n# gets the API Key from environment variable AZURE_OPENAI_API_KEY\nclient = AzureOpenAI(\n    api_version=api_version,\n    # https://learn.microsoft.com/en-us/azure/cognitive-services/openai/how-to/create-resource?pivots=web-portal#create-a-resource\n    azure_endpoint=\"https://example-endpoint.openai.azure.com\",\n)\n\ncompletion = client.chat.completions.create(\n    model=\"deployment-name\",  # e.g. gpt-35-instant\n    messages=[\n        {\n            \"role\": \"user\",\n            \"content\": \"How do I output all files in a directory using Python?\",\n        },\n    ],\n)\nprint(completion.model_dump_json(indent=2))\n\n\ndeployment_client = AzureOpenAI(\n    api_version=api_version,\n    # https://learn.microsoft.com/en-us/azure/cognitive-services/openai/how-to/create-resource?pivots=web-portal#create-a-resource\n    azure_endpoint=\"https://example-resource.azure.openai.com/\",\n    # Navigate to the Azure OpenAI Studio to deploy a model.\n    azure_deployment=\"deployment-name\",  # e.g. gpt-35-instant\n)\n\ncompletion = deployment_client.chat.completions.create(\n    model=\"&lt;ignored&gt;\",\n    messages=[\n        {\n            \"role\": \"user\",\n            \"content\": \"How do I output all files in a directory using Python?\",\n        },\n    ],\n)\nprint(completion.model_dump_json(indent=2))\n</code></pre>"},{"location":"examples/azure_ad/","title":"azure_ad.py","text":"<pre><code>from azure.identity import DefaultAzureCredential, get_bearer_token_provider\n\nfrom openai import AzureOpenAI\n\ntoken_provider = get_bearer_token_provider(DefaultAzureCredential(), \"https://cognitiveservices.azure.com/.default\")\n\n\n# may change in the future\n# https://learn.microsoft.com/en-us/azure/ai-services/openai/reference#rest-api-versioning\napi_version = \"2023-07-01-preview\"\n\n# https://learn.microsoft.com/en-us/azure/cognitive-services/openai/how-to/create-resource?pivots=web-portal#create-a-resource\nendpoint = \"https://my-resource.openai.azure.com\"\n\nclient = AzureOpenAI(\n    api_version=api_version,\n    azure_endpoint=endpoint,\n    azure_ad_token_provider=token_provider,\n)\n\ncompletion = client.chat.completions.create(\n    model=\"deployment-name\",  # e.g. gpt-35-instant\n    messages=[\n        {\n            \"role\": \"user\",\n            \"content\": \"How do I output all files in a directory using Python?\",\n        },\n    ],\n)\nprint(completion.model_dump_json(indent=2))\n</code></pre>"},{"location":"examples/demo/","title":"demo.py","text":"<pre><code>#!/usr/bin/env -S poetry run python\n\nfrom openai import OpenAI\n\n# gets API Key from environment variable OPENAI_API_KEY\nclient = OpenAI()\n\n# Non-streaming:\nprint(\"----- standard request -----\")\ncompletion = client.chat.completions.create(\n    model=\"gpt-4\",\n    messages=[\n        {\n            \"role\": \"user\",\n            \"content\": \"Say this is a test\",\n        },\n    ],\n)\nprint(completion.choices[0].message.content)\n\n# Streaming:\nprint(\"----- streaming request -----\")\nstream = client.chat.completions.create(\n    model=\"gpt-4\",\n    messages=[\n        {\n            \"role\": \"user\",\n            \"content\": \"How do I output all files in a directory using Python?\",\n        },\n    ],\n    stream=True,\n)\nfor chunk in stream:\n    if not chunk.choices:\n        continue\n\n    print(chunk.choices[0].delta.content, end=\"\")\nprint()\n</code></pre>"},{"location":"examples/module_client/","title":"module_client.py","text":"<pre><code>import openai\n\n# will default to `os.environ['OPENAI_API_KEY']` if not explicitly set\nopenai.api_key = \"...\"\n\n# all client options can be configured just like the `OpenAI` instantiation counterpart\nopenai.base_url = \"https://...\"\nopenai.default_headers = {\"x-foo\": \"true\"}\n\n# all API calls work in the exact same fashion as well\nstream = openai.chat.completions.create(\n    model=\"gpt-4\",\n    messages=[\n        {\n            \"role\": \"user\",\n            \"content\": \"How do I output all files in a directory using Python?\",\n        },\n    ],\n    stream=True,\n)\n\nfor chunk in stream:\n    print(chunk.choices[0].delta.content or \"\", end=\"\", flush=True)\n\nprint()\n</code></pre>"},{"location":"examples/picture/","title":"picture.py","text":"<pre><code>#!/usr/bin/env python\n\nfrom openai import OpenAI\n\n# gets OPENAI_API_KEY from your environment variables\nopenai = OpenAI()\n\nprompt = \"An astronaut lounging in a tropical resort in space, pixel art\"\nmodel = \"dall-e-3\"\n\n\ndef main() -&gt; None:\n    # Generate an image based on the prompt\n    response = openai.images.generate(prompt=prompt, model=model)\n\n    # Prints response containing a URL link to image\n    print(response)\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>"},{"location":"examples/streaming/","title":"streaming.py","text":"<pre><code>#!/usr/bin/env -S poetry run python\n\nimport asyncio\n\nfrom openai import OpenAI, AsyncOpenAI\n\n# This script assumes you have the OPENAI_API_KEY environment variable set to a valid OpenAI API key.\n#\n# You can run this script from the root directory like so:\n# `python examples/streaming.py`\n\n\ndef sync_main() -&gt; None:\n    client = OpenAI()\n    response = client.completions.create(\n        model=\"gpt-3.5-turbo-instruct\",\n        prompt=\"1,2,3,\",\n        max_tokens=5,\n        temperature=0,\n        stream=True,\n    )\n\n    # You can manually control iteration over the response\n    first = next(response)\n    print(f\"got response data: {first.model_dump_json(indent=2)}\")\n\n    # Or you could automatically iterate through all of data.\n    # Note that the for loop will not exit until *all* of the data has been processed.\n    for data in response:\n        print(data.model_dump_json())\n\n\nasync def async_main() -&gt; None:\n    client = AsyncOpenAI()\n    response = await client.completions.create(\n        model=\"gpt-3.5-turbo-instruct\",\n        prompt=\"1,2,3,\",\n        max_tokens=5,\n        temperature=0,\n        stream=True,\n    )\n\n    # You can manually control iteration over the response.\n    # In Python 3.10+ you can also use the `await anext(response)` builtin instead\n    first = await response.__anext__()\n    print(f\"got response data: {first.model_dump_json(indent=2)}\")\n\n    # Or you could automatically iterate through all of data.\n    # Note that the for loop will not exit until *all* of the data has been processed.\n    async for data in response:\n        print(data.model_dump_json())\n\n\nsync_main()\n\nasyncio.run(async_main())\n</code></pre>"},{"location":"reference/","title":"openai","text":"<p>The openai package is the core library to install in Python projects that need to call the OpenAI REST API. It inclues modules for working with OpenAI resources that provide access to its AI models, including large language models (LLMs) like GPT-4 and models for working with images and audio. The <code>openai</code> package provides both synchronous and asynchronous API clients, options to configure their behavior, and modules that provide Python code with an API surface to interact with the OpenAI platform.</p> <p>To get started, read the submodule descriptions in <code>resources</code> to determine which best fits your project. For example, the <code>resources.chat</code> submodule description indicates it's a good fit for conversational chat-style interactions with an LLM like GPT-4 Turbo. Or, maybe you need the <code>resources.audio</code> module to perform audio transcription, translation, and speech synthesis in your app.</p> <p>Once you've determined the resource to use, create an <code>OpenAI</code> or <code>AsyncOpenAI</code> client instance and access the instance attribute for that resource on the client object. For example, if you instantiate an <code>OpenAI</code> client object named <code>client</code>, you'd access the <code>OpenAI.chat</code> instance attribute:</p> <pre><code>from openai import OpenAI\n\n# Reads API key from OPENAI_API_KEY environment variable\nclient = OpenAI()\n\n# Use the `chat` resource to interact with the OpenAI chat completions endpoint\ncompletion = client.chat.completions.create(\n    model=\"gpt-4\",\n    messages=[\n        {\n            \"role\": \"user\",\n            \"content\": \"Say this is a test\",\n        },\n    ],\n)\nprint(completion.choices[0].message.content)\n</code></pre> <p>For more information about the REST API this package talks to or to find client libraries for other programming languages, see:</p> <ul> <li>REST API reference documentation for the OpenAPI REST API (platform.openai.com)</li> <li>OpenAPI Description (OAD) file for the OpenAPI REST API (GitHub)</li> <li>More client libraries for the OpenAI API (platform.openai.com)</li> </ul> MODULE DESCRIPTION <code>cli</code> <code>pagination</code> <code>resources</code> <p>The <code>resources</code> module aggregates classes and functions for interacting with the OpenAI API into several submodules, each representing a specific resource or feature of the API.</p> <p>The submodules' classes mirror the structure of the API's endpoints and offer synchronous and asynchronous communication with the API.</p> <p>Each resource is accessible as an attribute on the <code>OpenAI</code> and <code>AsyncOpenAI</code> clients. To work with a resource, initialize an instance of a client and then access the resource as an attribute on the client instance. For example, to work with the <code>chat</code> resource, create an instance of the <code>OpenAI</code> client and access the attributes and methods on <code>your_client_instance.chat</code>.</p> <code>types</code> <code>version</code> CLASS DESCRIPTION <code>APIConnectionError</code> <code>APIError</code> <code>APIResponseValidationError</code> <code>APIStatusError</code> <p>Raised when an API response has a status code of 4xx or 5xx.</p> <code>APITimeoutError</code> <code>AsyncOpenAI</code> <code>AsyncStream</code> <p>Provides the core interface to iterate over an asynchronous stream response.</p> <code>AuthenticationError</code> <code>BadRequestError</code> <code>BaseModel</code> <code>ConflictError</code> <code>InternalServerError</code> <code>NotFoundError</code> <code>NotGiven</code> <p>A sentinel singleton class used to distinguish omitted keyword arguments</p> <code>OpenAI</code> <p>Primary synchronous client interface for interacting with the services (resources) provided by the OpenAI API.</p> <code>OpenAIError</code> <code>PermissionDeniedError</code> <code>RateLimitError</code> <code>RequestOptions</code> <code>Stream</code> <p>Provides the core interface to iterate over a synchronous stream response.</p> <code>UnprocessableEntityError</code> FUNCTION DESCRIPTION <code>file_from_path</code> ATTRIBUTE DESCRIPTION <code>AsyncClient</code> <p> </p> <code>Client</code> <p> </p> <code>NOT_GIVEN</code> <p> </p> <code>NoneType</code> <p> TYPE: <code>Type[None]</code> </p> <code>ProxiesTypes</code> <p> </p> <code>Transport</code> <p> </p> <code>api_key</code> <p> TYPE: <code>str | None</code> </p> <code>api_type</code> <p> TYPE: <code>_ApiType | None</code> </p> <code>api_version</code> <p> TYPE: <code>str | None</code> </p> <code>azure_ad_token</code> <p> TYPE: <code>str | None</code> </p> <code>azure_ad_token_provider</code> <p> TYPE: <code>AzureADTokenProvider | None</code> </p> <code>azure_endpoint</code> <p> TYPE: <code>str | None</code> </p> <code>base_url</code> <p> TYPE: <code>str | URL | None</code> </p> <code>default_headers</code> <p> TYPE: <code>Mapping[str, str] | None</code> </p> <code>default_query</code> <p> TYPE: <code>Mapping[str, object] | None</code> </p> <code>http_client</code> <p> TYPE: <code>Client | None</code> </p> <code>max_retries</code> <p> TYPE: <code>int</code> </p> <code>organization</code> <p> TYPE: <code>str | None</code> </p> <code>timeout</code> <p> TYPE: <code>float | Timeout | None</code> </p>"},{"location":"reference/#src.openai.AsyncClient","title":"AsyncClient  <code>module-attribute</code>","text":"<pre><code>AsyncClient = AsyncOpenAI\n</code></pre>"},{"location":"reference/#src.openai.Client","title":"Client  <code>module-attribute</code>","text":"<pre><code>Client = OpenAI\n</code></pre>"},{"location":"reference/#src.openai.NOT_GIVEN","title":"NOT_GIVEN  <code>module-attribute</code>","text":"<pre><code>NOT_GIVEN = NotGiven()\n</code></pre>"},{"location":"reference/#src.openai.NoneType","title":"NoneType  <code>module-attribute</code>","text":"<pre><code>NoneType: Type[None]\n</code></pre>"},{"location":"reference/#src.openai.ProxiesTypes","title":"ProxiesTypes  <code>module-attribute</code>","text":"<pre><code>ProxiesTypes = Union[str, Proxy, ProxiesDict]\n</code></pre>"},{"location":"reference/#src.openai.Transport","title":"Transport  <code>module-attribute</code>","text":"<pre><code>Transport = BaseTransport\n</code></pre>"},{"location":"reference/#src.openai.api_key","title":"api_key  <code>module-attribute</code>","text":"<pre><code>api_key: str | None = None\n</code></pre>"},{"location":"reference/#src.openai.api_type","title":"api_type  <code>module-attribute</code>","text":"<pre><code>api_type: _ApiType | None = cast(\n    _ApiType, get(\"OPENAI_API_TYPE\")\n)\n</code></pre>"},{"location":"reference/#src.openai.api_version","title":"api_version  <code>module-attribute</code>","text":"<pre><code>api_version: str | None = get('OPENAI_API_VERSION')\n</code></pre>"},{"location":"reference/#src.openai.azure_ad_token","title":"azure_ad_token  <code>module-attribute</code>","text":"<pre><code>azure_ad_token: str | None = get('AZURE_OPENAI_AD_TOKEN')\n</code></pre>"},{"location":"reference/#src.openai.azure_ad_token_provider","title":"azure_ad_token_provider  <code>module-attribute</code>","text":"<pre><code>azure_ad_token_provider: AzureADTokenProvider | None = None\n</code></pre>"},{"location":"reference/#src.openai.azure_endpoint","title":"azure_endpoint  <code>module-attribute</code>","text":"<pre><code>azure_endpoint: str | None = get('AZURE_OPENAI_ENDPOINT')\n</code></pre>"},{"location":"reference/#src.openai.base_url","title":"base_url  <code>module-attribute</code>","text":"<pre><code>base_url: str | URL | None = None\n</code></pre>"},{"location":"reference/#src.openai.default_headers","title":"default_headers  <code>module-attribute</code>","text":"<pre><code>default_headers: Mapping[str, str] | None = None\n</code></pre>"},{"location":"reference/#src.openai.default_query","title":"default_query  <code>module-attribute</code>","text":"<pre><code>default_query: Mapping[str, object] | None = None\n</code></pre>"},{"location":"reference/#src.openai.http_client","title":"http_client  <code>module-attribute</code>","text":"<pre><code>http_client: Client | None = None\n</code></pre>"},{"location":"reference/#src.openai.max_retries","title":"max_retries  <code>module-attribute</code>","text":"<pre><code>max_retries: int = DEFAULT_MAX_RETRIES\n</code></pre>"},{"location":"reference/#src.openai.organization","title":"organization  <code>module-attribute</code>","text":"<pre><code>organization: str | None = None\n</code></pre>"},{"location":"reference/#src.openai.timeout","title":"timeout  <code>module-attribute</code>","text":"<pre><code>timeout: float | Timeout | None = DEFAULT_TIMEOUT\n</code></pre>"},{"location":"reference/#src.openai.APIConnectionError","title":"APIConnectionError","text":"<pre><code>APIConnectionError(\n    *, message: str = \"Connection error.\", request: Request\n)\n</code></pre>"},{"location":"reference/#src.openai.APIError","title":"APIError","text":"<pre><code>APIError(\n    message: str, request: Request, *, body: object | None\n)\n</code></pre> ATTRIBUTE DESCRIPTION <code>body</code> <p>The API response body.</p> <p> TYPE: <code>object | None</code> </p> <code>code</code> <p> TYPE: <code>Optional[str]</code> </p> <code>message</code> <p> TYPE: <code>str</code> </p> <code>param</code> <p> TYPE: <code>Optional[str]</code> </p> <code>request</code> <p> TYPE: <code>Request</code> </p> <code>type</code> <p> TYPE: <code>Optional[str]</code> </p>"},{"location":"reference/#src.openai.APIError.body","title":"body  <code>instance-attribute</code>","text":"<pre><code>body: object | None = body\n</code></pre> <p>The API response body.</p> <p>If the API responded with a valid JSON structure then this property will be the decoded result.</p> <p>If it isn't a valid JSON structure then this will be the raw response.</p> <p>If there was no response associated with this error then it will be <code>None</code>.</p>"},{"location":"reference/#src.openai.APIError.code","title":"code  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>code: Optional[str] = None\n</code></pre>"},{"location":"reference/#src.openai.APIError.message","title":"message  <code>instance-attribute</code>","text":"<pre><code>message: str = message\n</code></pre>"},{"location":"reference/#src.openai.APIError.param","title":"param  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>param: Optional[str] = None\n</code></pre>"},{"location":"reference/#src.openai.APIError.request","title":"request  <code>instance-attribute</code>","text":"<pre><code>request: Request = request\n</code></pre>"},{"location":"reference/#src.openai.APIError.type","title":"type  <code>instance-attribute</code>","text":"<pre><code>type: Optional[str]\n</code></pre>"},{"location":"reference/#src.openai.APIResponseValidationError","title":"APIResponseValidationError","text":"<pre><code>APIResponseValidationError(\n    response: Response,\n    body: object | None,\n    *,\n    message: str | None = None\n)\n</code></pre> ATTRIBUTE DESCRIPTION <code>response</code> <p> TYPE: <code>Response</code> </p> <code>status_code</code> <p> TYPE: <code>int</code> </p>"},{"location":"reference/#src.openai.APIResponseValidationError.response","title":"response  <code>instance-attribute</code>","text":"<pre><code>response: Response = response\n</code></pre>"},{"location":"reference/#src.openai.APIResponseValidationError.status_code","title":"status_code  <code>instance-attribute</code>","text":"<pre><code>status_code: int = status_code\n</code></pre>"},{"location":"reference/#src.openai.APIStatusError","title":"APIStatusError","text":"<pre><code>APIStatusError(\n    message: str, *, response: Response, body: object | None\n)\n</code></pre> <p>Raised when an API response has a status code of 4xx or 5xx.</p> ATTRIBUTE DESCRIPTION <code>response</code> <p> TYPE: <code>Response</code> </p> <code>status_code</code> <p> TYPE: <code>int</code> </p>"},{"location":"reference/#src.openai.APIStatusError.response","title":"response  <code>instance-attribute</code>","text":"<pre><code>response: Response = response\n</code></pre>"},{"location":"reference/#src.openai.APIStatusError.status_code","title":"status_code  <code>instance-attribute</code>","text":"<pre><code>status_code: int = status_code\n</code></pre>"},{"location":"reference/#src.openai.APITimeoutError","title":"APITimeoutError","text":"<pre><code>APITimeoutError(request: Request)\n</code></pre>"},{"location":"reference/#src.openai.AsyncOpenAI","title":"AsyncOpenAI","text":"<pre><code>AsyncOpenAI(\n    *,\n    api_key: str | None = None,\n    organization: str | None = None,\n    base_url: str | URL | None = None,\n    timeout: Union[\n        float, Timeout, None, NotGiven\n    ] = NOT_GIVEN,\n    max_retries: int = DEFAULT_MAX_RETRIES,\n    default_headers: Mapping[str, str] | None = None,\n    default_query: Mapping[str, object] | None = None,\n    http_client: AsyncClient | None = None,\n    _strict_response_validation: bool = False\n)\n</code></pre> <p>This automatically infers the following arguments from their corresponding environment variables if they are not provided: - <code>api_key</code> from <code>OPENAI_API_KEY</code> - <code>organization</code> from <code>OPENAI_ORG_ID</code></p> METHOD DESCRIPTION <code>copy</code> <p>Create a new client instance re-using the same options given to the current client with optional overriding.</p> ATTRIBUTE DESCRIPTION <code>api_key</code> <p> TYPE: <code>str</code> </p> <code>audio</code> <p> TYPE: <code>AsyncAudio</code> </p> <code>auth_headers</code> <p> TYPE: <code>dict[str, str]</code> </p> <code>beta</code> <p> TYPE: <code>AsyncBeta</code> </p> <code>chat</code> <p> TYPE: <code>AsyncChat</code> </p> <code>completions</code> <p> TYPE: <code>AsyncCompletions</code> </p> <code>default_headers</code> <p> TYPE: <code>dict[str, str | Omit]</code> </p> <code>embeddings</code> <p> TYPE: <code>AsyncEmbeddings</code> </p> <code>files</code> <p> TYPE: <code>AsyncFiles</code> </p> <code>fine_tuning</code> <p> TYPE: <code>AsyncFineTuning</code> </p> <code>images</code> <p> TYPE: <code>AsyncImages</code> </p> <code>models</code> <p> TYPE: <code>AsyncModels</code> </p> <code>moderations</code> <p> TYPE: <code>AsyncModerations</code> </p> <code>organization</code> <p> TYPE: <code>str | None</code> </p> <code>qs</code> <p> TYPE: <code>Querystring</code> </p> <code>with_options</code> <p> </p> <code>with_raw_response</code> <p> TYPE: <code>AsyncOpenAIWithRawResponse</code> </p> <code>with_streaming_response</code> <p> TYPE: <code>AsyncOpenAIWithStreamedResponse</code> </p>"},{"location":"reference/#src.openai.AsyncOpenAI.api_key","title":"api_key  <code>instance-attribute</code>","text":"<pre><code>api_key: str = api_key\n</code></pre>"},{"location":"reference/#src.openai.AsyncOpenAI.audio","title":"audio  <code>instance-attribute</code>","text":"<pre><code>audio: AsyncAudio = AsyncAudio(self)\n</code></pre>"},{"location":"reference/#src.openai.AsyncOpenAI.auth_headers","title":"auth_headers  <code>property</code>","text":"<pre><code>auth_headers: dict[str, str]\n</code></pre>"},{"location":"reference/#src.openai.AsyncOpenAI.beta","title":"beta  <code>instance-attribute</code>","text":"<pre><code>beta: AsyncBeta = AsyncBeta(self)\n</code></pre>"},{"location":"reference/#src.openai.AsyncOpenAI.chat","title":"chat  <code>instance-attribute</code>","text":"<pre><code>chat: AsyncChat = AsyncChat(self)\n</code></pre>"},{"location":"reference/#src.openai.AsyncOpenAI.completions","title":"completions  <code>instance-attribute</code>","text":"<pre><code>completions: AsyncCompletions = AsyncCompletions(self)\n</code></pre>"},{"location":"reference/#src.openai.AsyncOpenAI.default_headers","title":"default_headers  <code>property</code>","text":"<pre><code>default_headers: dict[str, str | Omit]\n</code></pre>"},{"location":"reference/#src.openai.AsyncOpenAI.embeddings","title":"embeddings  <code>instance-attribute</code>","text":"<pre><code>embeddings: AsyncEmbeddings = AsyncEmbeddings(self)\n</code></pre>"},{"location":"reference/#src.openai.AsyncOpenAI.files","title":"files  <code>instance-attribute</code>","text":"<pre><code>files: AsyncFiles = AsyncFiles(self)\n</code></pre>"},{"location":"reference/#src.openai.AsyncOpenAI.fine_tuning","title":"fine_tuning  <code>instance-attribute</code>","text":"<pre><code>fine_tuning: AsyncFineTuning = AsyncFineTuning(self)\n</code></pre>"},{"location":"reference/#src.openai.AsyncOpenAI.images","title":"images  <code>instance-attribute</code>","text":"<pre><code>images: AsyncImages = AsyncImages(self)\n</code></pre>"},{"location":"reference/#src.openai.AsyncOpenAI.models","title":"models  <code>instance-attribute</code>","text":"<pre><code>models: AsyncModels = AsyncModels(self)\n</code></pre>"},{"location":"reference/#src.openai.AsyncOpenAI.moderations","title":"moderations  <code>instance-attribute</code>","text":"<pre><code>moderations: AsyncModerations = AsyncModerations(self)\n</code></pre>"},{"location":"reference/#src.openai.AsyncOpenAI.organization","title":"organization  <code>instance-attribute</code>","text":"<pre><code>organization: str | None = organization\n</code></pre>"},{"location":"reference/#src.openai.AsyncOpenAI.qs","title":"qs  <code>property</code>","text":"<pre><code>qs: Querystring\n</code></pre>"},{"location":"reference/#src.openai.AsyncOpenAI.with_options","title":"with_options  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>with_options = copy\n</code></pre>"},{"location":"reference/#src.openai.AsyncOpenAI.with_raw_response","title":"with_raw_response  <code>instance-attribute</code>","text":"<pre><code>with_raw_response: AsyncOpenAIWithRawResponse = (\n    AsyncOpenAIWithRawResponse(self)\n)\n</code></pre>"},{"location":"reference/#src.openai.AsyncOpenAI.with_streaming_response","title":"with_streaming_response  <code>instance-attribute</code>","text":"<pre><code>with_streaming_response: AsyncOpenAIWithStreamedResponse = (\n    AsyncOpenAIWithStreamedResponse(self)\n)\n</code></pre>"},{"location":"reference/#src.openai.AsyncOpenAI.copy","title":"copy","text":"<pre><code>copy(\n    *,\n    api_key: str | None = None,\n    organization: str | None = None,\n    base_url: str | URL | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN,\n    http_client: AsyncClient | None = None,\n    max_retries: int | NotGiven = NOT_GIVEN,\n    default_headers: Mapping[str, str] | None = None,\n    set_default_headers: Mapping[str, str] | None = None,\n    default_query: Mapping[str, object] | None = None,\n    set_default_query: Mapping[str, object] | None = None,\n    _extra_kwargs: Mapping[str, Any] = {}\n) -&gt; Self\n</code></pre> <p>Create a new client instance re-using the same options given to the current client with optional overriding.</p>"},{"location":"reference/#src.openai.AsyncStream","title":"AsyncStream","text":"<pre><code>AsyncStream(\n    *,\n    cast_to: type[_T],\n    response: Response,\n    client: AsyncOpenAI\n)\n</code></pre> <p>Provides the core interface to iterate over an asynchronous stream response.</p> METHOD DESCRIPTION <code>close</code> <p>Close the response and release the connection.</p> ATTRIBUTE DESCRIPTION <code>response</code> <p> TYPE: <code>Response</code> </p>"},{"location":"reference/#src.openai.AsyncStream.response","title":"response  <code>instance-attribute</code>","text":"<pre><code>response: Response = response\n</code></pre>"},{"location":"reference/#src.openai.AsyncStream.close","title":"close  <code>async</code>","text":"<pre><code>close() -&gt; None\n</code></pre> <p>Close the response and release the connection.</p> <p>Automatically called if the response body is read to completion.</p>"},{"location":"reference/#src.openai.AuthenticationError","title":"AuthenticationError","text":"<pre><code>AuthenticationError(\n    message: str, *, response: Response, body: object | None\n)\n</code></pre> ATTRIBUTE DESCRIPTION <code>status_code</code> <p> TYPE: <code>Literal[401]</code> </p>"},{"location":"reference/#src.openai.AuthenticationError.status_code","title":"status_code  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>status_code: Literal[401] = 401\n</code></pre>"},{"location":"reference/#src.openai.BadRequestError","title":"BadRequestError","text":"<pre><code>BadRequestError(\n    message: str, *, response: Response, body: object | None\n)\n</code></pre> ATTRIBUTE DESCRIPTION <code>status_code</code> <p> TYPE: <code>Literal[400]</code> </p>"},{"location":"reference/#src.openai.BadRequestError.status_code","title":"status_code  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>status_code: Literal[400] = 400\n</code></pre>"},{"location":"reference/#src.openai.BaseModel","title":"BaseModel","text":"CLASS DESCRIPTION <code>Config</code> METHOD DESCRIPTION <code>construct</code> <code>model_dump</code> <p>Usage docs: https://docs.pydantic.dev/2.4/concepts/serialization/#modelmodel_dump</p> <code>model_dump_json</code> <p>Usage docs: https://docs.pydantic.dev/2.4/concepts/serialization/#modelmodel_dump_json</p> ATTRIBUTE DESCRIPTION <code>model_config</code> <p> TYPE: <code>ConfigDict</code> </p> <code>model_construct</code> <p> </p> <code>model_fields_set</code> <p> TYPE: <code>set[str]</code> </p>"},{"location":"reference/#src.openai.BaseModel.model_config","title":"model_config  <code>class-attribute</code>","text":"<pre><code>model_config: ConfigDict = ConfigDict(extra='allow')\n</code></pre>"},{"location":"reference/#src.openai.BaseModel.model_construct","title":"model_construct  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>model_construct = construct\n</code></pre>"},{"location":"reference/#src.openai.BaseModel.model_fields_set","title":"model_fields_set  <code>property</code>","text":"<pre><code>model_fields_set: set[str]\n</code></pre>"},{"location":"reference/#src.openai.BaseModel.Config","title":"Config","text":"ATTRIBUTE DESCRIPTION <code>extra</code> <p> TYPE: <code>Any</code> </p>"},{"location":"reference/#src.openai.BaseModel.Config.extra","title":"extra  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>extra: Any = allow\n</code></pre>"},{"location":"reference/#src.openai.BaseModel.construct","title":"construct  <code>classmethod</code>","text":"<pre><code>construct(\n    _fields_set: set[str] | None = None, **values: object\n) -&gt; ModelT\n</code></pre>"},{"location":"reference/#src.openai.BaseModel.model_dump","title":"model_dump","text":"<pre><code>model_dump(\n    *,\n    mode: Literal[\"json\", \"python\"] | str = \"python\",\n    include: IncEx = None,\n    exclude: IncEx = None,\n    by_alias: bool = False,\n    exclude_unset: bool = False,\n    exclude_defaults: bool = False,\n    exclude_none: bool = False,\n    round_trip: bool = False,\n    warnings: bool = True\n) -&gt; dict[str, Any]\n</code></pre> <p>Usage docs: https://docs.pydantic.dev/2.4/concepts/serialization/#modelmodel_dump</p> <p>Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.</p> PARAMETER  DESCRIPTION <code>mode</code> <p>The mode in which <code>to_python</code> should run. If mode is 'json', the dictionary will only contain JSON serializable types. If mode is 'python', the dictionary may contain any Python objects.</p> <p> TYPE: <code>Literal['json', 'python'] | str</code> DEFAULT: <code>'python'</code> </p> <code>include</code> <p>A list of fields to include in the output.</p> <p> TYPE: <code>IncEx</code> DEFAULT: <code>None</code> </p> <code>exclude</code> <p>A list of fields to exclude from the output.</p> <p> TYPE: <code>IncEx</code> DEFAULT: <code>None</code> </p> <code>by_alias</code> <p>Whether to use the field's alias in the dictionary key if defined.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>exclude_unset</code> <p>Whether to exclude fields that are unset or None from the output.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>exclude_defaults</code> <p>Whether to exclude fields that are set to their default value from the output.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>exclude_none</code> <p>Whether to exclude fields that have a value of <code>None</code> from the output.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>round_trip</code> <p>Whether to enable serialization and deserialization round-trip support.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>warnings</code> <p>Whether to log warnings when invalid fields are encountered.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> RETURNS DESCRIPTION <code>dict[str, Any]</code> <p>A dictionary representation of the model.</p>"},{"location":"reference/#src.openai.BaseModel.model_dump_json","title":"model_dump_json","text":"<pre><code>model_dump_json(\n    *,\n    indent: int | None = None,\n    include: IncEx = None,\n    exclude: IncEx = None,\n    by_alias: bool = False,\n    exclude_unset: bool = False,\n    exclude_defaults: bool = False,\n    exclude_none: bool = False,\n    round_trip: bool = False,\n    warnings: bool = True\n) -&gt; str\n</code></pre> <p>Usage docs: https://docs.pydantic.dev/2.4/concepts/serialization/#modelmodel_dump_json</p> <p>Generates a JSON representation of the model using Pydantic's <code>to_json</code> method.</p> PARAMETER  DESCRIPTION <code>indent</code> <p>Indentation to use in the JSON output. If None is passed, the output will be compact.</p> <p> TYPE: <code>int | None</code> DEFAULT: <code>None</code> </p> <code>include</code> <p>Field(s) to include in the JSON output. Can take either a string or set of strings.</p> <p> TYPE: <code>IncEx</code> DEFAULT: <code>None</code> </p> <code>exclude</code> <p>Field(s) to exclude from the JSON output. Can take either a string or set of strings.</p> <p> TYPE: <code>IncEx</code> DEFAULT: <code>None</code> </p> <code>by_alias</code> <p>Whether to serialize using field aliases.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>exclude_unset</code> <p>Whether to exclude fields that have not been explicitly set.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>exclude_defaults</code> <p>Whether to exclude fields that have the default value.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>exclude_none</code> <p>Whether to exclude fields that have a value of <code>None</code>.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>round_trip</code> <p>Whether to use serialization/deserialization between JSON and class instance.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>warnings</code> <p>Whether to show any warnings that occurred during serialization.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> RETURNS DESCRIPTION <code>str</code> <p>A JSON string representation of the model.</p>"},{"location":"reference/#src.openai.ConflictError","title":"ConflictError","text":"<pre><code>ConflictError(\n    message: str, *, response: Response, body: object | None\n)\n</code></pre> ATTRIBUTE DESCRIPTION <code>status_code</code> <p> TYPE: <code>Literal[409]</code> </p>"},{"location":"reference/#src.openai.ConflictError.status_code","title":"status_code  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>status_code: Literal[409] = 409\n</code></pre>"},{"location":"reference/#src.openai.InternalServerError","title":"InternalServerError","text":"<pre><code>InternalServerError(\n    message: str, *, response: Response, body: object | None\n)\n</code></pre>"},{"location":"reference/#src.openai.NotFoundError","title":"NotFoundError","text":"<pre><code>NotFoundError(\n    message: str, *, response: Response, body: object | None\n)\n</code></pre> ATTRIBUTE DESCRIPTION <code>status_code</code> <p> TYPE: <code>Literal[404]</code> </p>"},{"location":"reference/#src.openai.NotFoundError.status_code","title":"status_code  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>status_code: Literal[404] = 404\n</code></pre>"},{"location":"reference/#src.openai.NotGiven","title":"NotGiven","text":"<p>A sentinel singleton class used to distinguish omitted keyword arguments from those passed in with the value None (which may have different behavior).</p> <p>For example:</p> <pre><code>def get(timeout: Union[int, NotGiven, None] = NotGiven()) -&gt; Response:\n    ...\n\n\nget(timeout=1)  # 1s timeout\nget(timeout=None)  # No timeout\nget()  # Default timeout behavior, which may not be statically known at the method definition.\n</code></pre>"},{"location":"reference/#src.openai.OpenAI","title":"OpenAI","text":"<pre><code>OpenAI(\n    *,\n    api_key: str | None = None,\n    organization: str | None = None,\n    base_url: str | URL | None = None,\n    timeout: Union[\n        float, Timeout, None, NotGiven\n    ] = NOT_GIVEN,\n    max_retries: int = DEFAULT_MAX_RETRIES,\n    default_headers: Mapping[str, str] | None = None,\n    default_query: Mapping[str, object] | None = None,\n    http_client: Client | None = None,\n    _strict_response_validation: bool = False\n)\n</code></pre> <p>Primary synchronous client interface for interacting with the services (resources) provided by the OpenAI API.</p> <p>An instance of the <code>OpenAI</code> class is the top-level object you interact with to make synchronous calls to the OpenAI API. The client provides access to OpenAI's services, or resources, like text completion, chat, embeddings, image and audio processing, and managing the files used by these resources.</p> <p>The API authenticates requests to its endpoints by validating your API key, which you provide to the <code>OpenAI</code> client object in one of two ways:</p> <p> Set an  environment variable named <code>OPENAI_API_KEY</code> that contains your API key and then instantiate the client without passing the <code>api_key</code> parameter. This is the preferred method.</p> <p> Pass the <code>api_key</code> parameter explicitly when you instantiate the client object. Choose this method only if you're unwilling or unable to use a more secure method like setting the <code>OPENAI_API_KEY</code> environment variable.</p> Danger <p>To prevent unauthorized access to OpenAI services, securely manage credentials like your OpenAI API key.</p> <p>Examples:</p> <p>The following code snippets each create an instance of the <code>OpenAI</code> class ready to call the API. To interact with an OpenAI service (a <code>resource</code> in the API), you access the appropriate attribute on the initialized client object and call the the methods provided by that resource.</p> <ul> <li> <p>Create client using inferred API key \u2060\u2014 The API key is obtained by the <code>OpenAI</code> client automatically from     the <code>OPENAI_API_KEY</code> environment variable if you omit the <code>api_key</code> constructor argument.</p> <pre><code>from openai import OpenAI\n\n# Instantiate the client with NO 'api_key' param so the client will\n# read the OPENAI_API_KEY variable from the environment automatically\nclient = OpenAI()\n</code></pre> </li> <li> <p>Create client using explicit API key \u2060\u2014 Passing the API key explicitly directs the <code>OpenAI</code> client to use     that key instead of the <code>OPENAI_API_KEY</code> environment variable (if set).</p> <p> This instantiation method can pose an increased security risk. For example, by instantiating the client this way in your code, it's easier to accidentally commit your API key to version control, which you should never do.</p> <pre><code>from openai import OpenAI\n\n# !!! USE WITH CAUTION !!!\n\n# Instantiate the client and pass the API key explicitly\nclient = OpenAI(api_key='your_api_key_here')\n</code></pre> </li> </ul> PARAMETER  DESCRIPTION <code>api_key</code> <p>The API key used for authenticating requests to OpenAI. If not provided, the client attempts to retrieve the API key from the <code>OPENAI_API_KEY</code> environment variable. Defaults to None.</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>organization</code> <p>The ID of the organization under which the API calls are made. This is optional and typically used for OpenAI services that require organization-level access control. If not provided, the client attempts to retrieve the organization ID from the <code>OPENAI_ORG_ID</code> environment variable. Defaults to None.</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>base_url</code> <p>The base URL for the OpenAI API. This allows for custom API endpoints like those used for testing or specific API versions. If not provided, defaults to the official OpenAI API URL.</p> <p> TYPE: <code>str | URL | None</code> DEFAULT: <code>None</code> </p> <code>timeout</code> <p>The timeout for API requests. This can be specified as a float representing seconds, a <code>httpx.Timeout</code> object for fine-grained control, or <code>None</code> to use the default timeout. Defaults to <code>NOT_GIVEN</code>, which utilizes the <code>httpx</code> default timeout settings.</p> <p> TYPE: <code>Union[float, Timeout, None, NotGiven]</code> DEFAULT: <code>NOT_GIVEN</code> </p> <code>max_retries</code> <p>The maximum number of retries for failed requests. This can help handle transient network issues or rate limit errors gracefully. Defaults to a predefined constant <code>DEFAULT_MAX_RETRIES</code>.</p> <p> TYPE: <code>int</code> DEFAULT: <code>DEFAULT_MAX_RETRIES</code> </p> <code>default_headers</code> <p>Default headers to include with every request. This can be used to set global headers like <code>User-Agent</code> or custom headers required for integration. Defaults to None.</p> <p> TYPE: <code>Mapping[str, str] | None</code> DEFAULT: <code>None</code> </p> <code>default_query</code> <p>Default query parameters to include with every request. This is useful for setting global parameters that should be included in all API calls. Defaults to None.</p> <p> TYPE: <code>Mapping[str, object] | None</code> DEFAULT: <code>None</code> </p> <code>http_client</code> <p>An instance of <code>httpx.Client</code> to be used for making HTTP requests. This allows for custom configuration of the HTTP client, like setting proxies or client-side SSL certificates. If not provided, a default <code>httpx.Client</code> instance is used. Defaults to None.</p> <p> TYPE: <code>Client | None</code> DEFAULT: <code>None</code> </p> <code>_strict_response_validation</code> <p>Enables or disables strict validation of API responses against the expected schema. This is primarily used for development and debugging purposes to ensure the API responses match the expected format. Note that this argument may be removed or changed in future releases. Defaults to False.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> RAISES DESCRIPTION <code>OpenAIError</code> <p>If neither the <code>api_key</code> is provided nor the <code>OPENAI_API_KEY</code> environment variable is set, indicating that the client's requests to the OpenAI API would fail authentication.</p> METHOD DESCRIPTION <code>copy</code> <p>Create a new client instance re-using the same options given to the current client with optional overriding.</p> ATTRIBUTE DESCRIPTION <code>api_key</code> <p> TYPE: <code>str</code> </p> <code>audio</code> <p> TYPE: <code>Audio</code> </p> <code>auth_headers</code> <p> TYPE: <code>dict[str, str]</code> </p> <code>beta</code> <p> TYPE: <code>Beta</code> </p> <code>chat</code> <p> TYPE: <code>Chat</code> </p> <code>completions</code> <p> TYPE: <code>Completions</code> </p> <code>default_headers</code> <p> TYPE: <code>dict[str, str | Omit]</code> </p> <code>embeddings</code> <p> TYPE: <code>Embeddings</code> </p> <code>files</code> <p> TYPE: <code>Files</code> </p> <code>fine_tuning</code> <p> TYPE: <code>FineTuning</code> </p> <code>images</code> <p> TYPE: <code>Images</code> </p> <code>models</code> <p> TYPE: <code>Models</code> </p> <code>moderations</code> <p> TYPE: <code>Moderations</code> </p> <code>organization</code> <p> TYPE: <code>str | None</code> </p> <code>qs</code> <p> TYPE: <code>Querystring</code> </p> <code>with_options</code> <p> </p> <code>with_raw_response</code> <p> TYPE: <code>OpenAIWithRawResponse</code> </p> <code>with_streaming_response</code> <p> TYPE: <code>OpenAIWithStreamedResponse</code> </p>"},{"location":"reference/#src.openai.OpenAI.api_key","title":"api_key  <code>instance-attribute</code>","text":"<pre><code>api_key: str = api_key\n</code></pre>"},{"location":"reference/#src.openai.OpenAI.audio","title":"audio  <code>instance-attribute</code>","text":"<pre><code>audio: Audio = Audio(self)\n</code></pre>"},{"location":"reference/#src.openai.OpenAI.auth_headers","title":"auth_headers  <code>property</code>","text":"<pre><code>auth_headers: dict[str, str]\n</code></pre>"},{"location":"reference/#src.openai.OpenAI.beta","title":"beta  <code>instance-attribute</code>","text":"<pre><code>beta: Beta = Beta(self)\n</code></pre>"},{"location":"reference/#src.openai.OpenAI.chat","title":"chat  <code>instance-attribute</code>","text":"<pre><code>chat: Chat = Chat(self)\n</code></pre>"},{"location":"reference/#src.openai.OpenAI.completions","title":"completions  <code>instance-attribute</code>","text":"<pre><code>completions: Completions = Completions(self)\n</code></pre>"},{"location":"reference/#src.openai.OpenAI.default_headers","title":"default_headers  <code>property</code>","text":"<pre><code>default_headers: dict[str, str | Omit]\n</code></pre>"},{"location":"reference/#src.openai.OpenAI.embeddings","title":"embeddings  <code>instance-attribute</code>","text":"<pre><code>embeddings: Embeddings = Embeddings(self)\n</code></pre>"},{"location":"reference/#src.openai.OpenAI.files","title":"files  <code>instance-attribute</code>","text":"<pre><code>files: Files = Files(self)\n</code></pre>"},{"location":"reference/#src.openai.OpenAI.fine_tuning","title":"fine_tuning  <code>instance-attribute</code>","text":"<pre><code>fine_tuning: FineTuning = FineTuning(self)\n</code></pre>"},{"location":"reference/#src.openai.OpenAI.images","title":"images  <code>instance-attribute</code>","text":"<pre><code>images: Images = Images(self)\n</code></pre>"},{"location":"reference/#src.openai.OpenAI.models","title":"models  <code>instance-attribute</code>","text":"<pre><code>models: Models = Models(self)\n</code></pre>"},{"location":"reference/#src.openai.OpenAI.moderations","title":"moderations  <code>instance-attribute</code>","text":"<pre><code>moderations: Moderations = Moderations(self)\n</code></pre>"},{"location":"reference/#src.openai.OpenAI.organization","title":"organization  <code>instance-attribute</code>","text":"<pre><code>organization: str | None = organization\n</code></pre>"},{"location":"reference/#src.openai.OpenAI.qs","title":"qs  <code>property</code>","text":"<pre><code>qs: Querystring\n</code></pre>"},{"location":"reference/#src.openai.OpenAI.with_options","title":"with_options  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>with_options = copy\n</code></pre>"},{"location":"reference/#src.openai.OpenAI.with_raw_response","title":"with_raw_response  <code>instance-attribute</code>","text":"<pre><code>with_raw_response: OpenAIWithRawResponse = (\n    OpenAIWithRawResponse(self)\n)\n</code></pre>"},{"location":"reference/#src.openai.OpenAI.with_streaming_response","title":"with_streaming_response  <code>instance-attribute</code>","text":"<pre><code>with_streaming_response: OpenAIWithStreamedResponse = (\n    OpenAIWithStreamedResponse(self)\n)\n</code></pre>"},{"location":"reference/#src.openai.OpenAI.copy","title":"copy","text":"<pre><code>copy(\n    *,\n    api_key: str | None = None,\n    organization: str | None = None,\n    base_url: str | URL | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN,\n    http_client: Client | None = None,\n    max_retries: int | NotGiven = NOT_GIVEN,\n    default_headers: Mapping[str, str] | None = None,\n    set_default_headers: Mapping[str, str] | None = None,\n    default_query: Mapping[str, object] | None = None,\n    set_default_query: Mapping[str, object] | None = None,\n    _extra_kwargs: Mapping[str, Any] = {}\n) -&gt; Self\n</code></pre> <p>Create a new client instance re-using the same options given to the current client with optional overriding.</p>"},{"location":"reference/#src.openai.OpenAIError","title":"OpenAIError","text":""},{"location":"reference/#src.openai.PermissionDeniedError","title":"PermissionDeniedError","text":"<pre><code>PermissionDeniedError(\n    message: str, *, response: Response, body: object | None\n)\n</code></pre> ATTRIBUTE DESCRIPTION <code>status_code</code> <p> TYPE: <code>Literal[403]</code> </p>"},{"location":"reference/#src.openai.PermissionDeniedError.status_code","title":"status_code  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>status_code: Literal[403] = 403\n</code></pre>"},{"location":"reference/#src.openai.RateLimitError","title":"RateLimitError","text":"<pre><code>RateLimitError(\n    message: str, *, response: Response, body: object | None\n)\n</code></pre> ATTRIBUTE DESCRIPTION <code>status_code</code> <p> TYPE: <code>Literal[429]</code> </p>"},{"location":"reference/#src.openai.RateLimitError.status_code","title":"status_code  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>status_code: Literal[429] = 429\n</code></pre>"},{"location":"reference/#src.openai.RequestOptions","title":"RequestOptions","text":"ATTRIBUTE DESCRIPTION <code>extra_json</code> <p> TYPE: <code>AnyMapping</code> </p> <code>headers</code> <p> TYPE: <code>Headers</code> </p> <code>idempotency_key</code> <p> TYPE: <code>str</code> </p> <code>max_retries</code> <p> TYPE: <code>int</code> </p> <code>params</code> <p> TYPE: <code>Query</code> </p> <code>timeout</code> <p> TYPE: <code>float | Timeout | None</code> </p>"},{"location":"reference/#src.openai.RequestOptions.extra_json","title":"extra_json  <code>instance-attribute</code>","text":"<pre><code>extra_json: AnyMapping\n</code></pre>"},{"location":"reference/#src.openai.RequestOptions.headers","title":"headers  <code>instance-attribute</code>","text":"<pre><code>headers: Headers\n</code></pre>"},{"location":"reference/#src.openai.RequestOptions.idempotency_key","title":"idempotency_key  <code>instance-attribute</code>","text":"<pre><code>idempotency_key: str\n</code></pre>"},{"location":"reference/#src.openai.RequestOptions.max_retries","title":"max_retries  <code>instance-attribute</code>","text":"<pre><code>max_retries: int\n</code></pre>"},{"location":"reference/#src.openai.RequestOptions.params","title":"params  <code>instance-attribute</code>","text":"<pre><code>params: Query\n</code></pre>"},{"location":"reference/#src.openai.RequestOptions.timeout","title":"timeout  <code>instance-attribute</code>","text":"<pre><code>timeout: float | Timeout | None\n</code></pre>"},{"location":"reference/#src.openai.Stream","title":"Stream","text":"<pre><code>Stream(\n    *, cast_to: type[_T], response: Response, client: OpenAI\n)\n</code></pre> <p>Provides the core interface to iterate over a synchronous stream response.</p> METHOD DESCRIPTION <code>close</code> <p>Close the response and release the connection.</p> ATTRIBUTE DESCRIPTION <code>response</code> <p> TYPE: <code>Response</code> </p>"},{"location":"reference/#src.openai.Stream.response","title":"response  <code>instance-attribute</code>","text":"<pre><code>response: Response = response\n</code></pre>"},{"location":"reference/#src.openai.Stream.close","title":"close","text":"<pre><code>close() -&gt; None\n</code></pre> <p>Close the response and release the connection.</p> <p>Automatically called if the response body is read to completion.</p>"},{"location":"reference/#src.openai.UnprocessableEntityError","title":"UnprocessableEntityError","text":"<pre><code>UnprocessableEntityError(\n    message: str, *, response: Response, body: object | None\n)\n</code></pre> ATTRIBUTE DESCRIPTION <code>status_code</code> <p> TYPE: <code>Literal[422]</code> </p>"},{"location":"reference/#src.openai.UnprocessableEntityError.status_code","title":"status_code  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>status_code: Literal[422] = 422\n</code></pre>"},{"location":"reference/#src.openai.file_from_path","title":"file_from_path","text":"<pre><code>file_from_path(path: str) -&gt; FileTypes\n</code></pre>"},{"location":"reference/SUMMARY/","title":"SUMMARY","text":"<ul> <li>openai<ul> <li>pagination</li> <li>resources<ul> <li>audio<ul> <li>audio</li> <li>speech</li> <li>transcriptions</li> <li>translations</li> </ul> </li> <li>beta<ul> <li>assistants<ul> <li>assistants</li> <li>files</li> </ul> </li> <li>beta</li> <li>threads<ul> <li>messages<ul> <li>files</li> <li>messages</li> </ul> </li> <li>runs<ul> <li>runs</li> <li>steps</li> </ul> </li> <li>threads</li> </ul> </li> </ul> </li> <li>chat<ul> <li>chat</li> <li>completions</li> </ul> </li> <li>completions</li> <li>embeddings</li> <li>files</li> <li>fine_tuning<ul> <li>fine_tuning</li> <li>jobs</li> </ul> </li> <li>images</li> <li>models</li> <li>moderations</li> </ul> </li> <li>types<ul> <li>audio<ul> <li>speech_create_params</li> <li>transcription</li> <li>transcription_create_params</li> <li>translation</li> <li>translation_create_params</li> </ul> </li> <li>beta<ul> <li>assistant</li> <li>assistant_create_params</li> <li>assistant_deleted</li> <li>assistant_list_params</li> <li>assistant_update_params</li> <li>assistants<ul> <li>assistant_file</li> <li>file_create_params</li> <li>file_delete_response</li> <li>file_list_params</li> </ul> </li> <li>chat</li> <li>thread</li> <li>thread_create_and_run_params</li> <li>thread_create_params</li> <li>thread_deleted</li> <li>thread_update_params</li> <li>threads<ul> <li>message_content_image_file</li> <li>message_content_text</li> <li>message_create_params</li> <li>message_list_params</li> <li>message_update_params</li> <li>messages<ul> <li>file_list_params</li> <li>message_file</li> </ul> </li> <li>required_action_function_tool_call</li> <li>run</li> <li>run_create_params</li> <li>run_list_params</li> <li>run_submit_tool_outputs_params</li> <li>run_update_params</li> <li>runs<ul> <li>code_tool_call</li> <li>function_tool_call</li> <li>message_creation_step_details</li> <li>retrieval_tool_call</li> <li>run_step</li> <li>step_list_params</li> <li>tool_calls_step_details</li> </ul> </li> <li>thread_message</li> </ul> </li> </ul> </li> <li>chat<ul> <li>chat_completion</li> <li>chat_completion_assistant_message_param</li> <li>chat_completion_chunk</li> <li>chat_completion_content_part_image_param</li> <li>chat_completion_content_part_param</li> <li>chat_completion_content_part_text_param</li> <li>chat_completion_function_call_option_param</li> <li>chat_completion_function_message_param</li> <li>chat_completion_message</li> <li>chat_completion_message_param</li> <li>chat_completion_message_tool_call</li> <li>chat_completion_message_tool_call_param</li> <li>chat_completion_named_tool_choice_param</li> <li>chat_completion_role</li> <li>chat_completion_system_message_param</li> <li>chat_completion_token_logprob</li> <li>chat_completion_tool_choice_option_param</li> <li>chat_completion_tool_message_param</li> <li>chat_completion_tool_param</li> <li>chat_completion_user_message_param</li> <li>completion_create_params</li> </ul> </li> <li>completion</li> <li>completion_choice</li> <li>completion_create_params</li> <li>completion_usage</li> <li>create_embedding_response</li> <li>embedding</li> <li>embedding_create_params</li> <li>file_content</li> <li>file_create_params</li> <li>file_deleted</li> <li>file_list_params</li> <li>file_object</li> <li>fine_tuning<ul> <li>fine_tuning_job</li> <li>fine_tuning_job_event</li> <li>job_create_params</li> <li>job_list_events_params</li> <li>job_list_params</li> </ul> </li> <li>image</li> <li>image_create_variation_params</li> <li>image_edit_params</li> <li>image_generate_params</li> <li>images_response</li> <li>model</li> <li>model_deleted</li> <li>moderation</li> <li>moderation_create_params</li> <li>moderation_create_response</li> <li>shared<ul> <li>function_definition</li> <li>function_parameters</li> </ul> </li> <li>shared_params<ul> <li>function_definition</li> <li>function_parameters</li> </ul> </li> </ul> </li> <li>version</li> </ul> </li> </ul>"},{"location":"reference/pagination/","title":"pagination","text":"<p>Classes:</p> Name Description <code>AsyncCursorPage</code> <code>AsyncPage</code> <p>Note: no pagination actually occurs yet, this is for forwards-compatibility.</p> <code>CursorPageItem</code> <code>SyncCursorPage</code> <code>SyncPage</code> <p>Note: no pagination actually occurs yet, this is for forwards-compatibility.</p>"},{"location":"reference/pagination/#src.openai.pagination.AsyncCursorPage","title":"AsyncCursorPage","text":"<p>Methods:</p> Name Description <code>next_page_info</code> <p>Attributes:</p> Name Type Description <code>data</code> <code>List[_T]</code>"},{"location":"reference/pagination/#src.openai.pagination.AsyncCursorPage.data","title":"data  <code>instance-attribute</code>","text":"<pre><code>data: List[_T]\n</code></pre>"},{"location":"reference/pagination/#src.openai.pagination.AsyncCursorPage.next_page_info","title":"next_page_info","text":"<pre><code>next_page_info() -&gt; Optional[PageInfo]\n</code></pre>"},{"location":"reference/pagination/#src.openai.pagination.AsyncPage","title":"AsyncPage","text":"<p>Note: no pagination actually occurs yet, this is for forwards-compatibility.</p> <p>Methods:</p> Name Description <code>next_page_info</code> <p>This page represents a response that isn't actually paginated at the API level</p> <p>Attributes:</p> Name Type Description <code>data</code> <code>List[_T]</code> <code>object</code> <code>str</code>"},{"location":"reference/pagination/#src.openai.pagination.AsyncPage.data","title":"data  <code>instance-attribute</code>","text":"<pre><code>data: List[_T]\n</code></pre>"},{"location":"reference/pagination/#src.openai.pagination.AsyncPage.object","title":"object  <code>instance-attribute</code>","text":"<pre><code>object: str\n</code></pre>"},{"location":"reference/pagination/#src.openai.pagination.AsyncPage.next_page_info","title":"next_page_info","text":"<pre><code>next_page_info() -&gt; None\n</code></pre> <p>This page represents a response that isn't actually paginated at the API level so there will never be a next page.</p>"},{"location":"reference/pagination/#src.openai.pagination.CursorPageItem","title":"CursorPageItem","text":"<p>Attributes:</p> Name Type Description <code>id</code> <code>Optional[str]</code>"},{"location":"reference/pagination/#src.openai.pagination.CursorPageItem.id","title":"id  <code>instance-attribute</code>","text":"<pre><code>id: Optional[str]\n</code></pre>"},{"location":"reference/pagination/#src.openai.pagination.SyncCursorPage","title":"SyncCursorPage","text":"<p>Methods:</p> Name Description <code>next_page_info</code> <p>Attributes:</p> Name Type Description <code>data</code> <code>List[_T]</code>"},{"location":"reference/pagination/#src.openai.pagination.SyncCursorPage.data","title":"data  <code>instance-attribute</code>","text":"<pre><code>data: List[_T]\n</code></pre>"},{"location":"reference/pagination/#src.openai.pagination.SyncCursorPage.next_page_info","title":"next_page_info","text":"<pre><code>next_page_info() -&gt; Optional[PageInfo]\n</code></pre>"},{"location":"reference/pagination/#src.openai.pagination.SyncPage","title":"SyncPage","text":"<p>Note: no pagination actually occurs yet, this is for forwards-compatibility.</p> <p>Methods:</p> Name Description <code>next_page_info</code> <p>This page represents a response that isn't actually paginated at the API level</p> <p>Attributes:</p> Name Type Description <code>data</code> <code>List[_T]</code> <code>object</code> <code>str</code>"},{"location":"reference/pagination/#src.openai.pagination.SyncPage.data","title":"data  <code>instance-attribute</code>","text":"<pre><code>data: List[_T]\n</code></pre>"},{"location":"reference/pagination/#src.openai.pagination.SyncPage.object","title":"object  <code>instance-attribute</code>","text":"<pre><code>object: str\n</code></pre>"},{"location":"reference/pagination/#src.openai.pagination.SyncPage.next_page_info","title":"next_page_info","text":"<pre><code>next_page_info() -&gt; None\n</code></pre> <p>This page represents a response that isn't actually paginated at the API level so there will never be a next page.</p>"},{"location":"reference/version/","title":"version","text":"<p>Attributes:</p> Name Type Description <code>VERSION</code> <code>str</code>"},{"location":"reference/version/#src.openai.version.VERSION","title":"VERSION  <code>module-attribute</code>","text":"<pre><code>VERSION: str = __version__\n</code></pre>"},{"location":"reference/_extras/","title":"Index","text":"<p>Modules:</p> Name Description <code>numpy_proxy</code> <code>pandas_proxy</code>"},{"location":"reference/_extras/numpy_proxy/","title":"Numpy proxy","text":"<p>Classes:</p> Name Description <code>NumpyProxy</code> <p>Functions:</p> Name Description <code>has_numpy</code> <p>Attributes:</p> Name Type Description <code>NUMPY_INSTRUCTIONS</code>"},{"location":"reference/_extras/numpy_proxy/#src.openai._extras.numpy_proxy.NUMPY_INSTRUCTIONS","title":"NUMPY_INSTRUCTIONS  <code>module-attribute</code>","text":"<pre><code>NUMPY_INSTRUCTIONS = format_instructions(\n    library=\"numpy\", extra=\"datalib\"\n)\n</code></pre>"},{"location":"reference/_extras/numpy_proxy/#src.openai._extras.numpy_proxy.NumpyProxy","title":"NumpyProxy","text":""},{"location":"reference/_extras/numpy_proxy/#src.openai._extras.numpy_proxy.has_numpy","title":"has_numpy","text":"<pre><code>has_numpy() -&gt; bool\n</code></pre>"},{"location":"reference/_extras/pandas_proxy/","title":"Pandas proxy","text":"<p>Classes:</p> Name Description <code>PandasProxy</code> <p>Attributes:</p> Name Type Description <code>PANDAS_INSTRUCTIONS</code>"},{"location":"reference/_extras/pandas_proxy/#src.openai._extras.pandas_proxy.PANDAS_INSTRUCTIONS","title":"PANDAS_INSTRUCTIONS  <code>module-attribute</code>","text":"<pre><code>PANDAS_INSTRUCTIONS = format_instructions(\n    library=\"pandas\", extra=\"datalib\"\n)\n</code></pre>"},{"location":"reference/_extras/pandas_proxy/#src.openai._extras.pandas_proxy.PandasProxy","title":"PandasProxy","text":""},{"location":"reference/_utils/","title":"Index","text":""},{"location":"reference/resources/","title":"openai.resources","text":"<p>The <code>resources</code> module aggregates classes and functions for interacting with the OpenAI API into several submodules, each representing a specific resource or feature of the API.</p> <p>The submodules' classes mirror the structure of the API's endpoints and offer synchronous and asynchronous communication with the API.</p> <p>Each resource is accessible as an attribute on the <code>OpenAI</code> and <code>AsyncOpenAI</code> clients. To work with a resource, initialize an instance of a client and then access the resource as an attribute on the client instance. For example, to work with the <code>chat</code> resource, create an instance of the <code>OpenAI</code> client and access the attributes and methods on <code>your_client_instance.chat</code>.</p> <p>Modules:</p> Name Description <code>audio</code> <p>The <code>audio</code> module provides classes for audio processing operations like transcription, translation, and speech synthesis.</p> <p>Use the <code>audio</code> module by accessing the <code>OpenAI.audio</code> attribute on the client object, and then access the attribute for the feature you'd like to use:</p> <ul> <li><code>OpenAI.audio.transcriptions</code> - Transcribe spoken audio to text</li> <li><code>OpenAI.audio.translations</code> - Translate spoken audio to English</li> <li><code>OpenAI.audio.speech</code> - Generate spoken audio from text</li> </ul> <p>Examples:     <pre><code>from pathlib import Path\n\nfrom openai import OpenAI\n\nopenai = OpenAI()\n\nspeech_file_path = Path(__file__).parent / \"speech.mp3\"\n\n    # Create text-to-speech audio file\n    with openai.audio.speech.with_streaming_response.create(\n        model=\"tts-1\",\n        voice=\"alloy\",\n        input=\"The quick brown fox jumps over the lazy dog.\",\n    ) as response:\n        response.stream_to_file(speech_file_path)\n</code></pre></p> <code>beta</code> <p>The <code>beta</code> modules provides a unified interface for accessing beta features of the API, encapsulating synchronous and asynchronous access to resources in beta.</p> <p>The module aggregates the beta functionalities related to features like yet considered generally available (GA), offering a simplified entry point for interacting with these resources. It is designed to facilitate easy access to the cutting-edge features still under development, enabling developers to experiment with and leverage new capabilities before they become GA.</p> <code>chat</code> <p>The <code>chat</code> module provides classes for creating and managing chat sessions that leverage OpenAI's language models to generate conversational responses.</p> <p>The module supports both synchronous and asynchronous operations, offering interfaces for direct interaction with the completion endpoints tailored for chat applications. Designed for developers looking to integrate AI-powered chat functionalities into their applications and features like raw and streaming response handling for more flexible integration.</p> <code>completions</code> <p>The <code>completions</code> module provides access to the legacy chat endpoint, <code>/v1/completions</code>. Use the <code>chat.completions</code> module instead for new applications.</p> <p>You should not use this module for new projects. The legacy <code>/v1/completions</code> endpoint this module interacts with no longer receives updates and is expected to be deprecated. Use this module only in applications that require compatibility with the legacy endpoint.</p> <p>You're strongly encouraged to migrate existing applications to the <code>chat.completions</code> module\u2060\u2014which interacts with the current (non-legacy) <code>/v1/chat/completions</code> endpoint\u2014prior to the deprecation of the <code>/v1/completions</code> endpoint.</p> <code>embeddings</code> <p>The <code>embeddings</code> module provides classes for creating embeddings from text inputs using OpenAI's models and supports both synchronous and asynchronous operations as well as the handling of raw responses and streaming response capabilities.</p> <p>The module is appropriate for use in applications that require semantic analysis of text, like similarity searches, text clustering, and other natural language processing tasks that can benefit from high-dimensional vector representations of text.</p> <code>files</code> <p>The <code>files</code> module provides classes for uploading, retrieving, listing, and deleting files used across various OpenAI API endpoints.</p> <p>The module supports both synchronous and asynchronous operations, along with handling of raw responses and streaming of file content. Designed for use cases that involve managing large datasets or files for purposes like fine-tuning models or using assistants, this module facilitates the efficient handling of file-related operations on the OpenAI platform.</p> <code>fine_tuning</code> <p>The <code>fine_tuning</code> module provides classes for handling fine-tuning operations, including the initiation, management, and retrieval of fine-tuning jobs.</p> <p>The module supports synchronous and asynchronous operations, offering interfaces for working with jobs directly, as well as with raw or streaming responses. Designed for use in applications requiring custom model training on specific datasets to improve model performance for tailored tasks.</p> <code>images</code> <p>The <code>image</code> module provides functionality for creating variations of images, editing images based on textual prompts, and generating new images from prompts using specified models.</p> <p>The module supports both synchronous and asynchronous operations, with capabilities for handling raw responses and streaming. Suitable for applications requiring dynamic image generation or modification through the OpenAI API, this module leverages models like DALL-E to interpret text prompts into visual content.</p> <code>models</code> <p>The <code>models</code> module facilitates the retrieval, listing, and deletion of models on the OpenAI platform and supports both synchronous and asynchronous operations.</p> <p>The module enables developers to interact with models, providing functionalities like fetching detailed information about a specific model, listing all available models, and deleting fine-tuned models.</p> <code>moderations</code> <p>The <code>moderations</code> module provides functionality to submit text for moderation to determine whether it violates OpenAI's content policy.</p> <p>Moderation is particularly useful for developers looking to ensure the content generated or processed by their applications adheres to OpenAI's content policy. By leveraging the content moderation models provided by OpenAI, applications can automatically classify and filter out text that might be considered harmful or inappropriate.</p> <p>Classes:</p> Name Description <code>AsyncAudio</code> <code>AsyncAudioWithRawResponse</code> <code>AsyncAudioWithStreamingResponse</code> <code>AsyncBeta</code> <code>AsyncBetaWithRawResponse</code> <code>AsyncBetaWithStreamingResponse</code> <code>AsyncChat</code> <code>AsyncChatWithRawResponse</code> <code>AsyncChatWithStreamingResponse</code> <code>AsyncCompletions</code> <code>AsyncCompletionsWithRawResponse</code> <code>AsyncCompletionsWithStreamingResponse</code> <code>AsyncEmbeddings</code> <code>AsyncEmbeddingsWithRawResponse</code> <code>AsyncEmbeddingsWithStreamingResponse</code> <code>AsyncFiles</code> <code>AsyncFilesWithRawResponse</code> <code>AsyncFilesWithStreamingResponse</code> <code>AsyncFineTuning</code> <code>AsyncFineTuningWithRawResponse</code> <code>AsyncFineTuningWithStreamingResponse</code> <code>AsyncImages</code> <code>AsyncImagesWithRawResponse</code> <code>AsyncImagesWithStreamingResponse</code> <code>AsyncModels</code> <code>AsyncModelsWithRawResponse</code> <code>AsyncModelsWithStreamingResponse</code> <code>AsyncModerations</code> <code>AsyncModerationsWithRawResponse</code> <code>AsyncModerationsWithStreamingResponse</code> <code>Audio</code> <code>AudioWithRawResponse</code> <code>AudioWithStreamingResponse</code> <code>Beta</code> <code>BetaWithRawResponse</code> <code>BetaWithStreamingResponse</code> <code>Chat</code> <code>ChatWithRawResponse</code> <code>ChatWithStreamingResponse</code> <code>Completions</code> <code>CompletionsWithRawResponse</code> <code>CompletionsWithStreamingResponse</code> <code>Embeddings</code> <code>EmbeddingsWithRawResponse</code> <code>EmbeddingsWithStreamingResponse</code> <code>Files</code> <code>FilesWithRawResponse</code> <code>FilesWithStreamingResponse</code> <code>FineTuning</code> <code>FineTuningWithRawResponse</code> <code>FineTuningWithStreamingResponse</code> <code>Images</code> <code>ImagesWithRawResponse</code> <code>ImagesWithStreamingResponse</code> <code>Models</code> <code>ModelsWithRawResponse</code> <code>ModelsWithStreamingResponse</code> <code>Moderations</code> <code>ModerationsWithRawResponse</code> <code>ModerationsWithStreamingResponse</code>"},{"location":"reference/resources/#src.openai.resources.AsyncAudio","title":"AsyncAudio","text":"<pre><code>AsyncAudio(client: AsyncOpenAI)\n</code></pre> <p>Methods:</p> Name Description <code>speech</code> <code>transcriptions</code> <code>translations</code> <code>with_raw_response</code> <code>with_streaming_response</code>"},{"location":"reference/resources/#src.openai.resources.AsyncAudio.speech","title":"speech","text":"<pre><code>speech() -&gt; AsyncSpeech\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.AsyncAudio.transcriptions","title":"transcriptions","text":"<pre><code>transcriptions() -&gt; AsyncTranscriptions\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.AsyncAudio.translations","title":"translations","text":"<pre><code>translations() -&gt; AsyncTranslations\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.AsyncAudio.with_raw_response","title":"with_raw_response","text":"<pre><code>with_raw_response() -&gt; AsyncAudioWithRawResponse\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.AsyncAudio.with_streaming_response","title":"with_streaming_response","text":"<pre><code>with_streaming_response() -&gt; (\n    AsyncAudioWithStreamingResponse\n)\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.AsyncAudioWithRawResponse","title":"AsyncAudioWithRawResponse","text":"<pre><code>AsyncAudioWithRawResponse(audio: AsyncAudio)\n</code></pre> <p>Methods:</p> Name Description <code>speech</code> <code>transcriptions</code> <code>translations</code>"},{"location":"reference/resources/#src.openai.resources.AsyncAudioWithRawResponse.speech","title":"speech","text":"<pre><code>speech() -&gt; AsyncSpeechWithRawResponse\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.AsyncAudioWithRawResponse.transcriptions","title":"transcriptions","text":"<pre><code>transcriptions() -&gt; AsyncTranscriptionsWithRawResponse\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.AsyncAudioWithRawResponse.translations","title":"translations","text":"<pre><code>translations() -&gt; AsyncTranslationsWithRawResponse\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.AsyncAudioWithStreamingResponse","title":"AsyncAudioWithStreamingResponse","text":"<pre><code>AsyncAudioWithStreamingResponse(audio: AsyncAudio)\n</code></pre> <p>Methods:</p> Name Description <code>speech</code> <code>transcriptions</code> <code>translations</code>"},{"location":"reference/resources/#src.openai.resources.AsyncAudioWithStreamingResponse.speech","title":"speech","text":"<pre><code>speech() -&gt; AsyncSpeechWithStreamingResponse\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.AsyncAudioWithStreamingResponse.transcriptions","title":"transcriptions","text":"<pre><code>transcriptions() -&gt; (\n    AsyncTranscriptionsWithStreamingResponse\n)\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.AsyncAudioWithStreamingResponse.translations","title":"translations","text":"<pre><code>translations() -&gt; AsyncTranslationsWithStreamingResponse\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.AsyncBeta","title":"AsyncBeta","text":"<pre><code>AsyncBeta(client: AsyncOpenAI)\n</code></pre> <p>Methods:</p> Name Description <code>assistants</code> <code>threads</code> <code>with_raw_response</code> <code>with_streaming_response</code>"},{"location":"reference/resources/#src.openai.resources.AsyncBeta.assistants","title":"assistants","text":"<pre><code>assistants() -&gt; AsyncAssistants\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.AsyncBeta.threads","title":"threads","text":"<pre><code>threads() -&gt; AsyncThreads\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.AsyncBeta.with_raw_response","title":"with_raw_response","text":"<pre><code>with_raw_response() -&gt; AsyncBetaWithRawResponse\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.AsyncBeta.with_streaming_response","title":"with_streaming_response","text":"<pre><code>with_streaming_response() -&gt; AsyncBetaWithStreamingResponse\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.AsyncBetaWithRawResponse","title":"AsyncBetaWithRawResponse","text":"<pre><code>AsyncBetaWithRawResponse(beta: AsyncBeta)\n</code></pre> <p>Methods:</p> Name Description <code>assistants</code> <code>threads</code>"},{"location":"reference/resources/#src.openai.resources.AsyncBetaWithRawResponse.assistants","title":"assistants","text":"<pre><code>assistants() -&gt; AsyncAssistantsWithRawResponse\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.AsyncBetaWithRawResponse.threads","title":"threads","text":"<pre><code>threads() -&gt; AsyncThreadsWithRawResponse\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.AsyncBetaWithStreamingResponse","title":"AsyncBetaWithStreamingResponse","text":"<pre><code>AsyncBetaWithStreamingResponse(beta: AsyncBeta)\n</code></pre> <p>Methods:</p> Name Description <code>assistants</code> <code>threads</code>"},{"location":"reference/resources/#src.openai.resources.AsyncBetaWithStreamingResponse.assistants","title":"assistants","text":"<pre><code>assistants() -&gt; AsyncAssistantsWithStreamingResponse\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.AsyncBetaWithStreamingResponse.threads","title":"threads","text":"<pre><code>threads() -&gt; AsyncThreadsWithStreamingResponse\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.AsyncChat","title":"AsyncChat","text":"<pre><code>AsyncChat(client: AsyncOpenAI)\n</code></pre> <p>Methods:</p> Name Description <code>completions</code> <code>with_raw_response</code> <code>with_streaming_response</code>"},{"location":"reference/resources/#src.openai.resources.AsyncChat.completions","title":"completions","text":"<pre><code>completions() -&gt; AsyncCompletions\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.AsyncChat.with_raw_response","title":"with_raw_response","text":"<pre><code>with_raw_response() -&gt; AsyncChatWithRawResponse\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.AsyncChat.with_streaming_response","title":"with_streaming_response","text":"<pre><code>with_streaming_response() -&gt; AsyncChatWithStreamingResponse\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.AsyncChatWithRawResponse","title":"AsyncChatWithRawResponse","text":"<pre><code>AsyncChatWithRawResponse(chat: AsyncChat)\n</code></pre> <p>Methods:</p> Name Description <code>completions</code>"},{"location":"reference/resources/#src.openai.resources.AsyncChatWithRawResponse.completions","title":"completions","text":"<pre><code>completions() -&gt; AsyncCompletionsWithRawResponse\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.AsyncChatWithStreamingResponse","title":"AsyncChatWithStreamingResponse","text":"<pre><code>AsyncChatWithStreamingResponse(chat: AsyncChat)\n</code></pre> <p>Methods:</p> Name Description <code>completions</code>"},{"location":"reference/resources/#src.openai.resources.AsyncChatWithStreamingResponse.completions","title":"completions","text":"<pre><code>completions() -&gt; AsyncCompletionsWithStreamingResponse\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.AsyncCompletions","title":"AsyncCompletions","text":"<pre><code>AsyncCompletions(client: AsyncOpenAI)\n</code></pre> <p>Methods:</p> Name Description <code>create</code> <p>Creates a completion for the provided prompt and parameters.</p> <code>with_raw_response</code> <code>with_streaming_response</code>"},{"location":"reference/resources/#src.openai.resources.AsyncCompletions.create","title":"create  <code>async</code>","text":"<pre><code>create(\n    *,\n    model: Union[\n        str,\n        Literal[\n            \"gpt-3.5-turbo-instruct\",\n            \"davinci-002\",\n            \"babbage-002\",\n        ],\n    ],\n    prompt: Union[\n        str,\n        List[str],\n        Iterable[int],\n        Iterable[Iterable[int]],\n        None,\n    ],\n    best_of: Optional[int] | NotGiven = NOT_GIVEN,\n    echo: Optional[bool] | NotGiven = NOT_GIVEN,\n    frequency_penalty: (\n        Optional[float] | NotGiven\n    ) = NOT_GIVEN,\n    logit_bias: (\n        Optional[Dict[str, int]] | NotGiven\n    ) = NOT_GIVEN,\n    logprobs: Optional[int] | NotGiven = NOT_GIVEN,\n    max_tokens: Optional[int] | NotGiven = NOT_GIVEN,\n    n: Optional[int] | NotGiven = NOT_GIVEN,\n    presence_penalty: (\n        Optional[float] | NotGiven\n    ) = NOT_GIVEN,\n    seed: Optional[int] | NotGiven = NOT_GIVEN,\n    stop: (\n        Union[Optional[str], List[str], None] | NotGiven\n    ) = NOT_GIVEN,\n    stream: Optional[Literal[False]] | NotGiven = NOT_GIVEN,\n    suffix: Optional[str] | NotGiven = NOT_GIVEN,\n    temperature: Optional[float] | NotGiven = NOT_GIVEN,\n    top_p: Optional[float] | NotGiven = NOT_GIVEN,\n    user: str | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; Completion\n</code></pre><pre><code>create(\n    *,\n    model: Union[\n        str,\n        Literal[\n            \"gpt-3.5-turbo-instruct\",\n            \"davinci-002\",\n            \"babbage-002\",\n        ],\n    ],\n    prompt: Union[\n        str,\n        List[str],\n        Iterable[int],\n        Iterable[Iterable[int]],\n        None,\n    ],\n    stream: Literal[True],\n    best_of: Optional[int] | NotGiven = NOT_GIVEN,\n    echo: Optional[bool] | NotGiven = NOT_GIVEN,\n    frequency_penalty: (\n        Optional[float] | NotGiven\n    ) = NOT_GIVEN,\n    logit_bias: (\n        Optional[Dict[str, int]] | NotGiven\n    ) = NOT_GIVEN,\n    logprobs: Optional[int] | NotGiven = NOT_GIVEN,\n    max_tokens: Optional[int] | NotGiven = NOT_GIVEN,\n    n: Optional[int] | NotGiven = NOT_GIVEN,\n    presence_penalty: (\n        Optional[float] | NotGiven\n    ) = NOT_GIVEN,\n    seed: Optional[int] | NotGiven = NOT_GIVEN,\n    stop: (\n        Union[Optional[str], List[str], None] | NotGiven\n    ) = NOT_GIVEN,\n    suffix: Optional[str] | NotGiven = NOT_GIVEN,\n    temperature: Optional[float] | NotGiven = NOT_GIVEN,\n    top_p: Optional[float] | NotGiven = NOT_GIVEN,\n    user: str | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; AsyncStream[Completion]\n</code></pre><pre><code>create(\n    *,\n    model: Union[\n        str,\n        Literal[\n            \"gpt-3.5-turbo-instruct\",\n            \"davinci-002\",\n            \"babbage-002\",\n        ],\n    ],\n    prompt: Union[\n        str,\n        List[str],\n        Iterable[int],\n        Iterable[Iterable[int]],\n        None,\n    ],\n    stream: bool,\n    best_of: Optional[int] | NotGiven = NOT_GIVEN,\n    echo: Optional[bool] | NotGiven = NOT_GIVEN,\n    frequency_penalty: (\n        Optional[float] | NotGiven\n    ) = NOT_GIVEN,\n    logit_bias: (\n        Optional[Dict[str, int]] | NotGiven\n    ) = NOT_GIVEN,\n    logprobs: Optional[int] | NotGiven = NOT_GIVEN,\n    max_tokens: Optional[int] | NotGiven = NOT_GIVEN,\n    n: Optional[int] | NotGiven = NOT_GIVEN,\n    presence_penalty: (\n        Optional[float] | NotGiven\n    ) = NOT_GIVEN,\n    seed: Optional[int] | NotGiven = NOT_GIVEN,\n    stop: (\n        Union[Optional[str], List[str], None] | NotGiven\n    ) = NOT_GIVEN,\n    suffix: Optional[str] | NotGiven = NOT_GIVEN,\n    temperature: Optional[float] | NotGiven = NOT_GIVEN,\n    top_p: Optional[float] | NotGiven = NOT_GIVEN,\n    user: str | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; Completion | AsyncStream[Completion]\n</code></pre> <pre><code>create(\n    *,\n    model: Union[\n        str,\n        Literal[\n            \"gpt-3.5-turbo-instruct\",\n            \"davinci-002\",\n            \"babbage-002\",\n        ],\n    ],\n    prompt: Union[\n        str,\n        List[str],\n        Iterable[int],\n        Iterable[Iterable[int]],\n        None,\n    ],\n    best_of: Optional[int] | NotGiven = NOT_GIVEN,\n    echo: Optional[bool] | NotGiven = NOT_GIVEN,\n    frequency_penalty: (\n        Optional[float] | NotGiven\n    ) = NOT_GIVEN,\n    logit_bias: (\n        Optional[Dict[str, int]] | NotGiven\n    ) = NOT_GIVEN,\n    logprobs: Optional[int] | NotGiven = NOT_GIVEN,\n    max_tokens: Optional[int] | NotGiven = NOT_GIVEN,\n    n: Optional[int] | NotGiven = NOT_GIVEN,\n    presence_penalty: (\n        Optional[float] | NotGiven\n    ) = NOT_GIVEN,\n    seed: Optional[int] | NotGiven = NOT_GIVEN,\n    stop: (\n        Union[Optional[str], List[str], None] | NotGiven\n    ) = NOT_GIVEN,\n    stream: (\n        Optional[Literal[False]] | Literal[True] | NotGiven\n    ) = NOT_GIVEN,\n    suffix: Optional[str] | NotGiven = NOT_GIVEN,\n    temperature: Optional[float] | NotGiven = NOT_GIVEN,\n    top_p: Optional[float] | NotGiven = NOT_GIVEN,\n    user: str | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; Completion | AsyncStream[Completion]\n</code></pre> <p>Creates a completion for the provided prompt and parameters.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>Union[str, Literal['gpt-3.5-turbo-instruct', 'davinci-002', 'babbage-002']]</code> <p>ID of the model to use. You can use the   List models API to   see all of your available models, or see our   Model overview for   descriptions of them.</p> required <code>prompt</code> <code>Union[str, List[str], Iterable[int], Iterable[Iterable[int]], None]</code> <p>The prompt(s) to generate completions for, encoded as a string, array of   strings, array of tokens, or array of token arrays.</p> <p>Note that &lt;|endoftext|&gt; is the document separator that the model sees during   training, so if a prompt is not specified the model will generate as if from the   beginning of a new document.</p> required <code>best_of</code> <code>Optional[int] | NotGiven</code> <p>Generates <code>best_of</code> completions server-side and returns the \"best\" (the one with   the highest log probability per token). Results cannot be streamed.</p> <p>When used with <code>n</code>, <code>best_of</code> controls the number of candidate completions and   <code>n</code> specifies how many to return \u2013 <code>best_of</code> must be greater than <code>n</code>.</p> <p>Note: Because this parameter generates many completions, it can quickly   consume your token quota. Use carefully and ensure that you have reasonable   settings for <code>max_tokens</code> and <code>stop</code>.</p> <code>NOT_GIVEN</code> <code>echo</code> <code>Optional[bool] | NotGiven</code> <p>Echo back the prompt in addition to the completion</p> <code>NOT_GIVEN</code> <code>frequency_penalty</code> <code>Optional[float] | NotGiven</code> <p>Number between -2.0 and 2.0. Positive values penalize new tokens based on their   existing frequency in the text so far, decreasing the model's likelihood to   repeat the same line verbatim.</p> <p>See more information about frequency and presence penalties.</p> <code>NOT_GIVEN</code> <code>logit_bias</code> <code>Optional[Dict[str, int]] | NotGiven</code> <p>Modify the likelihood of specified tokens appearing in the completion.</p> <p>Accepts a JSON object that maps tokens (specified by their token ID in the GPT   tokenizer) to an associated bias value from -100 to 100. You can use this   tokenizer tool to convert text to token IDs.   Mathematically, the bias is added to the logits generated by the model prior to   sampling. The exact effect will vary per model, but values between -1 and 1   should decrease or increase likelihood of selection; values like -100 or 100   should result in a ban or exclusive selection of the relevant token.</p> <p>As an example, you can pass <code>{\"50256\": -100}</code> to prevent the &lt;|endoftext|&gt; token   from being generated.</p> <code>NOT_GIVEN</code> <code>logprobs</code> <code>Optional[int] | NotGiven</code> <p>Include the log probabilities on the <code>logprobs</code> most likely output tokens, as   well the chosen tokens. For example, if <code>logprobs</code> is 5, the API will return a   list of the 5 most likely tokens. The API will always return the <code>logprob</code> of   the sampled token, so there may be up to <code>logprobs+1</code> elements in the response.</p> <p>The maximum value for <code>logprobs</code> is 5.</p> <code>NOT_GIVEN</code> <code>max_tokens</code> <code>Optional[int] | NotGiven</code> <p>The maximum number of tokens that can be generated in the   completion.</p> <p>The token count of your prompt plus <code>max_tokens</code> cannot exceed the model's   context length.   Example Python code   for counting tokens.</p> <code>NOT_GIVEN</code> <code>n</code> <code>Optional[int] | NotGiven</code> <p>How many completions to generate for each prompt.</p> <p>Note: Because this parameter generates many completions, it can quickly   consume your token quota. Use carefully and ensure that you have reasonable   settings for <code>max_tokens</code> and <code>stop</code>.</p> <code>NOT_GIVEN</code> <code>presence_penalty</code> <code>Optional[float] | NotGiven</code> <p>Number between -2.0 and 2.0. Positive values penalize new tokens based on   whether they appear in the text so far, increasing the model's likelihood to   talk about new topics.</p> <p>See more information about frequency and presence penalties.</p> <code>NOT_GIVEN</code> <code>seed</code> <code>Optional[int] | NotGiven</code> <p>If specified, our system will make a best effort to sample deterministically,   such that repeated requests with the same <code>seed</code> and parameters should return   the same result.</p> <p>Determinism is not guaranteed, and you should refer to the <code>system_fingerprint</code>   response parameter to monitor changes in the backend.</p> <code>NOT_GIVEN</code> <code>stop</code> <code>Union[Optional[str], List[str], None] | NotGiven</code> <p>Up to 4 sequences where the API will stop generating further tokens. The   returned text will not contain the stop sequence.</p> <code>NOT_GIVEN</code> <code>stream</code> <code>Optional[Literal[False]] | Literal[True] | NotGiven</code> <p>Whether to stream back partial progress. If set, tokens will be sent as   data-only   server-sent events   as they become available, with the stream terminated by a <code>data: [DONE]</code>   message.   Example Python code.</p> <code>NOT_GIVEN</code> <code>suffix</code> <code>Optional[str] | NotGiven</code> <p>The suffix that comes after a completion of inserted text.</p> <code>NOT_GIVEN</code> <code>temperature</code> <code>Optional[float] | NotGiven</code> <p>What sampling temperature to use, between 0 and 2. Higher values like 0.8 will   make the output more random, while lower values like 0.2 will make it more   focused and deterministic.</p> <p>We generally recommend altering this or <code>top_p</code> but not both.</p> <code>NOT_GIVEN</code> <code>top_p</code> <code>Optional[float] | NotGiven</code> <p>An alternative to sampling with temperature, called nucleus sampling, where the   model considers the results of the tokens with top_p probability mass. So 0.1   means only the tokens comprising the top 10% probability mass are considered.</p> <p>We generally recommend altering this or <code>temperature</code> but not both.</p> <code>NOT_GIVEN</code> <code>user</code> <code>str | NotGiven</code> <p>A unique identifier representing your end-user, which can help OpenAI to monitor   and detect abuse.   Learn more.</p> <code>NOT_GIVEN</code> <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/#src.openai.resources.AsyncCompletions.with_raw_response","title":"with_raw_response","text":"<pre><code>with_raw_response() -&gt; AsyncCompletionsWithRawResponse\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.AsyncCompletions.with_streaming_response","title":"with_streaming_response","text":"<pre><code>with_streaming_response() -&gt; (\n    AsyncCompletionsWithStreamingResponse\n)\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.AsyncCompletionsWithRawResponse","title":"AsyncCompletionsWithRawResponse","text":"<pre><code>AsyncCompletionsWithRawResponse(\n    completions: AsyncCompletions,\n)\n</code></pre> <p>Attributes:</p> Name Type Description <code>create</code>"},{"location":"reference/resources/#src.openai.resources.AsyncCompletionsWithRawResponse.create","title":"create  <code>instance-attribute</code>","text":"<pre><code>create = async_to_raw_response_wrapper(create)\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.AsyncCompletionsWithStreamingResponse","title":"AsyncCompletionsWithStreamingResponse","text":"<pre><code>AsyncCompletionsWithStreamingResponse(\n    completions: AsyncCompletions,\n)\n</code></pre> <p>Attributes:</p> Name Type Description <code>create</code>"},{"location":"reference/resources/#src.openai.resources.AsyncCompletionsWithStreamingResponse.create","title":"create  <code>instance-attribute</code>","text":"<pre><code>create = async_to_streamed_response_wrapper(create)\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.AsyncEmbeddings","title":"AsyncEmbeddings","text":"<pre><code>AsyncEmbeddings(client: AsyncOpenAI)\n</code></pre> <p>Methods:</p> Name Description <code>create</code> <p>Creates an embedding vector representing the input text.</p> <code>with_raw_response</code> <code>with_streaming_response</code>"},{"location":"reference/resources/#src.openai.resources.AsyncEmbeddings.create","title":"create  <code>async</code>","text":"<pre><code>create(\n    *,\n    input: Union[\n        str,\n        List[str],\n        Iterable[int],\n        Iterable[Iterable[int]],\n    ],\n    model: Union[\n        str,\n        Literal[\n            \"text-embedding-ada-002\",\n            \"text-embedding-3-small\",\n            \"text-embedding-3-large\",\n        ],\n    ],\n    dimensions: int | NotGiven = NOT_GIVEN,\n    encoding_format: (\n        Literal[\"float\", \"base64\"] | NotGiven\n    ) = NOT_GIVEN,\n    user: str | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; CreateEmbeddingResponse\n</code></pre> <p>Creates an embedding vector representing the input text.</p> <p>Parameters:</p> Name Type Description Default <code>input</code> <code>Union[str, List[str], Iterable[int], Iterable[Iterable[int]]]</code> <p>Input text to embed, encoded as a string or array of tokens. To embed multiple   inputs in a single request, pass an array of strings or array of token arrays.   The input must not exceed the max input tokens for the model (8192 tokens for   <code>text-embedding-ada-002</code>), cannot be an empty string, and any array must be 2048   dimensions or less.   Example Python code   for counting tokens.</p> required <code>model</code> <code>Union[str, Literal['text-embedding-ada-002', 'text-embedding-3-small', 'text-embedding-3-large']]</code> <p>ID of the model to use. You can use the   List models API to   see all of your available models, or see our   Model overview for   descriptions of them.</p> required <code>dimensions</code> <code>int | NotGiven</code> <p>The number of dimensions the resulting output embeddings should have. Only   supported in <code>text-embedding-3</code> and later models.</p> <code>NOT_GIVEN</code> <code>encoding_format</code> <code>Literal['float', 'base64'] | NotGiven</code> <p>The format to return the embeddings in. Can be either <code>float</code> or   <code>base64</code>.</p> <code>NOT_GIVEN</code> <code>user</code> <code>str | NotGiven</code> <p>A unique identifier representing your end-user, which can help OpenAI to monitor   and detect abuse.   Learn more.</p> <code>NOT_GIVEN</code> <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/#src.openai.resources.AsyncEmbeddings.with_raw_response","title":"with_raw_response","text":"<pre><code>with_raw_response() -&gt; AsyncEmbeddingsWithRawResponse\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.AsyncEmbeddings.with_streaming_response","title":"with_streaming_response","text":"<pre><code>with_streaming_response() -&gt; (\n    AsyncEmbeddingsWithStreamingResponse\n)\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.AsyncEmbeddingsWithRawResponse","title":"AsyncEmbeddingsWithRawResponse","text":"<pre><code>AsyncEmbeddingsWithRawResponse(embeddings: AsyncEmbeddings)\n</code></pre> <p>Attributes:</p> Name Type Description <code>create</code>"},{"location":"reference/resources/#src.openai.resources.AsyncEmbeddingsWithRawResponse.create","title":"create  <code>instance-attribute</code>","text":"<pre><code>create = async_to_raw_response_wrapper(create)\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.AsyncEmbeddingsWithStreamingResponse","title":"AsyncEmbeddingsWithStreamingResponse","text":"<pre><code>AsyncEmbeddingsWithStreamingResponse(\n    embeddings: AsyncEmbeddings,\n)\n</code></pre> <p>Attributes:</p> Name Type Description <code>create</code>"},{"location":"reference/resources/#src.openai.resources.AsyncEmbeddingsWithStreamingResponse.create","title":"create  <code>instance-attribute</code>","text":"<pre><code>create = async_to_streamed_response_wrapper(create)\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.AsyncFiles","title":"AsyncFiles","text":"<pre><code>AsyncFiles(client: AsyncOpenAI)\n</code></pre> <p>Methods:</p> Name Description <code>content</code> <p>Returns the contents of the specified file.</p> <code>create</code> <p>Upload a file that can be used across various endpoints.</p> <code>delete</code> <p>Delete a file.</p> <code>list</code> <p>Returns a list of files that belong to the user's organization.</p> <code>retrieve</code> <p>Returns information about a specific file.</p> <code>retrieve_content</code> <p>Returns the contents of the specified file.</p> <code>wait_for_processing</code> <p>Waits for the given file to be processed, default timeout is 30 mins.</p> <code>with_raw_response</code> <code>with_streaming_response</code>"},{"location":"reference/resources/#src.openai.resources.AsyncFiles.content","title":"content  <code>async</code>","text":"<pre><code>content(\n    file_id: str,\n    *,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; HttpxBinaryResponseContent\n</code></pre> <p>Returns the contents of the specified file.</p> <p>Parameters:</p> Name Type Description Default <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/#src.openai.resources.AsyncFiles.create","title":"create  <code>async</code>","text":"<pre><code>create(\n    *,\n    file: FileTypes,\n    purpose: Literal[\"fine-tune\", \"assistants\"],\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; FileObject\n</code></pre> <p>Upload a file that can be used across various endpoints.</p> <p>The size of all the files uploaded by one organization can be up to 100 GB.</p> <p>The size of individual files can be a maximum of 512 MB or 2 million tokens for Assistants. See the Assistants Tools guide to learn more about the types of files supported. The Fine-tuning API only supports <code>.jsonl</code> files.</p> <p>Please contact us if you need to increase these storage limits.</p> <p>Parameters:</p> Name Type Description Default <code>file</code> <code>FileTypes</code> <p>The File object (not file name) to be uploaded.</p> required <code>purpose</code> <code>Literal['fine-tune', 'assistants']</code> <p>The intended purpose of the uploaded file.</p> <p>Use \"fine-tune\" for   Fine-tuning and   \"assistants\" for   Assistants and   Messages. This allows   us to validate the format of the uploaded file is correct for fine-tuning.</p> required <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/#src.openai.resources.AsyncFiles.delete","title":"delete  <code>async</code>","text":"<pre><code>delete(\n    file_id: str,\n    *,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; FileDeleted\n</code></pre> <p>Delete a file.</p> <p>Parameters:</p> Name Type Description Default <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/#src.openai.resources.AsyncFiles.list","title":"list","text":"<pre><code>list(\n    *,\n    purpose: str | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; AsyncPaginator[FileObject, AsyncPage[FileObject]]\n</code></pre> <p>Returns a list of files that belong to the user's organization.</p> <p>Parameters:</p> Name Type Description Default <code>purpose</code> <code>str | NotGiven</code> <p>Only return files with the given purpose.</p> <code>NOT_GIVEN</code> <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/#src.openai.resources.AsyncFiles.retrieve","title":"retrieve  <code>async</code>","text":"<pre><code>retrieve(\n    file_id: str,\n    *,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; FileObject\n</code></pre> <p>Returns information about a specific file.</p> <p>Parameters:</p> Name Type Description Default <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/#src.openai.resources.AsyncFiles.retrieve_content","title":"retrieve_content  <code>async</code>","text":"<pre><code>retrieve_content(\n    file_id: str,\n    *,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; str\n</code></pre> <p>Returns the contents of the specified file.</p> <p>Parameters:</p> Name Type Description Default <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/#src.openai.resources.AsyncFiles.wait_for_processing","title":"wait_for_processing  <code>async</code>","text":"<pre><code>wait_for_processing(\n    id: str,\n    *,\n    poll_interval: float = 5.0,\n    max_wait_seconds: float = 30 * 60\n) -&gt; FileObject\n</code></pre> <p>Waits for the given file to be processed, default timeout is 30 mins.</p>"},{"location":"reference/resources/#src.openai.resources.AsyncFiles.with_raw_response","title":"with_raw_response","text":"<pre><code>with_raw_response() -&gt; AsyncFilesWithRawResponse\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.AsyncFiles.with_streaming_response","title":"with_streaming_response","text":"<pre><code>with_streaming_response() -&gt; (\n    AsyncFilesWithStreamingResponse\n)\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.AsyncFilesWithRawResponse","title":"AsyncFilesWithRawResponse","text":"<pre><code>AsyncFilesWithRawResponse(files: AsyncFiles)\n</code></pre> <p>Attributes:</p> Name Type Description <code>content</code> <code>create</code> <code>delete</code> <code>list</code> <code>retrieve</code> <code>retrieve_content</code>"},{"location":"reference/resources/#src.openai.resources.AsyncFilesWithRawResponse.content","title":"content  <code>instance-attribute</code>","text":"<pre><code>content = async_to_raw_response_wrapper(content)\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.AsyncFilesWithRawResponse.create","title":"create  <code>instance-attribute</code>","text":"<pre><code>create = async_to_raw_response_wrapper(create)\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.AsyncFilesWithRawResponse.delete","title":"delete  <code>instance-attribute</code>","text":"<pre><code>delete = async_to_raw_response_wrapper(delete)\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.AsyncFilesWithRawResponse.list","title":"list  <code>instance-attribute</code>","text":"<pre><code>list = async_to_raw_response_wrapper(list)\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.AsyncFilesWithRawResponse.retrieve","title":"retrieve  <code>instance-attribute</code>","text":"<pre><code>retrieve = async_to_raw_response_wrapper(retrieve)\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.AsyncFilesWithRawResponse.retrieve_content","title":"retrieve_content  <code>instance-attribute</code>","text":"<pre><code>retrieve_content = async_to_raw_response_wrapper(\n    retrieve_content\n)\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.AsyncFilesWithStreamingResponse","title":"AsyncFilesWithStreamingResponse","text":"<pre><code>AsyncFilesWithStreamingResponse(files: AsyncFiles)\n</code></pre> <p>Attributes:</p> Name Type Description <code>content</code> <code>create</code> <code>delete</code> <code>list</code> <code>retrieve</code> <code>retrieve_content</code>"},{"location":"reference/resources/#src.openai.resources.AsyncFilesWithStreamingResponse.content","title":"content  <code>instance-attribute</code>","text":"<pre><code>content = async_to_custom_streamed_response_wrapper(\n    content, AsyncStreamedBinaryAPIResponse\n)\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.AsyncFilesWithStreamingResponse.create","title":"create  <code>instance-attribute</code>","text":"<pre><code>create = async_to_streamed_response_wrapper(create)\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.AsyncFilesWithStreamingResponse.delete","title":"delete  <code>instance-attribute</code>","text":"<pre><code>delete = async_to_streamed_response_wrapper(delete)\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.AsyncFilesWithStreamingResponse.list","title":"list  <code>instance-attribute</code>","text":"<pre><code>list = async_to_streamed_response_wrapper(list)\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.AsyncFilesWithStreamingResponse.retrieve","title":"retrieve  <code>instance-attribute</code>","text":"<pre><code>retrieve = async_to_streamed_response_wrapper(retrieve)\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.AsyncFilesWithStreamingResponse.retrieve_content","title":"retrieve_content  <code>instance-attribute</code>","text":"<pre><code>retrieve_content = async_to_streamed_response_wrapper(\n    retrieve_content\n)\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.AsyncFineTuning","title":"AsyncFineTuning","text":"<pre><code>AsyncFineTuning(client: AsyncOpenAI)\n</code></pre> <p>Methods:</p> Name Description <code>jobs</code> <code>with_raw_response</code> <code>with_streaming_response</code>"},{"location":"reference/resources/#src.openai.resources.AsyncFineTuning.jobs","title":"jobs","text":"<pre><code>jobs() -&gt; AsyncJobs\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.AsyncFineTuning.with_raw_response","title":"with_raw_response","text":"<pre><code>with_raw_response() -&gt; AsyncFineTuningWithRawResponse\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.AsyncFineTuning.with_streaming_response","title":"with_streaming_response","text":"<pre><code>with_streaming_response() -&gt; (\n    AsyncFineTuningWithStreamingResponse\n)\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.AsyncFineTuningWithRawResponse","title":"AsyncFineTuningWithRawResponse","text":"<pre><code>AsyncFineTuningWithRawResponse(\n    fine_tuning: AsyncFineTuning,\n)\n</code></pre> <p>Methods:</p> Name Description <code>jobs</code>"},{"location":"reference/resources/#src.openai.resources.AsyncFineTuningWithRawResponse.jobs","title":"jobs","text":"<pre><code>jobs() -&gt; AsyncJobsWithRawResponse\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.AsyncFineTuningWithStreamingResponse","title":"AsyncFineTuningWithStreamingResponse","text":"<pre><code>AsyncFineTuningWithStreamingResponse(\n    fine_tuning: AsyncFineTuning,\n)\n</code></pre> <p>Methods:</p> Name Description <code>jobs</code>"},{"location":"reference/resources/#src.openai.resources.AsyncFineTuningWithStreamingResponse.jobs","title":"jobs","text":"<pre><code>jobs() -&gt; AsyncJobsWithStreamingResponse\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.AsyncImages","title":"AsyncImages","text":"<pre><code>AsyncImages(client: AsyncOpenAI)\n</code></pre> <p>Methods:</p> Name Description <code>create_variation</code> <p>Creates a variation of a given image.</p> <code>edit</code> <p>Creates an edited or extended image given an original image and a prompt.</p> <code>generate</code> <p>Creates an image given a prompt.</p> <code>with_raw_response</code> <code>with_streaming_response</code>"},{"location":"reference/resources/#src.openai.resources.AsyncImages.create_variation","title":"create_variation  <code>async</code>","text":"<pre><code>create_variation(\n    *,\n    image: FileTypes,\n    model: (\n        Union[str, Literal[\"dall-e-2\"], None] | NotGiven\n    ) = NOT_GIVEN,\n    n: Optional[int] | NotGiven = NOT_GIVEN,\n    response_format: (\n        Optional[Literal[\"url\", \"b64_json\"]] | NotGiven\n    ) = NOT_GIVEN,\n    size: (\n        Optional[Literal[\"256x256\", \"512x512\", \"1024x1024\"]]\n        | NotGiven\n    ) = NOT_GIVEN,\n    user: str | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; ImagesResponse\n</code></pre> <p>Creates a variation of a given image.</p> <p>Parameters:</p> Name Type Description Default <code>image</code> <code>FileTypes</code> <p>The image to use as the basis for the variation(s). Must be a valid PNG file,   less than 4MB, and square.</p> required <code>model</code> <code>Union[str, Literal['dall-e-2'], None] | NotGiven</code> <p>The model to use for image generation. Only <code>dall-e-2</code> is supported at this   time.</p> <code>NOT_GIVEN</code> <code>n</code> <code>Optional[int] | NotGiven</code> <p>The number of images to generate. Must be between 1 and 10. For <code>dall-e-3</code>, only   <code>n=1</code> is supported.</p> <code>NOT_GIVEN</code> <code>response_format</code> <code>Optional[Literal['url', 'b64_json']] | NotGiven</code> <p>The format in which the generated images are returned. Must be one of <code>url</code> or   <code>b64_json</code>. URLs are only valid for 60 minutes after the image has been   generated.</p> <code>NOT_GIVEN</code> <code>size</code> <code>Optional[Literal['256x256', '512x512', '1024x1024']] | NotGiven</code> <p>The size of the generated images. Must be one of <code>256x256</code>, <code>512x512</code>, or   <code>1024x1024</code>.</p> <code>NOT_GIVEN</code> <code>user</code> <code>str | NotGiven</code> <p>A unique identifier representing your end-user, which can help OpenAI to monitor   and detect abuse.   Learn more.</p> <code>NOT_GIVEN</code> <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/#src.openai.resources.AsyncImages.edit","title":"edit  <code>async</code>","text":"<pre><code>edit(\n    *,\n    image: FileTypes,\n    prompt: str,\n    mask: FileTypes | NotGiven = NOT_GIVEN,\n    model: (\n        Union[str, Literal[\"dall-e-2\"], None] | NotGiven\n    ) = NOT_GIVEN,\n    n: Optional[int] | NotGiven = NOT_GIVEN,\n    response_format: (\n        Optional[Literal[\"url\", \"b64_json\"]] | NotGiven\n    ) = NOT_GIVEN,\n    size: (\n        Optional[Literal[\"256x256\", \"512x512\", \"1024x1024\"]]\n        | NotGiven\n    ) = NOT_GIVEN,\n    user: str | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; ImagesResponse\n</code></pre> <p>Creates an edited or extended image given an original image and a prompt.</p> <p>Parameters:</p> Name Type Description Default <code>image</code> <code>FileTypes</code> <p>The image to edit. Must be a valid PNG file, less than 4MB, and square. If mask   is not provided, image must have transparency, which will be used as the mask.</p> required <code>prompt</code> <code>str</code> <p>A text description of the desired image(s). The maximum length is 1000   characters.</p> required <code>mask</code> <code>FileTypes | NotGiven</code> <p>An additional image whose fully transparent areas (e.g. where alpha is zero)   indicate where <code>image</code> should be edited. Must be a valid PNG file, less than   4MB, and have the same dimensions as <code>image</code>.</p> <code>NOT_GIVEN</code> <code>model</code> <code>Union[str, Literal['dall-e-2'], None] | NotGiven</code> <p>The model to use for image generation. Only <code>dall-e-2</code> is supported at this   time.</p> <code>NOT_GIVEN</code> <code>n</code> <code>Optional[int] | NotGiven</code> <p>The number of images to generate. Must be between 1 and 10.</p> <code>NOT_GIVEN</code> <code>response_format</code> <code>Optional[Literal['url', 'b64_json']] | NotGiven</code> <p>The format in which the generated images are returned. Must be one of <code>url</code> or   <code>b64_json</code>. URLs are only valid for 60 minutes after the image has been   generated.</p> <code>NOT_GIVEN</code> <code>size</code> <code>Optional[Literal['256x256', '512x512', '1024x1024']] | NotGiven</code> <p>The size of the generated images. Must be one of <code>256x256</code>, <code>512x512</code>, or   <code>1024x1024</code>.</p> <code>NOT_GIVEN</code> <code>user</code> <code>str | NotGiven</code> <p>A unique identifier representing your end-user, which can help OpenAI to monitor   and detect abuse.   Learn more.</p> <code>NOT_GIVEN</code> <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/#src.openai.resources.AsyncImages.generate","title":"generate  <code>async</code>","text":"<pre><code>generate(\n    *,\n    prompt: str,\n    model: (\n        Union[str, Literal[\"dall-e-2\", \"dall-e-3\"], None]\n        | NotGiven\n    ) = NOT_GIVEN,\n    n: Optional[int] | NotGiven = NOT_GIVEN,\n    quality: (\n        Literal[\"standard\", \"hd\"] | NotGiven\n    ) = NOT_GIVEN,\n    response_format: (\n        Optional[Literal[\"url\", \"b64_json\"]] | NotGiven\n    ) = NOT_GIVEN,\n    size: (\n        Optional[\n            Literal[\n                \"256x256\",\n                \"512x512\",\n                \"1024x1024\",\n                \"1792x1024\",\n                \"1024x1792\",\n            ]\n        ]\n        | NotGiven\n    ) = NOT_GIVEN,\n    style: (\n        Optional[Literal[\"vivid\", \"natural\"]] | NotGiven\n    ) = NOT_GIVEN,\n    user: str | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; ImagesResponse\n</code></pre> <p>Creates an image given a prompt.</p> <p>Parameters:</p> Name Type Description Default <code>prompt</code> <code>str</code> <p>A text description of the desired image(s). The maximum length is 1000   characters for <code>dall-e-2</code> and 4000 characters for <code>dall-e-3</code>.</p> required <code>model</code> <code>Union[str, Literal['dall-e-2', 'dall-e-3'], None] | NotGiven</code> <p>The model to use for image generation.</p> <code>NOT_GIVEN</code> <code>n</code> <code>Optional[int] | NotGiven</code> <p>The number of images to generate. Must be between 1 and 10. For <code>dall-e-3</code>, only   <code>n=1</code> is supported.</p> <code>NOT_GIVEN</code> <code>quality</code> <code>Literal['standard', 'hd'] | NotGiven</code> <p>The quality of the image that will be generated. <code>hd</code> creates images with finer   details and greater consistency across the image. This param is only supported   for <code>dall-e-3</code>.</p> <code>NOT_GIVEN</code> <code>response_format</code> <code>Optional[Literal['url', 'b64_json']] | NotGiven</code> <p>The format in which the generated images are returned. Must be one of <code>url</code> or   <code>b64_json</code>. URLs are only valid for 60 minutes after the image has been   generated.</p> <code>NOT_GIVEN</code> <code>size</code> <code>Optional[Literal['256x256', '512x512', '1024x1024', '1792x1024', '1024x1792']] | NotGiven</code> <p>The size of the generated images. Must be one of <code>256x256</code>, <code>512x512</code>, or   <code>1024x1024</code> for <code>dall-e-2</code>. Must be one of <code>1024x1024</code>, <code>1792x1024</code>, or   <code>1024x1792</code> for <code>dall-e-3</code> models.</p> <code>NOT_GIVEN</code> <code>style</code> <code>Optional[Literal['vivid', 'natural']] | NotGiven</code> <p>The style of the generated images. Must be one of <code>vivid</code> or <code>natural</code>. Vivid   causes the model to lean towards generating hyper-real and dramatic images.   Natural causes the model to produce more natural, less hyper-real looking   images. This param is only supported for <code>dall-e-3</code>.</p> <code>NOT_GIVEN</code> <code>user</code> <code>str | NotGiven</code> <p>A unique identifier representing your end-user, which can help OpenAI to monitor   and detect abuse.   Learn more.</p> <code>NOT_GIVEN</code> <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/#src.openai.resources.AsyncImages.with_raw_response","title":"with_raw_response","text":"<pre><code>with_raw_response() -&gt; AsyncImagesWithRawResponse\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.AsyncImages.with_streaming_response","title":"with_streaming_response","text":"<pre><code>with_streaming_response() -&gt; (\n    AsyncImagesWithStreamingResponse\n)\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.AsyncImagesWithRawResponse","title":"AsyncImagesWithRawResponse","text":"<pre><code>AsyncImagesWithRawResponse(images: AsyncImages)\n</code></pre> <p>Attributes:</p> Name Type Description <code>create_variation</code> <code>edit</code> <code>generate</code>"},{"location":"reference/resources/#src.openai.resources.AsyncImagesWithRawResponse.create_variation","title":"create_variation  <code>instance-attribute</code>","text":"<pre><code>create_variation = async_to_raw_response_wrapper(\n    create_variation\n)\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.AsyncImagesWithRawResponse.edit","title":"edit  <code>instance-attribute</code>","text":"<pre><code>edit = async_to_raw_response_wrapper(edit)\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.AsyncImagesWithRawResponse.generate","title":"generate  <code>instance-attribute</code>","text":"<pre><code>generate = async_to_raw_response_wrapper(generate)\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.AsyncImagesWithStreamingResponse","title":"AsyncImagesWithStreamingResponse","text":"<pre><code>AsyncImagesWithStreamingResponse(images: AsyncImages)\n</code></pre> <p>Attributes:</p> Name Type Description <code>create_variation</code> <code>edit</code> <code>generate</code>"},{"location":"reference/resources/#src.openai.resources.AsyncImagesWithStreamingResponse.create_variation","title":"create_variation  <code>instance-attribute</code>","text":"<pre><code>create_variation = async_to_streamed_response_wrapper(\n    create_variation\n)\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.AsyncImagesWithStreamingResponse.edit","title":"edit  <code>instance-attribute</code>","text":"<pre><code>edit = async_to_streamed_response_wrapper(edit)\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.AsyncImagesWithStreamingResponse.generate","title":"generate  <code>instance-attribute</code>","text":"<pre><code>generate = async_to_streamed_response_wrapper(generate)\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.AsyncModels","title":"AsyncModels","text":"<pre><code>AsyncModels(client: AsyncOpenAI)\n</code></pre> <p>Methods:</p> Name Description <code>delete</code> <p>Delete a fine-tuned model.</p> <code>list</code> <p>Lists the currently available models, and provides basic information about each</p> <code>retrieve</code> <p>Retrieves a model instance, providing basic information about the model such as</p> <code>with_raw_response</code> <code>with_streaming_response</code>"},{"location":"reference/resources/#src.openai.resources.AsyncModels.delete","title":"delete  <code>async</code>","text":"<pre><code>delete(\n    model: str,\n    *,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; ModelDeleted\n</code></pre> <p>Delete a fine-tuned model.</p> <p>You must have the Owner role in your organization to delete a model.</p> <p>Parameters:</p> Name Type Description Default <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/#src.openai.resources.AsyncModels.list","title":"list","text":"<pre><code>list(\n    *,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; AsyncPaginator[Model, AsyncPage[Model]]\n</code></pre> <p>Lists the currently available models, and provides basic information about each one such as the owner and availability.</p>"},{"location":"reference/resources/#src.openai.resources.AsyncModels.retrieve","title":"retrieve  <code>async</code>","text":"<pre><code>retrieve(\n    model: str,\n    *,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; Model\n</code></pre> <p>Retrieves a model instance, providing basic information about the model such as the owner and permissioning.</p> <p>Parameters:</p> Name Type Description Default <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/#src.openai.resources.AsyncModels.with_raw_response","title":"with_raw_response","text":"<pre><code>with_raw_response() -&gt; AsyncModelsWithRawResponse\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.AsyncModels.with_streaming_response","title":"with_streaming_response","text":"<pre><code>with_streaming_response() -&gt; (\n    AsyncModelsWithStreamingResponse\n)\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.AsyncModelsWithRawResponse","title":"AsyncModelsWithRawResponse","text":"<pre><code>AsyncModelsWithRawResponse(models: AsyncModels)\n</code></pre> <p>Attributes:</p> Name Type Description <code>delete</code> <code>list</code> <code>retrieve</code>"},{"location":"reference/resources/#src.openai.resources.AsyncModelsWithRawResponse.delete","title":"delete  <code>instance-attribute</code>","text":"<pre><code>delete = async_to_raw_response_wrapper(delete)\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.AsyncModelsWithRawResponse.list","title":"list  <code>instance-attribute</code>","text":"<pre><code>list = async_to_raw_response_wrapper(list)\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.AsyncModelsWithRawResponse.retrieve","title":"retrieve  <code>instance-attribute</code>","text":"<pre><code>retrieve = async_to_raw_response_wrapper(retrieve)\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.AsyncModelsWithStreamingResponse","title":"AsyncModelsWithStreamingResponse","text":"<pre><code>AsyncModelsWithStreamingResponse(models: AsyncModels)\n</code></pre> <p>Attributes:</p> Name Type Description <code>delete</code> <code>list</code> <code>retrieve</code>"},{"location":"reference/resources/#src.openai.resources.AsyncModelsWithStreamingResponse.delete","title":"delete  <code>instance-attribute</code>","text":"<pre><code>delete = async_to_streamed_response_wrapper(delete)\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.AsyncModelsWithStreamingResponse.list","title":"list  <code>instance-attribute</code>","text":"<pre><code>list = async_to_streamed_response_wrapper(list)\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.AsyncModelsWithStreamingResponse.retrieve","title":"retrieve  <code>instance-attribute</code>","text":"<pre><code>retrieve = async_to_streamed_response_wrapper(retrieve)\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.AsyncModerations","title":"AsyncModerations","text":"<pre><code>AsyncModerations(client: AsyncOpenAI)\n</code></pre> <p>Methods:</p> Name Description <code>create</code> <p>Classifies if text is potentially harmful.</p> <code>with_raw_response</code> <code>with_streaming_response</code>"},{"location":"reference/resources/#src.openai.resources.AsyncModerations.create","title":"create  <code>async</code>","text":"<pre><code>create(\n    *,\n    input: Union[str, List[str]],\n    model: (\n        Union[\n            str,\n            Literal[\n                \"text-moderation-latest\",\n                \"text-moderation-stable\",\n            ],\n        ]\n        | NotGiven\n    ) = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; ModerationCreateResponse\n</code></pre> <p>Classifies if text is potentially harmful.</p> <p>Parameters:</p> Name Type Description Default <code>input</code> <code>Union[str, List[str]]</code> <p>The input text to classify</p> required <code>model</code> <code>Union[str, Literal['text-moderation-latest', 'text-moderation-stable']] | NotGiven</code> <p>Two content moderations models are available: <code>text-moderation-stable</code> and   <code>text-moderation-latest</code>.</p> <p>The default is <code>text-moderation-latest</code> which will be automatically upgraded   over time. This ensures you are always using our most accurate model. If you use   <code>text-moderation-stable</code>, we will provide advanced notice before updating the   model. Accuracy of <code>text-moderation-stable</code> may be slightly lower than for   <code>text-moderation-latest</code>.</p> <code>NOT_GIVEN</code> <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/#src.openai.resources.AsyncModerations.with_raw_response","title":"with_raw_response","text":"<pre><code>with_raw_response() -&gt; AsyncModerationsWithRawResponse\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.AsyncModerations.with_streaming_response","title":"with_streaming_response","text":"<pre><code>with_streaming_response() -&gt; (\n    AsyncModerationsWithStreamingResponse\n)\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.AsyncModerationsWithRawResponse","title":"AsyncModerationsWithRawResponse","text":"<pre><code>AsyncModerationsWithRawResponse(\n    moderations: AsyncModerations,\n)\n</code></pre> <p>Attributes:</p> Name Type Description <code>create</code>"},{"location":"reference/resources/#src.openai.resources.AsyncModerationsWithRawResponse.create","title":"create  <code>instance-attribute</code>","text":"<pre><code>create = async_to_raw_response_wrapper(create)\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.AsyncModerationsWithStreamingResponse","title":"AsyncModerationsWithStreamingResponse","text":"<pre><code>AsyncModerationsWithStreamingResponse(\n    moderations: AsyncModerations,\n)\n</code></pre> <p>Attributes:</p> Name Type Description <code>create</code>"},{"location":"reference/resources/#src.openai.resources.AsyncModerationsWithStreamingResponse.create","title":"create  <code>instance-attribute</code>","text":"<pre><code>create = async_to_streamed_response_wrapper(create)\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.Audio","title":"Audio","text":"<pre><code>Audio(client: OpenAI)\n</code></pre> <p>Methods:</p> Name Description <code>speech</code> <code>transcriptions</code> <code>translations</code> <code>with_raw_response</code> <code>with_streaming_response</code>"},{"location":"reference/resources/#src.openai.resources.Audio.speech","title":"speech","text":"<pre><code>speech() -&gt; Speech\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.Audio.transcriptions","title":"transcriptions","text":"<pre><code>transcriptions() -&gt; Transcriptions\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.Audio.translations","title":"translations","text":"<pre><code>translations() -&gt; Translations\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.Audio.with_raw_response","title":"with_raw_response","text":"<pre><code>with_raw_response() -&gt; AudioWithRawResponse\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.Audio.with_streaming_response","title":"with_streaming_response","text":"<pre><code>with_streaming_response() -&gt; AudioWithStreamingResponse\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.AudioWithRawResponse","title":"AudioWithRawResponse","text":"<pre><code>AudioWithRawResponse(audio: Audio)\n</code></pre> <p>Methods:</p> Name Description <code>speech</code> <code>transcriptions</code> <code>translations</code>"},{"location":"reference/resources/#src.openai.resources.AudioWithRawResponse.speech","title":"speech","text":"<pre><code>speech() -&gt; SpeechWithRawResponse\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.AudioWithRawResponse.transcriptions","title":"transcriptions","text":"<pre><code>transcriptions() -&gt; TranscriptionsWithRawResponse\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.AudioWithRawResponse.translations","title":"translations","text":"<pre><code>translations() -&gt; TranslationsWithRawResponse\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.AudioWithStreamingResponse","title":"AudioWithStreamingResponse","text":"<pre><code>AudioWithStreamingResponse(audio: Audio)\n</code></pre> <p>Methods:</p> Name Description <code>speech</code> <code>transcriptions</code> <code>translations</code>"},{"location":"reference/resources/#src.openai.resources.AudioWithStreamingResponse.speech","title":"speech","text":"<pre><code>speech() -&gt; SpeechWithStreamingResponse\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.AudioWithStreamingResponse.transcriptions","title":"transcriptions","text":"<pre><code>transcriptions() -&gt; TranscriptionsWithStreamingResponse\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.AudioWithStreamingResponse.translations","title":"translations","text":"<pre><code>translations() -&gt; TranslationsWithStreamingResponse\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.Beta","title":"Beta","text":"<pre><code>Beta(client: OpenAI)\n</code></pre> <p>Methods:</p> Name Description <code>assistants</code> <code>threads</code> <code>with_raw_response</code> <code>with_streaming_response</code>"},{"location":"reference/resources/#src.openai.resources.Beta.assistants","title":"assistants","text":"<pre><code>assistants() -&gt; Assistants\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.Beta.threads","title":"threads","text":"<pre><code>threads() -&gt; Threads\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.Beta.with_raw_response","title":"with_raw_response","text":"<pre><code>with_raw_response() -&gt; BetaWithRawResponse\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.Beta.with_streaming_response","title":"with_streaming_response","text":"<pre><code>with_streaming_response() -&gt; BetaWithStreamingResponse\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.BetaWithRawResponse","title":"BetaWithRawResponse","text":"<pre><code>BetaWithRawResponse(beta: Beta)\n</code></pre> <p>Methods:</p> Name Description <code>assistants</code> <code>threads</code>"},{"location":"reference/resources/#src.openai.resources.BetaWithRawResponse.assistants","title":"assistants","text":"<pre><code>assistants() -&gt; AssistantsWithRawResponse\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.BetaWithRawResponse.threads","title":"threads","text":"<pre><code>threads() -&gt; ThreadsWithRawResponse\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.BetaWithStreamingResponse","title":"BetaWithStreamingResponse","text":"<pre><code>BetaWithStreamingResponse(beta: Beta)\n</code></pre> <p>Methods:</p> Name Description <code>assistants</code> <code>threads</code>"},{"location":"reference/resources/#src.openai.resources.BetaWithStreamingResponse.assistants","title":"assistants","text":"<pre><code>assistants() -&gt; AssistantsWithStreamingResponse\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.BetaWithStreamingResponse.threads","title":"threads","text":"<pre><code>threads() -&gt; ThreadsWithStreamingResponse\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.Chat","title":"Chat","text":"<pre><code>Chat(client: OpenAI)\n</code></pre> <p>Methods:</p> Name Description <code>completions</code> <code>with_raw_response</code> <code>with_streaming_response</code>"},{"location":"reference/resources/#src.openai.resources.Chat.completions","title":"completions","text":"<pre><code>completions() -&gt; Completions\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.Chat.with_raw_response","title":"with_raw_response","text":"<pre><code>with_raw_response() -&gt; ChatWithRawResponse\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.Chat.with_streaming_response","title":"with_streaming_response","text":"<pre><code>with_streaming_response() -&gt; ChatWithStreamingResponse\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.ChatWithRawResponse","title":"ChatWithRawResponse","text":"<pre><code>ChatWithRawResponse(chat: Chat)\n</code></pre> <p>Methods:</p> Name Description <code>completions</code>"},{"location":"reference/resources/#src.openai.resources.ChatWithRawResponse.completions","title":"completions","text":"<pre><code>completions() -&gt; CompletionsWithRawResponse\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.ChatWithStreamingResponse","title":"ChatWithStreamingResponse","text":"<pre><code>ChatWithStreamingResponse(chat: Chat)\n</code></pre> <p>Methods:</p> Name Description <code>completions</code>"},{"location":"reference/resources/#src.openai.resources.ChatWithStreamingResponse.completions","title":"completions","text":"<pre><code>completions() -&gt; CompletionsWithStreamingResponse\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.Completions","title":"Completions","text":"<pre><code>Completions(client: OpenAI)\n</code></pre> <p>Methods:</p> Name Description <code>create</code> <p>Creates a completion for the provided prompt and parameters.</p> <code>with_raw_response</code> <code>with_streaming_response</code>"},{"location":"reference/resources/#src.openai.resources.Completions.create","title":"create","text":"<pre><code>create(\n    *,\n    model: Union[\n        str,\n        Literal[\n            \"gpt-3.5-turbo-instruct\",\n            \"davinci-002\",\n            \"babbage-002\",\n        ],\n    ],\n    prompt: Union[\n        str,\n        List[str],\n        Iterable[int],\n        Iterable[Iterable[int]],\n        None,\n    ],\n    best_of: Optional[int] | NotGiven = NOT_GIVEN,\n    echo: Optional[bool] | NotGiven = NOT_GIVEN,\n    frequency_penalty: (\n        Optional[float] | NotGiven\n    ) = NOT_GIVEN,\n    logit_bias: (\n        Optional[Dict[str, int]] | NotGiven\n    ) = NOT_GIVEN,\n    logprobs: Optional[int] | NotGiven = NOT_GIVEN,\n    max_tokens: Optional[int] | NotGiven = NOT_GIVEN,\n    n: Optional[int] | NotGiven = NOT_GIVEN,\n    presence_penalty: (\n        Optional[float] | NotGiven\n    ) = NOT_GIVEN,\n    seed: Optional[int] | NotGiven = NOT_GIVEN,\n    stop: (\n        Union[Optional[str], List[str], None] | NotGiven\n    ) = NOT_GIVEN,\n    stream: Optional[Literal[False]] | NotGiven = NOT_GIVEN,\n    suffix: Optional[str] | NotGiven = NOT_GIVEN,\n    temperature: Optional[float] | NotGiven = NOT_GIVEN,\n    top_p: Optional[float] | NotGiven = NOT_GIVEN,\n    user: str | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; Completion\n</code></pre><pre><code>create(\n    *,\n    model: Union[\n        str,\n        Literal[\n            \"gpt-3.5-turbo-instruct\",\n            \"davinci-002\",\n            \"babbage-002\",\n        ],\n    ],\n    prompt: Union[\n        str,\n        List[str],\n        Iterable[int],\n        Iterable[Iterable[int]],\n        None,\n    ],\n    stream: Literal[True],\n    best_of: Optional[int] | NotGiven = NOT_GIVEN,\n    echo: Optional[bool] | NotGiven = NOT_GIVEN,\n    frequency_penalty: (\n        Optional[float] | NotGiven\n    ) = NOT_GIVEN,\n    logit_bias: (\n        Optional[Dict[str, int]] | NotGiven\n    ) = NOT_GIVEN,\n    logprobs: Optional[int] | NotGiven = NOT_GIVEN,\n    max_tokens: Optional[int] | NotGiven = NOT_GIVEN,\n    n: Optional[int] | NotGiven = NOT_GIVEN,\n    presence_penalty: (\n        Optional[float] | NotGiven\n    ) = NOT_GIVEN,\n    seed: Optional[int] | NotGiven = NOT_GIVEN,\n    stop: (\n        Union[Optional[str], List[str], None] | NotGiven\n    ) = NOT_GIVEN,\n    suffix: Optional[str] | NotGiven = NOT_GIVEN,\n    temperature: Optional[float] | NotGiven = NOT_GIVEN,\n    top_p: Optional[float] | NotGiven = NOT_GIVEN,\n    user: str | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; Stream[Completion]\n</code></pre><pre><code>create(\n    *,\n    model: Union[\n        str,\n        Literal[\n            \"gpt-3.5-turbo-instruct\",\n            \"davinci-002\",\n            \"babbage-002\",\n        ],\n    ],\n    prompt: Union[\n        str,\n        List[str],\n        Iterable[int],\n        Iterable[Iterable[int]],\n        None,\n    ],\n    stream: bool,\n    best_of: Optional[int] | NotGiven = NOT_GIVEN,\n    echo: Optional[bool] | NotGiven = NOT_GIVEN,\n    frequency_penalty: (\n        Optional[float] | NotGiven\n    ) = NOT_GIVEN,\n    logit_bias: (\n        Optional[Dict[str, int]] | NotGiven\n    ) = NOT_GIVEN,\n    logprobs: Optional[int] | NotGiven = NOT_GIVEN,\n    max_tokens: Optional[int] | NotGiven = NOT_GIVEN,\n    n: Optional[int] | NotGiven = NOT_GIVEN,\n    presence_penalty: (\n        Optional[float] | NotGiven\n    ) = NOT_GIVEN,\n    seed: Optional[int] | NotGiven = NOT_GIVEN,\n    stop: (\n        Union[Optional[str], List[str], None] | NotGiven\n    ) = NOT_GIVEN,\n    suffix: Optional[str] | NotGiven = NOT_GIVEN,\n    temperature: Optional[float] | NotGiven = NOT_GIVEN,\n    top_p: Optional[float] | NotGiven = NOT_GIVEN,\n    user: str | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; Completion | Stream[Completion]\n</code></pre> <pre><code>create(\n    *,\n    model: Union[\n        str,\n        Literal[\n            \"gpt-3.5-turbo-instruct\",\n            \"davinci-002\",\n            \"babbage-002\",\n        ],\n    ],\n    prompt: Union[\n        str,\n        List[str],\n        Iterable[int],\n        Iterable[Iterable[int]],\n        None,\n    ],\n    best_of: Optional[int] | NotGiven = NOT_GIVEN,\n    echo: Optional[bool] | NotGiven = NOT_GIVEN,\n    frequency_penalty: (\n        Optional[float] | NotGiven\n    ) = NOT_GIVEN,\n    logit_bias: (\n        Optional[Dict[str, int]] | NotGiven\n    ) = NOT_GIVEN,\n    logprobs: Optional[int] | NotGiven = NOT_GIVEN,\n    max_tokens: Optional[int] | NotGiven = NOT_GIVEN,\n    n: Optional[int] | NotGiven = NOT_GIVEN,\n    presence_penalty: (\n        Optional[float] | NotGiven\n    ) = NOT_GIVEN,\n    seed: Optional[int] | NotGiven = NOT_GIVEN,\n    stop: (\n        Union[Optional[str], List[str], None] | NotGiven\n    ) = NOT_GIVEN,\n    stream: (\n        Optional[Literal[False]] | Literal[True] | NotGiven\n    ) = NOT_GIVEN,\n    suffix: Optional[str] | NotGiven = NOT_GIVEN,\n    temperature: Optional[float] | NotGiven = NOT_GIVEN,\n    top_p: Optional[float] | NotGiven = NOT_GIVEN,\n    user: str | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; Completion | Stream[Completion]\n</code></pre> <p>Creates a completion for the provided prompt and parameters.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>Union[str, Literal['gpt-3.5-turbo-instruct', 'davinci-002', 'babbage-002']]</code> <p>ID of the model to use. You can use the   List models API to   see all of your available models, or see our   Model overview for   descriptions of them.</p> required <code>prompt</code> <code>Union[str, List[str], Iterable[int], Iterable[Iterable[int]], None]</code> <p>The prompt(s) to generate completions for, encoded as a string, array of   strings, array of tokens, or array of token arrays.</p> <p>Note that &lt;|endoftext|&gt; is the document separator that the model sees during   training, so if a prompt is not specified the model will generate as if from the   beginning of a new document.</p> required <code>best_of</code> <code>Optional[int] | NotGiven</code> <p>Generates <code>best_of</code> completions server-side and returns the \"best\" (the one with   the highest log probability per token). Results cannot be streamed.</p> <p>When used with <code>n</code>, <code>best_of</code> controls the number of candidate completions and   <code>n</code> specifies how many to return \u2013 <code>best_of</code> must be greater than <code>n</code>.</p> <p>Note: Because this parameter generates many completions, it can quickly   consume your token quota. Use carefully and ensure that you have reasonable   settings for <code>max_tokens</code> and <code>stop</code>.</p> <code>NOT_GIVEN</code> <code>echo</code> <code>Optional[bool] | NotGiven</code> <p>Echo back the prompt in addition to the completion</p> <code>NOT_GIVEN</code> <code>frequency_penalty</code> <code>Optional[float] | NotGiven</code> <p>Number between -2.0 and 2.0. Positive values penalize new tokens based on their   existing frequency in the text so far, decreasing the model's likelihood to   repeat the same line verbatim.</p> <p>See more information about frequency and presence penalties.</p> <code>NOT_GIVEN</code> <code>logit_bias</code> <code>Optional[Dict[str, int]] | NotGiven</code> <p>Modify the likelihood of specified tokens appearing in the completion.</p> <p>Accepts a JSON object that maps tokens (specified by their token ID in the GPT   tokenizer) to an associated bias value from -100 to 100. You can use this   tokenizer tool to convert text to token IDs.   Mathematically, the bias is added to the logits generated by the model prior to   sampling. The exact effect will vary per model, but values between -1 and 1   should decrease or increase likelihood of selection; values like -100 or 100   should result in a ban or exclusive selection of the relevant token.</p> <p>As an example, you can pass <code>{\"50256\": -100}</code> to prevent the &lt;|endoftext|&gt; token   from being generated.</p> <code>NOT_GIVEN</code> <code>logprobs</code> <code>Optional[int] | NotGiven</code> <p>Include the log probabilities on the <code>logprobs</code> most likely output tokens, as   well the chosen tokens. For example, if <code>logprobs</code> is 5, the API will return a   list of the 5 most likely tokens. The API will always return the <code>logprob</code> of   the sampled token, so there may be up to <code>logprobs+1</code> elements in the response.</p> <p>The maximum value for <code>logprobs</code> is 5.</p> <code>NOT_GIVEN</code> <code>max_tokens</code> <code>Optional[int] | NotGiven</code> <p>The maximum number of tokens that can be generated in the   completion.</p> <p>The token count of your prompt plus <code>max_tokens</code> cannot exceed the model's   context length.   Example Python code   for counting tokens.</p> <code>NOT_GIVEN</code> <code>n</code> <code>Optional[int] | NotGiven</code> <p>How many completions to generate for each prompt.</p> <p>Note: Because this parameter generates many completions, it can quickly   consume your token quota. Use carefully and ensure that you have reasonable   settings for <code>max_tokens</code> and <code>stop</code>.</p> <code>NOT_GIVEN</code> <code>presence_penalty</code> <code>Optional[float] | NotGiven</code> <p>Number between -2.0 and 2.0. Positive values penalize new tokens based on   whether they appear in the text so far, increasing the model's likelihood to   talk about new topics.</p> <p>See more information about frequency and presence penalties.</p> <code>NOT_GIVEN</code> <code>seed</code> <code>Optional[int] | NotGiven</code> <p>If specified, our system will make a best effort to sample deterministically,   such that repeated requests with the same <code>seed</code> and parameters should return   the same result.</p> <p>Determinism is not guaranteed, and you should refer to the <code>system_fingerprint</code>   response parameter to monitor changes in the backend.</p> <code>NOT_GIVEN</code> <code>stop</code> <code>Union[Optional[str], List[str], None] | NotGiven</code> <p>Up to 4 sequences where the API will stop generating further tokens. The   returned text will not contain the stop sequence.</p> <code>NOT_GIVEN</code> <code>stream</code> <code>Optional[Literal[False]] | Literal[True] | NotGiven</code> <p>Whether to stream back partial progress. If set, tokens will be sent as   data-only   server-sent events   as they become available, with the stream terminated by a <code>data: [DONE]</code>   message.   Example Python code.</p> <code>NOT_GIVEN</code> <code>suffix</code> <code>Optional[str] | NotGiven</code> <p>The suffix that comes after a completion of inserted text.</p> <code>NOT_GIVEN</code> <code>temperature</code> <code>Optional[float] | NotGiven</code> <p>What sampling temperature to use, between 0 and 2. Higher values like 0.8 will   make the output more random, while lower values like 0.2 will make it more   focused and deterministic.</p> <p>We generally recommend altering this or <code>top_p</code> but not both.</p> <code>NOT_GIVEN</code> <code>top_p</code> <code>Optional[float] | NotGiven</code> <p>An alternative to sampling with temperature, called nucleus sampling, where the   model considers the results of the tokens with top_p probability mass. So 0.1   means only the tokens comprising the top 10% probability mass are considered.</p> <p>We generally recommend altering this or <code>temperature</code> but not both.</p> <code>NOT_GIVEN</code> <code>user</code> <code>str | NotGiven</code> <p>A unique identifier representing your end-user, which can help OpenAI to monitor   and detect abuse.   Learn more.</p> <code>NOT_GIVEN</code> <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/#src.openai.resources.Completions.with_raw_response","title":"with_raw_response","text":"<pre><code>with_raw_response() -&gt; CompletionsWithRawResponse\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.Completions.with_streaming_response","title":"with_streaming_response","text":"<pre><code>with_streaming_response() -&gt; (\n    CompletionsWithStreamingResponse\n)\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.CompletionsWithRawResponse","title":"CompletionsWithRawResponse","text":"<pre><code>CompletionsWithRawResponse(completions: Completions)\n</code></pre> <p>Attributes:</p> Name Type Description <code>create</code>"},{"location":"reference/resources/#src.openai.resources.CompletionsWithRawResponse.create","title":"create  <code>instance-attribute</code>","text":"<pre><code>create = to_raw_response_wrapper(create)\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.CompletionsWithStreamingResponse","title":"CompletionsWithStreamingResponse","text":"<pre><code>CompletionsWithStreamingResponse(completions: Completions)\n</code></pre> <p>Attributes:</p> Name Type Description <code>create</code>"},{"location":"reference/resources/#src.openai.resources.CompletionsWithStreamingResponse.create","title":"create  <code>instance-attribute</code>","text":"<pre><code>create = to_streamed_response_wrapper(create)\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.Embeddings","title":"Embeddings","text":"<pre><code>Embeddings(client: OpenAI)\n</code></pre> <p>Methods:</p> Name Description <code>create</code> <p>Creates an embedding vector representing the input text.</p> <code>with_raw_response</code> <code>with_streaming_response</code>"},{"location":"reference/resources/#src.openai.resources.Embeddings.create","title":"create","text":"<pre><code>create(\n    *,\n    input: Union[\n        str,\n        List[str],\n        Iterable[int],\n        Iterable[Iterable[int]],\n    ],\n    model: Union[\n        str,\n        Literal[\n            \"text-embedding-ada-002\",\n            \"text-embedding-3-small\",\n            \"text-embedding-3-large\",\n        ],\n    ],\n    dimensions: int | NotGiven = NOT_GIVEN,\n    encoding_format: (\n        Literal[\"float\", \"base64\"] | NotGiven\n    ) = NOT_GIVEN,\n    user: str | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; CreateEmbeddingResponse\n</code></pre> <p>Creates an embedding vector representing the input text.</p> <p>Parameters:</p> Name Type Description Default <code>input</code> <code>Union[str, List[str], Iterable[int], Iterable[Iterable[int]]]</code> <p>Input text to embed, encoded as a string or array of tokens. To embed multiple   inputs in a single request, pass an array of strings or array of token arrays.   The input must not exceed the max input tokens for the model (8192 tokens for   <code>text-embedding-ada-002</code>), cannot be an empty string, and any array must be 2048   dimensions or less.   Example Python code   for counting tokens.</p> required <code>model</code> <code>Union[str, Literal['text-embedding-ada-002', 'text-embedding-3-small', 'text-embedding-3-large']]</code> <p>ID of the model to use. You can use the   List models API to   see all of your available models, or see our   Model overview for   descriptions of them.</p> required <code>dimensions</code> <code>int | NotGiven</code> <p>The number of dimensions the resulting output embeddings should have. Only   supported in <code>text-embedding-3</code> and later models.</p> <code>NOT_GIVEN</code> <code>encoding_format</code> <code>Literal['float', 'base64'] | NotGiven</code> <p>The format to return the embeddings in. Can be either <code>float</code> or   <code>base64</code>.</p> <code>NOT_GIVEN</code> <code>user</code> <code>str | NotGiven</code> <p>A unique identifier representing your end-user, which can help OpenAI to monitor   and detect abuse.   Learn more.</p> <code>NOT_GIVEN</code> <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/#src.openai.resources.Embeddings.with_raw_response","title":"with_raw_response","text":"<pre><code>with_raw_response() -&gt; EmbeddingsWithRawResponse\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.Embeddings.with_streaming_response","title":"with_streaming_response","text":"<pre><code>with_streaming_response() -&gt; (\n    EmbeddingsWithStreamingResponse\n)\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.EmbeddingsWithRawResponse","title":"EmbeddingsWithRawResponse","text":"<pre><code>EmbeddingsWithRawResponse(embeddings: Embeddings)\n</code></pre> <p>Attributes:</p> Name Type Description <code>create</code>"},{"location":"reference/resources/#src.openai.resources.EmbeddingsWithRawResponse.create","title":"create  <code>instance-attribute</code>","text":"<pre><code>create = to_raw_response_wrapper(create)\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.EmbeddingsWithStreamingResponse","title":"EmbeddingsWithStreamingResponse","text":"<pre><code>EmbeddingsWithStreamingResponse(embeddings: Embeddings)\n</code></pre> <p>Attributes:</p> Name Type Description <code>create</code>"},{"location":"reference/resources/#src.openai.resources.EmbeddingsWithStreamingResponse.create","title":"create  <code>instance-attribute</code>","text":"<pre><code>create = to_streamed_response_wrapper(create)\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.Files","title":"Files","text":"<pre><code>Files(client: OpenAI)\n</code></pre> <p>Methods:</p> Name Description <code>content</code> <p>Returns the contents of the specified file.</p> <code>create</code> <p>Upload a file that can be used across various endpoints.</p> <code>delete</code> <p>Delete a file.</p> <code>list</code> <p>Returns a list of files that belong to the user's organization.</p> <code>retrieve</code> <p>Returns information about a specific file.</p> <code>retrieve_content</code> <p>Returns the contents of the specified file.</p> <code>wait_for_processing</code> <p>Waits for the given file to be processed, default timeout is 30 mins.</p> <code>with_raw_response</code> <code>with_streaming_response</code>"},{"location":"reference/resources/#src.openai.resources.Files.content","title":"content","text":"<pre><code>content(\n    file_id: str,\n    *,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; HttpxBinaryResponseContent\n</code></pre> <p>Returns the contents of the specified file.</p> <p>Parameters:</p> Name Type Description Default <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/#src.openai.resources.Files.create","title":"create","text":"<pre><code>create(\n    *,\n    file: FileTypes,\n    purpose: Literal[\"fine-tune\", \"assistants\"],\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; FileObject\n</code></pre> <p>Upload a file that can be used across various endpoints.</p> <p>The size of all the files uploaded by one organization can be up to 100 GB.</p> <p>The size of individual files can be a maximum of 512 MB or 2 million tokens for Assistants. See the Assistants Tools guide to learn more about the types of files supported. The Fine-tuning API only supports <code>.jsonl</code> files.</p> <p>Please contact us if you need to increase these storage limits.</p> <p>Parameters:</p> Name Type Description Default <code>file</code> <code>FileTypes</code> <p>The File object (not file name) to be uploaded.</p> required <code>purpose</code> <code>Literal['fine-tune', 'assistants']</code> <p>The intended purpose of the uploaded file.</p> <p>Use \"fine-tune\" for   Fine-tuning and   \"assistants\" for   Assistants and   Messages. This allows   us to validate the format of the uploaded file is correct for fine-tuning.</p> required <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/#src.openai.resources.Files.delete","title":"delete","text":"<pre><code>delete(\n    file_id: str,\n    *,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; FileDeleted\n</code></pre> <p>Delete a file.</p> <p>Parameters:</p> Name Type Description Default <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/#src.openai.resources.Files.list","title":"list","text":"<pre><code>list(\n    *,\n    purpose: str | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; SyncPage[FileObject]\n</code></pre> <p>Returns a list of files that belong to the user's organization.</p> <p>Parameters:</p> Name Type Description Default <code>purpose</code> <code>str | NotGiven</code> <p>Only return files with the given purpose.</p> <code>NOT_GIVEN</code> <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/#src.openai.resources.Files.retrieve","title":"retrieve","text":"<pre><code>retrieve(\n    file_id: str,\n    *,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; FileObject\n</code></pre> <p>Returns information about a specific file.</p> <p>Parameters:</p> Name Type Description Default <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/#src.openai.resources.Files.retrieve_content","title":"retrieve_content","text":"<pre><code>retrieve_content(\n    file_id: str,\n    *,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; str\n</code></pre> <p>Returns the contents of the specified file.</p> <p>Parameters:</p> Name Type Description Default <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/#src.openai.resources.Files.wait_for_processing","title":"wait_for_processing","text":"<pre><code>wait_for_processing(\n    id: str,\n    *,\n    poll_interval: float = 5.0,\n    max_wait_seconds: float = 30 * 60\n) -&gt; FileObject\n</code></pre> <p>Waits for the given file to be processed, default timeout is 30 mins.</p>"},{"location":"reference/resources/#src.openai.resources.Files.with_raw_response","title":"with_raw_response","text":"<pre><code>with_raw_response() -&gt; FilesWithRawResponse\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.Files.with_streaming_response","title":"with_streaming_response","text":"<pre><code>with_streaming_response() -&gt; FilesWithStreamingResponse\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.FilesWithRawResponse","title":"FilesWithRawResponse","text":"<pre><code>FilesWithRawResponse(files: Files)\n</code></pre> <p>Attributes:</p> Name Type Description <code>content</code> <code>create</code> <code>delete</code> <code>list</code> <code>retrieve</code> <code>retrieve_content</code>"},{"location":"reference/resources/#src.openai.resources.FilesWithRawResponse.content","title":"content  <code>instance-attribute</code>","text":"<pre><code>content = to_raw_response_wrapper(content)\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.FilesWithRawResponse.create","title":"create  <code>instance-attribute</code>","text":"<pre><code>create = to_raw_response_wrapper(create)\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.FilesWithRawResponse.delete","title":"delete  <code>instance-attribute</code>","text":"<pre><code>delete = to_raw_response_wrapper(delete)\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.FilesWithRawResponse.list","title":"list  <code>instance-attribute</code>","text":"<pre><code>list = to_raw_response_wrapper(list)\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.FilesWithRawResponse.retrieve","title":"retrieve  <code>instance-attribute</code>","text":"<pre><code>retrieve = to_raw_response_wrapper(retrieve)\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.FilesWithRawResponse.retrieve_content","title":"retrieve_content  <code>instance-attribute</code>","text":"<pre><code>retrieve_content = to_raw_response_wrapper(retrieve_content)\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.FilesWithStreamingResponse","title":"FilesWithStreamingResponse","text":"<pre><code>FilesWithStreamingResponse(files: Files)\n</code></pre> <p>Attributes:</p> Name Type Description <code>content</code> <code>create</code> <code>delete</code> <code>list</code> <code>retrieve</code> <code>retrieve_content</code>"},{"location":"reference/resources/#src.openai.resources.FilesWithStreamingResponse.content","title":"content  <code>instance-attribute</code>","text":"<pre><code>content = to_custom_streamed_response_wrapper(\n    content, StreamedBinaryAPIResponse\n)\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.FilesWithStreamingResponse.create","title":"create  <code>instance-attribute</code>","text":"<pre><code>create = to_streamed_response_wrapper(create)\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.FilesWithStreamingResponse.delete","title":"delete  <code>instance-attribute</code>","text":"<pre><code>delete = to_streamed_response_wrapper(delete)\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.FilesWithStreamingResponse.list","title":"list  <code>instance-attribute</code>","text":"<pre><code>list = to_streamed_response_wrapper(list)\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.FilesWithStreamingResponse.retrieve","title":"retrieve  <code>instance-attribute</code>","text":"<pre><code>retrieve = to_streamed_response_wrapper(retrieve)\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.FilesWithStreamingResponse.retrieve_content","title":"retrieve_content  <code>instance-attribute</code>","text":"<pre><code>retrieve_content = to_streamed_response_wrapper(\n    retrieve_content\n)\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.FineTuning","title":"FineTuning","text":"<pre><code>FineTuning(client: OpenAI)\n</code></pre> <p>Methods:</p> Name Description <code>jobs</code> <code>with_raw_response</code> <code>with_streaming_response</code>"},{"location":"reference/resources/#src.openai.resources.FineTuning.jobs","title":"jobs","text":"<pre><code>jobs() -&gt; Jobs\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.FineTuning.with_raw_response","title":"with_raw_response","text":"<pre><code>with_raw_response() -&gt; FineTuningWithRawResponse\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.FineTuning.with_streaming_response","title":"with_streaming_response","text":"<pre><code>with_streaming_response() -&gt; (\n    FineTuningWithStreamingResponse\n)\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.FineTuningWithRawResponse","title":"FineTuningWithRawResponse","text":"<pre><code>FineTuningWithRawResponse(fine_tuning: FineTuning)\n</code></pre> <p>Methods:</p> Name Description <code>jobs</code>"},{"location":"reference/resources/#src.openai.resources.FineTuningWithRawResponse.jobs","title":"jobs","text":"<pre><code>jobs() -&gt; JobsWithRawResponse\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.FineTuningWithStreamingResponse","title":"FineTuningWithStreamingResponse","text":"<pre><code>FineTuningWithStreamingResponse(fine_tuning: FineTuning)\n</code></pre> <p>Methods:</p> Name Description <code>jobs</code>"},{"location":"reference/resources/#src.openai.resources.FineTuningWithStreamingResponse.jobs","title":"jobs","text":"<pre><code>jobs() -&gt; JobsWithStreamingResponse\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.Images","title":"Images","text":"<pre><code>Images(client: OpenAI)\n</code></pre> <p>Methods:</p> Name Description <code>create_variation</code> <p>Creates a variation of a given image.</p> <code>edit</code> <p>Creates an edited or extended image given an original image and a prompt.</p> <code>generate</code> <p>Creates an image given a prompt.</p> <code>with_raw_response</code> <code>with_streaming_response</code>"},{"location":"reference/resources/#src.openai.resources.Images.create_variation","title":"create_variation","text":"<pre><code>create_variation(\n    *,\n    image: FileTypes,\n    model: (\n        Union[str, Literal[\"dall-e-2\"], None] | NotGiven\n    ) = NOT_GIVEN,\n    n: Optional[int] | NotGiven = NOT_GIVEN,\n    response_format: (\n        Optional[Literal[\"url\", \"b64_json\"]] | NotGiven\n    ) = NOT_GIVEN,\n    size: (\n        Optional[Literal[\"256x256\", \"512x512\", \"1024x1024\"]]\n        | NotGiven\n    ) = NOT_GIVEN,\n    user: str | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; ImagesResponse\n</code></pre> <p>Creates a variation of a given image.</p> <p>Parameters:</p> Name Type Description Default <code>image</code> <code>FileTypes</code> <p>The image to use as the basis for the variation(s). Must be a valid PNG file,   less than 4MB, and square.</p> required <code>model</code> <code>Union[str, Literal['dall-e-2'], None] | NotGiven</code> <p>The model to use for image generation. Only <code>dall-e-2</code> is supported at this   time.</p> <code>NOT_GIVEN</code> <code>n</code> <code>Optional[int] | NotGiven</code> <p>The number of images to generate. Must be between 1 and 10. For <code>dall-e-3</code>, only   <code>n=1</code> is supported.</p> <code>NOT_GIVEN</code> <code>response_format</code> <code>Optional[Literal['url', 'b64_json']] | NotGiven</code> <p>The format in which the generated images are returned. Must be one of <code>url</code> or   <code>b64_json</code>. URLs are only valid for 60 minutes after the image has been   generated.</p> <code>NOT_GIVEN</code> <code>size</code> <code>Optional[Literal['256x256', '512x512', '1024x1024']] | NotGiven</code> <p>The size of the generated images. Must be one of <code>256x256</code>, <code>512x512</code>, or   <code>1024x1024</code>.</p> <code>NOT_GIVEN</code> <code>user</code> <code>str | NotGiven</code> <p>A unique identifier representing your end-user, which can help OpenAI to monitor   and detect abuse.   Learn more.</p> <code>NOT_GIVEN</code> <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/#src.openai.resources.Images.edit","title":"edit","text":"<pre><code>edit(\n    *,\n    image: FileTypes,\n    prompt: str,\n    mask: FileTypes | NotGiven = NOT_GIVEN,\n    model: (\n        Union[str, Literal[\"dall-e-2\"], None] | NotGiven\n    ) = NOT_GIVEN,\n    n: Optional[int] | NotGiven = NOT_GIVEN,\n    response_format: (\n        Optional[Literal[\"url\", \"b64_json\"]] | NotGiven\n    ) = NOT_GIVEN,\n    size: (\n        Optional[Literal[\"256x256\", \"512x512\", \"1024x1024\"]]\n        | NotGiven\n    ) = NOT_GIVEN,\n    user: str | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; ImagesResponse\n</code></pre> <p>Creates an edited or extended image given an original image and a prompt.</p> <p>Parameters:</p> Name Type Description Default <code>image</code> <code>FileTypes</code> <p>The image to edit. Must be a valid PNG file, less than 4MB, and square. If mask   is not provided, image must have transparency, which will be used as the mask.</p> required <code>prompt</code> <code>str</code> <p>A text description of the desired image(s). The maximum length is 1000   characters.</p> required <code>mask</code> <code>FileTypes | NotGiven</code> <p>An additional image whose fully transparent areas (e.g. where alpha is zero)   indicate where <code>image</code> should be edited. Must be a valid PNG file, less than   4MB, and have the same dimensions as <code>image</code>.</p> <code>NOT_GIVEN</code> <code>model</code> <code>Union[str, Literal['dall-e-2'], None] | NotGiven</code> <p>The model to use for image generation. Only <code>dall-e-2</code> is supported at this   time.</p> <code>NOT_GIVEN</code> <code>n</code> <code>Optional[int] | NotGiven</code> <p>The number of images to generate. Must be between 1 and 10.</p> <code>NOT_GIVEN</code> <code>response_format</code> <code>Optional[Literal['url', 'b64_json']] | NotGiven</code> <p>The format in which the generated images are returned. Must be one of <code>url</code> or   <code>b64_json</code>. URLs are only valid for 60 minutes after the image has been   generated.</p> <code>NOT_GIVEN</code> <code>size</code> <code>Optional[Literal['256x256', '512x512', '1024x1024']] | NotGiven</code> <p>The size of the generated images. Must be one of <code>256x256</code>, <code>512x512</code>, or   <code>1024x1024</code>.</p> <code>NOT_GIVEN</code> <code>user</code> <code>str | NotGiven</code> <p>A unique identifier representing your end-user, which can help OpenAI to monitor   and detect abuse.   Learn more.</p> <code>NOT_GIVEN</code> <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/#src.openai.resources.Images.generate","title":"generate","text":"<pre><code>generate(\n    *,\n    prompt: str,\n    model: (\n        Union[str, Literal[\"dall-e-2\", \"dall-e-3\"], None]\n        | NotGiven\n    ) = NOT_GIVEN,\n    n: Optional[int] | NotGiven = NOT_GIVEN,\n    quality: (\n        Literal[\"standard\", \"hd\"] | NotGiven\n    ) = NOT_GIVEN,\n    response_format: (\n        Optional[Literal[\"url\", \"b64_json\"]] | NotGiven\n    ) = NOT_GIVEN,\n    size: (\n        Optional[\n            Literal[\n                \"256x256\",\n                \"512x512\",\n                \"1024x1024\",\n                \"1792x1024\",\n                \"1024x1792\",\n            ]\n        ]\n        | NotGiven\n    ) = NOT_GIVEN,\n    style: (\n        Optional[Literal[\"vivid\", \"natural\"]] | NotGiven\n    ) = NOT_GIVEN,\n    user: str | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; ImagesResponse\n</code></pre> <p>Creates an image given a prompt.</p> <p>Parameters:</p> Name Type Description Default <code>prompt</code> <code>str</code> <p>A text description of the desired image(s). The maximum length is 1000   characters for <code>dall-e-2</code> and 4000 characters for <code>dall-e-3</code>.</p> required <code>model</code> <code>Union[str, Literal['dall-e-2', 'dall-e-3'], None] | NotGiven</code> <p>The model to use for image generation.</p> <code>NOT_GIVEN</code> <code>n</code> <code>Optional[int] | NotGiven</code> <p>The number of images to generate. Must be between 1 and 10. For <code>dall-e-3</code>, only   <code>n=1</code> is supported.</p> <code>NOT_GIVEN</code> <code>quality</code> <code>Literal['standard', 'hd'] | NotGiven</code> <p>The quality of the image that will be generated. <code>hd</code> creates images with finer   details and greater consistency across the image. This param is only supported   for <code>dall-e-3</code>.</p> <code>NOT_GIVEN</code> <code>response_format</code> <code>Optional[Literal['url', 'b64_json']] | NotGiven</code> <p>The format in which the generated images are returned. Must be one of <code>url</code> or   <code>b64_json</code>. URLs are only valid for 60 minutes after the image has been   generated.</p> <code>NOT_GIVEN</code> <code>size</code> <code>Optional[Literal['256x256', '512x512', '1024x1024', '1792x1024', '1024x1792']] | NotGiven</code> <p>The size of the generated images. Must be one of <code>256x256</code>, <code>512x512</code>, or   <code>1024x1024</code> for <code>dall-e-2</code>. Must be one of <code>1024x1024</code>, <code>1792x1024</code>, or   <code>1024x1792</code> for <code>dall-e-3</code> models.</p> <code>NOT_GIVEN</code> <code>style</code> <code>Optional[Literal['vivid', 'natural']] | NotGiven</code> <p>The style of the generated images. Must be one of <code>vivid</code> or <code>natural</code>. Vivid   causes the model to lean towards generating hyper-real and dramatic images.   Natural causes the model to produce more natural, less hyper-real looking   images. This param is only supported for <code>dall-e-3</code>.</p> <code>NOT_GIVEN</code> <code>user</code> <code>str | NotGiven</code> <p>A unique identifier representing your end-user, which can help OpenAI to monitor   and detect abuse.   Learn more.</p> <code>NOT_GIVEN</code> <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/#src.openai.resources.Images.with_raw_response","title":"with_raw_response","text":"<pre><code>with_raw_response() -&gt; ImagesWithRawResponse\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.Images.with_streaming_response","title":"with_streaming_response","text":"<pre><code>with_streaming_response() -&gt; ImagesWithStreamingResponse\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.ImagesWithRawResponse","title":"ImagesWithRawResponse","text":"<pre><code>ImagesWithRawResponse(images: Images)\n</code></pre> <p>Attributes:</p> Name Type Description <code>create_variation</code> <code>edit</code> <code>generate</code>"},{"location":"reference/resources/#src.openai.resources.ImagesWithRawResponse.create_variation","title":"create_variation  <code>instance-attribute</code>","text":"<pre><code>create_variation = to_raw_response_wrapper(create_variation)\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.ImagesWithRawResponse.edit","title":"edit  <code>instance-attribute</code>","text":"<pre><code>edit = to_raw_response_wrapper(edit)\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.ImagesWithRawResponse.generate","title":"generate  <code>instance-attribute</code>","text":"<pre><code>generate = to_raw_response_wrapper(generate)\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.ImagesWithStreamingResponse","title":"ImagesWithStreamingResponse","text":"<pre><code>ImagesWithStreamingResponse(images: Images)\n</code></pre> <p>Attributes:</p> Name Type Description <code>create_variation</code> <code>edit</code> <code>generate</code>"},{"location":"reference/resources/#src.openai.resources.ImagesWithStreamingResponse.create_variation","title":"create_variation  <code>instance-attribute</code>","text":"<pre><code>create_variation = to_streamed_response_wrapper(\n    create_variation\n)\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.ImagesWithStreamingResponse.edit","title":"edit  <code>instance-attribute</code>","text":"<pre><code>edit = to_streamed_response_wrapper(edit)\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.ImagesWithStreamingResponse.generate","title":"generate  <code>instance-attribute</code>","text":"<pre><code>generate = to_streamed_response_wrapper(generate)\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.Models","title":"Models","text":"<pre><code>Models(client: OpenAI)\n</code></pre> <p>Methods:</p> Name Description <code>delete</code> <p>Delete a fine-tuned model.</p> <code>list</code> <p>Lists the currently available models, and provides basic information about each</p> <code>retrieve</code> <p>Retrieves a model instance, providing basic information about the model such as</p> <code>with_raw_response</code> <code>with_streaming_response</code>"},{"location":"reference/resources/#src.openai.resources.Models.delete","title":"delete","text":"<pre><code>delete(\n    model: str,\n    *,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; ModelDeleted\n</code></pre> <p>Delete a fine-tuned model.</p> <p>You must have the Owner role in your organization to delete a model.</p> <p>Parameters:</p> Name Type Description Default <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/#src.openai.resources.Models.list","title":"list","text":"<pre><code>list(\n    *,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; SyncPage[Model]\n</code></pre> <p>Lists the currently available models, and provides basic information about each one such as the owner and availability.</p>"},{"location":"reference/resources/#src.openai.resources.Models.retrieve","title":"retrieve","text":"<pre><code>retrieve(\n    model: str,\n    *,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; Model\n</code></pre> <p>Retrieves a model instance, providing basic information about the model such as the owner and permissioning.</p> <p>Parameters:</p> Name Type Description Default <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/#src.openai.resources.Models.with_raw_response","title":"with_raw_response","text":"<pre><code>with_raw_response() -&gt; ModelsWithRawResponse\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.Models.with_streaming_response","title":"with_streaming_response","text":"<pre><code>with_streaming_response() -&gt; ModelsWithStreamingResponse\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.ModelsWithRawResponse","title":"ModelsWithRawResponse","text":"<pre><code>ModelsWithRawResponse(models: Models)\n</code></pre> <p>Attributes:</p> Name Type Description <code>delete</code> <code>list</code> <code>retrieve</code>"},{"location":"reference/resources/#src.openai.resources.ModelsWithRawResponse.delete","title":"delete  <code>instance-attribute</code>","text":"<pre><code>delete = to_raw_response_wrapper(delete)\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.ModelsWithRawResponse.list","title":"list  <code>instance-attribute</code>","text":"<pre><code>list = to_raw_response_wrapper(list)\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.ModelsWithRawResponse.retrieve","title":"retrieve  <code>instance-attribute</code>","text":"<pre><code>retrieve = to_raw_response_wrapper(retrieve)\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.ModelsWithStreamingResponse","title":"ModelsWithStreamingResponse","text":"<pre><code>ModelsWithStreamingResponse(models: Models)\n</code></pre> <p>Attributes:</p> Name Type Description <code>delete</code> <code>list</code> <code>retrieve</code>"},{"location":"reference/resources/#src.openai.resources.ModelsWithStreamingResponse.delete","title":"delete  <code>instance-attribute</code>","text":"<pre><code>delete = to_streamed_response_wrapper(delete)\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.ModelsWithStreamingResponse.list","title":"list  <code>instance-attribute</code>","text":"<pre><code>list = to_streamed_response_wrapper(list)\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.ModelsWithStreamingResponse.retrieve","title":"retrieve  <code>instance-attribute</code>","text":"<pre><code>retrieve = to_streamed_response_wrapper(retrieve)\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.Moderations","title":"Moderations","text":"<pre><code>Moderations(client: OpenAI)\n</code></pre> <p>Methods:</p> Name Description <code>create</code> <p>Classifies if text is potentially harmful.</p> <code>with_raw_response</code> <code>with_streaming_response</code>"},{"location":"reference/resources/#src.openai.resources.Moderations.create","title":"create","text":"<pre><code>create(\n    *,\n    input: Union[str, List[str]],\n    model: (\n        Union[\n            str,\n            Literal[\n                \"text-moderation-latest\",\n                \"text-moderation-stable\",\n            ],\n        ]\n        | NotGiven\n    ) = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; ModerationCreateResponse\n</code></pre> <p>Classifies if text is potentially harmful.</p> <p>Parameters:</p> Name Type Description Default <code>input</code> <code>Union[str, List[str]]</code> <p>The input text to classify</p> required <code>model</code> <code>Union[str, Literal['text-moderation-latest', 'text-moderation-stable']] | NotGiven</code> <p>Two content moderations models are available: <code>text-moderation-stable</code> and   <code>text-moderation-latest</code>.</p> <p>The default is <code>text-moderation-latest</code> which will be automatically upgraded   over time. This ensures you are always using our most accurate model. If you use   <code>text-moderation-stable</code>, we will provide advanced notice before updating the   model. Accuracy of <code>text-moderation-stable</code> may be slightly lower than for   <code>text-moderation-latest</code>.</p> <code>NOT_GIVEN</code> <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/#src.openai.resources.Moderations.with_raw_response","title":"with_raw_response","text":"<pre><code>with_raw_response() -&gt; ModerationsWithRawResponse\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.Moderations.with_streaming_response","title":"with_streaming_response","text":"<pre><code>with_streaming_response() -&gt; (\n    ModerationsWithStreamingResponse\n)\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.ModerationsWithRawResponse","title":"ModerationsWithRawResponse","text":"<pre><code>ModerationsWithRawResponse(moderations: Moderations)\n</code></pre> <p>Attributes:</p> Name Type Description <code>create</code>"},{"location":"reference/resources/#src.openai.resources.ModerationsWithRawResponse.create","title":"create  <code>instance-attribute</code>","text":"<pre><code>create = to_raw_response_wrapper(create)\n</code></pre>"},{"location":"reference/resources/#src.openai.resources.ModerationsWithStreamingResponse","title":"ModerationsWithStreamingResponse","text":"<pre><code>ModerationsWithStreamingResponse(moderations: Moderations)\n</code></pre> <p>Attributes:</p> Name Type Description <code>create</code>"},{"location":"reference/resources/#src.openai.resources.ModerationsWithStreamingResponse.create","title":"create  <code>instance-attribute</code>","text":"<pre><code>create = to_streamed_response_wrapper(create)\n</code></pre>"},{"location":"reference/resources/completions/","title":"completions","text":"<p>The <code>completions</code> module provides access to the legacy chat endpoint, <code>/v1/completions</code>. Use the <code>chat.completions</code> module instead for new applications.</p> <p>You should not use this module for new projects. The legacy <code>/v1/completions</code> endpoint this module interacts with no longer receives updates and is expected to be deprecated. Use this module only in applications that require compatibility with the legacy endpoint.</p> <p>You're strongly encouraged to migrate existing applications to the <code>chat.completions</code> module\u2060\u2014which interacts with the current (non-legacy) <code>/v1/chat/completions</code> endpoint\u2014prior to the deprecation of the <code>/v1/completions</code> endpoint.</p> <p>Classes:</p> Name Description <code>AsyncCompletions</code> <code>AsyncCompletionsWithRawResponse</code> <code>AsyncCompletionsWithStreamingResponse</code> <code>Completions</code> <code>CompletionsWithRawResponse</code> <code>CompletionsWithStreamingResponse</code>"},{"location":"reference/resources/completions/#src.openai.resources.completions.AsyncCompletions","title":"AsyncCompletions","text":"<pre><code>AsyncCompletions(client: AsyncOpenAI)\n</code></pre> <p>Methods:</p> Name Description <code>create</code> <p>Creates a completion for the provided prompt and parameters.</p> <code>with_raw_response</code> <code>with_streaming_response</code>"},{"location":"reference/resources/completions/#src.openai.resources.completions.AsyncCompletions.create","title":"create  <code>async</code>","text":"<pre><code>create(\n    *,\n    model: Union[\n        str,\n        Literal[\n            \"gpt-3.5-turbo-instruct\",\n            \"davinci-002\",\n            \"babbage-002\",\n        ],\n    ],\n    prompt: Union[\n        str,\n        List[str],\n        Iterable[int],\n        Iterable[Iterable[int]],\n        None,\n    ],\n    best_of: Optional[int] | NotGiven = NOT_GIVEN,\n    echo: Optional[bool] | NotGiven = NOT_GIVEN,\n    frequency_penalty: (\n        Optional[float] | NotGiven\n    ) = NOT_GIVEN,\n    logit_bias: (\n        Optional[Dict[str, int]] | NotGiven\n    ) = NOT_GIVEN,\n    logprobs: Optional[int] | NotGiven = NOT_GIVEN,\n    max_tokens: Optional[int] | NotGiven = NOT_GIVEN,\n    n: Optional[int] | NotGiven = NOT_GIVEN,\n    presence_penalty: (\n        Optional[float] | NotGiven\n    ) = NOT_GIVEN,\n    seed: Optional[int] | NotGiven = NOT_GIVEN,\n    stop: (\n        Union[Optional[str], List[str], None] | NotGiven\n    ) = NOT_GIVEN,\n    stream: Optional[Literal[False]] | NotGiven = NOT_GIVEN,\n    suffix: Optional[str] | NotGiven = NOT_GIVEN,\n    temperature: Optional[float] | NotGiven = NOT_GIVEN,\n    top_p: Optional[float] | NotGiven = NOT_GIVEN,\n    user: str | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; Completion\n</code></pre><pre><code>create(\n    *,\n    model: Union[\n        str,\n        Literal[\n            \"gpt-3.5-turbo-instruct\",\n            \"davinci-002\",\n            \"babbage-002\",\n        ],\n    ],\n    prompt: Union[\n        str,\n        List[str],\n        Iterable[int],\n        Iterable[Iterable[int]],\n        None,\n    ],\n    stream: Literal[True],\n    best_of: Optional[int] | NotGiven = NOT_GIVEN,\n    echo: Optional[bool] | NotGiven = NOT_GIVEN,\n    frequency_penalty: (\n        Optional[float] | NotGiven\n    ) = NOT_GIVEN,\n    logit_bias: (\n        Optional[Dict[str, int]] | NotGiven\n    ) = NOT_GIVEN,\n    logprobs: Optional[int] | NotGiven = NOT_GIVEN,\n    max_tokens: Optional[int] | NotGiven = NOT_GIVEN,\n    n: Optional[int] | NotGiven = NOT_GIVEN,\n    presence_penalty: (\n        Optional[float] | NotGiven\n    ) = NOT_GIVEN,\n    seed: Optional[int] | NotGiven = NOT_GIVEN,\n    stop: (\n        Union[Optional[str], List[str], None] | NotGiven\n    ) = NOT_GIVEN,\n    suffix: Optional[str] | NotGiven = NOT_GIVEN,\n    temperature: Optional[float] | NotGiven = NOT_GIVEN,\n    top_p: Optional[float] | NotGiven = NOT_GIVEN,\n    user: str | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; AsyncStream[Completion]\n</code></pre><pre><code>create(\n    *,\n    model: Union[\n        str,\n        Literal[\n            \"gpt-3.5-turbo-instruct\",\n            \"davinci-002\",\n            \"babbage-002\",\n        ],\n    ],\n    prompt: Union[\n        str,\n        List[str],\n        Iterable[int],\n        Iterable[Iterable[int]],\n        None,\n    ],\n    stream: bool,\n    best_of: Optional[int] | NotGiven = NOT_GIVEN,\n    echo: Optional[bool] | NotGiven = NOT_GIVEN,\n    frequency_penalty: (\n        Optional[float] | NotGiven\n    ) = NOT_GIVEN,\n    logit_bias: (\n        Optional[Dict[str, int]] | NotGiven\n    ) = NOT_GIVEN,\n    logprobs: Optional[int] | NotGiven = NOT_GIVEN,\n    max_tokens: Optional[int] | NotGiven = NOT_GIVEN,\n    n: Optional[int] | NotGiven = NOT_GIVEN,\n    presence_penalty: (\n        Optional[float] | NotGiven\n    ) = NOT_GIVEN,\n    seed: Optional[int] | NotGiven = NOT_GIVEN,\n    stop: (\n        Union[Optional[str], List[str], None] | NotGiven\n    ) = NOT_GIVEN,\n    suffix: Optional[str] | NotGiven = NOT_GIVEN,\n    temperature: Optional[float] | NotGiven = NOT_GIVEN,\n    top_p: Optional[float] | NotGiven = NOT_GIVEN,\n    user: str | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; Completion | AsyncStream[Completion]\n</code></pre> <pre><code>create(\n    *,\n    model: Union[\n        str,\n        Literal[\n            \"gpt-3.5-turbo-instruct\",\n            \"davinci-002\",\n            \"babbage-002\",\n        ],\n    ],\n    prompt: Union[\n        str,\n        List[str],\n        Iterable[int],\n        Iterable[Iterable[int]],\n        None,\n    ],\n    best_of: Optional[int] | NotGiven = NOT_GIVEN,\n    echo: Optional[bool] | NotGiven = NOT_GIVEN,\n    frequency_penalty: (\n        Optional[float] | NotGiven\n    ) = NOT_GIVEN,\n    logit_bias: (\n        Optional[Dict[str, int]] | NotGiven\n    ) = NOT_GIVEN,\n    logprobs: Optional[int] | NotGiven = NOT_GIVEN,\n    max_tokens: Optional[int] | NotGiven = NOT_GIVEN,\n    n: Optional[int] | NotGiven = NOT_GIVEN,\n    presence_penalty: (\n        Optional[float] | NotGiven\n    ) = NOT_GIVEN,\n    seed: Optional[int] | NotGiven = NOT_GIVEN,\n    stop: (\n        Union[Optional[str], List[str], None] | NotGiven\n    ) = NOT_GIVEN,\n    stream: (\n        Optional[Literal[False]] | Literal[True] | NotGiven\n    ) = NOT_GIVEN,\n    suffix: Optional[str] | NotGiven = NOT_GIVEN,\n    temperature: Optional[float] | NotGiven = NOT_GIVEN,\n    top_p: Optional[float] | NotGiven = NOT_GIVEN,\n    user: str | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; Completion | AsyncStream[Completion]\n</code></pre> <p>Creates a completion for the provided prompt and parameters.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>Union[str, Literal['gpt-3.5-turbo-instruct', 'davinci-002', 'babbage-002']]</code> <p>ID of the model to use. You can use the   List models API to   see all of your available models, or see our   Model overview for   descriptions of them.</p> required <code>prompt</code> <code>Union[str, List[str], Iterable[int], Iterable[Iterable[int]], None]</code> <p>The prompt(s) to generate completions for, encoded as a string, array of   strings, array of tokens, or array of token arrays.</p> <p>Note that &lt;|endoftext|&gt; is the document separator that the model sees during   training, so if a prompt is not specified the model will generate as if from the   beginning of a new document.</p> required <code>best_of</code> <code>Optional[int] | NotGiven</code> <p>Generates <code>best_of</code> completions server-side and returns the \"best\" (the one with   the highest log probability per token). Results cannot be streamed.</p> <p>When used with <code>n</code>, <code>best_of</code> controls the number of candidate completions and   <code>n</code> specifies how many to return \u2013 <code>best_of</code> must be greater than <code>n</code>.</p> <p>Note: Because this parameter generates many completions, it can quickly   consume your token quota. Use carefully and ensure that you have reasonable   settings for <code>max_tokens</code> and <code>stop</code>.</p> <code>NOT_GIVEN</code> <code>echo</code> <code>Optional[bool] | NotGiven</code> <p>Echo back the prompt in addition to the completion</p> <code>NOT_GIVEN</code> <code>frequency_penalty</code> <code>Optional[float] | NotGiven</code> <p>Number between -2.0 and 2.0. Positive values penalize new tokens based on their   existing frequency in the text so far, decreasing the model's likelihood to   repeat the same line verbatim.</p> <p>See more information about frequency and presence penalties.</p> <code>NOT_GIVEN</code> <code>logit_bias</code> <code>Optional[Dict[str, int]] | NotGiven</code> <p>Modify the likelihood of specified tokens appearing in the completion.</p> <p>Accepts a JSON object that maps tokens (specified by their token ID in the GPT   tokenizer) to an associated bias value from -100 to 100. You can use this   tokenizer tool to convert text to token IDs.   Mathematically, the bias is added to the logits generated by the model prior to   sampling. The exact effect will vary per model, but values between -1 and 1   should decrease or increase likelihood of selection; values like -100 or 100   should result in a ban or exclusive selection of the relevant token.</p> <p>As an example, you can pass <code>{\"50256\": -100}</code> to prevent the &lt;|endoftext|&gt; token   from being generated.</p> <code>NOT_GIVEN</code> <code>logprobs</code> <code>Optional[int] | NotGiven</code> <p>Include the log probabilities on the <code>logprobs</code> most likely output tokens, as   well the chosen tokens. For example, if <code>logprobs</code> is 5, the API will return a   list of the 5 most likely tokens. The API will always return the <code>logprob</code> of   the sampled token, so there may be up to <code>logprobs+1</code> elements in the response.</p> <p>The maximum value for <code>logprobs</code> is 5.</p> <code>NOT_GIVEN</code> <code>max_tokens</code> <code>Optional[int] | NotGiven</code> <p>The maximum number of tokens that can be generated in the   completion.</p> <p>The token count of your prompt plus <code>max_tokens</code> cannot exceed the model's   context length.   Example Python code   for counting tokens.</p> <code>NOT_GIVEN</code> <code>n</code> <code>Optional[int] | NotGiven</code> <p>How many completions to generate for each prompt.</p> <p>Note: Because this parameter generates many completions, it can quickly   consume your token quota. Use carefully and ensure that you have reasonable   settings for <code>max_tokens</code> and <code>stop</code>.</p> <code>NOT_GIVEN</code> <code>presence_penalty</code> <code>Optional[float] | NotGiven</code> <p>Number between -2.0 and 2.0. Positive values penalize new tokens based on   whether they appear in the text so far, increasing the model's likelihood to   talk about new topics.</p> <p>See more information about frequency and presence penalties.</p> <code>NOT_GIVEN</code> <code>seed</code> <code>Optional[int] | NotGiven</code> <p>If specified, our system will make a best effort to sample deterministically,   such that repeated requests with the same <code>seed</code> and parameters should return   the same result.</p> <p>Determinism is not guaranteed, and you should refer to the <code>system_fingerprint</code>   response parameter to monitor changes in the backend.</p> <code>NOT_GIVEN</code> <code>stop</code> <code>Union[Optional[str], List[str], None] | NotGiven</code> <p>Up to 4 sequences where the API will stop generating further tokens. The   returned text will not contain the stop sequence.</p> <code>NOT_GIVEN</code> <code>stream</code> <code>Optional[Literal[False]] | Literal[True] | NotGiven</code> <p>Whether to stream back partial progress. If set, tokens will be sent as   data-only   server-sent events   as they become available, with the stream terminated by a <code>data: [DONE]</code>   message.   Example Python code.</p> <code>NOT_GIVEN</code> <code>suffix</code> <code>Optional[str] | NotGiven</code> <p>The suffix that comes after a completion of inserted text.</p> <code>NOT_GIVEN</code> <code>temperature</code> <code>Optional[float] | NotGiven</code> <p>What sampling temperature to use, between 0 and 2. Higher values like 0.8 will   make the output more random, while lower values like 0.2 will make it more   focused and deterministic.</p> <p>We generally recommend altering this or <code>top_p</code> but not both.</p> <code>NOT_GIVEN</code> <code>top_p</code> <code>Optional[float] | NotGiven</code> <p>An alternative to sampling with temperature, called nucleus sampling, where the   model considers the results of the tokens with top_p probability mass. So 0.1   means only the tokens comprising the top 10% probability mass are considered.</p> <p>We generally recommend altering this or <code>temperature</code> but not both.</p> <code>NOT_GIVEN</code> <code>user</code> <code>str | NotGiven</code> <p>A unique identifier representing your end-user, which can help OpenAI to monitor   and detect abuse.   Learn more.</p> <code>NOT_GIVEN</code> <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/completions/#src.openai.resources.completions.AsyncCompletions.with_raw_response","title":"with_raw_response","text":"<pre><code>with_raw_response() -&gt; AsyncCompletionsWithRawResponse\n</code></pre>"},{"location":"reference/resources/completions/#src.openai.resources.completions.AsyncCompletions.with_streaming_response","title":"with_streaming_response","text":"<pre><code>with_streaming_response() -&gt; (\n    AsyncCompletionsWithStreamingResponse\n)\n</code></pre>"},{"location":"reference/resources/completions/#src.openai.resources.completions.AsyncCompletionsWithRawResponse","title":"AsyncCompletionsWithRawResponse","text":"<pre><code>AsyncCompletionsWithRawResponse(\n    completions: AsyncCompletions,\n)\n</code></pre> <p>Attributes:</p> Name Type Description <code>create</code>"},{"location":"reference/resources/completions/#src.openai.resources.completions.AsyncCompletionsWithRawResponse.create","title":"create  <code>instance-attribute</code>","text":"<pre><code>create = async_to_raw_response_wrapper(create)\n</code></pre>"},{"location":"reference/resources/completions/#src.openai.resources.completions.AsyncCompletionsWithStreamingResponse","title":"AsyncCompletionsWithStreamingResponse","text":"<pre><code>AsyncCompletionsWithStreamingResponse(\n    completions: AsyncCompletions,\n)\n</code></pre> <p>Attributes:</p> Name Type Description <code>create</code>"},{"location":"reference/resources/completions/#src.openai.resources.completions.AsyncCompletionsWithStreamingResponse.create","title":"create  <code>instance-attribute</code>","text":"<pre><code>create = async_to_streamed_response_wrapper(create)\n</code></pre>"},{"location":"reference/resources/completions/#src.openai.resources.completions.Completions","title":"Completions","text":"<pre><code>Completions(client: OpenAI)\n</code></pre> <p>Methods:</p> Name Description <code>create</code> <p>Creates a completion for the provided prompt and parameters.</p> <code>with_raw_response</code> <code>with_streaming_response</code>"},{"location":"reference/resources/completions/#src.openai.resources.completions.Completions.create","title":"create","text":"<pre><code>create(\n    *,\n    model: Union[\n        str,\n        Literal[\n            \"gpt-3.5-turbo-instruct\",\n            \"davinci-002\",\n            \"babbage-002\",\n        ],\n    ],\n    prompt: Union[\n        str,\n        List[str],\n        Iterable[int],\n        Iterable[Iterable[int]],\n        None,\n    ],\n    best_of: Optional[int] | NotGiven = NOT_GIVEN,\n    echo: Optional[bool] | NotGiven = NOT_GIVEN,\n    frequency_penalty: (\n        Optional[float] | NotGiven\n    ) = NOT_GIVEN,\n    logit_bias: (\n        Optional[Dict[str, int]] | NotGiven\n    ) = NOT_GIVEN,\n    logprobs: Optional[int] | NotGiven = NOT_GIVEN,\n    max_tokens: Optional[int] | NotGiven = NOT_GIVEN,\n    n: Optional[int] | NotGiven = NOT_GIVEN,\n    presence_penalty: (\n        Optional[float] | NotGiven\n    ) = NOT_GIVEN,\n    seed: Optional[int] | NotGiven = NOT_GIVEN,\n    stop: (\n        Union[Optional[str], List[str], None] | NotGiven\n    ) = NOT_GIVEN,\n    stream: Optional[Literal[False]] | NotGiven = NOT_GIVEN,\n    suffix: Optional[str] | NotGiven = NOT_GIVEN,\n    temperature: Optional[float] | NotGiven = NOT_GIVEN,\n    top_p: Optional[float] | NotGiven = NOT_GIVEN,\n    user: str | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; Completion\n</code></pre><pre><code>create(\n    *,\n    model: Union[\n        str,\n        Literal[\n            \"gpt-3.5-turbo-instruct\",\n            \"davinci-002\",\n            \"babbage-002\",\n        ],\n    ],\n    prompt: Union[\n        str,\n        List[str],\n        Iterable[int],\n        Iterable[Iterable[int]],\n        None,\n    ],\n    stream: Literal[True],\n    best_of: Optional[int] | NotGiven = NOT_GIVEN,\n    echo: Optional[bool] | NotGiven = NOT_GIVEN,\n    frequency_penalty: (\n        Optional[float] | NotGiven\n    ) = NOT_GIVEN,\n    logit_bias: (\n        Optional[Dict[str, int]] | NotGiven\n    ) = NOT_GIVEN,\n    logprobs: Optional[int] | NotGiven = NOT_GIVEN,\n    max_tokens: Optional[int] | NotGiven = NOT_GIVEN,\n    n: Optional[int] | NotGiven = NOT_GIVEN,\n    presence_penalty: (\n        Optional[float] | NotGiven\n    ) = NOT_GIVEN,\n    seed: Optional[int] | NotGiven = NOT_GIVEN,\n    stop: (\n        Union[Optional[str], List[str], None] | NotGiven\n    ) = NOT_GIVEN,\n    suffix: Optional[str] | NotGiven = NOT_GIVEN,\n    temperature: Optional[float] | NotGiven = NOT_GIVEN,\n    top_p: Optional[float] | NotGiven = NOT_GIVEN,\n    user: str | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; Stream[Completion]\n</code></pre><pre><code>create(\n    *,\n    model: Union[\n        str,\n        Literal[\n            \"gpt-3.5-turbo-instruct\",\n            \"davinci-002\",\n            \"babbage-002\",\n        ],\n    ],\n    prompt: Union[\n        str,\n        List[str],\n        Iterable[int],\n        Iterable[Iterable[int]],\n        None,\n    ],\n    stream: bool,\n    best_of: Optional[int] | NotGiven = NOT_GIVEN,\n    echo: Optional[bool] | NotGiven = NOT_GIVEN,\n    frequency_penalty: (\n        Optional[float] | NotGiven\n    ) = NOT_GIVEN,\n    logit_bias: (\n        Optional[Dict[str, int]] | NotGiven\n    ) = NOT_GIVEN,\n    logprobs: Optional[int] | NotGiven = NOT_GIVEN,\n    max_tokens: Optional[int] | NotGiven = NOT_GIVEN,\n    n: Optional[int] | NotGiven = NOT_GIVEN,\n    presence_penalty: (\n        Optional[float] | NotGiven\n    ) = NOT_GIVEN,\n    seed: Optional[int] | NotGiven = NOT_GIVEN,\n    stop: (\n        Union[Optional[str], List[str], None] | NotGiven\n    ) = NOT_GIVEN,\n    suffix: Optional[str] | NotGiven = NOT_GIVEN,\n    temperature: Optional[float] | NotGiven = NOT_GIVEN,\n    top_p: Optional[float] | NotGiven = NOT_GIVEN,\n    user: str | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; Completion | Stream[Completion]\n</code></pre> <pre><code>create(\n    *,\n    model: Union[\n        str,\n        Literal[\n            \"gpt-3.5-turbo-instruct\",\n            \"davinci-002\",\n            \"babbage-002\",\n        ],\n    ],\n    prompt: Union[\n        str,\n        List[str],\n        Iterable[int],\n        Iterable[Iterable[int]],\n        None,\n    ],\n    best_of: Optional[int] | NotGiven = NOT_GIVEN,\n    echo: Optional[bool] | NotGiven = NOT_GIVEN,\n    frequency_penalty: (\n        Optional[float] | NotGiven\n    ) = NOT_GIVEN,\n    logit_bias: (\n        Optional[Dict[str, int]] | NotGiven\n    ) = NOT_GIVEN,\n    logprobs: Optional[int] | NotGiven = NOT_GIVEN,\n    max_tokens: Optional[int] | NotGiven = NOT_GIVEN,\n    n: Optional[int] | NotGiven = NOT_GIVEN,\n    presence_penalty: (\n        Optional[float] | NotGiven\n    ) = NOT_GIVEN,\n    seed: Optional[int] | NotGiven = NOT_GIVEN,\n    stop: (\n        Union[Optional[str], List[str], None] | NotGiven\n    ) = NOT_GIVEN,\n    stream: (\n        Optional[Literal[False]] | Literal[True] | NotGiven\n    ) = NOT_GIVEN,\n    suffix: Optional[str] | NotGiven = NOT_GIVEN,\n    temperature: Optional[float] | NotGiven = NOT_GIVEN,\n    top_p: Optional[float] | NotGiven = NOT_GIVEN,\n    user: str | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; Completion | Stream[Completion]\n</code></pre> <p>Creates a completion for the provided prompt and parameters.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>Union[str, Literal['gpt-3.5-turbo-instruct', 'davinci-002', 'babbage-002']]</code> <p>ID of the model to use. You can use the   List models API to   see all of your available models, or see our   Model overview for   descriptions of them.</p> required <code>prompt</code> <code>Union[str, List[str], Iterable[int], Iterable[Iterable[int]], None]</code> <p>The prompt(s) to generate completions for, encoded as a string, array of   strings, array of tokens, or array of token arrays.</p> <p>Note that &lt;|endoftext|&gt; is the document separator that the model sees during   training, so if a prompt is not specified the model will generate as if from the   beginning of a new document.</p> required <code>best_of</code> <code>Optional[int] | NotGiven</code> <p>Generates <code>best_of</code> completions server-side and returns the \"best\" (the one with   the highest log probability per token). Results cannot be streamed.</p> <p>When used with <code>n</code>, <code>best_of</code> controls the number of candidate completions and   <code>n</code> specifies how many to return \u2013 <code>best_of</code> must be greater than <code>n</code>.</p> <p>Note: Because this parameter generates many completions, it can quickly   consume your token quota. Use carefully and ensure that you have reasonable   settings for <code>max_tokens</code> and <code>stop</code>.</p> <code>NOT_GIVEN</code> <code>echo</code> <code>Optional[bool] | NotGiven</code> <p>Echo back the prompt in addition to the completion</p> <code>NOT_GIVEN</code> <code>frequency_penalty</code> <code>Optional[float] | NotGiven</code> <p>Number between -2.0 and 2.0. Positive values penalize new tokens based on their   existing frequency in the text so far, decreasing the model's likelihood to   repeat the same line verbatim.</p> <p>See more information about frequency and presence penalties.</p> <code>NOT_GIVEN</code> <code>logit_bias</code> <code>Optional[Dict[str, int]] | NotGiven</code> <p>Modify the likelihood of specified tokens appearing in the completion.</p> <p>Accepts a JSON object that maps tokens (specified by their token ID in the GPT   tokenizer) to an associated bias value from -100 to 100. You can use this   tokenizer tool to convert text to token IDs.   Mathematically, the bias is added to the logits generated by the model prior to   sampling. The exact effect will vary per model, but values between -1 and 1   should decrease or increase likelihood of selection; values like -100 or 100   should result in a ban or exclusive selection of the relevant token.</p> <p>As an example, you can pass <code>{\"50256\": -100}</code> to prevent the &lt;|endoftext|&gt; token   from being generated.</p> <code>NOT_GIVEN</code> <code>logprobs</code> <code>Optional[int] | NotGiven</code> <p>Include the log probabilities on the <code>logprobs</code> most likely output tokens, as   well the chosen tokens. For example, if <code>logprobs</code> is 5, the API will return a   list of the 5 most likely tokens. The API will always return the <code>logprob</code> of   the sampled token, so there may be up to <code>logprobs+1</code> elements in the response.</p> <p>The maximum value for <code>logprobs</code> is 5.</p> <code>NOT_GIVEN</code> <code>max_tokens</code> <code>Optional[int] | NotGiven</code> <p>The maximum number of tokens that can be generated in the   completion.</p> <p>The token count of your prompt plus <code>max_tokens</code> cannot exceed the model's   context length.   Example Python code   for counting tokens.</p> <code>NOT_GIVEN</code> <code>n</code> <code>Optional[int] | NotGiven</code> <p>How many completions to generate for each prompt.</p> <p>Note: Because this parameter generates many completions, it can quickly   consume your token quota. Use carefully and ensure that you have reasonable   settings for <code>max_tokens</code> and <code>stop</code>.</p> <code>NOT_GIVEN</code> <code>presence_penalty</code> <code>Optional[float] | NotGiven</code> <p>Number between -2.0 and 2.0. Positive values penalize new tokens based on   whether they appear in the text so far, increasing the model's likelihood to   talk about new topics.</p> <p>See more information about frequency and presence penalties.</p> <code>NOT_GIVEN</code> <code>seed</code> <code>Optional[int] | NotGiven</code> <p>If specified, our system will make a best effort to sample deterministically,   such that repeated requests with the same <code>seed</code> and parameters should return   the same result.</p> <p>Determinism is not guaranteed, and you should refer to the <code>system_fingerprint</code>   response parameter to monitor changes in the backend.</p> <code>NOT_GIVEN</code> <code>stop</code> <code>Union[Optional[str], List[str], None] | NotGiven</code> <p>Up to 4 sequences where the API will stop generating further tokens. The   returned text will not contain the stop sequence.</p> <code>NOT_GIVEN</code> <code>stream</code> <code>Optional[Literal[False]] | Literal[True] | NotGiven</code> <p>Whether to stream back partial progress. If set, tokens will be sent as   data-only   server-sent events   as they become available, with the stream terminated by a <code>data: [DONE]</code>   message.   Example Python code.</p> <code>NOT_GIVEN</code> <code>suffix</code> <code>Optional[str] | NotGiven</code> <p>The suffix that comes after a completion of inserted text.</p> <code>NOT_GIVEN</code> <code>temperature</code> <code>Optional[float] | NotGiven</code> <p>What sampling temperature to use, between 0 and 2. Higher values like 0.8 will   make the output more random, while lower values like 0.2 will make it more   focused and deterministic.</p> <p>We generally recommend altering this or <code>top_p</code> but not both.</p> <code>NOT_GIVEN</code> <code>top_p</code> <code>Optional[float] | NotGiven</code> <p>An alternative to sampling with temperature, called nucleus sampling, where the   model considers the results of the tokens with top_p probability mass. So 0.1   means only the tokens comprising the top 10% probability mass are considered.</p> <p>We generally recommend altering this or <code>temperature</code> but not both.</p> <code>NOT_GIVEN</code> <code>user</code> <code>str | NotGiven</code> <p>A unique identifier representing your end-user, which can help OpenAI to monitor   and detect abuse.   Learn more.</p> <code>NOT_GIVEN</code> <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/completions/#src.openai.resources.completions.Completions.with_raw_response","title":"with_raw_response","text":"<pre><code>with_raw_response() -&gt; CompletionsWithRawResponse\n</code></pre>"},{"location":"reference/resources/completions/#src.openai.resources.completions.Completions.with_streaming_response","title":"with_streaming_response","text":"<pre><code>with_streaming_response() -&gt; (\n    CompletionsWithStreamingResponse\n)\n</code></pre>"},{"location":"reference/resources/completions/#src.openai.resources.completions.CompletionsWithRawResponse","title":"CompletionsWithRawResponse","text":"<pre><code>CompletionsWithRawResponse(completions: Completions)\n</code></pre> <p>Attributes:</p> Name Type Description <code>create</code>"},{"location":"reference/resources/completions/#src.openai.resources.completions.CompletionsWithRawResponse.create","title":"create  <code>instance-attribute</code>","text":"<pre><code>create = to_raw_response_wrapper(create)\n</code></pre>"},{"location":"reference/resources/completions/#src.openai.resources.completions.CompletionsWithStreamingResponse","title":"CompletionsWithStreamingResponse","text":"<pre><code>CompletionsWithStreamingResponse(completions: Completions)\n</code></pre> <p>Attributes:</p> Name Type Description <code>create</code>"},{"location":"reference/resources/completions/#src.openai.resources.completions.CompletionsWithStreamingResponse.create","title":"create  <code>instance-attribute</code>","text":"<pre><code>create = to_streamed_response_wrapper(create)\n</code></pre>"},{"location":"reference/resources/embeddings/","title":"embeddings","text":"<p>The <code>embeddings</code> module provides classes for creating embeddings from text inputs using OpenAI's models and supports both synchronous and asynchronous operations as well as the handling of raw responses and streaming response capabilities.</p> <p>The module is appropriate for use in applications that require semantic analysis of text, like similarity searches, text clustering, and other natural language processing tasks that can benefit from high-dimensional vector representations of text.</p> <p>Classes:</p> Name Description <code>AsyncEmbeddings</code> <code>AsyncEmbeddingsWithRawResponse</code> <code>AsyncEmbeddingsWithStreamingResponse</code> <code>Embeddings</code> <code>EmbeddingsWithRawResponse</code> <code>EmbeddingsWithStreamingResponse</code>"},{"location":"reference/resources/embeddings/#src.openai.resources.embeddings.AsyncEmbeddings","title":"AsyncEmbeddings","text":"<pre><code>AsyncEmbeddings(client: AsyncOpenAI)\n</code></pre> <p>Methods:</p> Name Description <code>create</code> <p>Creates an embedding vector representing the input text.</p> <code>with_raw_response</code> <code>with_streaming_response</code>"},{"location":"reference/resources/embeddings/#src.openai.resources.embeddings.AsyncEmbeddings.create","title":"create  <code>async</code>","text":"<pre><code>create(\n    *,\n    input: Union[\n        str,\n        List[str],\n        Iterable[int],\n        Iterable[Iterable[int]],\n    ],\n    model: Union[\n        str,\n        Literal[\n            \"text-embedding-ada-002\",\n            \"text-embedding-3-small\",\n            \"text-embedding-3-large\",\n        ],\n    ],\n    dimensions: int | NotGiven = NOT_GIVEN,\n    encoding_format: (\n        Literal[\"float\", \"base64\"] | NotGiven\n    ) = NOT_GIVEN,\n    user: str | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; CreateEmbeddingResponse\n</code></pre> <p>Creates an embedding vector representing the input text.</p> <p>Parameters:</p> Name Type Description Default <code>input</code> <code>Union[str, List[str], Iterable[int], Iterable[Iterable[int]]]</code> <p>Input text to embed, encoded as a string or array of tokens. To embed multiple   inputs in a single request, pass an array of strings or array of token arrays.   The input must not exceed the max input tokens for the model (8192 tokens for   <code>text-embedding-ada-002</code>), cannot be an empty string, and any array must be 2048   dimensions or less.   Example Python code   for counting tokens.</p> required <code>model</code> <code>Union[str, Literal['text-embedding-ada-002', 'text-embedding-3-small', 'text-embedding-3-large']]</code> <p>ID of the model to use. You can use the   List models API to   see all of your available models, or see our   Model overview for   descriptions of them.</p> required <code>dimensions</code> <code>int | NotGiven</code> <p>The number of dimensions the resulting output embeddings should have. Only   supported in <code>text-embedding-3</code> and later models.</p> <code>NOT_GIVEN</code> <code>encoding_format</code> <code>Literal['float', 'base64'] | NotGiven</code> <p>The format to return the embeddings in. Can be either <code>float</code> or   <code>base64</code>.</p> <code>NOT_GIVEN</code> <code>user</code> <code>str | NotGiven</code> <p>A unique identifier representing your end-user, which can help OpenAI to monitor   and detect abuse.   Learn more.</p> <code>NOT_GIVEN</code> <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/embeddings/#src.openai.resources.embeddings.AsyncEmbeddings.with_raw_response","title":"with_raw_response","text":"<pre><code>with_raw_response() -&gt; AsyncEmbeddingsWithRawResponse\n</code></pre>"},{"location":"reference/resources/embeddings/#src.openai.resources.embeddings.AsyncEmbeddings.with_streaming_response","title":"with_streaming_response","text":"<pre><code>with_streaming_response() -&gt; (\n    AsyncEmbeddingsWithStreamingResponse\n)\n</code></pre>"},{"location":"reference/resources/embeddings/#src.openai.resources.embeddings.AsyncEmbeddingsWithRawResponse","title":"AsyncEmbeddingsWithRawResponse","text":"<pre><code>AsyncEmbeddingsWithRawResponse(embeddings: AsyncEmbeddings)\n</code></pre> <p>Attributes:</p> Name Type Description <code>create</code>"},{"location":"reference/resources/embeddings/#src.openai.resources.embeddings.AsyncEmbeddingsWithRawResponse.create","title":"create  <code>instance-attribute</code>","text":"<pre><code>create = async_to_raw_response_wrapper(create)\n</code></pre>"},{"location":"reference/resources/embeddings/#src.openai.resources.embeddings.AsyncEmbeddingsWithStreamingResponse","title":"AsyncEmbeddingsWithStreamingResponse","text":"<pre><code>AsyncEmbeddingsWithStreamingResponse(\n    embeddings: AsyncEmbeddings,\n)\n</code></pre> <p>Attributes:</p> Name Type Description <code>create</code>"},{"location":"reference/resources/embeddings/#src.openai.resources.embeddings.AsyncEmbeddingsWithStreamingResponse.create","title":"create  <code>instance-attribute</code>","text":"<pre><code>create = async_to_streamed_response_wrapper(create)\n</code></pre>"},{"location":"reference/resources/embeddings/#src.openai.resources.embeddings.Embeddings","title":"Embeddings","text":"<pre><code>Embeddings(client: OpenAI)\n</code></pre> <p>Methods:</p> Name Description <code>create</code> <p>Creates an embedding vector representing the input text.</p> <code>with_raw_response</code> <code>with_streaming_response</code>"},{"location":"reference/resources/embeddings/#src.openai.resources.embeddings.Embeddings.create","title":"create","text":"<pre><code>create(\n    *,\n    input: Union[\n        str,\n        List[str],\n        Iterable[int],\n        Iterable[Iterable[int]],\n    ],\n    model: Union[\n        str,\n        Literal[\n            \"text-embedding-ada-002\",\n            \"text-embedding-3-small\",\n            \"text-embedding-3-large\",\n        ],\n    ],\n    dimensions: int | NotGiven = NOT_GIVEN,\n    encoding_format: (\n        Literal[\"float\", \"base64\"] | NotGiven\n    ) = NOT_GIVEN,\n    user: str | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; CreateEmbeddingResponse\n</code></pre> <p>Creates an embedding vector representing the input text.</p> <p>Parameters:</p> Name Type Description Default <code>input</code> <code>Union[str, List[str], Iterable[int], Iterable[Iterable[int]]]</code> <p>Input text to embed, encoded as a string or array of tokens. To embed multiple   inputs in a single request, pass an array of strings or array of token arrays.   The input must not exceed the max input tokens for the model (8192 tokens for   <code>text-embedding-ada-002</code>), cannot be an empty string, and any array must be 2048   dimensions or less.   Example Python code   for counting tokens.</p> required <code>model</code> <code>Union[str, Literal['text-embedding-ada-002', 'text-embedding-3-small', 'text-embedding-3-large']]</code> <p>ID of the model to use. You can use the   List models API to   see all of your available models, or see our   Model overview for   descriptions of them.</p> required <code>dimensions</code> <code>int | NotGiven</code> <p>The number of dimensions the resulting output embeddings should have. Only   supported in <code>text-embedding-3</code> and later models.</p> <code>NOT_GIVEN</code> <code>encoding_format</code> <code>Literal['float', 'base64'] | NotGiven</code> <p>The format to return the embeddings in. Can be either <code>float</code> or   <code>base64</code>.</p> <code>NOT_GIVEN</code> <code>user</code> <code>str | NotGiven</code> <p>A unique identifier representing your end-user, which can help OpenAI to monitor   and detect abuse.   Learn more.</p> <code>NOT_GIVEN</code> <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/embeddings/#src.openai.resources.embeddings.Embeddings.with_raw_response","title":"with_raw_response","text":"<pre><code>with_raw_response() -&gt; EmbeddingsWithRawResponse\n</code></pre>"},{"location":"reference/resources/embeddings/#src.openai.resources.embeddings.Embeddings.with_streaming_response","title":"with_streaming_response","text":"<pre><code>with_streaming_response() -&gt; (\n    EmbeddingsWithStreamingResponse\n)\n</code></pre>"},{"location":"reference/resources/embeddings/#src.openai.resources.embeddings.EmbeddingsWithRawResponse","title":"EmbeddingsWithRawResponse","text":"<pre><code>EmbeddingsWithRawResponse(embeddings: Embeddings)\n</code></pre> <p>Attributes:</p> Name Type Description <code>create</code>"},{"location":"reference/resources/embeddings/#src.openai.resources.embeddings.EmbeddingsWithRawResponse.create","title":"create  <code>instance-attribute</code>","text":"<pre><code>create = to_raw_response_wrapper(create)\n</code></pre>"},{"location":"reference/resources/embeddings/#src.openai.resources.embeddings.EmbeddingsWithStreamingResponse","title":"EmbeddingsWithStreamingResponse","text":"<pre><code>EmbeddingsWithStreamingResponse(embeddings: Embeddings)\n</code></pre> <p>Attributes:</p> Name Type Description <code>create</code>"},{"location":"reference/resources/embeddings/#src.openai.resources.embeddings.EmbeddingsWithStreamingResponse.create","title":"create  <code>instance-attribute</code>","text":"<pre><code>create = to_streamed_response_wrapper(create)\n</code></pre>"},{"location":"reference/resources/files/","title":"files","text":"<p>The <code>files</code> module provides classes for uploading, retrieving, listing, and deleting files used across various OpenAI API endpoints.</p> <p>The module supports both synchronous and asynchronous operations, along with handling of raw responses and streaming of file content. Designed for use cases that involve managing large datasets or files for purposes like fine-tuning models or using assistants, this module facilitates the efficient handling of file-related operations on the OpenAI platform.</p> <p>Classes:</p> Name Description <code>AsyncFiles</code> <code>AsyncFilesWithRawResponse</code> <code>AsyncFilesWithStreamingResponse</code> <code>Files</code> <code>FilesWithRawResponse</code> <code>FilesWithStreamingResponse</code>"},{"location":"reference/resources/files/#src.openai.resources.files.AsyncFiles","title":"AsyncFiles","text":"<pre><code>AsyncFiles(client: AsyncOpenAI)\n</code></pre> <p>Methods:</p> Name Description <code>content</code> <p>Returns the contents of the specified file.</p> <code>create</code> <p>Upload a file that can be used across various endpoints.</p> <code>delete</code> <p>Delete a file.</p> <code>list</code> <p>Returns a list of files that belong to the user's organization.</p> <code>retrieve</code> <p>Returns information about a specific file.</p> <code>retrieve_content</code> <p>Returns the contents of the specified file.</p> <code>wait_for_processing</code> <p>Waits for the given file to be processed, default timeout is 30 mins.</p> <code>with_raw_response</code> <code>with_streaming_response</code>"},{"location":"reference/resources/files/#src.openai.resources.files.AsyncFiles.content","title":"content  <code>async</code>","text":"<pre><code>content(\n    file_id: str,\n    *,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; HttpxBinaryResponseContent\n</code></pre> <p>Returns the contents of the specified file.</p> <p>Parameters:</p> Name Type Description Default <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/files/#src.openai.resources.files.AsyncFiles.create","title":"create  <code>async</code>","text":"<pre><code>create(\n    *,\n    file: FileTypes,\n    purpose: Literal[\"fine-tune\", \"assistants\"],\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; FileObject\n</code></pre> <p>Upload a file that can be used across various endpoints.</p> <p>The size of all the files uploaded by one organization can be up to 100 GB.</p> <p>The size of individual files can be a maximum of 512 MB or 2 million tokens for Assistants. See the Assistants Tools guide to learn more about the types of files supported. The Fine-tuning API only supports <code>.jsonl</code> files.</p> <p>Please contact us if you need to increase these storage limits.</p> <p>Parameters:</p> Name Type Description Default <code>file</code> <code>FileTypes</code> <p>The File object (not file name) to be uploaded.</p> required <code>purpose</code> <code>Literal['fine-tune', 'assistants']</code> <p>The intended purpose of the uploaded file.</p> <p>Use \"fine-tune\" for   Fine-tuning and   \"assistants\" for   Assistants and   Messages. This allows   us to validate the format of the uploaded file is correct for fine-tuning.</p> required <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/files/#src.openai.resources.files.AsyncFiles.delete","title":"delete  <code>async</code>","text":"<pre><code>delete(\n    file_id: str,\n    *,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; FileDeleted\n</code></pre> <p>Delete a file.</p> <p>Parameters:</p> Name Type Description Default <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/files/#src.openai.resources.files.AsyncFiles.list","title":"list","text":"<pre><code>list(\n    *,\n    purpose: str | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; AsyncPaginator[FileObject, AsyncPage[FileObject]]\n</code></pre> <p>Returns a list of files that belong to the user's organization.</p> <p>Parameters:</p> Name Type Description Default <code>purpose</code> <code>str | NotGiven</code> <p>Only return files with the given purpose.</p> <code>NOT_GIVEN</code> <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/files/#src.openai.resources.files.AsyncFiles.retrieve","title":"retrieve  <code>async</code>","text":"<pre><code>retrieve(\n    file_id: str,\n    *,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; FileObject\n</code></pre> <p>Returns information about a specific file.</p> <p>Parameters:</p> Name Type Description Default <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/files/#src.openai.resources.files.AsyncFiles.retrieve_content","title":"retrieve_content  <code>async</code>","text":"<pre><code>retrieve_content(\n    file_id: str,\n    *,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; str\n</code></pre> <p>Returns the contents of the specified file.</p> <p>Parameters:</p> Name Type Description Default <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/files/#src.openai.resources.files.AsyncFiles.wait_for_processing","title":"wait_for_processing  <code>async</code>","text":"<pre><code>wait_for_processing(\n    id: str,\n    *,\n    poll_interval: float = 5.0,\n    max_wait_seconds: float = 30 * 60\n) -&gt; FileObject\n</code></pre> <p>Waits for the given file to be processed, default timeout is 30 mins.</p>"},{"location":"reference/resources/files/#src.openai.resources.files.AsyncFiles.with_raw_response","title":"with_raw_response","text":"<pre><code>with_raw_response() -&gt; AsyncFilesWithRawResponse\n</code></pre>"},{"location":"reference/resources/files/#src.openai.resources.files.AsyncFiles.with_streaming_response","title":"with_streaming_response","text":"<pre><code>with_streaming_response() -&gt; (\n    AsyncFilesWithStreamingResponse\n)\n</code></pre>"},{"location":"reference/resources/files/#src.openai.resources.files.AsyncFilesWithRawResponse","title":"AsyncFilesWithRawResponse","text":"<pre><code>AsyncFilesWithRawResponse(files: AsyncFiles)\n</code></pre> <p>Attributes:</p> Name Type Description <code>content</code> <code>create</code> <code>delete</code> <code>list</code> <code>retrieve</code> <code>retrieve_content</code>"},{"location":"reference/resources/files/#src.openai.resources.files.AsyncFilesWithRawResponse.content","title":"content  <code>instance-attribute</code>","text":"<pre><code>content = async_to_raw_response_wrapper(content)\n</code></pre>"},{"location":"reference/resources/files/#src.openai.resources.files.AsyncFilesWithRawResponse.create","title":"create  <code>instance-attribute</code>","text":"<pre><code>create = async_to_raw_response_wrapper(create)\n</code></pre>"},{"location":"reference/resources/files/#src.openai.resources.files.AsyncFilesWithRawResponse.delete","title":"delete  <code>instance-attribute</code>","text":"<pre><code>delete = async_to_raw_response_wrapper(delete)\n</code></pre>"},{"location":"reference/resources/files/#src.openai.resources.files.AsyncFilesWithRawResponse.list","title":"list  <code>instance-attribute</code>","text":"<pre><code>list = async_to_raw_response_wrapper(list)\n</code></pre>"},{"location":"reference/resources/files/#src.openai.resources.files.AsyncFilesWithRawResponse.retrieve","title":"retrieve  <code>instance-attribute</code>","text":"<pre><code>retrieve = async_to_raw_response_wrapper(retrieve)\n</code></pre>"},{"location":"reference/resources/files/#src.openai.resources.files.AsyncFilesWithRawResponse.retrieve_content","title":"retrieve_content  <code>instance-attribute</code>","text":"<pre><code>retrieve_content = async_to_raw_response_wrapper(\n    retrieve_content\n)\n</code></pre>"},{"location":"reference/resources/files/#src.openai.resources.files.AsyncFilesWithStreamingResponse","title":"AsyncFilesWithStreamingResponse","text":"<pre><code>AsyncFilesWithStreamingResponse(files: AsyncFiles)\n</code></pre> <p>Attributes:</p> Name Type Description <code>content</code> <code>create</code> <code>delete</code> <code>list</code> <code>retrieve</code> <code>retrieve_content</code>"},{"location":"reference/resources/files/#src.openai.resources.files.AsyncFilesWithStreamingResponse.content","title":"content  <code>instance-attribute</code>","text":"<pre><code>content = async_to_custom_streamed_response_wrapper(\n    content, AsyncStreamedBinaryAPIResponse\n)\n</code></pre>"},{"location":"reference/resources/files/#src.openai.resources.files.AsyncFilesWithStreamingResponse.create","title":"create  <code>instance-attribute</code>","text":"<pre><code>create = async_to_streamed_response_wrapper(create)\n</code></pre>"},{"location":"reference/resources/files/#src.openai.resources.files.AsyncFilesWithStreamingResponse.delete","title":"delete  <code>instance-attribute</code>","text":"<pre><code>delete = async_to_streamed_response_wrapper(delete)\n</code></pre>"},{"location":"reference/resources/files/#src.openai.resources.files.AsyncFilesWithStreamingResponse.list","title":"list  <code>instance-attribute</code>","text":"<pre><code>list = async_to_streamed_response_wrapper(list)\n</code></pre>"},{"location":"reference/resources/files/#src.openai.resources.files.AsyncFilesWithStreamingResponse.retrieve","title":"retrieve  <code>instance-attribute</code>","text":"<pre><code>retrieve = async_to_streamed_response_wrapper(retrieve)\n</code></pre>"},{"location":"reference/resources/files/#src.openai.resources.files.AsyncFilesWithStreamingResponse.retrieve_content","title":"retrieve_content  <code>instance-attribute</code>","text":"<pre><code>retrieve_content = async_to_streamed_response_wrapper(\n    retrieve_content\n)\n</code></pre>"},{"location":"reference/resources/files/#src.openai.resources.files.Files","title":"Files","text":"<pre><code>Files(client: OpenAI)\n</code></pre> <p>Methods:</p> Name Description <code>content</code> <p>Returns the contents of the specified file.</p> <code>create</code> <p>Upload a file that can be used across various endpoints.</p> <code>delete</code> <p>Delete a file.</p> <code>list</code> <p>Returns a list of files that belong to the user's organization.</p> <code>retrieve</code> <p>Returns information about a specific file.</p> <code>retrieve_content</code> <p>Returns the contents of the specified file.</p> <code>wait_for_processing</code> <p>Waits for the given file to be processed, default timeout is 30 mins.</p> <code>with_raw_response</code> <code>with_streaming_response</code>"},{"location":"reference/resources/files/#src.openai.resources.files.Files.content","title":"content","text":"<pre><code>content(\n    file_id: str,\n    *,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; HttpxBinaryResponseContent\n</code></pre> <p>Returns the contents of the specified file.</p> <p>Parameters:</p> Name Type Description Default <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/files/#src.openai.resources.files.Files.create","title":"create","text":"<pre><code>create(\n    *,\n    file: FileTypes,\n    purpose: Literal[\"fine-tune\", \"assistants\"],\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; FileObject\n</code></pre> <p>Upload a file that can be used across various endpoints.</p> <p>The size of all the files uploaded by one organization can be up to 100 GB.</p> <p>The size of individual files can be a maximum of 512 MB or 2 million tokens for Assistants. See the Assistants Tools guide to learn more about the types of files supported. The Fine-tuning API only supports <code>.jsonl</code> files.</p> <p>Please contact us if you need to increase these storage limits.</p> <p>Parameters:</p> Name Type Description Default <code>file</code> <code>FileTypes</code> <p>The File object (not file name) to be uploaded.</p> required <code>purpose</code> <code>Literal['fine-tune', 'assistants']</code> <p>The intended purpose of the uploaded file.</p> <p>Use \"fine-tune\" for   Fine-tuning and   \"assistants\" for   Assistants and   Messages. This allows   us to validate the format of the uploaded file is correct for fine-tuning.</p> required <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/files/#src.openai.resources.files.Files.delete","title":"delete","text":"<pre><code>delete(\n    file_id: str,\n    *,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; FileDeleted\n</code></pre> <p>Delete a file.</p> <p>Parameters:</p> Name Type Description Default <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/files/#src.openai.resources.files.Files.list","title":"list","text":"<pre><code>list(\n    *,\n    purpose: str | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; SyncPage[FileObject]\n</code></pre> <p>Returns a list of files that belong to the user's organization.</p> <p>Parameters:</p> Name Type Description Default <code>purpose</code> <code>str | NotGiven</code> <p>Only return files with the given purpose.</p> <code>NOT_GIVEN</code> <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/files/#src.openai.resources.files.Files.retrieve","title":"retrieve","text":"<pre><code>retrieve(\n    file_id: str,\n    *,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; FileObject\n</code></pre> <p>Returns information about a specific file.</p> <p>Parameters:</p> Name Type Description Default <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/files/#src.openai.resources.files.Files.retrieve_content","title":"retrieve_content","text":"<pre><code>retrieve_content(\n    file_id: str,\n    *,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; str\n</code></pre> <p>Returns the contents of the specified file.</p> <p>Parameters:</p> Name Type Description Default <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/files/#src.openai.resources.files.Files.wait_for_processing","title":"wait_for_processing","text":"<pre><code>wait_for_processing(\n    id: str,\n    *,\n    poll_interval: float = 5.0,\n    max_wait_seconds: float = 30 * 60\n) -&gt; FileObject\n</code></pre> <p>Waits for the given file to be processed, default timeout is 30 mins.</p>"},{"location":"reference/resources/files/#src.openai.resources.files.Files.with_raw_response","title":"with_raw_response","text":"<pre><code>with_raw_response() -&gt; FilesWithRawResponse\n</code></pre>"},{"location":"reference/resources/files/#src.openai.resources.files.Files.with_streaming_response","title":"with_streaming_response","text":"<pre><code>with_streaming_response() -&gt; FilesWithStreamingResponse\n</code></pre>"},{"location":"reference/resources/files/#src.openai.resources.files.FilesWithRawResponse","title":"FilesWithRawResponse","text":"<pre><code>FilesWithRawResponse(files: Files)\n</code></pre> <p>Attributes:</p> Name Type Description <code>content</code> <code>create</code> <code>delete</code> <code>list</code> <code>retrieve</code> <code>retrieve_content</code>"},{"location":"reference/resources/files/#src.openai.resources.files.FilesWithRawResponse.content","title":"content  <code>instance-attribute</code>","text":"<pre><code>content = to_raw_response_wrapper(content)\n</code></pre>"},{"location":"reference/resources/files/#src.openai.resources.files.FilesWithRawResponse.create","title":"create  <code>instance-attribute</code>","text":"<pre><code>create = to_raw_response_wrapper(create)\n</code></pre>"},{"location":"reference/resources/files/#src.openai.resources.files.FilesWithRawResponse.delete","title":"delete  <code>instance-attribute</code>","text":"<pre><code>delete = to_raw_response_wrapper(delete)\n</code></pre>"},{"location":"reference/resources/files/#src.openai.resources.files.FilesWithRawResponse.list","title":"list  <code>instance-attribute</code>","text":"<pre><code>list = to_raw_response_wrapper(list)\n</code></pre>"},{"location":"reference/resources/files/#src.openai.resources.files.FilesWithRawResponse.retrieve","title":"retrieve  <code>instance-attribute</code>","text":"<pre><code>retrieve = to_raw_response_wrapper(retrieve)\n</code></pre>"},{"location":"reference/resources/files/#src.openai.resources.files.FilesWithRawResponse.retrieve_content","title":"retrieve_content  <code>instance-attribute</code>","text":"<pre><code>retrieve_content = to_raw_response_wrapper(retrieve_content)\n</code></pre>"},{"location":"reference/resources/files/#src.openai.resources.files.FilesWithStreamingResponse","title":"FilesWithStreamingResponse","text":"<pre><code>FilesWithStreamingResponse(files: Files)\n</code></pre> <p>Attributes:</p> Name Type Description <code>content</code> <code>create</code> <code>delete</code> <code>list</code> <code>retrieve</code> <code>retrieve_content</code>"},{"location":"reference/resources/files/#src.openai.resources.files.FilesWithStreamingResponse.content","title":"content  <code>instance-attribute</code>","text":"<pre><code>content = to_custom_streamed_response_wrapper(\n    content, StreamedBinaryAPIResponse\n)\n</code></pre>"},{"location":"reference/resources/files/#src.openai.resources.files.FilesWithStreamingResponse.create","title":"create  <code>instance-attribute</code>","text":"<pre><code>create = to_streamed_response_wrapper(create)\n</code></pre>"},{"location":"reference/resources/files/#src.openai.resources.files.FilesWithStreamingResponse.delete","title":"delete  <code>instance-attribute</code>","text":"<pre><code>delete = to_streamed_response_wrapper(delete)\n</code></pre>"},{"location":"reference/resources/files/#src.openai.resources.files.FilesWithStreamingResponse.list","title":"list  <code>instance-attribute</code>","text":"<pre><code>list = to_streamed_response_wrapper(list)\n</code></pre>"},{"location":"reference/resources/files/#src.openai.resources.files.FilesWithStreamingResponse.retrieve","title":"retrieve  <code>instance-attribute</code>","text":"<pre><code>retrieve = to_streamed_response_wrapper(retrieve)\n</code></pre>"},{"location":"reference/resources/files/#src.openai.resources.files.FilesWithStreamingResponse.retrieve_content","title":"retrieve_content  <code>instance-attribute</code>","text":"<pre><code>retrieve_content = to_streamed_response_wrapper(\n    retrieve_content\n)\n</code></pre>"},{"location":"reference/resources/images/","title":"images","text":"<p>The <code>image</code> module provides functionality for creating variations of images, editing images based on textual prompts, and generating new images from prompts using specified models.</p> <p>The module supports both synchronous and asynchronous operations, with capabilities for handling raw responses and streaming. Suitable for applications requiring dynamic image generation or modification through the OpenAI API, this module leverages models like DALL-E to interpret text prompts into visual content.</p> <p>Classes:</p> Name Description <code>AsyncImages</code> <code>AsyncImagesWithRawResponse</code> <code>AsyncImagesWithStreamingResponse</code> <code>Images</code> <code>ImagesWithRawResponse</code> <code>ImagesWithStreamingResponse</code>"},{"location":"reference/resources/images/#src.openai.resources.images.AsyncImages","title":"AsyncImages","text":"<pre><code>AsyncImages(client: AsyncOpenAI)\n</code></pre> <p>Methods:</p> Name Description <code>create_variation</code> <p>Creates a variation of a given image.</p> <code>edit</code> <p>Creates an edited or extended image given an original image and a prompt.</p> <code>generate</code> <p>Creates an image given a prompt.</p> <code>with_raw_response</code> <code>with_streaming_response</code>"},{"location":"reference/resources/images/#src.openai.resources.images.AsyncImages.create_variation","title":"create_variation  <code>async</code>","text":"<pre><code>create_variation(\n    *,\n    image: FileTypes,\n    model: (\n        Union[str, Literal[\"dall-e-2\"], None] | NotGiven\n    ) = NOT_GIVEN,\n    n: Optional[int] | NotGiven = NOT_GIVEN,\n    response_format: (\n        Optional[Literal[\"url\", \"b64_json\"]] | NotGiven\n    ) = NOT_GIVEN,\n    size: (\n        Optional[Literal[\"256x256\", \"512x512\", \"1024x1024\"]]\n        | NotGiven\n    ) = NOT_GIVEN,\n    user: str | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; ImagesResponse\n</code></pre> <p>Creates a variation of a given image.</p> <p>Parameters:</p> Name Type Description Default <code>image</code> <code>FileTypes</code> <p>The image to use as the basis for the variation(s). Must be a valid PNG file,   less than 4MB, and square.</p> required <code>model</code> <code>Union[str, Literal['dall-e-2'], None] | NotGiven</code> <p>The model to use for image generation. Only <code>dall-e-2</code> is supported at this   time.</p> <code>NOT_GIVEN</code> <code>n</code> <code>Optional[int] | NotGiven</code> <p>The number of images to generate. Must be between 1 and 10. For <code>dall-e-3</code>, only   <code>n=1</code> is supported.</p> <code>NOT_GIVEN</code> <code>response_format</code> <code>Optional[Literal['url', 'b64_json']] | NotGiven</code> <p>The format in which the generated images are returned. Must be one of <code>url</code> or   <code>b64_json</code>. URLs are only valid for 60 minutes after the image has been   generated.</p> <code>NOT_GIVEN</code> <code>size</code> <code>Optional[Literal['256x256', '512x512', '1024x1024']] | NotGiven</code> <p>The size of the generated images. Must be one of <code>256x256</code>, <code>512x512</code>, or   <code>1024x1024</code>.</p> <code>NOT_GIVEN</code> <code>user</code> <code>str | NotGiven</code> <p>A unique identifier representing your end-user, which can help OpenAI to monitor   and detect abuse.   Learn more.</p> <code>NOT_GIVEN</code> <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/images/#src.openai.resources.images.AsyncImages.edit","title":"edit  <code>async</code>","text":"<pre><code>edit(\n    *,\n    image: FileTypes,\n    prompt: str,\n    mask: FileTypes | NotGiven = NOT_GIVEN,\n    model: (\n        Union[str, Literal[\"dall-e-2\"], None] | NotGiven\n    ) = NOT_GIVEN,\n    n: Optional[int] | NotGiven = NOT_GIVEN,\n    response_format: (\n        Optional[Literal[\"url\", \"b64_json\"]] | NotGiven\n    ) = NOT_GIVEN,\n    size: (\n        Optional[Literal[\"256x256\", \"512x512\", \"1024x1024\"]]\n        | NotGiven\n    ) = NOT_GIVEN,\n    user: str | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; ImagesResponse\n</code></pre> <p>Creates an edited or extended image given an original image and a prompt.</p> <p>Parameters:</p> Name Type Description Default <code>image</code> <code>FileTypes</code> <p>The image to edit. Must be a valid PNG file, less than 4MB, and square. If mask   is not provided, image must have transparency, which will be used as the mask.</p> required <code>prompt</code> <code>str</code> <p>A text description of the desired image(s). The maximum length is 1000   characters.</p> required <code>mask</code> <code>FileTypes | NotGiven</code> <p>An additional image whose fully transparent areas (e.g. where alpha is zero)   indicate where <code>image</code> should be edited. Must be a valid PNG file, less than   4MB, and have the same dimensions as <code>image</code>.</p> <code>NOT_GIVEN</code> <code>model</code> <code>Union[str, Literal['dall-e-2'], None] | NotGiven</code> <p>The model to use for image generation. Only <code>dall-e-2</code> is supported at this   time.</p> <code>NOT_GIVEN</code> <code>n</code> <code>Optional[int] | NotGiven</code> <p>The number of images to generate. Must be between 1 and 10.</p> <code>NOT_GIVEN</code> <code>response_format</code> <code>Optional[Literal['url', 'b64_json']] | NotGiven</code> <p>The format in which the generated images are returned. Must be one of <code>url</code> or   <code>b64_json</code>. URLs are only valid for 60 minutes after the image has been   generated.</p> <code>NOT_GIVEN</code> <code>size</code> <code>Optional[Literal['256x256', '512x512', '1024x1024']] | NotGiven</code> <p>The size of the generated images. Must be one of <code>256x256</code>, <code>512x512</code>, or   <code>1024x1024</code>.</p> <code>NOT_GIVEN</code> <code>user</code> <code>str | NotGiven</code> <p>A unique identifier representing your end-user, which can help OpenAI to monitor   and detect abuse.   Learn more.</p> <code>NOT_GIVEN</code> <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/images/#src.openai.resources.images.AsyncImages.generate","title":"generate  <code>async</code>","text":"<pre><code>generate(\n    *,\n    prompt: str,\n    model: (\n        Union[str, Literal[\"dall-e-2\", \"dall-e-3\"], None]\n        | NotGiven\n    ) = NOT_GIVEN,\n    n: Optional[int] | NotGiven = NOT_GIVEN,\n    quality: (\n        Literal[\"standard\", \"hd\"] | NotGiven\n    ) = NOT_GIVEN,\n    response_format: (\n        Optional[Literal[\"url\", \"b64_json\"]] | NotGiven\n    ) = NOT_GIVEN,\n    size: (\n        Optional[\n            Literal[\n                \"256x256\",\n                \"512x512\",\n                \"1024x1024\",\n                \"1792x1024\",\n                \"1024x1792\",\n            ]\n        ]\n        | NotGiven\n    ) = NOT_GIVEN,\n    style: (\n        Optional[Literal[\"vivid\", \"natural\"]] | NotGiven\n    ) = NOT_GIVEN,\n    user: str | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; ImagesResponse\n</code></pre> <p>Creates an image given a prompt.</p> <p>Parameters:</p> Name Type Description Default <code>prompt</code> <code>str</code> <p>A text description of the desired image(s). The maximum length is 1000   characters for <code>dall-e-2</code> and 4000 characters for <code>dall-e-3</code>.</p> required <code>model</code> <code>Union[str, Literal['dall-e-2', 'dall-e-3'], None] | NotGiven</code> <p>The model to use for image generation.</p> <code>NOT_GIVEN</code> <code>n</code> <code>Optional[int] | NotGiven</code> <p>The number of images to generate. Must be between 1 and 10. For <code>dall-e-3</code>, only   <code>n=1</code> is supported.</p> <code>NOT_GIVEN</code> <code>quality</code> <code>Literal['standard', 'hd'] | NotGiven</code> <p>The quality of the image that will be generated. <code>hd</code> creates images with finer   details and greater consistency across the image. This param is only supported   for <code>dall-e-3</code>.</p> <code>NOT_GIVEN</code> <code>response_format</code> <code>Optional[Literal['url', 'b64_json']] | NotGiven</code> <p>The format in which the generated images are returned. Must be one of <code>url</code> or   <code>b64_json</code>. URLs are only valid for 60 minutes after the image has been   generated.</p> <code>NOT_GIVEN</code> <code>size</code> <code>Optional[Literal['256x256', '512x512', '1024x1024', '1792x1024', '1024x1792']] | NotGiven</code> <p>The size of the generated images. Must be one of <code>256x256</code>, <code>512x512</code>, or   <code>1024x1024</code> for <code>dall-e-2</code>. Must be one of <code>1024x1024</code>, <code>1792x1024</code>, or   <code>1024x1792</code> for <code>dall-e-3</code> models.</p> <code>NOT_GIVEN</code> <code>style</code> <code>Optional[Literal['vivid', 'natural']] | NotGiven</code> <p>The style of the generated images. Must be one of <code>vivid</code> or <code>natural</code>. Vivid   causes the model to lean towards generating hyper-real and dramatic images.   Natural causes the model to produce more natural, less hyper-real looking   images. This param is only supported for <code>dall-e-3</code>.</p> <code>NOT_GIVEN</code> <code>user</code> <code>str | NotGiven</code> <p>A unique identifier representing your end-user, which can help OpenAI to monitor   and detect abuse.   Learn more.</p> <code>NOT_GIVEN</code> <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/images/#src.openai.resources.images.AsyncImages.with_raw_response","title":"with_raw_response","text":"<pre><code>with_raw_response() -&gt; AsyncImagesWithRawResponse\n</code></pre>"},{"location":"reference/resources/images/#src.openai.resources.images.AsyncImages.with_streaming_response","title":"with_streaming_response","text":"<pre><code>with_streaming_response() -&gt; (\n    AsyncImagesWithStreamingResponse\n)\n</code></pre>"},{"location":"reference/resources/images/#src.openai.resources.images.AsyncImagesWithRawResponse","title":"AsyncImagesWithRawResponse","text":"<pre><code>AsyncImagesWithRawResponse(images: AsyncImages)\n</code></pre> <p>Attributes:</p> Name Type Description <code>create_variation</code> <code>edit</code> <code>generate</code>"},{"location":"reference/resources/images/#src.openai.resources.images.AsyncImagesWithRawResponse.create_variation","title":"create_variation  <code>instance-attribute</code>","text":"<pre><code>create_variation = async_to_raw_response_wrapper(\n    create_variation\n)\n</code></pre>"},{"location":"reference/resources/images/#src.openai.resources.images.AsyncImagesWithRawResponse.edit","title":"edit  <code>instance-attribute</code>","text":"<pre><code>edit = async_to_raw_response_wrapper(edit)\n</code></pre>"},{"location":"reference/resources/images/#src.openai.resources.images.AsyncImagesWithRawResponse.generate","title":"generate  <code>instance-attribute</code>","text":"<pre><code>generate = async_to_raw_response_wrapper(generate)\n</code></pre>"},{"location":"reference/resources/images/#src.openai.resources.images.AsyncImagesWithStreamingResponse","title":"AsyncImagesWithStreamingResponse","text":"<pre><code>AsyncImagesWithStreamingResponse(images: AsyncImages)\n</code></pre> <p>Attributes:</p> Name Type Description <code>create_variation</code> <code>edit</code> <code>generate</code>"},{"location":"reference/resources/images/#src.openai.resources.images.AsyncImagesWithStreamingResponse.create_variation","title":"create_variation  <code>instance-attribute</code>","text":"<pre><code>create_variation = async_to_streamed_response_wrapper(\n    create_variation\n)\n</code></pre>"},{"location":"reference/resources/images/#src.openai.resources.images.AsyncImagesWithStreamingResponse.edit","title":"edit  <code>instance-attribute</code>","text":"<pre><code>edit = async_to_streamed_response_wrapper(edit)\n</code></pre>"},{"location":"reference/resources/images/#src.openai.resources.images.AsyncImagesWithStreamingResponse.generate","title":"generate  <code>instance-attribute</code>","text":"<pre><code>generate = async_to_streamed_response_wrapper(generate)\n</code></pre>"},{"location":"reference/resources/images/#src.openai.resources.images.Images","title":"Images","text":"<pre><code>Images(client: OpenAI)\n</code></pre> <p>Methods:</p> Name Description <code>create_variation</code> <p>Creates a variation of a given image.</p> <code>edit</code> <p>Creates an edited or extended image given an original image and a prompt.</p> <code>generate</code> <p>Creates an image given a prompt.</p> <code>with_raw_response</code> <code>with_streaming_response</code>"},{"location":"reference/resources/images/#src.openai.resources.images.Images.create_variation","title":"create_variation","text":"<pre><code>create_variation(\n    *,\n    image: FileTypes,\n    model: (\n        Union[str, Literal[\"dall-e-2\"], None] | NotGiven\n    ) = NOT_GIVEN,\n    n: Optional[int] | NotGiven = NOT_GIVEN,\n    response_format: (\n        Optional[Literal[\"url\", \"b64_json\"]] | NotGiven\n    ) = NOT_GIVEN,\n    size: (\n        Optional[Literal[\"256x256\", \"512x512\", \"1024x1024\"]]\n        | NotGiven\n    ) = NOT_GIVEN,\n    user: str | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; ImagesResponse\n</code></pre> <p>Creates a variation of a given image.</p> <p>Parameters:</p> Name Type Description Default <code>image</code> <code>FileTypes</code> <p>The image to use as the basis for the variation(s). Must be a valid PNG file,   less than 4MB, and square.</p> required <code>model</code> <code>Union[str, Literal['dall-e-2'], None] | NotGiven</code> <p>The model to use for image generation. Only <code>dall-e-2</code> is supported at this   time.</p> <code>NOT_GIVEN</code> <code>n</code> <code>Optional[int] | NotGiven</code> <p>The number of images to generate. Must be between 1 and 10. For <code>dall-e-3</code>, only   <code>n=1</code> is supported.</p> <code>NOT_GIVEN</code> <code>response_format</code> <code>Optional[Literal['url', 'b64_json']] | NotGiven</code> <p>The format in which the generated images are returned. Must be one of <code>url</code> or   <code>b64_json</code>. URLs are only valid for 60 minutes after the image has been   generated.</p> <code>NOT_GIVEN</code> <code>size</code> <code>Optional[Literal['256x256', '512x512', '1024x1024']] | NotGiven</code> <p>The size of the generated images. Must be one of <code>256x256</code>, <code>512x512</code>, or   <code>1024x1024</code>.</p> <code>NOT_GIVEN</code> <code>user</code> <code>str | NotGiven</code> <p>A unique identifier representing your end-user, which can help OpenAI to monitor   and detect abuse.   Learn more.</p> <code>NOT_GIVEN</code> <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/images/#src.openai.resources.images.Images.edit","title":"edit","text":"<pre><code>edit(\n    *,\n    image: FileTypes,\n    prompt: str,\n    mask: FileTypes | NotGiven = NOT_GIVEN,\n    model: (\n        Union[str, Literal[\"dall-e-2\"], None] | NotGiven\n    ) = NOT_GIVEN,\n    n: Optional[int] | NotGiven = NOT_GIVEN,\n    response_format: (\n        Optional[Literal[\"url\", \"b64_json\"]] | NotGiven\n    ) = NOT_GIVEN,\n    size: (\n        Optional[Literal[\"256x256\", \"512x512\", \"1024x1024\"]]\n        | NotGiven\n    ) = NOT_GIVEN,\n    user: str | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; ImagesResponse\n</code></pre> <p>Creates an edited or extended image given an original image and a prompt.</p> <p>Parameters:</p> Name Type Description Default <code>image</code> <code>FileTypes</code> <p>The image to edit. Must be a valid PNG file, less than 4MB, and square. If mask   is not provided, image must have transparency, which will be used as the mask.</p> required <code>prompt</code> <code>str</code> <p>A text description of the desired image(s). The maximum length is 1000   characters.</p> required <code>mask</code> <code>FileTypes | NotGiven</code> <p>An additional image whose fully transparent areas (e.g. where alpha is zero)   indicate where <code>image</code> should be edited. Must be a valid PNG file, less than   4MB, and have the same dimensions as <code>image</code>.</p> <code>NOT_GIVEN</code> <code>model</code> <code>Union[str, Literal['dall-e-2'], None] | NotGiven</code> <p>The model to use for image generation. Only <code>dall-e-2</code> is supported at this   time.</p> <code>NOT_GIVEN</code> <code>n</code> <code>Optional[int] | NotGiven</code> <p>The number of images to generate. Must be between 1 and 10.</p> <code>NOT_GIVEN</code> <code>response_format</code> <code>Optional[Literal['url', 'b64_json']] | NotGiven</code> <p>The format in which the generated images are returned. Must be one of <code>url</code> or   <code>b64_json</code>. URLs are only valid for 60 minutes after the image has been   generated.</p> <code>NOT_GIVEN</code> <code>size</code> <code>Optional[Literal['256x256', '512x512', '1024x1024']] | NotGiven</code> <p>The size of the generated images. Must be one of <code>256x256</code>, <code>512x512</code>, or   <code>1024x1024</code>.</p> <code>NOT_GIVEN</code> <code>user</code> <code>str | NotGiven</code> <p>A unique identifier representing your end-user, which can help OpenAI to monitor   and detect abuse.   Learn more.</p> <code>NOT_GIVEN</code> <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/images/#src.openai.resources.images.Images.generate","title":"generate","text":"<pre><code>generate(\n    *,\n    prompt: str,\n    model: (\n        Union[str, Literal[\"dall-e-2\", \"dall-e-3\"], None]\n        | NotGiven\n    ) = NOT_GIVEN,\n    n: Optional[int] | NotGiven = NOT_GIVEN,\n    quality: (\n        Literal[\"standard\", \"hd\"] | NotGiven\n    ) = NOT_GIVEN,\n    response_format: (\n        Optional[Literal[\"url\", \"b64_json\"]] | NotGiven\n    ) = NOT_GIVEN,\n    size: (\n        Optional[\n            Literal[\n                \"256x256\",\n                \"512x512\",\n                \"1024x1024\",\n                \"1792x1024\",\n                \"1024x1792\",\n            ]\n        ]\n        | NotGiven\n    ) = NOT_GIVEN,\n    style: (\n        Optional[Literal[\"vivid\", \"natural\"]] | NotGiven\n    ) = NOT_GIVEN,\n    user: str | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; ImagesResponse\n</code></pre> <p>Creates an image given a prompt.</p> <p>Parameters:</p> Name Type Description Default <code>prompt</code> <code>str</code> <p>A text description of the desired image(s). The maximum length is 1000   characters for <code>dall-e-2</code> and 4000 characters for <code>dall-e-3</code>.</p> required <code>model</code> <code>Union[str, Literal['dall-e-2', 'dall-e-3'], None] | NotGiven</code> <p>The model to use for image generation.</p> <code>NOT_GIVEN</code> <code>n</code> <code>Optional[int] | NotGiven</code> <p>The number of images to generate. Must be between 1 and 10. For <code>dall-e-3</code>, only   <code>n=1</code> is supported.</p> <code>NOT_GIVEN</code> <code>quality</code> <code>Literal['standard', 'hd'] | NotGiven</code> <p>The quality of the image that will be generated. <code>hd</code> creates images with finer   details and greater consistency across the image. This param is only supported   for <code>dall-e-3</code>.</p> <code>NOT_GIVEN</code> <code>response_format</code> <code>Optional[Literal['url', 'b64_json']] | NotGiven</code> <p>The format in which the generated images are returned. Must be one of <code>url</code> or   <code>b64_json</code>. URLs are only valid for 60 minutes after the image has been   generated.</p> <code>NOT_GIVEN</code> <code>size</code> <code>Optional[Literal['256x256', '512x512', '1024x1024', '1792x1024', '1024x1792']] | NotGiven</code> <p>The size of the generated images. Must be one of <code>256x256</code>, <code>512x512</code>, or   <code>1024x1024</code> for <code>dall-e-2</code>. Must be one of <code>1024x1024</code>, <code>1792x1024</code>, or   <code>1024x1792</code> for <code>dall-e-3</code> models.</p> <code>NOT_GIVEN</code> <code>style</code> <code>Optional[Literal['vivid', 'natural']] | NotGiven</code> <p>The style of the generated images. Must be one of <code>vivid</code> or <code>natural</code>. Vivid   causes the model to lean towards generating hyper-real and dramatic images.   Natural causes the model to produce more natural, less hyper-real looking   images. This param is only supported for <code>dall-e-3</code>.</p> <code>NOT_GIVEN</code> <code>user</code> <code>str | NotGiven</code> <p>A unique identifier representing your end-user, which can help OpenAI to monitor   and detect abuse.   Learn more.</p> <code>NOT_GIVEN</code> <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/images/#src.openai.resources.images.Images.with_raw_response","title":"with_raw_response","text":"<pre><code>with_raw_response() -&gt; ImagesWithRawResponse\n</code></pre>"},{"location":"reference/resources/images/#src.openai.resources.images.Images.with_streaming_response","title":"with_streaming_response","text":"<pre><code>with_streaming_response() -&gt; ImagesWithStreamingResponse\n</code></pre>"},{"location":"reference/resources/images/#src.openai.resources.images.ImagesWithRawResponse","title":"ImagesWithRawResponse","text":"<pre><code>ImagesWithRawResponse(images: Images)\n</code></pre> <p>Attributes:</p> Name Type Description <code>create_variation</code> <code>edit</code> <code>generate</code>"},{"location":"reference/resources/images/#src.openai.resources.images.ImagesWithRawResponse.create_variation","title":"create_variation  <code>instance-attribute</code>","text":"<pre><code>create_variation = to_raw_response_wrapper(create_variation)\n</code></pre>"},{"location":"reference/resources/images/#src.openai.resources.images.ImagesWithRawResponse.edit","title":"edit  <code>instance-attribute</code>","text":"<pre><code>edit = to_raw_response_wrapper(edit)\n</code></pre>"},{"location":"reference/resources/images/#src.openai.resources.images.ImagesWithRawResponse.generate","title":"generate  <code>instance-attribute</code>","text":"<pre><code>generate = to_raw_response_wrapper(generate)\n</code></pre>"},{"location":"reference/resources/images/#src.openai.resources.images.ImagesWithStreamingResponse","title":"ImagesWithStreamingResponse","text":"<pre><code>ImagesWithStreamingResponse(images: Images)\n</code></pre> <p>Attributes:</p> Name Type Description <code>create_variation</code> <code>edit</code> <code>generate</code>"},{"location":"reference/resources/images/#src.openai.resources.images.ImagesWithStreamingResponse.create_variation","title":"create_variation  <code>instance-attribute</code>","text":"<pre><code>create_variation = to_streamed_response_wrapper(\n    create_variation\n)\n</code></pre>"},{"location":"reference/resources/images/#src.openai.resources.images.ImagesWithStreamingResponse.edit","title":"edit  <code>instance-attribute</code>","text":"<pre><code>edit = to_streamed_response_wrapper(edit)\n</code></pre>"},{"location":"reference/resources/images/#src.openai.resources.images.ImagesWithStreamingResponse.generate","title":"generate  <code>instance-attribute</code>","text":"<pre><code>generate = to_streamed_response_wrapper(generate)\n</code></pre>"},{"location":"reference/resources/models/","title":"models","text":"<p>The <code>models</code> module facilitates the retrieval, listing, and deletion of models on the OpenAI platform and supports both synchronous and asynchronous operations.</p> <p>The module enables developers to interact with models, providing functionalities like fetching detailed information about a specific model, listing all available models, and deleting fine-tuned models.</p> <p>Classes:</p> Name Description <code>AsyncModels</code> <code>AsyncModelsWithRawResponse</code> <code>AsyncModelsWithStreamingResponse</code> <code>Models</code> <code>ModelsWithRawResponse</code> <code>ModelsWithStreamingResponse</code>"},{"location":"reference/resources/models/#src.openai.resources.models.AsyncModels","title":"AsyncModels","text":"<pre><code>AsyncModels(client: AsyncOpenAI)\n</code></pre> <p>Methods:</p> Name Description <code>delete</code> <p>Delete a fine-tuned model.</p> <code>list</code> <p>Lists the currently available models, and provides basic information about each</p> <code>retrieve</code> <p>Retrieves a model instance, providing basic information about the model such as</p> <code>with_raw_response</code> <code>with_streaming_response</code>"},{"location":"reference/resources/models/#src.openai.resources.models.AsyncModels.delete","title":"delete  <code>async</code>","text":"<pre><code>delete(\n    model: str,\n    *,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; ModelDeleted\n</code></pre> <p>Delete a fine-tuned model.</p> <p>You must have the Owner role in your organization to delete a model.</p> <p>Parameters:</p> Name Type Description Default <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/models/#src.openai.resources.models.AsyncModels.list","title":"list","text":"<pre><code>list(\n    *,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; AsyncPaginator[Model, AsyncPage[Model]]\n</code></pre> <p>Lists the currently available models, and provides basic information about each one such as the owner and availability.</p>"},{"location":"reference/resources/models/#src.openai.resources.models.AsyncModels.retrieve","title":"retrieve  <code>async</code>","text":"<pre><code>retrieve(\n    model: str,\n    *,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; Model\n</code></pre> <p>Retrieves a model instance, providing basic information about the model such as the owner and permissioning.</p> <p>Parameters:</p> Name Type Description Default <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/models/#src.openai.resources.models.AsyncModels.with_raw_response","title":"with_raw_response","text":"<pre><code>with_raw_response() -&gt; AsyncModelsWithRawResponse\n</code></pre>"},{"location":"reference/resources/models/#src.openai.resources.models.AsyncModels.with_streaming_response","title":"with_streaming_response","text":"<pre><code>with_streaming_response() -&gt; (\n    AsyncModelsWithStreamingResponse\n)\n</code></pre>"},{"location":"reference/resources/models/#src.openai.resources.models.AsyncModelsWithRawResponse","title":"AsyncModelsWithRawResponse","text":"<pre><code>AsyncModelsWithRawResponse(models: AsyncModels)\n</code></pre> <p>Attributes:</p> Name Type Description <code>delete</code> <code>list</code> <code>retrieve</code>"},{"location":"reference/resources/models/#src.openai.resources.models.AsyncModelsWithRawResponse.delete","title":"delete  <code>instance-attribute</code>","text":"<pre><code>delete = async_to_raw_response_wrapper(delete)\n</code></pre>"},{"location":"reference/resources/models/#src.openai.resources.models.AsyncModelsWithRawResponse.list","title":"list  <code>instance-attribute</code>","text":"<pre><code>list = async_to_raw_response_wrapper(list)\n</code></pre>"},{"location":"reference/resources/models/#src.openai.resources.models.AsyncModelsWithRawResponse.retrieve","title":"retrieve  <code>instance-attribute</code>","text":"<pre><code>retrieve = async_to_raw_response_wrapper(retrieve)\n</code></pre>"},{"location":"reference/resources/models/#src.openai.resources.models.AsyncModelsWithStreamingResponse","title":"AsyncModelsWithStreamingResponse","text":"<pre><code>AsyncModelsWithStreamingResponse(models: AsyncModels)\n</code></pre> <p>Attributes:</p> Name Type Description <code>delete</code> <code>list</code> <code>retrieve</code>"},{"location":"reference/resources/models/#src.openai.resources.models.AsyncModelsWithStreamingResponse.delete","title":"delete  <code>instance-attribute</code>","text":"<pre><code>delete = async_to_streamed_response_wrapper(delete)\n</code></pre>"},{"location":"reference/resources/models/#src.openai.resources.models.AsyncModelsWithStreamingResponse.list","title":"list  <code>instance-attribute</code>","text":"<pre><code>list = async_to_streamed_response_wrapper(list)\n</code></pre>"},{"location":"reference/resources/models/#src.openai.resources.models.AsyncModelsWithStreamingResponse.retrieve","title":"retrieve  <code>instance-attribute</code>","text":"<pre><code>retrieve = async_to_streamed_response_wrapper(retrieve)\n</code></pre>"},{"location":"reference/resources/models/#src.openai.resources.models.Models","title":"Models","text":"<pre><code>Models(client: OpenAI)\n</code></pre> <p>Methods:</p> Name Description <code>delete</code> <p>Delete a fine-tuned model.</p> <code>list</code> <p>Lists the currently available models, and provides basic information about each</p> <code>retrieve</code> <p>Retrieves a model instance, providing basic information about the model such as</p> <code>with_raw_response</code> <code>with_streaming_response</code>"},{"location":"reference/resources/models/#src.openai.resources.models.Models.delete","title":"delete","text":"<pre><code>delete(\n    model: str,\n    *,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; ModelDeleted\n</code></pre> <p>Delete a fine-tuned model.</p> <p>You must have the Owner role in your organization to delete a model.</p> <p>Parameters:</p> Name Type Description Default <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/models/#src.openai.resources.models.Models.list","title":"list","text":"<pre><code>list(\n    *,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; SyncPage[Model]\n</code></pre> <p>Lists the currently available models, and provides basic information about each one such as the owner and availability.</p>"},{"location":"reference/resources/models/#src.openai.resources.models.Models.retrieve","title":"retrieve","text":"<pre><code>retrieve(\n    model: str,\n    *,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; Model\n</code></pre> <p>Retrieves a model instance, providing basic information about the model such as the owner and permissioning.</p> <p>Parameters:</p> Name Type Description Default <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/models/#src.openai.resources.models.Models.with_raw_response","title":"with_raw_response","text":"<pre><code>with_raw_response() -&gt; ModelsWithRawResponse\n</code></pre>"},{"location":"reference/resources/models/#src.openai.resources.models.Models.with_streaming_response","title":"with_streaming_response","text":"<pre><code>with_streaming_response() -&gt; ModelsWithStreamingResponse\n</code></pre>"},{"location":"reference/resources/models/#src.openai.resources.models.ModelsWithRawResponse","title":"ModelsWithRawResponse","text":"<pre><code>ModelsWithRawResponse(models: Models)\n</code></pre> <p>Attributes:</p> Name Type Description <code>delete</code> <code>list</code> <code>retrieve</code>"},{"location":"reference/resources/models/#src.openai.resources.models.ModelsWithRawResponse.delete","title":"delete  <code>instance-attribute</code>","text":"<pre><code>delete = to_raw_response_wrapper(delete)\n</code></pre>"},{"location":"reference/resources/models/#src.openai.resources.models.ModelsWithRawResponse.list","title":"list  <code>instance-attribute</code>","text":"<pre><code>list = to_raw_response_wrapper(list)\n</code></pre>"},{"location":"reference/resources/models/#src.openai.resources.models.ModelsWithRawResponse.retrieve","title":"retrieve  <code>instance-attribute</code>","text":"<pre><code>retrieve = to_raw_response_wrapper(retrieve)\n</code></pre>"},{"location":"reference/resources/models/#src.openai.resources.models.ModelsWithStreamingResponse","title":"ModelsWithStreamingResponse","text":"<pre><code>ModelsWithStreamingResponse(models: Models)\n</code></pre> <p>Attributes:</p> Name Type Description <code>delete</code> <code>list</code> <code>retrieve</code>"},{"location":"reference/resources/models/#src.openai.resources.models.ModelsWithStreamingResponse.delete","title":"delete  <code>instance-attribute</code>","text":"<pre><code>delete = to_streamed_response_wrapper(delete)\n</code></pre>"},{"location":"reference/resources/models/#src.openai.resources.models.ModelsWithStreamingResponse.list","title":"list  <code>instance-attribute</code>","text":"<pre><code>list = to_streamed_response_wrapper(list)\n</code></pre>"},{"location":"reference/resources/models/#src.openai.resources.models.ModelsWithStreamingResponse.retrieve","title":"retrieve  <code>instance-attribute</code>","text":"<pre><code>retrieve = to_streamed_response_wrapper(retrieve)\n</code></pre>"},{"location":"reference/resources/moderations/","title":"moderations","text":"<p>The <code>moderations</code> module provides functionality to submit text for moderation to determine whether it violates OpenAI's content policy.</p> <p>Moderation is particularly useful for developers looking to ensure the content generated or processed by their applications adheres to OpenAI's content policy. By leveraging the content moderation models provided by OpenAI, applications can automatically classify and filter out text that might be considered harmful or inappropriate.</p> <p>Classes:</p> Name Description <code>AsyncModerations</code> <code>AsyncModerationsWithRawResponse</code> <code>AsyncModerationsWithStreamingResponse</code> <code>Moderations</code> <code>ModerationsWithRawResponse</code> <code>ModerationsWithStreamingResponse</code>"},{"location":"reference/resources/moderations/#src.openai.resources.moderations.AsyncModerations","title":"AsyncModerations","text":"<pre><code>AsyncModerations(client: AsyncOpenAI)\n</code></pre> <p>Methods:</p> Name Description <code>create</code> <p>Classifies if text is potentially harmful.</p> <code>with_raw_response</code> <code>with_streaming_response</code>"},{"location":"reference/resources/moderations/#src.openai.resources.moderations.AsyncModerations.create","title":"create  <code>async</code>","text":"<pre><code>create(\n    *,\n    input: Union[str, List[str]],\n    model: (\n        Union[\n            str,\n            Literal[\n                \"text-moderation-latest\",\n                \"text-moderation-stable\",\n            ],\n        ]\n        | NotGiven\n    ) = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; ModerationCreateResponse\n</code></pre> <p>Classifies if text is potentially harmful.</p> <p>Parameters:</p> Name Type Description Default <code>input</code> <code>Union[str, List[str]]</code> <p>The input text to classify</p> required <code>model</code> <code>Union[str, Literal['text-moderation-latest', 'text-moderation-stable']] | NotGiven</code> <p>Two content moderations models are available: <code>text-moderation-stable</code> and   <code>text-moderation-latest</code>.</p> <p>The default is <code>text-moderation-latest</code> which will be automatically upgraded   over time. This ensures you are always using our most accurate model. If you use   <code>text-moderation-stable</code>, we will provide advanced notice before updating the   model. Accuracy of <code>text-moderation-stable</code> may be slightly lower than for   <code>text-moderation-latest</code>.</p> <code>NOT_GIVEN</code> <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/moderations/#src.openai.resources.moderations.AsyncModerations.with_raw_response","title":"with_raw_response","text":"<pre><code>with_raw_response() -&gt; AsyncModerationsWithRawResponse\n</code></pre>"},{"location":"reference/resources/moderations/#src.openai.resources.moderations.AsyncModerations.with_streaming_response","title":"with_streaming_response","text":"<pre><code>with_streaming_response() -&gt; (\n    AsyncModerationsWithStreamingResponse\n)\n</code></pre>"},{"location":"reference/resources/moderations/#src.openai.resources.moderations.AsyncModerationsWithRawResponse","title":"AsyncModerationsWithRawResponse","text":"<pre><code>AsyncModerationsWithRawResponse(\n    moderations: AsyncModerations,\n)\n</code></pre> <p>Attributes:</p> Name Type Description <code>create</code>"},{"location":"reference/resources/moderations/#src.openai.resources.moderations.AsyncModerationsWithRawResponse.create","title":"create  <code>instance-attribute</code>","text":"<pre><code>create = async_to_raw_response_wrapper(create)\n</code></pre>"},{"location":"reference/resources/moderations/#src.openai.resources.moderations.AsyncModerationsWithStreamingResponse","title":"AsyncModerationsWithStreamingResponse","text":"<pre><code>AsyncModerationsWithStreamingResponse(\n    moderations: AsyncModerations,\n)\n</code></pre> <p>Attributes:</p> Name Type Description <code>create</code>"},{"location":"reference/resources/moderations/#src.openai.resources.moderations.AsyncModerationsWithStreamingResponse.create","title":"create  <code>instance-attribute</code>","text":"<pre><code>create = async_to_streamed_response_wrapper(create)\n</code></pre>"},{"location":"reference/resources/moderations/#src.openai.resources.moderations.Moderations","title":"Moderations","text":"<pre><code>Moderations(client: OpenAI)\n</code></pre> <p>Methods:</p> Name Description <code>create</code> <p>Classifies if text is potentially harmful.</p> <code>with_raw_response</code> <code>with_streaming_response</code>"},{"location":"reference/resources/moderations/#src.openai.resources.moderations.Moderations.create","title":"create","text":"<pre><code>create(\n    *,\n    input: Union[str, List[str]],\n    model: (\n        Union[\n            str,\n            Literal[\n                \"text-moderation-latest\",\n                \"text-moderation-stable\",\n            ],\n        ]\n        | NotGiven\n    ) = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; ModerationCreateResponse\n</code></pre> <p>Classifies if text is potentially harmful.</p> <p>Parameters:</p> Name Type Description Default <code>input</code> <code>Union[str, List[str]]</code> <p>The input text to classify</p> required <code>model</code> <code>Union[str, Literal['text-moderation-latest', 'text-moderation-stable']] | NotGiven</code> <p>Two content moderations models are available: <code>text-moderation-stable</code> and   <code>text-moderation-latest</code>.</p> <p>The default is <code>text-moderation-latest</code> which will be automatically upgraded   over time. This ensures you are always using our most accurate model. If you use   <code>text-moderation-stable</code>, we will provide advanced notice before updating the   model. Accuracy of <code>text-moderation-stable</code> may be slightly lower than for   <code>text-moderation-latest</code>.</p> <code>NOT_GIVEN</code> <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/moderations/#src.openai.resources.moderations.Moderations.with_raw_response","title":"with_raw_response","text":"<pre><code>with_raw_response() -&gt; ModerationsWithRawResponse\n</code></pre>"},{"location":"reference/resources/moderations/#src.openai.resources.moderations.Moderations.with_streaming_response","title":"with_streaming_response","text":"<pre><code>with_streaming_response() -&gt; (\n    ModerationsWithStreamingResponse\n)\n</code></pre>"},{"location":"reference/resources/moderations/#src.openai.resources.moderations.ModerationsWithRawResponse","title":"ModerationsWithRawResponse","text":"<pre><code>ModerationsWithRawResponse(moderations: Moderations)\n</code></pre> <p>Attributes:</p> Name Type Description <code>create</code>"},{"location":"reference/resources/moderations/#src.openai.resources.moderations.ModerationsWithRawResponse.create","title":"create  <code>instance-attribute</code>","text":"<pre><code>create = to_raw_response_wrapper(create)\n</code></pre>"},{"location":"reference/resources/moderations/#src.openai.resources.moderations.ModerationsWithStreamingResponse","title":"ModerationsWithStreamingResponse","text":"<pre><code>ModerationsWithStreamingResponse(moderations: Moderations)\n</code></pre> <p>Attributes:</p> Name Type Description <code>create</code>"},{"location":"reference/resources/moderations/#src.openai.resources.moderations.ModerationsWithStreamingResponse.create","title":"create  <code>instance-attribute</code>","text":"<pre><code>create = to_streamed_response_wrapper(create)\n</code></pre>"},{"location":"reference/resources/audio/","title":"openai.resources.audio","text":"<p>The <code>audio</code> module provides classes for audio processing operations like transcription, translation, and speech synthesis.</p> <p>Use the <code>audio</code> module by accessing the <code>OpenAI.audio</code> attribute on the client object, and then access the attribute for the feature you'd like to use:</p> <ul> <li><code>OpenAI.audio.transcriptions</code> - Transcribe spoken audio to text</li> <li><code>OpenAI.audio.translations</code> - Translate spoken audio to English</li> <li><code>OpenAI.audio.speech</code> - Generate spoken audio from text</li> </ul> <p>Examples:     <pre><code>from pathlib import Path\n\nfrom openai import OpenAI\n\nopenai = OpenAI()\n\nspeech_file_path = Path(__file__).parent / \"speech.mp3\"\n\n    # Create text-to-speech audio file\n    with openai.audio.speech.with_streaming_response.create(\n        model=\"tts-1\",\n        voice=\"alloy\",\n        input=\"The quick brown fox jumps over the lazy dog.\",\n    ) as response:\n        response.stream_to_file(speech_file_path)\n</code></pre></p> <p>Modules:</p> Name Description <code>audio</code> <p>The <code>audio</code> module provides classes for audio processing operations like transcription, translation, and speech synthesis.</p> <p>Use the <code>audio</code> module by accessing the <code>OpenAI.audio</code> attribute on the client object, and then access the attribute for the feature you'd like to use:</p> <ul> <li><code>OpenAI.audio.transcriptions</code> - Transcribe spoken audio to text</li> <li><code>OpenAI.audio.translations</code> - Translate spoken audio to English</li> <li><code>OpenAI.audio.speech</code> - Generate spoken audio from text</li> </ul> <p>Examples:     <pre><code>from pathlib import Path\n\nfrom openai import OpenAI\n\nopenai = OpenAI()\n\nspeech_file_path = Path(__file__).parent / \"speech.mp3\"\n\n    # Create text-to-speech audio file\n    with openai.audio.speech.with_streaming_response.create(\n        model=\"tts-1\",\n        voice=\"alloy\",\n        input=\"The quick brown fox jumps over the lazy dog.\",\n    ) as response:\n        response.stream_to_file(speech_file_path)\n</code></pre></p> <code>speech</code> <code>transcriptions</code> <code>translations</code> <p>Classes:</p> Name Description <code>AsyncAudio</code> <code>AsyncAudioWithRawResponse</code> <code>AsyncAudioWithStreamingResponse</code> <code>AsyncSpeech</code> <code>AsyncSpeechWithRawResponse</code> <code>AsyncSpeechWithStreamingResponse</code> <code>AsyncTranscriptions</code> <code>AsyncTranscriptionsWithRawResponse</code> <code>AsyncTranscriptionsWithStreamingResponse</code> <code>AsyncTranslations</code> <code>AsyncTranslationsWithRawResponse</code> <code>AsyncTranslationsWithStreamingResponse</code> <code>Audio</code> <code>AudioWithRawResponse</code> <code>AudioWithStreamingResponse</code> <code>Speech</code> <code>SpeechWithRawResponse</code> <code>SpeechWithStreamingResponse</code> <code>Transcriptions</code> <code>TranscriptionsWithRawResponse</code> <code>TranscriptionsWithStreamingResponse</code> <code>Translations</code> <code>TranslationsWithRawResponse</code> <code>TranslationsWithStreamingResponse</code>"},{"location":"reference/resources/audio/#src.openai.resources.audio.AsyncAudio","title":"AsyncAudio","text":"<pre><code>AsyncAudio(client: AsyncOpenAI)\n</code></pre> <p>Methods:</p> Name Description <code>speech</code> <code>transcriptions</code> <code>translations</code> <code>with_raw_response</code> <code>with_streaming_response</code>"},{"location":"reference/resources/audio/#src.openai.resources.audio.AsyncAudio.speech","title":"speech","text":"<pre><code>speech() -&gt; AsyncSpeech\n</code></pre>"},{"location":"reference/resources/audio/#src.openai.resources.audio.AsyncAudio.transcriptions","title":"transcriptions","text":"<pre><code>transcriptions() -&gt; AsyncTranscriptions\n</code></pre>"},{"location":"reference/resources/audio/#src.openai.resources.audio.AsyncAudio.translations","title":"translations","text":"<pre><code>translations() -&gt; AsyncTranslations\n</code></pre>"},{"location":"reference/resources/audio/#src.openai.resources.audio.AsyncAudio.with_raw_response","title":"with_raw_response","text":"<pre><code>with_raw_response() -&gt; AsyncAudioWithRawResponse\n</code></pre>"},{"location":"reference/resources/audio/#src.openai.resources.audio.AsyncAudio.with_streaming_response","title":"with_streaming_response","text":"<pre><code>with_streaming_response() -&gt; (\n    AsyncAudioWithStreamingResponse\n)\n</code></pre>"},{"location":"reference/resources/audio/#src.openai.resources.audio.AsyncAudioWithRawResponse","title":"AsyncAudioWithRawResponse","text":"<pre><code>AsyncAudioWithRawResponse(audio: AsyncAudio)\n</code></pre> <p>Methods:</p> Name Description <code>speech</code> <code>transcriptions</code> <code>translations</code>"},{"location":"reference/resources/audio/#src.openai.resources.audio.AsyncAudioWithRawResponse.speech","title":"speech","text":"<pre><code>speech() -&gt; AsyncSpeechWithRawResponse\n</code></pre>"},{"location":"reference/resources/audio/#src.openai.resources.audio.AsyncAudioWithRawResponse.transcriptions","title":"transcriptions","text":"<pre><code>transcriptions() -&gt; AsyncTranscriptionsWithRawResponse\n</code></pre>"},{"location":"reference/resources/audio/#src.openai.resources.audio.AsyncAudioWithRawResponse.translations","title":"translations","text":"<pre><code>translations() -&gt; AsyncTranslationsWithRawResponse\n</code></pre>"},{"location":"reference/resources/audio/#src.openai.resources.audio.AsyncAudioWithStreamingResponse","title":"AsyncAudioWithStreamingResponse","text":"<pre><code>AsyncAudioWithStreamingResponse(audio: AsyncAudio)\n</code></pre> <p>Methods:</p> Name Description <code>speech</code> <code>transcriptions</code> <code>translations</code>"},{"location":"reference/resources/audio/#src.openai.resources.audio.AsyncAudioWithStreamingResponse.speech","title":"speech","text":"<pre><code>speech() -&gt; AsyncSpeechWithStreamingResponse\n</code></pre>"},{"location":"reference/resources/audio/#src.openai.resources.audio.AsyncAudioWithStreamingResponse.transcriptions","title":"transcriptions","text":"<pre><code>transcriptions() -&gt; (\n    AsyncTranscriptionsWithStreamingResponse\n)\n</code></pre>"},{"location":"reference/resources/audio/#src.openai.resources.audio.AsyncAudioWithStreamingResponse.translations","title":"translations","text":"<pre><code>translations() -&gt; AsyncTranslationsWithStreamingResponse\n</code></pre>"},{"location":"reference/resources/audio/#src.openai.resources.audio.AsyncSpeech","title":"AsyncSpeech","text":"<pre><code>AsyncSpeech(client: AsyncOpenAI)\n</code></pre> <p>Methods:</p> Name Description <code>create</code> <p>Generates audio from the input text.</p> <code>with_raw_response</code> <code>with_streaming_response</code>"},{"location":"reference/resources/audio/#src.openai.resources.audio.AsyncSpeech.create","title":"create  <code>async</code>","text":"<pre><code>create(\n    *,\n    input: str,\n    model: Union[str, Literal[\"tts-1\", \"tts-1-hd\"]],\n    voice: Literal[\n        \"alloy\", \"echo\", \"fable\", \"onyx\", \"nova\", \"shimmer\"\n    ],\n    response_format: (\n        Literal[\"mp3\", \"opus\", \"aac\", \"flac\", \"wav\", \"pcm\"]\n        | NotGiven\n    ) = NOT_GIVEN,\n    speed: float | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; HttpxBinaryResponseContent\n</code></pre> <p>Generates audio from the input text.</p> <p>Parameters:</p> Name Type Description Default <code>input</code> <code>str</code> <p>The text to generate audio for. The maximum length is 4096 characters.</p> required <code>model</code> <code>Union[str, Literal['tts-1', 'tts-1-hd']]</code> <p>One of the available TTS models:   <code>tts-1</code> or <code>tts-1-hd</code></p> required <code>voice</code> <code>Literal['alloy', 'echo', 'fable', 'onyx', 'nova', 'shimmer']</code> <p>The voice to use when generating the audio. Supported voices are <code>alloy</code>,   <code>echo</code>, <code>fable</code>, <code>onyx</code>, <code>nova</code>, and <code>shimmer</code>. Previews of the voices are   available in the   Text to speech guide.</p> required <code>response_format</code> <code>Literal['mp3', 'opus', 'aac', 'flac', 'wav', 'pcm'] | NotGiven</code> <p>The format to audio in. Supported formats are <code>mp3</code>, <code>opus</code>, <code>aac</code>, <code>flac</code>,   <code>wav</code>, and <code>pcm</code>.</p> <code>NOT_GIVEN</code> <code>speed</code> <code>float | NotGiven</code> <p>The speed of the generated audio. Select a value from <code>0.25</code> to <code>4.0</code>. <code>1.0</code> is   the default.</p> <code>NOT_GIVEN</code> <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/audio/#src.openai.resources.audio.AsyncSpeech.with_raw_response","title":"with_raw_response","text":"<pre><code>with_raw_response() -&gt; AsyncSpeechWithRawResponse\n</code></pre>"},{"location":"reference/resources/audio/#src.openai.resources.audio.AsyncSpeech.with_streaming_response","title":"with_streaming_response","text":"<pre><code>with_streaming_response() -&gt; (\n    AsyncSpeechWithStreamingResponse\n)\n</code></pre>"},{"location":"reference/resources/audio/#src.openai.resources.audio.AsyncSpeechWithRawResponse","title":"AsyncSpeechWithRawResponse","text":"<pre><code>AsyncSpeechWithRawResponse(speech: AsyncSpeech)\n</code></pre> <p>Attributes:</p> Name Type Description <code>create</code>"},{"location":"reference/resources/audio/#src.openai.resources.audio.AsyncSpeechWithRawResponse.create","title":"create  <code>instance-attribute</code>","text":"<pre><code>create = async_to_raw_response_wrapper(create)\n</code></pre>"},{"location":"reference/resources/audio/#src.openai.resources.audio.AsyncSpeechWithStreamingResponse","title":"AsyncSpeechWithStreamingResponse","text":"<pre><code>AsyncSpeechWithStreamingResponse(speech: AsyncSpeech)\n</code></pre> <p>Attributes:</p> Name Type Description <code>create</code>"},{"location":"reference/resources/audio/#src.openai.resources.audio.AsyncSpeechWithStreamingResponse.create","title":"create  <code>instance-attribute</code>","text":"<pre><code>create = async_to_custom_streamed_response_wrapper(\n    create, AsyncStreamedBinaryAPIResponse\n)\n</code></pre>"},{"location":"reference/resources/audio/#src.openai.resources.audio.AsyncTranscriptions","title":"AsyncTranscriptions","text":"<pre><code>AsyncTranscriptions(client: AsyncOpenAI)\n</code></pre> <p>Methods:</p> Name Description <code>create</code> <p>Transcribes audio into the input language.</p> <code>with_raw_response</code> <code>with_streaming_response</code>"},{"location":"reference/resources/audio/#src.openai.resources.audio.AsyncTranscriptions.create","title":"create  <code>async</code>","text":"<pre><code>create(\n    *,\n    file: FileTypes,\n    model: Union[str, Literal[\"whisper-1\"]],\n    language: str | NotGiven = NOT_GIVEN,\n    prompt: str | NotGiven = NOT_GIVEN,\n    response_format: (\n        Literal[\n            \"json\", \"text\", \"srt\", \"verbose_json\", \"vtt\"\n        ]\n        | NotGiven\n    ) = NOT_GIVEN,\n    temperature: float | NotGiven = NOT_GIVEN,\n    timestamp_granularities: (\n        List[Literal[\"word\", \"segment\"]] | NotGiven\n    ) = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; Transcription\n</code></pre> <p>Transcribes audio into the input language.</p> <p>Parameters:</p> Name Type Description Default <code>file</code> <code>FileTypes</code> <p>The audio file object (not file name) to transcribe, in one of these formats:   flac, mp3, mp4, mpeg, mpga, m4a, ogg, wav, or webm.</p> required <code>model</code> <code>Union[str, Literal['whisper-1']]</code> <p>ID of the model to use. Only <code>whisper-1</code> (which is powered by our open source   Whisper V2 model) is currently available.</p> required <code>language</code> <code>str | NotGiven</code> <p>The language of the input audio. Supplying the input language in   ISO-639-1 format will   improve accuracy and latency.</p> <code>NOT_GIVEN</code> <code>prompt</code> <code>str | NotGiven</code> <p>An optional text to guide the model's style or continue a previous audio   segment. The   prompt   should match the audio language.</p> <code>NOT_GIVEN</code> <code>response_format</code> <code>Literal['json', 'text', 'srt', 'verbose_json', 'vtt'] | NotGiven</code> <p>The format of the transcript output, in one of these options: <code>json</code>, <code>text</code>,   <code>srt</code>, <code>verbose_json</code>, or <code>vtt</code>.</p> <code>NOT_GIVEN</code> <code>temperature</code> <code>float | NotGiven</code> <p>The sampling temperature, between 0 and 1. Higher values like 0.8 will make the   output more random, while lower values like 0.2 will make it more focused and   deterministic. If set to 0, the model will use   log probability to   automatically increase the temperature until certain thresholds are hit.</p> <code>NOT_GIVEN</code> <code>timestamp_granularities</code> <code>List[Literal['word', 'segment']] | NotGiven</code> <p>The timestamp granularities to populate for this transcription.   <code>response_format</code> must be set <code>verbose_json</code> to use timestamp granularities.   Either or both of these options are supported: <code>word</code>, or <code>segment</code>. Note: There   is no additional latency for segment timestamps, but generating word timestamps   incurs additional latency.</p> <code>NOT_GIVEN</code> <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/audio/#src.openai.resources.audio.AsyncTranscriptions.with_raw_response","title":"with_raw_response","text":"<pre><code>with_raw_response() -&gt; AsyncTranscriptionsWithRawResponse\n</code></pre>"},{"location":"reference/resources/audio/#src.openai.resources.audio.AsyncTranscriptions.with_streaming_response","title":"with_streaming_response","text":"<pre><code>with_streaming_response() -&gt; (\n    AsyncTranscriptionsWithStreamingResponse\n)\n</code></pre>"},{"location":"reference/resources/audio/#src.openai.resources.audio.AsyncTranscriptionsWithRawResponse","title":"AsyncTranscriptionsWithRawResponse","text":"<pre><code>AsyncTranscriptionsWithRawResponse(\n    transcriptions: AsyncTranscriptions,\n)\n</code></pre> <p>Attributes:</p> Name Type Description <code>create</code>"},{"location":"reference/resources/audio/#src.openai.resources.audio.AsyncTranscriptionsWithRawResponse.create","title":"create  <code>instance-attribute</code>","text":"<pre><code>create = async_to_raw_response_wrapper(create)\n</code></pre>"},{"location":"reference/resources/audio/#src.openai.resources.audio.AsyncTranscriptionsWithStreamingResponse","title":"AsyncTranscriptionsWithStreamingResponse","text":"<pre><code>AsyncTranscriptionsWithStreamingResponse(\n    transcriptions: AsyncTranscriptions,\n)\n</code></pre> <p>Attributes:</p> Name Type Description <code>create</code>"},{"location":"reference/resources/audio/#src.openai.resources.audio.AsyncTranscriptionsWithStreamingResponse.create","title":"create  <code>instance-attribute</code>","text":"<pre><code>create = async_to_streamed_response_wrapper(create)\n</code></pre>"},{"location":"reference/resources/audio/#src.openai.resources.audio.AsyncTranslations","title":"AsyncTranslations","text":"<pre><code>AsyncTranslations(client: AsyncOpenAI)\n</code></pre> <p>Methods:</p> Name Description <code>create</code> <p>Translates audio into English.</p> <code>with_raw_response</code> <code>with_streaming_response</code>"},{"location":"reference/resources/audio/#src.openai.resources.audio.AsyncTranslations.create","title":"create  <code>async</code>","text":"<pre><code>create(\n    *,\n    file: FileTypes,\n    model: Union[str, Literal[\"whisper-1\"]],\n    prompt: str | NotGiven = NOT_GIVEN,\n    response_format: str | NotGiven = NOT_GIVEN,\n    temperature: float | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; Translation\n</code></pre> <p>Translates audio into English.</p> <p>Parameters:</p> Name Type Description Default <code>file</code> <code>FileTypes</code> <p>The audio file object (not file name) translate, in one of these formats: flac,   mp3, mp4, mpeg, mpga, m4a, ogg, wav, or webm.</p> required <code>model</code> <code>Union[str, Literal['whisper-1']]</code> <p>ID of the model to use. Only <code>whisper-1</code> (which is powered by our open source   Whisper V2 model) is currently available.</p> required <code>prompt</code> <code>str | NotGiven</code> <p>An optional text to guide the model's style or continue a previous audio   segment. The   prompt   should be in English.</p> <code>NOT_GIVEN</code> <code>response_format</code> <code>str | NotGiven</code> <p>The format of the transcript output, in one of these options: <code>json</code>, <code>text</code>,   <code>srt</code>, <code>verbose_json</code>, or <code>vtt</code>.</p> <code>NOT_GIVEN</code> <code>temperature</code> <code>float | NotGiven</code> <p>The sampling temperature, between 0 and 1. Higher values like 0.8 will make the   output more random, while lower values like 0.2 will make it more focused and   deterministic. If set to 0, the model will use   log probability to   automatically increase the temperature until certain thresholds are hit.</p> <code>NOT_GIVEN</code> <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/audio/#src.openai.resources.audio.AsyncTranslations.with_raw_response","title":"with_raw_response","text":"<pre><code>with_raw_response() -&gt; AsyncTranslationsWithRawResponse\n</code></pre>"},{"location":"reference/resources/audio/#src.openai.resources.audio.AsyncTranslations.with_streaming_response","title":"with_streaming_response","text":"<pre><code>with_streaming_response() -&gt; (\n    AsyncTranslationsWithStreamingResponse\n)\n</code></pre>"},{"location":"reference/resources/audio/#src.openai.resources.audio.AsyncTranslationsWithRawResponse","title":"AsyncTranslationsWithRawResponse","text":"<pre><code>AsyncTranslationsWithRawResponse(\n    translations: AsyncTranslations,\n)\n</code></pre> <p>Attributes:</p> Name Type Description <code>create</code>"},{"location":"reference/resources/audio/#src.openai.resources.audio.AsyncTranslationsWithRawResponse.create","title":"create  <code>instance-attribute</code>","text":"<pre><code>create = async_to_raw_response_wrapper(create)\n</code></pre>"},{"location":"reference/resources/audio/#src.openai.resources.audio.AsyncTranslationsWithStreamingResponse","title":"AsyncTranslationsWithStreamingResponse","text":"<pre><code>AsyncTranslationsWithStreamingResponse(\n    translations: AsyncTranslations,\n)\n</code></pre> <p>Attributes:</p> Name Type Description <code>create</code>"},{"location":"reference/resources/audio/#src.openai.resources.audio.AsyncTranslationsWithStreamingResponse.create","title":"create  <code>instance-attribute</code>","text":"<pre><code>create = async_to_streamed_response_wrapper(create)\n</code></pre>"},{"location":"reference/resources/audio/#src.openai.resources.audio.Audio","title":"Audio","text":"<pre><code>Audio(client: OpenAI)\n</code></pre> <p>Methods:</p> Name Description <code>speech</code> <code>transcriptions</code> <code>translations</code> <code>with_raw_response</code> <code>with_streaming_response</code>"},{"location":"reference/resources/audio/#src.openai.resources.audio.Audio.speech","title":"speech","text":"<pre><code>speech() -&gt; Speech\n</code></pre>"},{"location":"reference/resources/audio/#src.openai.resources.audio.Audio.transcriptions","title":"transcriptions","text":"<pre><code>transcriptions() -&gt; Transcriptions\n</code></pre>"},{"location":"reference/resources/audio/#src.openai.resources.audio.Audio.translations","title":"translations","text":"<pre><code>translations() -&gt; Translations\n</code></pre>"},{"location":"reference/resources/audio/#src.openai.resources.audio.Audio.with_raw_response","title":"with_raw_response","text":"<pre><code>with_raw_response() -&gt; AudioWithRawResponse\n</code></pre>"},{"location":"reference/resources/audio/#src.openai.resources.audio.Audio.with_streaming_response","title":"with_streaming_response","text":"<pre><code>with_streaming_response() -&gt; AudioWithStreamingResponse\n</code></pre>"},{"location":"reference/resources/audio/#src.openai.resources.audio.AudioWithRawResponse","title":"AudioWithRawResponse","text":"<pre><code>AudioWithRawResponse(audio: Audio)\n</code></pre> <p>Methods:</p> Name Description <code>speech</code> <code>transcriptions</code> <code>translations</code>"},{"location":"reference/resources/audio/#src.openai.resources.audio.AudioWithRawResponse.speech","title":"speech","text":"<pre><code>speech() -&gt; SpeechWithRawResponse\n</code></pre>"},{"location":"reference/resources/audio/#src.openai.resources.audio.AudioWithRawResponse.transcriptions","title":"transcriptions","text":"<pre><code>transcriptions() -&gt; TranscriptionsWithRawResponse\n</code></pre>"},{"location":"reference/resources/audio/#src.openai.resources.audio.AudioWithRawResponse.translations","title":"translations","text":"<pre><code>translations() -&gt; TranslationsWithRawResponse\n</code></pre>"},{"location":"reference/resources/audio/#src.openai.resources.audio.AudioWithStreamingResponse","title":"AudioWithStreamingResponse","text":"<pre><code>AudioWithStreamingResponse(audio: Audio)\n</code></pre> <p>Methods:</p> Name Description <code>speech</code> <code>transcriptions</code> <code>translations</code>"},{"location":"reference/resources/audio/#src.openai.resources.audio.AudioWithStreamingResponse.speech","title":"speech","text":"<pre><code>speech() -&gt; SpeechWithStreamingResponse\n</code></pre>"},{"location":"reference/resources/audio/#src.openai.resources.audio.AudioWithStreamingResponse.transcriptions","title":"transcriptions","text":"<pre><code>transcriptions() -&gt; TranscriptionsWithStreamingResponse\n</code></pre>"},{"location":"reference/resources/audio/#src.openai.resources.audio.AudioWithStreamingResponse.translations","title":"translations","text":"<pre><code>translations() -&gt; TranslationsWithStreamingResponse\n</code></pre>"},{"location":"reference/resources/audio/#src.openai.resources.audio.Speech","title":"Speech","text":"<pre><code>Speech(client: OpenAI)\n</code></pre> <p>Methods:</p> Name Description <code>create</code> <p>Generates audio from the input text.</p> <code>with_raw_response</code> <code>with_streaming_response</code>"},{"location":"reference/resources/audio/#src.openai.resources.audio.Speech.create","title":"create","text":"<pre><code>create(\n    *,\n    input: str,\n    model: Union[str, Literal[\"tts-1\", \"tts-1-hd\"]],\n    voice: Literal[\n        \"alloy\", \"echo\", \"fable\", \"onyx\", \"nova\", \"shimmer\"\n    ],\n    response_format: (\n        Literal[\"mp3\", \"opus\", \"aac\", \"flac\", \"wav\", \"pcm\"]\n        | NotGiven\n    ) = NOT_GIVEN,\n    speed: float | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; HttpxBinaryResponseContent\n</code></pre> <p>Generates audio from the input text.</p> <p>Parameters:</p> Name Type Description Default <code>input</code> <code>str</code> <p>The text to generate audio for. The maximum length is 4096 characters.</p> required <code>model</code> <code>Union[str, Literal['tts-1', 'tts-1-hd']]</code> <p>One of the available TTS models:   <code>tts-1</code> or <code>tts-1-hd</code></p> required <code>voice</code> <code>Literal['alloy', 'echo', 'fable', 'onyx', 'nova', 'shimmer']</code> <p>The voice to use when generating the audio. Supported voices are <code>alloy</code>,   <code>echo</code>, <code>fable</code>, <code>onyx</code>, <code>nova</code>, and <code>shimmer</code>. Previews of the voices are   available in the   Text to speech guide.</p> required <code>response_format</code> <code>Literal['mp3', 'opus', 'aac', 'flac', 'wav', 'pcm'] | NotGiven</code> <p>The format to audio in. Supported formats are <code>mp3</code>, <code>opus</code>, <code>aac</code>, <code>flac</code>,   <code>wav</code>, and <code>pcm</code>.</p> <code>NOT_GIVEN</code> <code>speed</code> <code>float | NotGiven</code> <p>The speed of the generated audio. Select a value from <code>0.25</code> to <code>4.0</code>. <code>1.0</code> is   the default.</p> <code>NOT_GIVEN</code> <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/audio/#src.openai.resources.audio.Speech.with_raw_response","title":"with_raw_response","text":"<pre><code>with_raw_response() -&gt; SpeechWithRawResponse\n</code></pre>"},{"location":"reference/resources/audio/#src.openai.resources.audio.Speech.with_streaming_response","title":"with_streaming_response","text":"<pre><code>with_streaming_response() -&gt; SpeechWithStreamingResponse\n</code></pre>"},{"location":"reference/resources/audio/#src.openai.resources.audio.SpeechWithRawResponse","title":"SpeechWithRawResponse","text":"<pre><code>SpeechWithRawResponse(speech: Speech)\n</code></pre> <p>Attributes:</p> Name Type Description <code>create</code>"},{"location":"reference/resources/audio/#src.openai.resources.audio.SpeechWithRawResponse.create","title":"create  <code>instance-attribute</code>","text":"<pre><code>create = to_raw_response_wrapper(create)\n</code></pre>"},{"location":"reference/resources/audio/#src.openai.resources.audio.SpeechWithStreamingResponse","title":"SpeechWithStreamingResponse","text":"<pre><code>SpeechWithStreamingResponse(speech: Speech)\n</code></pre> <p>Attributes:</p> Name Type Description <code>create</code>"},{"location":"reference/resources/audio/#src.openai.resources.audio.SpeechWithStreamingResponse.create","title":"create  <code>instance-attribute</code>","text":"<pre><code>create = to_custom_streamed_response_wrapper(\n    create, StreamedBinaryAPIResponse\n)\n</code></pre>"},{"location":"reference/resources/audio/#src.openai.resources.audio.Transcriptions","title":"Transcriptions","text":"<pre><code>Transcriptions(client: OpenAI)\n</code></pre> <p>Methods:</p> Name Description <code>create</code> <p>Transcribes audio into the input language.</p> <code>with_raw_response</code> <code>with_streaming_response</code>"},{"location":"reference/resources/audio/#src.openai.resources.audio.Transcriptions.create","title":"create","text":"<pre><code>create(\n    *,\n    file: FileTypes,\n    model: Union[str, Literal[\"whisper-1\"]],\n    language: str | NotGiven = NOT_GIVEN,\n    prompt: str | NotGiven = NOT_GIVEN,\n    response_format: (\n        Literal[\n            \"json\", \"text\", \"srt\", \"verbose_json\", \"vtt\"\n        ]\n        | NotGiven\n    ) = NOT_GIVEN,\n    temperature: float | NotGiven = NOT_GIVEN,\n    timestamp_granularities: (\n        List[Literal[\"word\", \"segment\"]] | NotGiven\n    ) = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; Transcription\n</code></pre> <p>Transcribes audio into the input language.</p> <p>Parameters:</p> Name Type Description Default <code>file</code> <code>FileTypes</code> <p>The audio file object (not file name) to transcribe, in one of these formats:   flac, mp3, mp4, mpeg, mpga, m4a, ogg, wav, or webm.</p> required <code>model</code> <code>Union[str, Literal['whisper-1']]</code> <p>ID of the model to use. Only <code>whisper-1</code> (which is powered by our open source   Whisper V2 model) is currently available.</p> required <code>language</code> <code>str | NotGiven</code> <p>The language of the input audio. Supplying the input language in   ISO-639-1 format will   improve accuracy and latency.</p> <code>NOT_GIVEN</code> <code>prompt</code> <code>str | NotGiven</code> <p>An optional text to guide the model's style or continue a previous audio   segment. The   prompt   should match the audio language.</p> <code>NOT_GIVEN</code> <code>response_format</code> <code>Literal['json', 'text', 'srt', 'verbose_json', 'vtt'] | NotGiven</code> <p>The format of the transcript output, in one of these options: <code>json</code>, <code>text</code>,   <code>srt</code>, <code>verbose_json</code>, or <code>vtt</code>.</p> <code>NOT_GIVEN</code> <code>temperature</code> <code>float | NotGiven</code> <p>The sampling temperature, between 0 and 1. Higher values like 0.8 will make the   output more random, while lower values like 0.2 will make it more focused and   deterministic. If set to 0, the model will use   log probability to   automatically increase the temperature until certain thresholds are hit.</p> <code>NOT_GIVEN</code> <code>timestamp_granularities</code> <code>List[Literal['word', 'segment']] | NotGiven</code> <p>The timestamp granularities to populate for this transcription.   <code>response_format</code> must be set <code>verbose_json</code> to use timestamp granularities.   Either or both of these options are supported: <code>word</code>, or <code>segment</code>. Note: There   is no additional latency for segment timestamps, but generating word timestamps   incurs additional latency.</p> <code>NOT_GIVEN</code> <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/audio/#src.openai.resources.audio.Transcriptions.with_raw_response","title":"with_raw_response","text":"<pre><code>with_raw_response() -&gt; TranscriptionsWithRawResponse\n</code></pre>"},{"location":"reference/resources/audio/#src.openai.resources.audio.Transcriptions.with_streaming_response","title":"with_streaming_response","text":"<pre><code>with_streaming_response() -&gt; (\n    TranscriptionsWithStreamingResponse\n)\n</code></pre>"},{"location":"reference/resources/audio/#src.openai.resources.audio.TranscriptionsWithRawResponse","title":"TranscriptionsWithRawResponse","text":"<pre><code>TranscriptionsWithRawResponse(\n    transcriptions: Transcriptions,\n)\n</code></pre> <p>Attributes:</p> Name Type Description <code>create</code>"},{"location":"reference/resources/audio/#src.openai.resources.audio.TranscriptionsWithRawResponse.create","title":"create  <code>instance-attribute</code>","text":"<pre><code>create = to_raw_response_wrapper(create)\n</code></pre>"},{"location":"reference/resources/audio/#src.openai.resources.audio.TranscriptionsWithStreamingResponse","title":"TranscriptionsWithStreamingResponse","text":"<pre><code>TranscriptionsWithStreamingResponse(\n    transcriptions: Transcriptions,\n)\n</code></pre> <p>Attributes:</p> Name Type Description <code>create</code>"},{"location":"reference/resources/audio/#src.openai.resources.audio.TranscriptionsWithStreamingResponse.create","title":"create  <code>instance-attribute</code>","text":"<pre><code>create = to_streamed_response_wrapper(create)\n</code></pre>"},{"location":"reference/resources/audio/#src.openai.resources.audio.Translations","title":"Translations","text":"<pre><code>Translations(client: OpenAI)\n</code></pre> <p>Methods:</p> Name Description <code>create</code> <p>Translates audio into English.</p> <code>with_raw_response</code> <code>with_streaming_response</code>"},{"location":"reference/resources/audio/#src.openai.resources.audio.Translations.create","title":"create","text":"<pre><code>create(\n    *,\n    file: FileTypes,\n    model: Union[str, Literal[\"whisper-1\"]],\n    prompt: str | NotGiven = NOT_GIVEN,\n    response_format: str | NotGiven = NOT_GIVEN,\n    temperature: float | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; Translation\n</code></pre> <p>Translates audio into English.</p> <p>Parameters:</p> Name Type Description Default <code>file</code> <code>FileTypes</code> <p>The audio file object (not file name) translate, in one of these formats: flac,   mp3, mp4, mpeg, mpga, m4a, ogg, wav, or webm.</p> required <code>model</code> <code>Union[str, Literal['whisper-1']]</code> <p>ID of the model to use. Only <code>whisper-1</code> (which is powered by our open source   Whisper V2 model) is currently available.</p> required <code>prompt</code> <code>str | NotGiven</code> <p>An optional text to guide the model's style or continue a previous audio   segment. The   prompt   should be in English.</p> <code>NOT_GIVEN</code> <code>response_format</code> <code>str | NotGiven</code> <p>The format of the transcript output, in one of these options: <code>json</code>, <code>text</code>,   <code>srt</code>, <code>verbose_json</code>, or <code>vtt</code>.</p> <code>NOT_GIVEN</code> <code>temperature</code> <code>float | NotGiven</code> <p>The sampling temperature, between 0 and 1. Higher values like 0.8 will make the   output more random, while lower values like 0.2 will make it more focused and   deterministic. If set to 0, the model will use   log probability to   automatically increase the temperature until certain thresholds are hit.</p> <code>NOT_GIVEN</code> <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/audio/#src.openai.resources.audio.Translations.with_raw_response","title":"with_raw_response","text":"<pre><code>with_raw_response() -&gt; TranslationsWithRawResponse\n</code></pre>"},{"location":"reference/resources/audio/#src.openai.resources.audio.Translations.with_streaming_response","title":"with_streaming_response","text":"<pre><code>with_streaming_response() -&gt; (\n    TranslationsWithStreamingResponse\n)\n</code></pre>"},{"location":"reference/resources/audio/#src.openai.resources.audio.TranslationsWithRawResponse","title":"TranslationsWithRawResponse","text":"<pre><code>TranslationsWithRawResponse(translations: Translations)\n</code></pre> <p>Attributes:</p> Name Type Description <code>create</code>"},{"location":"reference/resources/audio/#src.openai.resources.audio.TranslationsWithRawResponse.create","title":"create  <code>instance-attribute</code>","text":"<pre><code>create = to_raw_response_wrapper(create)\n</code></pre>"},{"location":"reference/resources/audio/#src.openai.resources.audio.TranslationsWithStreamingResponse","title":"TranslationsWithStreamingResponse","text":"<pre><code>TranslationsWithStreamingResponse(\n    translations: Translations,\n)\n</code></pre> <p>Attributes:</p> Name Type Description <code>create</code>"},{"location":"reference/resources/audio/#src.openai.resources.audio.TranslationsWithStreamingResponse.create","title":"create  <code>instance-attribute</code>","text":"<pre><code>create = to_streamed_response_wrapper(create)\n</code></pre>"},{"location":"reference/resources/audio/audio/","title":"audio","text":"<p>The <code>audio</code> module provides classes for audio processing operations like transcription, translation, and speech synthesis.</p> <p>Use the <code>audio</code> module by accessing the <code>OpenAI.audio</code> attribute on the client object, and then access the attribute for the feature you'd like to use:</p> <ul> <li><code>OpenAI.audio.transcriptions</code> - Transcribe spoken audio to text</li> <li><code>OpenAI.audio.translations</code> - Translate spoken audio to English</li> <li><code>OpenAI.audio.speech</code> - Generate spoken audio from text</li> </ul> <p>Examples:     <pre><code>from pathlib import Path\n\nfrom openai import OpenAI\n\nopenai = OpenAI()\n\nspeech_file_path = Path(__file__).parent / \"speech.mp3\"\n\n    # Create text-to-speech audio file\n    with openai.audio.speech.with_streaming_response.create(\n        model=\"tts-1\",\n        voice=\"alloy\",\n        input=\"The quick brown fox jumps over the lazy dog.\",\n    ) as response:\n        response.stream_to_file(speech_file_path)\n</code></pre></p> <p>Classes:</p> Name Description <code>AsyncAudio</code> <code>AsyncAudioWithRawResponse</code> <code>AsyncAudioWithStreamingResponse</code> <code>Audio</code> <code>AudioWithRawResponse</code> <code>AudioWithStreamingResponse</code>"},{"location":"reference/resources/audio/audio/#src.openai.resources.audio.audio.AsyncAudio","title":"AsyncAudio","text":"<pre><code>AsyncAudio(client: AsyncOpenAI)\n</code></pre> <p>Methods:</p> Name Description <code>speech</code> <code>transcriptions</code> <code>translations</code> <code>with_raw_response</code> <code>with_streaming_response</code>"},{"location":"reference/resources/audio/audio/#src.openai.resources.audio.audio.AsyncAudio.speech","title":"speech","text":"<pre><code>speech() -&gt; AsyncSpeech\n</code></pre>"},{"location":"reference/resources/audio/audio/#src.openai.resources.audio.audio.AsyncAudio.transcriptions","title":"transcriptions","text":"<pre><code>transcriptions() -&gt; AsyncTranscriptions\n</code></pre>"},{"location":"reference/resources/audio/audio/#src.openai.resources.audio.audio.AsyncAudio.translations","title":"translations","text":"<pre><code>translations() -&gt; AsyncTranslations\n</code></pre>"},{"location":"reference/resources/audio/audio/#src.openai.resources.audio.audio.AsyncAudio.with_raw_response","title":"with_raw_response","text":"<pre><code>with_raw_response() -&gt; AsyncAudioWithRawResponse\n</code></pre>"},{"location":"reference/resources/audio/audio/#src.openai.resources.audio.audio.AsyncAudio.with_streaming_response","title":"with_streaming_response","text":"<pre><code>with_streaming_response() -&gt; (\n    AsyncAudioWithStreamingResponse\n)\n</code></pre>"},{"location":"reference/resources/audio/audio/#src.openai.resources.audio.audio.AsyncAudioWithRawResponse","title":"AsyncAudioWithRawResponse","text":"<pre><code>AsyncAudioWithRawResponse(audio: AsyncAudio)\n</code></pre> <p>Methods:</p> Name Description <code>speech</code> <code>transcriptions</code> <code>translations</code>"},{"location":"reference/resources/audio/audio/#src.openai.resources.audio.audio.AsyncAudioWithRawResponse.speech","title":"speech","text":"<pre><code>speech() -&gt; AsyncSpeechWithRawResponse\n</code></pre>"},{"location":"reference/resources/audio/audio/#src.openai.resources.audio.audio.AsyncAudioWithRawResponse.transcriptions","title":"transcriptions","text":"<pre><code>transcriptions() -&gt; AsyncTranscriptionsWithRawResponse\n</code></pre>"},{"location":"reference/resources/audio/audio/#src.openai.resources.audio.audio.AsyncAudioWithRawResponse.translations","title":"translations","text":"<pre><code>translations() -&gt; AsyncTranslationsWithRawResponse\n</code></pre>"},{"location":"reference/resources/audio/audio/#src.openai.resources.audio.audio.AsyncAudioWithStreamingResponse","title":"AsyncAudioWithStreamingResponse","text":"<pre><code>AsyncAudioWithStreamingResponse(audio: AsyncAudio)\n</code></pre> <p>Methods:</p> Name Description <code>speech</code> <code>transcriptions</code> <code>translations</code>"},{"location":"reference/resources/audio/audio/#src.openai.resources.audio.audio.AsyncAudioWithStreamingResponse.speech","title":"speech","text":"<pre><code>speech() -&gt; AsyncSpeechWithStreamingResponse\n</code></pre>"},{"location":"reference/resources/audio/audio/#src.openai.resources.audio.audio.AsyncAudioWithStreamingResponse.transcriptions","title":"transcriptions","text":"<pre><code>transcriptions() -&gt; (\n    AsyncTranscriptionsWithStreamingResponse\n)\n</code></pre>"},{"location":"reference/resources/audio/audio/#src.openai.resources.audio.audio.AsyncAudioWithStreamingResponse.translations","title":"translations","text":"<pre><code>translations() -&gt; AsyncTranslationsWithStreamingResponse\n</code></pre>"},{"location":"reference/resources/audio/audio/#src.openai.resources.audio.audio.Audio","title":"Audio","text":"<pre><code>Audio(client: OpenAI)\n</code></pre> <p>Methods:</p> Name Description <code>speech</code> <code>transcriptions</code> <code>translations</code> <code>with_raw_response</code> <code>with_streaming_response</code>"},{"location":"reference/resources/audio/audio/#src.openai.resources.audio.audio.Audio.speech","title":"speech","text":"<pre><code>speech() -&gt; Speech\n</code></pre>"},{"location":"reference/resources/audio/audio/#src.openai.resources.audio.audio.Audio.transcriptions","title":"transcriptions","text":"<pre><code>transcriptions() -&gt; Transcriptions\n</code></pre>"},{"location":"reference/resources/audio/audio/#src.openai.resources.audio.audio.Audio.translations","title":"translations","text":"<pre><code>translations() -&gt; Translations\n</code></pre>"},{"location":"reference/resources/audio/audio/#src.openai.resources.audio.audio.Audio.with_raw_response","title":"with_raw_response","text":"<pre><code>with_raw_response() -&gt; AudioWithRawResponse\n</code></pre>"},{"location":"reference/resources/audio/audio/#src.openai.resources.audio.audio.Audio.with_streaming_response","title":"with_streaming_response","text":"<pre><code>with_streaming_response() -&gt; AudioWithStreamingResponse\n</code></pre>"},{"location":"reference/resources/audio/audio/#src.openai.resources.audio.audio.AudioWithRawResponse","title":"AudioWithRawResponse","text":"<pre><code>AudioWithRawResponse(audio: Audio)\n</code></pre> <p>Methods:</p> Name Description <code>speech</code> <code>transcriptions</code> <code>translations</code>"},{"location":"reference/resources/audio/audio/#src.openai.resources.audio.audio.AudioWithRawResponse.speech","title":"speech","text":"<pre><code>speech() -&gt; SpeechWithRawResponse\n</code></pre>"},{"location":"reference/resources/audio/audio/#src.openai.resources.audio.audio.AudioWithRawResponse.transcriptions","title":"transcriptions","text":"<pre><code>transcriptions() -&gt; TranscriptionsWithRawResponse\n</code></pre>"},{"location":"reference/resources/audio/audio/#src.openai.resources.audio.audio.AudioWithRawResponse.translations","title":"translations","text":"<pre><code>translations() -&gt; TranslationsWithRawResponse\n</code></pre>"},{"location":"reference/resources/audio/audio/#src.openai.resources.audio.audio.AudioWithStreamingResponse","title":"AudioWithStreamingResponse","text":"<pre><code>AudioWithStreamingResponse(audio: Audio)\n</code></pre> <p>Methods:</p> Name Description <code>speech</code> <code>transcriptions</code> <code>translations</code>"},{"location":"reference/resources/audio/audio/#src.openai.resources.audio.audio.AudioWithStreamingResponse.speech","title":"speech","text":"<pre><code>speech() -&gt; SpeechWithStreamingResponse\n</code></pre>"},{"location":"reference/resources/audio/audio/#src.openai.resources.audio.audio.AudioWithStreamingResponse.transcriptions","title":"transcriptions","text":"<pre><code>transcriptions() -&gt; TranscriptionsWithStreamingResponse\n</code></pre>"},{"location":"reference/resources/audio/audio/#src.openai.resources.audio.audio.AudioWithStreamingResponse.translations","title":"translations","text":"<pre><code>translations() -&gt; TranslationsWithStreamingResponse\n</code></pre>"},{"location":"reference/resources/audio/speech/","title":"speech","text":"<p>Classes:</p> Name Description <code>AsyncSpeech</code> <code>AsyncSpeechWithRawResponse</code> <code>AsyncSpeechWithStreamingResponse</code> <code>Speech</code> <code>SpeechWithRawResponse</code> <code>SpeechWithStreamingResponse</code>"},{"location":"reference/resources/audio/speech/#src.openai.resources.audio.speech.AsyncSpeech","title":"AsyncSpeech","text":"<pre><code>AsyncSpeech(client: AsyncOpenAI)\n</code></pre> <p>Methods:</p> Name Description <code>create</code> <p>Generates audio from the input text.</p> <code>with_raw_response</code> <code>with_streaming_response</code>"},{"location":"reference/resources/audio/speech/#src.openai.resources.audio.speech.AsyncSpeech.create","title":"create  <code>async</code>","text":"<pre><code>create(\n    *,\n    input: str,\n    model: Union[str, Literal[\"tts-1\", \"tts-1-hd\"]],\n    voice: Literal[\n        \"alloy\", \"echo\", \"fable\", \"onyx\", \"nova\", \"shimmer\"\n    ],\n    response_format: (\n        Literal[\"mp3\", \"opus\", \"aac\", \"flac\", \"wav\", \"pcm\"]\n        | NotGiven\n    ) = NOT_GIVEN,\n    speed: float | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; HttpxBinaryResponseContent\n</code></pre> <p>Generates audio from the input text.</p> <p>Parameters:</p> Name Type Description Default <code>input</code> <code>str</code> <p>The text to generate audio for. The maximum length is 4096 characters.</p> required <code>model</code> <code>Union[str, Literal['tts-1', 'tts-1-hd']]</code> <p>One of the available TTS models:   <code>tts-1</code> or <code>tts-1-hd</code></p> required <code>voice</code> <code>Literal['alloy', 'echo', 'fable', 'onyx', 'nova', 'shimmer']</code> <p>The voice to use when generating the audio. Supported voices are <code>alloy</code>,   <code>echo</code>, <code>fable</code>, <code>onyx</code>, <code>nova</code>, and <code>shimmer</code>. Previews of the voices are   available in the   Text to speech guide.</p> required <code>response_format</code> <code>Literal['mp3', 'opus', 'aac', 'flac', 'wav', 'pcm'] | NotGiven</code> <p>The format to audio in. Supported formats are <code>mp3</code>, <code>opus</code>, <code>aac</code>, <code>flac</code>,   <code>wav</code>, and <code>pcm</code>.</p> <code>NOT_GIVEN</code> <code>speed</code> <code>float | NotGiven</code> <p>The speed of the generated audio. Select a value from <code>0.25</code> to <code>4.0</code>. <code>1.0</code> is   the default.</p> <code>NOT_GIVEN</code> <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/audio/speech/#src.openai.resources.audio.speech.AsyncSpeech.with_raw_response","title":"with_raw_response","text":"<pre><code>with_raw_response() -&gt; AsyncSpeechWithRawResponse\n</code></pre>"},{"location":"reference/resources/audio/speech/#src.openai.resources.audio.speech.AsyncSpeech.with_streaming_response","title":"with_streaming_response","text":"<pre><code>with_streaming_response() -&gt; (\n    AsyncSpeechWithStreamingResponse\n)\n</code></pre>"},{"location":"reference/resources/audio/speech/#src.openai.resources.audio.speech.AsyncSpeechWithRawResponse","title":"AsyncSpeechWithRawResponse","text":"<pre><code>AsyncSpeechWithRawResponse(speech: AsyncSpeech)\n</code></pre> <p>Attributes:</p> Name Type Description <code>create</code>"},{"location":"reference/resources/audio/speech/#src.openai.resources.audio.speech.AsyncSpeechWithRawResponse.create","title":"create  <code>instance-attribute</code>","text":"<pre><code>create = async_to_raw_response_wrapper(create)\n</code></pre>"},{"location":"reference/resources/audio/speech/#src.openai.resources.audio.speech.AsyncSpeechWithStreamingResponse","title":"AsyncSpeechWithStreamingResponse","text":"<pre><code>AsyncSpeechWithStreamingResponse(speech: AsyncSpeech)\n</code></pre> <p>Attributes:</p> Name Type Description <code>create</code>"},{"location":"reference/resources/audio/speech/#src.openai.resources.audio.speech.AsyncSpeechWithStreamingResponse.create","title":"create  <code>instance-attribute</code>","text":"<pre><code>create = async_to_custom_streamed_response_wrapper(\n    create, AsyncStreamedBinaryAPIResponse\n)\n</code></pre>"},{"location":"reference/resources/audio/speech/#src.openai.resources.audio.speech.Speech","title":"Speech","text":"<pre><code>Speech(client: OpenAI)\n</code></pre> <p>Methods:</p> Name Description <code>create</code> <p>Generates audio from the input text.</p> <code>with_raw_response</code> <code>with_streaming_response</code>"},{"location":"reference/resources/audio/speech/#src.openai.resources.audio.speech.Speech.create","title":"create","text":"<pre><code>create(\n    *,\n    input: str,\n    model: Union[str, Literal[\"tts-1\", \"tts-1-hd\"]],\n    voice: Literal[\n        \"alloy\", \"echo\", \"fable\", \"onyx\", \"nova\", \"shimmer\"\n    ],\n    response_format: (\n        Literal[\"mp3\", \"opus\", \"aac\", \"flac\", \"wav\", \"pcm\"]\n        | NotGiven\n    ) = NOT_GIVEN,\n    speed: float | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; HttpxBinaryResponseContent\n</code></pre> <p>Generates audio from the input text.</p> <p>Parameters:</p> Name Type Description Default <code>input</code> <code>str</code> <p>The text to generate audio for. The maximum length is 4096 characters.</p> required <code>model</code> <code>Union[str, Literal['tts-1', 'tts-1-hd']]</code> <p>One of the available TTS models:   <code>tts-1</code> or <code>tts-1-hd</code></p> required <code>voice</code> <code>Literal['alloy', 'echo', 'fable', 'onyx', 'nova', 'shimmer']</code> <p>The voice to use when generating the audio. Supported voices are <code>alloy</code>,   <code>echo</code>, <code>fable</code>, <code>onyx</code>, <code>nova</code>, and <code>shimmer</code>. Previews of the voices are   available in the   Text to speech guide.</p> required <code>response_format</code> <code>Literal['mp3', 'opus', 'aac', 'flac', 'wav', 'pcm'] | NotGiven</code> <p>The format to audio in. Supported formats are <code>mp3</code>, <code>opus</code>, <code>aac</code>, <code>flac</code>,   <code>wav</code>, and <code>pcm</code>.</p> <code>NOT_GIVEN</code> <code>speed</code> <code>float | NotGiven</code> <p>The speed of the generated audio. Select a value from <code>0.25</code> to <code>4.0</code>. <code>1.0</code> is   the default.</p> <code>NOT_GIVEN</code> <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/audio/speech/#src.openai.resources.audio.speech.Speech.with_raw_response","title":"with_raw_response","text":"<pre><code>with_raw_response() -&gt; SpeechWithRawResponse\n</code></pre>"},{"location":"reference/resources/audio/speech/#src.openai.resources.audio.speech.Speech.with_streaming_response","title":"with_streaming_response","text":"<pre><code>with_streaming_response() -&gt; SpeechWithStreamingResponse\n</code></pre>"},{"location":"reference/resources/audio/speech/#src.openai.resources.audio.speech.SpeechWithRawResponse","title":"SpeechWithRawResponse","text":"<pre><code>SpeechWithRawResponse(speech: Speech)\n</code></pre> <p>Attributes:</p> Name Type Description <code>create</code>"},{"location":"reference/resources/audio/speech/#src.openai.resources.audio.speech.SpeechWithRawResponse.create","title":"create  <code>instance-attribute</code>","text":"<pre><code>create = to_raw_response_wrapper(create)\n</code></pre>"},{"location":"reference/resources/audio/speech/#src.openai.resources.audio.speech.SpeechWithStreamingResponse","title":"SpeechWithStreamingResponse","text":"<pre><code>SpeechWithStreamingResponse(speech: Speech)\n</code></pre> <p>Attributes:</p> Name Type Description <code>create</code>"},{"location":"reference/resources/audio/speech/#src.openai.resources.audio.speech.SpeechWithStreamingResponse.create","title":"create  <code>instance-attribute</code>","text":"<pre><code>create = to_custom_streamed_response_wrapper(\n    create, StreamedBinaryAPIResponse\n)\n</code></pre>"},{"location":"reference/resources/audio/transcriptions/","title":"transcriptions","text":"<p>Classes:</p> Name Description <code>AsyncTranscriptions</code> <code>AsyncTranscriptionsWithRawResponse</code> <code>AsyncTranscriptionsWithStreamingResponse</code> <code>Transcriptions</code> <code>TranscriptionsWithRawResponse</code> <code>TranscriptionsWithStreamingResponse</code>"},{"location":"reference/resources/audio/transcriptions/#src.openai.resources.audio.transcriptions.AsyncTranscriptions","title":"AsyncTranscriptions","text":"<pre><code>AsyncTranscriptions(client: AsyncOpenAI)\n</code></pre> <p>Methods:</p> Name Description <code>create</code> <p>Transcribes audio into the input language.</p> <code>with_raw_response</code> <code>with_streaming_response</code>"},{"location":"reference/resources/audio/transcriptions/#src.openai.resources.audio.transcriptions.AsyncTranscriptions.create","title":"create  <code>async</code>","text":"<pre><code>create(\n    *,\n    file: FileTypes,\n    model: Union[str, Literal[\"whisper-1\"]],\n    language: str | NotGiven = NOT_GIVEN,\n    prompt: str | NotGiven = NOT_GIVEN,\n    response_format: (\n        Literal[\n            \"json\", \"text\", \"srt\", \"verbose_json\", \"vtt\"\n        ]\n        | NotGiven\n    ) = NOT_GIVEN,\n    temperature: float | NotGiven = NOT_GIVEN,\n    timestamp_granularities: (\n        List[Literal[\"word\", \"segment\"]] | NotGiven\n    ) = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; Transcription\n</code></pre> <p>Transcribes audio into the input language.</p> <p>Parameters:</p> Name Type Description Default <code>file</code> <code>FileTypes</code> <p>The audio file object (not file name) to transcribe, in one of these formats:   flac, mp3, mp4, mpeg, mpga, m4a, ogg, wav, or webm.</p> required <code>model</code> <code>Union[str, Literal['whisper-1']]</code> <p>ID of the model to use. Only <code>whisper-1</code> (which is powered by our open source   Whisper V2 model) is currently available.</p> required <code>language</code> <code>str | NotGiven</code> <p>The language of the input audio. Supplying the input language in   ISO-639-1 format will   improve accuracy and latency.</p> <code>NOT_GIVEN</code> <code>prompt</code> <code>str | NotGiven</code> <p>An optional text to guide the model's style or continue a previous audio   segment. The   prompt   should match the audio language.</p> <code>NOT_GIVEN</code> <code>response_format</code> <code>Literal['json', 'text', 'srt', 'verbose_json', 'vtt'] | NotGiven</code> <p>The format of the transcript output, in one of these options: <code>json</code>, <code>text</code>,   <code>srt</code>, <code>verbose_json</code>, or <code>vtt</code>.</p> <code>NOT_GIVEN</code> <code>temperature</code> <code>float | NotGiven</code> <p>The sampling temperature, between 0 and 1. Higher values like 0.8 will make the   output more random, while lower values like 0.2 will make it more focused and   deterministic. If set to 0, the model will use   log probability to   automatically increase the temperature until certain thresholds are hit.</p> <code>NOT_GIVEN</code> <code>timestamp_granularities</code> <code>List[Literal['word', 'segment']] | NotGiven</code> <p>The timestamp granularities to populate for this transcription.   <code>response_format</code> must be set <code>verbose_json</code> to use timestamp granularities.   Either or both of these options are supported: <code>word</code>, or <code>segment</code>. Note: There   is no additional latency for segment timestamps, but generating word timestamps   incurs additional latency.</p> <code>NOT_GIVEN</code> <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/audio/transcriptions/#src.openai.resources.audio.transcriptions.AsyncTranscriptions.with_raw_response","title":"with_raw_response","text":"<pre><code>with_raw_response() -&gt; AsyncTranscriptionsWithRawResponse\n</code></pre>"},{"location":"reference/resources/audio/transcriptions/#src.openai.resources.audio.transcriptions.AsyncTranscriptions.with_streaming_response","title":"with_streaming_response","text":"<pre><code>with_streaming_response() -&gt; (\n    AsyncTranscriptionsWithStreamingResponse\n)\n</code></pre>"},{"location":"reference/resources/audio/transcriptions/#src.openai.resources.audio.transcriptions.AsyncTranscriptionsWithRawResponse","title":"AsyncTranscriptionsWithRawResponse","text":"<pre><code>AsyncTranscriptionsWithRawResponse(\n    transcriptions: AsyncTranscriptions,\n)\n</code></pre> <p>Attributes:</p> Name Type Description <code>create</code>"},{"location":"reference/resources/audio/transcriptions/#src.openai.resources.audio.transcriptions.AsyncTranscriptionsWithRawResponse.create","title":"create  <code>instance-attribute</code>","text":"<pre><code>create = async_to_raw_response_wrapper(create)\n</code></pre>"},{"location":"reference/resources/audio/transcriptions/#src.openai.resources.audio.transcriptions.AsyncTranscriptionsWithStreamingResponse","title":"AsyncTranscriptionsWithStreamingResponse","text":"<pre><code>AsyncTranscriptionsWithStreamingResponse(\n    transcriptions: AsyncTranscriptions,\n)\n</code></pre> <p>Attributes:</p> Name Type Description <code>create</code>"},{"location":"reference/resources/audio/transcriptions/#src.openai.resources.audio.transcriptions.AsyncTranscriptionsWithStreamingResponse.create","title":"create  <code>instance-attribute</code>","text":"<pre><code>create = async_to_streamed_response_wrapper(create)\n</code></pre>"},{"location":"reference/resources/audio/transcriptions/#src.openai.resources.audio.transcriptions.Transcriptions","title":"Transcriptions","text":"<pre><code>Transcriptions(client: OpenAI)\n</code></pre> <p>Methods:</p> Name Description <code>create</code> <p>Transcribes audio into the input language.</p> <code>with_raw_response</code> <code>with_streaming_response</code>"},{"location":"reference/resources/audio/transcriptions/#src.openai.resources.audio.transcriptions.Transcriptions.create","title":"create","text":"<pre><code>create(\n    *,\n    file: FileTypes,\n    model: Union[str, Literal[\"whisper-1\"]],\n    language: str | NotGiven = NOT_GIVEN,\n    prompt: str | NotGiven = NOT_GIVEN,\n    response_format: (\n        Literal[\n            \"json\", \"text\", \"srt\", \"verbose_json\", \"vtt\"\n        ]\n        | NotGiven\n    ) = NOT_GIVEN,\n    temperature: float | NotGiven = NOT_GIVEN,\n    timestamp_granularities: (\n        List[Literal[\"word\", \"segment\"]] | NotGiven\n    ) = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; Transcription\n</code></pre> <p>Transcribes audio into the input language.</p> <p>Parameters:</p> Name Type Description Default <code>file</code> <code>FileTypes</code> <p>The audio file object (not file name) to transcribe, in one of these formats:   flac, mp3, mp4, mpeg, mpga, m4a, ogg, wav, or webm.</p> required <code>model</code> <code>Union[str, Literal['whisper-1']]</code> <p>ID of the model to use. Only <code>whisper-1</code> (which is powered by our open source   Whisper V2 model) is currently available.</p> required <code>language</code> <code>str | NotGiven</code> <p>The language of the input audio. Supplying the input language in   ISO-639-1 format will   improve accuracy and latency.</p> <code>NOT_GIVEN</code> <code>prompt</code> <code>str | NotGiven</code> <p>An optional text to guide the model's style or continue a previous audio   segment. The   prompt   should match the audio language.</p> <code>NOT_GIVEN</code> <code>response_format</code> <code>Literal['json', 'text', 'srt', 'verbose_json', 'vtt'] | NotGiven</code> <p>The format of the transcript output, in one of these options: <code>json</code>, <code>text</code>,   <code>srt</code>, <code>verbose_json</code>, or <code>vtt</code>.</p> <code>NOT_GIVEN</code> <code>temperature</code> <code>float | NotGiven</code> <p>The sampling temperature, between 0 and 1. Higher values like 0.8 will make the   output more random, while lower values like 0.2 will make it more focused and   deterministic. If set to 0, the model will use   log probability to   automatically increase the temperature until certain thresholds are hit.</p> <code>NOT_GIVEN</code> <code>timestamp_granularities</code> <code>List[Literal['word', 'segment']] | NotGiven</code> <p>The timestamp granularities to populate for this transcription.   <code>response_format</code> must be set <code>verbose_json</code> to use timestamp granularities.   Either or both of these options are supported: <code>word</code>, or <code>segment</code>. Note: There   is no additional latency for segment timestamps, but generating word timestamps   incurs additional latency.</p> <code>NOT_GIVEN</code> <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/audio/transcriptions/#src.openai.resources.audio.transcriptions.Transcriptions.with_raw_response","title":"with_raw_response","text":"<pre><code>with_raw_response() -&gt; TranscriptionsWithRawResponse\n</code></pre>"},{"location":"reference/resources/audio/transcriptions/#src.openai.resources.audio.transcriptions.Transcriptions.with_streaming_response","title":"with_streaming_response","text":"<pre><code>with_streaming_response() -&gt; (\n    TranscriptionsWithStreamingResponse\n)\n</code></pre>"},{"location":"reference/resources/audio/transcriptions/#src.openai.resources.audio.transcriptions.TranscriptionsWithRawResponse","title":"TranscriptionsWithRawResponse","text":"<pre><code>TranscriptionsWithRawResponse(\n    transcriptions: Transcriptions,\n)\n</code></pre> <p>Attributes:</p> Name Type Description <code>create</code>"},{"location":"reference/resources/audio/transcriptions/#src.openai.resources.audio.transcriptions.TranscriptionsWithRawResponse.create","title":"create  <code>instance-attribute</code>","text":"<pre><code>create = to_raw_response_wrapper(create)\n</code></pre>"},{"location":"reference/resources/audio/transcriptions/#src.openai.resources.audio.transcriptions.TranscriptionsWithStreamingResponse","title":"TranscriptionsWithStreamingResponse","text":"<pre><code>TranscriptionsWithStreamingResponse(\n    transcriptions: Transcriptions,\n)\n</code></pre> <p>Attributes:</p> Name Type Description <code>create</code>"},{"location":"reference/resources/audio/transcriptions/#src.openai.resources.audio.transcriptions.TranscriptionsWithStreamingResponse.create","title":"create  <code>instance-attribute</code>","text":"<pre><code>create = to_streamed_response_wrapper(create)\n</code></pre>"},{"location":"reference/resources/audio/translations/","title":"translations","text":"<p>Classes:</p> Name Description <code>AsyncTranslations</code> <code>AsyncTranslationsWithRawResponse</code> <code>AsyncTranslationsWithStreamingResponse</code> <code>Translations</code> <code>TranslationsWithRawResponse</code> <code>TranslationsWithStreamingResponse</code>"},{"location":"reference/resources/audio/translations/#src.openai.resources.audio.translations.AsyncTranslations","title":"AsyncTranslations","text":"<pre><code>AsyncTranslations(client: AsyncOpenAI)\n</code></pre> <p>Methods:</p> Name Description <code>create</code> <p>Translates audio into English.</p> <code>with_raw_response</code> <code>with_streaming_response</code>"},{"location":"reference/resources/audio/translations/#src.openai.resources.audio.translations.AsyncTranslations.create","title":"create  <code>async</code>","text":"<pre><code>create(\n    *,\n    file: FileTypes,\n    model: Union[str, Literal[\"whisper-1\"]],\n    prompt: str | NotGiven = NOT_GIVEN,\n    response_format: str | NotGiven = NOT_GIVEN,\n    temperature: float | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; Translation\n</code></pre> <p>Translates audio into English.</p> <p>Parameters:</p> Name Type Description Default <code>file</code> <code>FileTypes</code> <p>The audio file object (not file name) translate, in one of these formats: flac,   mp3, mp4, mpeg, mpga, m4a, ogg, wav, or webm.</p> required <code>model</code> <code>Union[str, Literal['whisper-1']]</code> <p>ID of the model to use. Only <code>whisper-1</code> (which is powered by our open source   Whisper V2 model) is currently available.</p> required <code>prompt</code> <code>str | NotGiven</code> <p>An optional text to guide the model's style or continue a previous audio   segment. The   prompt   should be in English.</p> <code>NOT_GIVEN</code> <code>response_format</code> <code>str | NotGiven</code> <p>The format of the transcript output, in one of these options: <code>json</code>, <code>text</code>,   <code>srt</code>, <code>verbose_json</code>, or <code>vtt</code>.</p> <code>NOT_GIVEN</code> <code>temperature</code> <code>float | NotGiven</code> <p>The sampling temperature, between 0 and 1. Higher values like 0.8 will make the   output more random, while lower values like 0.2 will make it more focused and   deterministic. If set to 0, the model will use   log probability to   automatically increase the temperature until certain thresholds are hit.</p> <code>NOT_GIVEN</code> <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/audio/translations/#src.openai.resources.audio.translations.AsyncTranslations.with_raw_response","title":"with_raw_response","text":"<pre><code>with_raw_response() -&gt; AsyncTranslationsWithRawResponse\n</code></pre>"},{"location":"reference/resources/audio/translations/#src.openai.resources.audio.translations.AsyncTranslations.with_streaming_response","title":"with_streaming_response","text":"<pre><code>with_streaming_response() -&gt; (\n    AsyncTranslationsWithStreamingResponse\n)\n</code></pre>"},{"location":"reference/resources/audio/translations/#src.openai.resources.audio.translations.AsyncTranslationsWithRawResponse","title":"AsyncTranslationsWithRawResponse","text":"<pre><code>AsyncTranslationsWithRawResponse(\n    translations: AsyncTranslations,\n)\n</code></pre> <p>Attributes:</p> Name Type Description <code>create</code>"},{"location":"reference/resources/audio/translations/#src.openai.resources.audio.translations.AsyncTranslationsWithRawResponse.create","title":"create  <code>instance-attribute</code>","text":"<pre><code>create = async_to_raw_response_wrapper(create)\n</code></pre>"},{"location":"reference/resources/audio/translations/#src.openai.resources.audio.translations.AsyncTranslationsWithStreamingResponse","title":"AsyncTranslationsWithStreamingResponse","text":"<pre><code>AsyncTranslationsWithStreamingResponse(\n    translations: AsyncTranslations,\n)\n</code></pre> <p>Attributes:</p> Name Type Description <code>create</code>"},{"location":"reference/resources/audio/translations/#src.openai.resources.audio.translations.AsyncTranslationsWithStreamingResponse.create","title":"create  <code>instance-attribute</code>","text":"<pre><code>create = async_to_streamed_response_wrapper(create)\n</code></pre>"},{"location":"reference/resources/audio/translations/#src.openai.resources.audio.translations.Translations","title":"Translations","text":"<pre><code>Translations(client: OpenAI)\n</code></pre> <p>Methods:</p> Name Description <code>create</code> <p>Translates audio into English.</p> <code>with_raw_response</code> <code>with_streaming_response</code>"},{"location":"reference/resources/audio/translations/#src.openai.resources.audio.translations.Translations.create","title":"create","text":"<pre><code>create(\n    *,\n    file: FileTypes,\n    model: Union[str, Literal[\"whisper-1\"]],\n    prompt: str | NotGiven = NOT_GIVEN,\n    response_format: str | NotGiven = NOT_GIVEN,\n    temperature: float | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; Translation\n</code></pre> <p>Translates audio into English.</p> <p>Parameters:</p> Name Type Description Default <code>file</code> <code>FileTypes</code> <p>The audio file object (not file name) translate, in one of these formats: flac,   mp3, mp4, mpeg, mpga, m4a, ogg, wav, or webm.</p> required <code>model</code> <code>Union[str, Literal['whisper-1']]</code> <p>ID of the model to use. Only <code>whisper-1</code> (which is powered by our open source   Whisper V2 model) is currently available.</p> required <code>prompt</code> <code>str | NotGiven</code> <p>An optional text to guide the model's style or continue a previous audio   segment. The   prompt   should be in English.</p> <code>NOT_GIVEN</code> <code>response_format</code> <code>str | NotGiven</code> <p>The format of the transcript output, in one of these options: <code>json</code>, <code>text</code>,   <code>srt</code>, <code>verbose_json</code>, or <code>vtt</code>.</p> <code>NOT_GIVEN</code> <code>temperature</code> <code>float | NotGiven</code> <p>The sampling temperature, between 0 and 1. Higher values like 0.8 will make the   output more random, while lower values like 0.2 will make it more focused and   deterministic. If set to 0, the model will use   log probability to   automatically increase the temperature until certain thresholds are hit.</p> <code>NOT_GIVEN</code> <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/audio/translations/#src.openai.resources.audio.translations.Translations.with_raw_response","title":"with_raw_response","text":"<pre><code>with_raw_response() -&gt; TranslationsWithRawResponse\n</code></pre>"},{"location":"reference/resources/audio/translations/#src.openai.resources.audio.translations.Translations.with_streaming_response","title":"with_streaming_response","text":"<pre><code>with_streaming_response() -&gt; (\n    TranslationsWithStreamingResponse\n)\n</code></pre>"},{"location":"reference/resources/audio/translations/#src.openai.resources.audio.translations.TranslationsWithRawResponse","title":"TranslationsWithRawResponse","text":"<pre><code>TranslationsWithRawResponse(translations: Translations)\n</code></pre> <p>Attributes:</p> Name Type Description <code>create</code>"},{"location":"reference/resources/audio/translations/#src.openai.resources.audio.translations.TranslationsWithRawResponse.create","title":"create  <code>instance-attribute</code>","text":"<pre><code>create = to_raw_response_wrapper(create)\n</code></pre>"},{"location":"reference/resources/audio/translations/#src.openai.resources.audio.translations.TranslationsWithStreamingResponse","title":"TranslationsWithStreamingResponse","text":"<pre><code>TranslationsWithStreamingResponse(\n    translations: Translations,\n)\n</code></pre> <p>Attributes:</p> Name Type Description <code>create</code>"},{"location":"reference/resources/audio/translations/#src.openai.resources.audio.translations.TranslationsWithStreamingResponse.create","title":"create  <code>instance-attribute</code>","text":"<pre><code>create = to_streamed_response_wrapper(create)\n</code></pre>"},{"location":"reference/resources/beta/","title":"openai.resources.beta","text":"<p>The <code>beta</code> modules provides a unified interface for accessing beta features of the API, encapsulating synchronous and asynchronous access to resources in beta.</p> <p>The module aggregates the beta functionalities related to features like yet considered generally available (GA), offering a simplified entry point for interacting with these resources. It is designed to facilitate easy access to the cutting-edge features still under development, enabling developers to experiment with and leverage new capabilities before they become GA.</p> <p>Modules:</p> Name Description <code>assistants</code> <code>beta</code> <p>The <code>beta</code> modules provides a unified interface for accessing beta features of the API, encapsulating synchronous and asynchronous access to resources in beta.</p> <p>The module aggregates the beta functionalities related to features like yet considered generally available (GA), offering a simplified entry point for interacting with these resources. It is designed to facilitate easy access to the cutting-edge features still under development, enabling developers to experiment with and leverage new capabilities before they become GA.</p> <code>threads</code> <p>Classes:</p> Name Description <code>Assistants</code> <code>AssistantsWithRawResponse</code> <code>AssistantsWithStreamingResponse</code> <code>AsyncAssistants</code> <code>AsyncAssistantsWithRawResponse</code> <code>AsyncAssistantsWithStreamingResponse</code> <code>AsyncBeta</code> <code>AsyncBetaWithRawResponse</code> <code>AsyncBetaWithStreamingResponse</code> <code>AsyncThreads</code> <code>AsyncThreadsWithRawResponse</code> <code>AsyncThreadsWithStreamingResponse</code> <code>Beta</code> <code>BetaWithRawResponse</code> <code>BetaWithStreamingResponse</code> <code>Threads</code> <code>ThreadsWithRawResponse</code> <code>ThreadsWithStreamingResponse</code>"},{"location":"reference/resources/beta/#src.openai.resources.beta.Assistants","title":"Assistants","text":"<pre><code>Assistants(client: OpenAI)\n</code></pre> <p>Methods:</p> Name Description <code>create</code> <p>Create an assistant with a model and instructions.</p> <code>delete</code> <p>Delete an assistant.</p> <code>files</code> <code>list</code> <p>Returns a list of assistants.</p> <code>retrieve</code> <p>Retrieves an assistant.</p> <code>update</code> <p>Modifies an assistant.</p> <code>with_raw_response</code> <code>with_streaming_response</code>"},{"location":"reference/resources/beta/#src.openai.resources.beta.Assistants.create","title":"create","text":"<pre><code>create(\n    *,\n    model: str,\n    description: Optional[str] | NotGiven = NOT_GIVEN,\n    file_ids: List[str] | NotGiven = NOT_GIVEN,\n    instructions: Optional[str] | NotGiven = NOT_GIVEN,\n    metadata: Optional[object] | NotGiven = NOT_GIVEN,\n    name: Optional[str] | NotGiven = NOT_GIVEN,\n    tools: Iterable[Tool] | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; Assistant\n</code></pre> <p>Create an assistant with a model and instructions.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>str</code> <p>ID of the model to use. You can use the   List models API to   see all of your available models, or see our   Model overview for   descriptions of them.</p> required <code>description</code> <code>Optional[str] | NotGiven</code> <p>The description of the assistant. The maximum length is 512 characters.</p> <code>NOT_GIVEN</code> <code>file_ids</code> <code>List[str] | NotGiven</code> <p>A list of file IDs   attached to this assistant. There can be a maximum of 20 files attached to the   assistant. Files are ordered by their creation date in ascending order.</p> <code>NOT_GIVEN</code> <code>instructions</code> <code>Optional[str] | NotGiven</code> <p>The system instructions that the assistant uses. The maximum length is 32768   characters.</p> <code>NOT_GIVEN</code> <code>metadata</code> <code>Optional[object] | NotGiven</code> <p>Set of 16 key-value pairs that can be attached to an object. This can be useful   for storing additional information about the object in a structured format. Keys   can be a maximum of 64 characters long and values can be a maxium of 512   characters long.</p> <code>NOT_GIVEN</code> <code>name</code> <code>Optional[str] | NotGiven</code> <p>The name of the assistant. The maximum length is 256 characters.</p> <code>NOT_GIVEN</code> <code>tools</code> <code>Iterable[Tool] | NotGiven</code> <p>A list of tool enabled on the assistant. There can be a maximum of 128 tools per   assistant. Tools can be of types <code>code_interpreter</code>, <code>retrieval</code>, or <code>function</code>.</p> <code>NOT_GIVEN</code> <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/beta/#src.openai.resources.beta.Assistants.delete","title":"delete","text":"<pre><code>delete(\n    assistant_id: str,\n    *,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; AssistantDeleted\n</code></pre> <p>Delete an assistant.</p> <p>Parameters:</p> Name Type Description Default <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/beta/#src.openai.resources.beta.Assistants.files","title":"files","text":"<pre><code>files() -&gt; Files\n</code></pre>"},{"location":"reference/resources/beta/#src.openai.resources.beta.Assistants.list","title":"list","text":"<pre><code>list(\n    *,\n    after: str | NotGiven = NOT_GIVEN,\n    before: str | NotGiven = NOT_GIVEN,\n    limit: int | NotGiven = NOT_GIVEN,\n    order: Literal[\"asc\", \"desc\"] | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; SyncCursorPage[Assistant]\n</code></pre> <p>Returns a list of assistants.</p> <p>Parameters:</p> Name Type Description Default <code>after</code> <code>str | NotGiven</code> <p>A cursor for use in pagination.</p> <code>NOT_GIVEN</code> <p><code>after</code> is an object ID that defines your place       in the list. For instance, if you make a list request and receive 100 objects,       ending with obj_foo, your subsequent call can include after=obj_foo in order to       fetch the next page of the list.</p> <p>before: A cursor for use in pagination. <code>before</code> is an object ID that defines your place       in the list. For instance, if you make a list request and receive 100 objects,       ending with obj_foo, your subsequent call can include before=obj_foo in order to       fetch the previous page of the list.</p> <p>limit: A limit on the number of objects to be returned. Limit can range between 1 and       100, and the default is 20.</p> <p>order: Sort order by the <code>created_at</code> timestamp of the objects. <code>asc</code> for ascending       order and <code>desc</code> for descending order.</p> <p>extra_headers: Send extra headers</p> <p>extra_query: Add additional query parameters to the request</p> <p>extra_body: Add additional JSON properties to the request</p> <p>timeout: Override the client-level default timeout for this request, in seconds</p>"},{"location":"reference/resources/beta/#src.openai.resources.beta.Assistants.retrieve","title":"retrieve","text":"<pre><code>retrieve(\n    assistant_id: str,\n    *,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; Assistant\n</code></pre> <p>Retrieves an assistant.</p> <p>Parameters:</p> Name Type Description Default <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/beta/#src.openai.resources.beta.Assistants.update","title":"update","text":"<pre><code>update(\n    assistant_id: str,\n    *,\n    description: Optional[str] | NotGiven = NOT_GIVEN,\n    file_ids: List[str] | NotGiven = NOT_GIVEN,\n    instructions: Optional[str] | NotGiven = NOT_GIVEN,\n    metadata: Optional[object] | NotGiven = NOT_GIVEN,\n    model: str | NotGiven = NOT_GIVEN,\n    name: Optional[str] | NotGiven = NOT_GIVEN,\n    tools: Iterable[Tool] | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; Assistant\n</code></pre> <p>Modifies an assistant.</p> <p>Parameters:</p> Name Type Description Default <code>description</code> <code>Optional[str] | NotGiven</code> <p>The description of the assistant.</p> <code>NOT_GIVEN</code> <p>The maximum length is 512 characters.</p> <p>file_ids: A list of File IDs       attached to this assistant. There can be a maximum of 20 files attached to the       assistant. Files are ordered by their creation date in ascending order. If a       file was previously attached to the list but does not show up in the list, it       will be deleted from the assistant.</p> <p>instructions: The system instructions that the assistant uses. The maximum length is 32768       characters.</p> <p>metadata: Set of 16 key-value pairs that can be attached to an object. This can be useful       for storing additional information about the object in a structured format. Keys       can be a maximum of 64 characters long and values can be a maxium of 512       characters long.</p> <p>model: ID of the model to use. You can use the       List models API to       see all of your available models, or see our       Model overview for       descriptions of them.</p> <p>name: The name of the assistant. The maximum length is 256 characters.</p> <p>tools: A list of tool enabled on the assistant. There can be a maximum of 128 tools per       assistant. Tools can be of types <code>code_interpreter</code>, <code>retrieval</code>, or <code>function</code>.</p> <p>extra_headers: Send extra headers</p> <p>extra_query: Add additional query parameters to the request</p> <p>extra_body: Add additional JSON properties to the request</p> <p>timeout: Override the client-level default timeout for this request, in seconds</p>"},{"location":"reference/resources/beta/#src.openai.resources.beta.Assistants.with_raw_response","title":"with_raw_response","text":"<pre><code>with_raw_response() -&gt; AssistantsWithRawResponse\n</code></pre>"},{"location":"reference/resources/beta/#src.openai.resources.beta.Assistants.with_streaming_response","title":"with_streaming_response","text":"<pre><code>with_streaming_response() -&gt; (\n    AssistantsWithStreamingResponse\n)\n</code></pre>"},{"location":"reference/resources/beta/#src.openai.resources.beta.AssistantsWithRawResponse","title":"AssistantsWithRawResponse","text":"<pre><code>AssistantsWithRawResponse(assistants: Assistants)\n</code></pre> <p>Methods:</p> Name Description <code>files</code> <p>Attributes:</p> Name Type Description <code>create</code> <code>delete</code> <code>list</code> <code>retrieve</code> <code>update</code>"},{"location":"reference/resources/beta/#src.openai.resources.beta.AssistantsWithRawResponse.create","title":"create  <code>instance-attribute</code>","text":"<pre><code>create = to_raw_response_wrapper(create)\n</code></pre>"},{"location":"reference/resources/beta/#src.openai.resources.beta.AssistantsWithRawResponse.delete","title":"delete  <code>instance-attribute</code>","text":"<pre><code>delete = to_raw_response_wrapper(delete)\n</code></pre>"},{"location":"reference/resources/beta/#src.openai.resources.beta.AssistantsWithRawResponse.list","title":"list  <code>instance-attribute</code>","text":"<pre><code>list = to_raw_response_wrapper(list)\n</code></pre>"},{"location":"reference/resources/beta/#src.openai.resources.beta.AssistantsWithRawResponse.retrieve","title":"retrieve  <code>instance-attribute</code>","text":"<pre><code>retrieve = to_raw_response_wrapper(retrieve)\n</code></pre>"},{"location":"reference/resources/beta/#src.openai.resources.beta.AssistantsWithRawResponse.update","title":"update  <code>instance-attribute</code>","text":"<pre><code>update = to_raw_response_wrapper(update)\n</code></pre>"},{"location":"reference/resources/beta/#src.openai.resources.beta.AssistantsWithRawResponse.files","title":"files","text":"<pre><code>files() -&gt; FilesWithRawResponse\n</code></pre>"},{"location":"reference/resources/beta/#src.openai.resources.beta.AssistantsWithStreamingResponse","title":"AssistantsWithStreamingResponse","text":"<pre><code>AssistantsWithStreamingResponse(assistants: Assistants)\n</code></pre> <p>Methods:</p> Name Description <code>files</code> <p>Attributes:</p> Name Type Description <code>create</code> <code>delete</code> <code>list</code> <code>retrieve</code> <code>update</code>"},{"location":"reference/resources/beta/#src.openai.resources.beta.AssistantsWithStreamingResponse.create","title":"create  <code>instance-attribute</code>","text":"<pre><code>create = to_streamed_response_wrapper(create)\n</code></pre>"},{"location":"reference/resources/beta/#src.openai.resources.beta.AssistantsWithStreamingResponse.delete","title":"delete  <code>instance-attribute</code>","text":"<pre><code>delete = to_streamed_response_wrapper(delete)\n</code></pre>"},{"location":"reference/resources/beta/#src.openai.resources.beta.AssistantsWithStreamingResponse.list","title":"list  <code>instance-attribute</code>","text":"<pre><code>list = to_streamed_response_wrapper(list)\n</code></pre>"},{"location":"reference/resources/beta/#src.openai.resources.beta.AssistantsWithStreamingResponse.retrieve","title":"retrieve  <code>instance-attribute</code>","text":"<pre><code>retrieve = to_streamed_response_wrapper(retrieve)\n</code></pre>"},{"location":"reference/resources/beta/#src.openai.resources.beta.AssistantsWithStreamingResponse.update","title":"update  <code>instance-attribute</code>","text":"<pre><code>update = to_streamed_response_wrapper(update)\n</code></pre>"},{"location":"reference/resources/beta/#src.openai.resources.beta.AssistantsWithStreamingResponse.files","title":"files","text":"<pre><code>files() -&gt; FilesWithStreamingResponse\n</code></pre>"},{"location":"reference/resources/beta/#src.openai.resources.beta.AsyncAssistants","title":"AsyncAssistants","text":"<pre><code>AsyncAssistants(client: AsyncOpenAI)\n</code></pre> <p>Methods:</p> Name Description <code>create</code> <p>Create an assistant with a model and instructions.</p> <code>delete</code> <p>Delete an assistant.</p> <code>files</code> <code>list</code> <p>Returns a list of assistants.</p> <code>retrieve</code> <p>Retrieves an assistant.</p> <code>update</code> <p>Modifies an assistant.</p> <code>with_raw_response</code> <code>with_streaming_response</code>"},{"location":"reference/resources/beta/#src.openai.resources.beta.AsyncAssistants.create","title":"create  <code>async</code>","text":"<pre><code>create(\n    *,\n    model: str,\n    description: Optional[str] | NotGiven = NOT_GIVEN,\n    file_ids: List[str] | NotGiven = NOT_GIVEN,\n    instructions: Optional[str] | NotGiven = NOT_GIVEN,\n    metadata: Optional[object] | NotGiven = NOT_GIVEN,\n    name: Optional[str] | NotGiven = NOT_GIVEN,\n    tools: Iterable[Tool] | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; Assistant\n</code></pre> <p>Create an assistant with a model and instructions.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>str</code> <p>ID of the model to use. You can use the   List models API to   see all of your available models, or see our   Model overview for   descriptions of them.</p> required <code>description</code> <code>Optional[str] | NotGiven</code> <p>The description of the assistant. The maximum length is 512 characters.</p> <code>NOT_GIVEN</code> <code>file_ids</code> <code>List[str] | NotGiven</code> <p>A list of file IDs   attached to this assistant. There can be a maximum of 20 files attached to the   assistant. Files are ordered by their creation date in ascending order.</p> <code>NOT_GIVEN</code> <code>instructions</code> <code>Optional[str] | NotGiven</code> <p>The system instructions that the assistant uses. The maximum length is 32768   characters.</p> <code>NOT_GIVEN</code> <code>metadata</code> <code>Optional[object] | NotGiven</code> <p>Set of 16 key-value pairs that can be attached to an object. This can be useful   for storing additional information about the object in a structured format. Keys   can be a maximum of 64 characters long and values can be a maxium of 512   characters long.</p> <code>NOT_GIVEN</code> <code>name</code> <code>Optional[str] | NotGiven</code> <p>The name of the assistant. The maximum length is 256 characters.</p> <code>NOT_GIVEN</code> <code>tools</code> <code>Iterable[Tool] | NotGiven</code> <p>A list of tool enabled on the assistant. There can be a maximum of 128 tools per   assistant. Tools can be of types <code>code_interpreter</code>, <code>retrieval</code>, or <code>function</code>.</p> <code>NOT_GIVEN</code> <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/beta/#src.openai.resources.beta.AsyncAssistants.delete","title":"delete  <code>async</code>","text":"<pre><code>delete(\n    assistant_id: str,\n    *,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; AssistantDeleted\n</code></pre> <p>Delete an assistant.</p> <p>Parameters:</p> Name Type Description Default <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/beta/#src.openai.resources.beta.AsyncAssistants.files","title":"files","text":"<pre><code>files() -&gt; AsyncFiles\n</code></pre>"},{"location":"reference/resources/beta/#src.openai.resources.beta.AsyncAssistants.list","title":"list","text":"<pre><code>list(\n    *,\n    after: str | NotGiven = NOT_GIVEN,\n    before: str | NotGiven = NOT_GIVEN,\n    limit: int | NotGiven = NOT_GIVEN,\n    order: Literal[\"asc\", \"desc\"] | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; AsyncPaginator[Assistant, AsyncCursorPage[Assistant]]\n</code></pre> <p>Returns a list of assistants.</p> <p>Parameters:</p> Name Type Description Default <code>after</code> <code>str | NotGiven</code> <p>A cursor for use in pagination.</p> <code>NOT_GIVEN</code> <p><code>after</code> is an object ID that defines your place       in the list. For instance, if you make a list request and receive 100 objects,       ending with obj_foo, your subsequent call can include after=obj_foo in order to       fetch the next page of the list.</p> <p>before: A cursor for use in pagination. <code>before</code> is an object ID that defines your place       in the list. For instance, if you make a list request and receive 100 objects,       ending with obj_foo, your subsequent call can include before=obj_foo in order to       fetch the previous page of the list.</p> <p>limit: A limit on the number of objects to be returned. Limit can range between 1 and       100, and the default is 20.</p> <p>order: Sort order by the <code>created_at</code> timestamp of the objects. <code>asc</code> for ascending       order and <code>desc</code> for descending order.</p> <p>extra_headers: Send extra headers</p> <p>extra_query: Add additional query parameters to the request</p> <p>extra_body: Add additional JSON properties to the request</p> <p>timeout: Override the client-level default timeout for this request, in seconds</p>"},{"location":"reference/resources/beta/#src.openai.resources.beta.AsyncAssistants.retrieve","title":"retrieve  <code>async</code>","text":"<pre><code>retrieve(\n    assistant_id: str,\n    *,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; Assistant\n</code></pre> <p>Retrieves an assistant.</p> <p>Parameters:</p> Name Type Description Default <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/beta/#src.openai.resources.beta.AsyncAssistants.update","title":"update  <code>async</code>","text":"<pre><code>update(\n    assistant_id: str,\n    *,\n    description: Optional[str] | NotGiven = NOT_GIVEN,\n    file_ids: List[str] | NotGiven = NOT_GIVEN,\n    instructions: Optional[str] | NotGiven = NOT_GIVEN,\n    metadata: Optional[object] | NotGiven = NOT_GIVEN,\n    model: str | NotGiven = NOT_GIVEN,\n    name: Optional[str] | NotGiven = NOT_GIVEN,\n    tools: Iterable[Tool] | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; Assistant\n</code></pre> <p>Modifies an assistant.</p> <p>Parameters:</p> Name Type Description Default <code>description</code> <code>Optional[str] | NotGiven</code> <p>The description of the assistant.</p> <code>NOT_GIVEN</code> <p>The maximum length is 512 characters.</p> <p>file_ids: A list of File IDs       attached to this assistant. There can be a maximum of 20 files attached to the       assistant. Files are ordered by their creation date in ascending order. If a       file was previously attached to the list but does not show up in the list, it       will be deleted from the assistant.</p> <p>instructions: The system instructions that the assistant uses. The maximum length is 32768       characters.</p> <p>metadata: Set of 16 key-value pairs that can be attached to an object. This can be useful       for storing additional information about the object in a structured format. Keys       can be a maximum of 64 characters long and values can be a maxium of 512       characters long.</p> <p>model: ID of the model to use. You can use the       List models API to       see all of your available models, or see our       Model overview for       descriptions of them.</p> <p>name: The name of the assistant. The maximum length is 256 characters.</p> <p>tools: A list of tool enabled on the assistant. There can be a maximum of 128 tools per       assistant. Tools can be of types <code>code_interpreter</code>, <code>retrieval</code>, or <code>function</code>.</p> <p>extra_headers: Send extra headers</p> <p>extra_query: Add additional query parameters to the request</p> <p>extra_body: Add additional JSON properties to the request</p> <p>timeout: Override the client-level default timeout for this request, in seconds</p>"},{"location":"reference/resources/beta/#src.openai.resources.beta.AsyncAssistants.with_raw_response","title":"with_raw_response","text":"<pre><code>with_raw_response() -&gt; AsyncAssistantsWithRawResponse\n</code></pre>"},{"location":"reference/resources/beta/#src.openai.resources.beta.AsyncAssistants.with_streaming_response","title":"with_streaming_response","text":"<pre><code>with_streaming_response() -&gt; (\n    AsyncAssistantsWithStreamingResponse\n)\n</code></pre>"},{"location":"reference/resources/beta/#src.openai.resources.beta.AsyncAssistantsWithRawResponse","title":"AsyncAssistantsWithRawResponse","text":"<pre><code>AsyncAssistantsWithRawResponse(assistants: AsyncAssistants)\n</code></pre> <p>Methods:</p> Name Description <code>files</code> <p>Attributes:</p> Name Type Description <code>create</code> <code>delete</code> <code>list</code> <code>retrieve</code> <code>update</code>"},{"location":"reference/resources/beta/#src.openai.resources.beta.AsyncAssistantsWithRawResponse.create","title":"create  <code>instance-attribute</code>","text":"<pre><code>create = async_to_raw_response_wrapper(create)\n</code></pre>"},{"location":"reference/resources/beta/#src.openai.resources.beta.AsyncAssistantsWithRawResponse.delete","title":"delete  <code>instance-attribute</code>","text":"<pre><code>delete = async_to_raw_response_wrapper(delete)\n</code></pre>"},{"location":"reference/resources/beta/#src.openai.resources.beta.AsyncAssistantsWithRawResponse.list","title":"list  <code>instance-attribute</code>","text":"<pre><code>list = async_to_raw_response_wrapper(list)\n</code></pre>"},{"location":"reference/resources/beta/#src.openai.resources.beta.AsyncAssistantsWithRawResponse.retrieve","title":"retrieve  <code>instance-attribute</code>","text":"<pre><code>retrieve = async_to_raw_response_wrapper(retrieve)\n</code></pre>"},{"location":"reference/resources/beta/#src.openai.resources.beta.AsyncAssistantsWithRawResponse.update","title":"update  <code>instance-attribute</code>","text":"<pre><code>update = async_to_raw_response_wrapper(update)\n</code></pre>"},{"location":"reference/resources/beta/#src.openai.resources.beta.AsyncAssistantsWithRawResponse.files","title":"files","text":"<pre><code>files() -&gt; AsyncFilesWithRawResponse\n</code></pre>"},{"location":"reference/resources/beta/#src.openai.resources.beta.AsyncAssistantsWithStreamingResponse","title":"AsyncAssistantsWithStreamingResponse","text":"<pre><code>AsyncAssistantsWithStreamingResponse(\n    assistants: AsyncAssistants,\n)\n</code></pre> <p>Methods:</p> Name Description <code>files</code> <p>Attributes:</p> Name Type Description <code>create</code> <code>delete</code> <code>list</code> <code>retrieve</code> <code>update</code>"},{"location":"reference/resources/beta/#src.openai.resources.beta.AsyncAssistantsWithStreamingResponse.create","title":"create  <code>instance-attribute</code>","text":"<pre><code>create = async_to_streamed_response_wrapper(create)\n</code></pre>"},{"location":"reference/resources/beta/#src.openai.resources.beta.AsyncAssistantsWithStreamingResponse.delete","title":"delete  <code>instance-attribute</code>","text":"<pre><code>delete = async_to_streamed_response_wrapper(delete)\n</code></pre>"},{"location":"reference/resources/beta/#src.openai.resources.beta.AsyncAssistantsWithStreamingResponse.list","title":"list  <code>instance-attribute</code>","text":"<pre><code>list = async_to_streamed_response_wrapper(list)\n</code></pre>"},{"location":"reference/resources/beta/#src.openai.resources.beta.AsyncAssistantsWithStreamingResponse.retrieve","title":"retrieve  <code>instance-attribute</code>","text":"<pre><code>retrieve = async_to_streamed_response_wrapper(retrieve)\n</code></pre>"},{"location":"reference/resources/beta/#src.openai.resources.beta.AsyncAssistantsWithStreamingResponse.update","title":"update  <code>instance-attribute</code>","text":"<pre><code>update = async_to_streamed_response_wrapper(update)\n</code></pre>"},{"location":"reference/resources/beta/#src.openai.resources.beta.AsyncAssistantsWithStreamingResponse.files","title":"files","text":"<pre><code>files() -&gt; AsyncFilesWithStreamingResponse\n</code></pre>"},{"location":"reference/resources/beta/#src.openai.resources.beta.AsyncBeta","title":"AsyncBeta","text":"<pre><code>AsyncBeta(client: AsyncOpenAI)\n</code></pre> <p>Methods:</p> Name Description <code>assistants</code> <code>threads</code> <code>with_raw_response</code> <code>with_streaming_response</code>"},{"location":"reference/resources/beta/#src.openai.resources.beta.AsyncBeta.assistants","title":"assistants","text":"<pre><code>assistants() -&gt; AsyncAssistants\n</code></pre>"},{"location":"reference/resources/beta/#src.openai.resources.beta.AsyncBeta.threads","title":"threads","text":"<pre><code>threads() -&gt; AsyncThreads\n</code></pre>"},{"location":"reference/resources/beta/#src.openai.resources.beta.AsyncBeta.with_raw_response","title":"with_raw_response","text":"<pre><code>with_raw_response() -&gt; AsyncBetaWithRawResponse\n</code></pre>"},{"location":"reference/resources/beta/#src.openai.resources.beta.AsyncBeta.with_streaming_response","title":"with_streaming_response","text":"<pre><code>with_streaming_response() -&gt; AsyncBetaWithStreamingResponse\n</code></pre>"},{"location":"reference/resources/beta/#src.openai.resources.beta.AsyncBetaWithRawResponse","title":"AsyncBetaWithRawResponse","text":"<pre><code>AsyncBetaWithRawResponse(beta: AsyncBeta)\n</code></pre> <p>Methods:</p> Name Description <code>assistants</code> <code>threads</code>"},{"location":"reference/resources/beta/#src.openai.resources.beta.AsyncBetaWithRawResponse.assistants","title":"assistants","text":"<pre><code>assistants() -&gt; AsyncAssistantsWithRawResponse\n</code></pre>"},{"location":"reference/resources/beta/#src.openai.resources.beta.AsyncBetaWithRawResponse.threads","title":"threads","text":"<pre><code>threads() -&gt; AsyncThreadsWithRawResponse\n</code></pre>"},{"location":"reference/resources/beta/#src.openai.resources.beta.AsyncBetaWithStreamingResponse","title":"AsyncBetaWithStreamingResponse","text":"<pre><code>AsyncBetaWithStreamingResponse(beta: AsyncBeta)\n</code></pre> <p>Methods:</p> Name Description <code>assistants</code> <code>threads</code>"},{"location":"reference/resources/beta/#src.openai.resources.beta.AsyncBetaWithStreamingResponse.assistants","title":"assistants","text":"<pre><code>assistants() -&gt; AsyncAssistantsWithStreamingResponse\n</code></pre>"},{"location":"reference/resources/beta/#src.openai.resources.beta.AsyncBetaWithStreamingResponse.threads","title":"threads","text":"<pre><code>threads() -&gt; AsyncThreadsWithStreamingResponse\n</code></pre>"},{"location":"reference/resources/beta/#src.openai.resources.beta.AsyncThreads","title":"AsyncThreads","text":"<pre><code>AsyncThreads(client: AsyncOpenAI)\n</code></pre> <p>Methods:</p> Name Description <code>create</code> <p>Create a thread.</p> <code>create_and_run</code> <p>Create a thread and run it in one request.</p> <code>delete</code> <p>Delete a thread.</p> <code>messages</code> <code>retrieve</code> <p>Retrieves a thread.</p> <code>runs</code> <code>update</code> <p>Modifies a thread.</p> <code>with_raw_response</code> <code>with_streaming_response</code>"},{"location":"reference/resources/beta/#src.openai.resources.beta.AsyncThreads.create","title":"create  <code>async</code>","text":"<pre><code>create(\n    *,\n    messages: Iterable[Message] | NotGiven = NOT_GIVEN,\n    metadata: Optional[object] | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; Thread\n</code></pre> <p>Create a thread.</p> <p>Parameters:</p> Name Type Description Default <code>messages</code> <code>Iterable[Message] | NotGiven</code> <p>A list of messages to   start the thread with.</p> <code>NOT_GIVEN</code> <code>metadata</code> <code>Optional[object] | NotGiven</code> <p>Set of 16 key-value pairs that can be attached to an object. This can be useful   for storing additional information about the object in a structured format. Keys   can be a maximum of 64 characters long and values can be a maxium of 512   characters long.</p> <code>NOT_GIVEN</code> <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/beta/#src.openai.resources.beta.AsyncThreads.create_and_run","title":"create_and_run  <code>async</code>","text":"<pre><code>create_and_run(\n    *,\n    assistant_id: str,\n    instructions: Optional[str] | NotGiven = NOT_GIVEN,\n    metadata: Optional[object] | NotGiven = NOT_GIVEN,\n    model: Optional[str] | NotGiven = NOT_GIVEN,\n    thread: Thread | NotGiven = NOT_GIVEN,\n    tools: Optional[Iterable[Tool]] | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; Run\n</code></pre> <p>Create a thread and run it in one request.</p> <p>Parameters:</p> Name Type Description Default <code>assistant_id</code> <code>str</code> <p>The ID of the   assistant to use to   execute this run.</p> required <code>instructions</code> <code>Optional[str] | NotGiven</code> <p>Override the default system message of the assistant. This is useful for   modifying the behavior on a per-run basis.</p> <code>NOT_GIVEN</code> <code>metadata</code> <code>Optional[object] | NotGiven</code> <p>Set of 16 key-value pairs that can be attached to an object. This can be useful   for storing additional information about the object in a structured format. Keys   can be a maximum of 64 characters long and values can be a maxium of 512   characters long.</p> <code>NOT_GIVEN</code> <code>model</code> <code>Optional[str] | NotGiven</code> <p>The ID of the Model to   be used to execute this run. If a value is provided here, it will override the   model associated with the assistant. If not, the model associated with the   assistant will be used.</p> <code>NOT_GIVEN</code> <code>thread</code> <code>Thread | NotGiven</code> <p>If no thread is provided, an empty thread will be created.</p> <code>NOT_GIVEN</code> <code>tools</code> <code>Optional[Iterable[Tool]] | NotGiven</code> <p>Override the tools the assistant can use for this run. This is useful for   modifying the behavior on a per-run basis.</p> <code>NOT_GIVEN</code> <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/beta/#src.openai.resources.beta.AsyncThreads.delete","title":"delete  <code>async</code>","text":"<pre><code>delete(\n    thread_id: str,\n    *,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; ThreadDeleted\n</code></pre> <p>Delete a thread.</p> <p>Parameters:</p> Name Type Description Default <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/beta/#src.openai.resources.beta.AsyncThreads.messages","title":"messages","text":"<pre><code>messages() -&gt; AsyncMessages\n</code></pre>"},{"location":"reference/resources/beta/#src.openai.resources.beta.AsyncThreads.retrieve","title":"retrieve  <code>async</code>","text":"<pre><code>retrieve(\n    thread_id: str,\n    *,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; Thread\n</code></pre> <p>Retrieves a thread.</p> <p>Parameters:</p> Name Type Description Default <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/beta/#src.openai.resources.beta.AsyncThreads.runs","title":"runs","text":"<pre><code>runs() -&gt; AsyncRuns\n</code></pre>"},{"location":"reference/resources/beta/#src.openai.resources.beta.AsyncThreads.update","title":"update  <code>async</code>","text":"<pre><code>update(\n    thread_id: str,\n    *,\n    metadata: Optional[object] | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; Thread\n</code></pre> <p>Modifies a thread.</p> <p>Parameters:</p> Name Type Description Default <code>metadata</code> <code>Optional[object] | NotGiven</code> <p>Set of 16 key-value pairs that can be attached to an object. This can be useful   for storing additional information about the object in a structured format. Keys   can be a maximum of 64 characters long and values can be a maxium of 512   characters long.</p> <code>NOT_GIVEN</code> <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/beta/#src.openai.resources.beta.AsyncThreads.with_raw_response","title":"with_raw_response","text":"<pre><code>with_raw_response() -&gt; AsyncThreadsWithRawResponse\n</code></pre>"},{"location":"reference/resources/beta/#src.openai.resources.beta.AsyncThreads.with_streaming_response","title":"with_streaming_response","text":"<pre><code>with_streaming_response() -&gt; (\n    AsyncThreadsWithStreamingResponse\n)\n</code></pre>"},{"location":"reference/resources/beta/#src.openai.resources.beta.AsyncThreadsWithRawResponse","title":"AsyncThreadsWithRawResponse","text":"<pre><code>AsyncThreadsWithRawResponse(threads: AsyncThreads)\n</code></pre> <p>Methods:</p> Name Description <code>messages</code> <code>runs</code> <p>Attributes:</p> Name Type Description <code>create</code> <code>create_and_run</code> <code>delete</code> <code>retrieve</code> <code>update</code>"},{"location":"reference/resources/beta/#src.openai.resources.beta.AsyncThreadsWithRawResponse.create","title":"create  <code>instance-attribute</code>","text":"<pre><code>create = async_to_raw_response_wrapper(create)\n</code></pre>"},{"location":"reference/resources/beta/#src.openai.resources.beta.AsyncThreadsWithRawResponse.create_and_run","title":"create_and_run  <code>instance-attribute</code>","text":"<pre><code>create_and_run = async_to_raw_response_wrapper(\n    create_and_run\n)\n</code></pre>"},{"location":"reference/resources/beta/#src.openai.resources.beta.AsyncThreadsWithRawResponse.delete","title":"delete  <code>instance-attribute</code>","text":"<pre><code>delete = async_to_raw_response_wrapper(delete)\n</code></pre>"},{"location":"reference/resources/beta/#src.openai.resources.beta.AsyncThreadsWithRawResponse.retrieve","title":"retrieve  <code>instance-attribute</code>","text":"<pre><code>retrieve = async_to_raw_response_wrapper(retrieve)\n</code></pre>"},{"location":"reference/resources/beta/#src.openai.resources.beta.AsyncThreadsWithRawResponse.update","title":"update  <code>instance-attribute</code>","text":"<pre><code>update = async_to_raw_response_wrapper(update)\n</code></pre>"},{"location":"reference/resources/beta/#src.openai.resources.beta.AsyncThreadsWithRawResponse.messages","title":"messages","text":"<pre><code>messages() -&gt; AsyncMessagesWithRawResponse\n</code></pre>"},{"location":"reference/resources/beta/#src.openai.resources.beta.AsyncThreadsWithRawResponse.runs","title":"runs","text":"<pre><code>runs() -&gt; AsyncRunsWithRawResponse\n</code></pre>"},{"location":"reference/resources/beta/#src.openai.resources.beta.AsyncThreadsWithStreamingResponse","title":"AsyncThreadsWithStreamingResponse","text":"<pre><code>AsyncThreadsWithStreamingResponse(threads: AsyncThreads)\n</code></pre> <p>Methods:</p> Name Description <code>messages</code> <code>runs</code> <p>Attributes:</p> Name Type Description <code>create</code> <code>create_and_run</code> <code>delete</code> <code>retrieve</code> <code>update</code>"},{"location":"reference/resources/beta/#src.openai.resources.beta.AsyncThreadsWithStreamingResponse.create","title":"create  <code>instance-attribute</code>","text":"<pre><code>create = async_to_streamed_response_wrapper(create)\n</code></pre>"},{"location":"reference/resources/beta/#src.openai.resources.beta.AsyncThreadsWithStreamingResponse.create_and_run","title":"create_and_run  <code>instance-attribute</code>","text":"<pre><code>create_and_run = async_to_streamed_response_wrapper(\n    create_and_run\n)\n</code></pre>"},{"location":"reference/resources/beta/#src.openai.resources.beta.AsyncThreadsWithStreamingResponse.delete","title":"delete  <code>instance-attribute</code>","text":"<pre><code>delete = async_to_streamed_response_wrapper(delete)\n</code></pre>"},{"location":"reference/resources/beta/#src.openai.resources.beta.AsyncThreadsWithStreamingResponse.retrieve","title":"retrieve  <code>instance-attribute</code>","text":"<pre><code>retrieve = async_to_streamed_response_wrapper(retrieve)\n</code></pre>"},{"location":"reference/resources/beta/#src.openai.resources.beta.AsyncThreadsWithStreamingResponse.update","title":"update  <code>instance-attribute</code>","text":"<pre><code>update = async_to_streamed_response_wrapper(update)\n</code></pre>"},{"location":"reference/resources/beta/#src.openai.resources.beta.AsyncThreadsWithStreamingResponse.messages","title":"messages","text":"<pre><code>messages() -&gt; AsyncMessagesWithStreamingResponse\n</code></pre>"},{"location":"reference/resources/beta/#src.openai.resources.beta.AsyncThreadsWithStreamingResponse.runs","title":"runs","text":"<pre><code>runs() -&gt; AsyncRunsWithStreamingResponse\n</code></pre>"},{"location":"reference/resources/beta/#src.openai.resources.beta.Beta","title":"Beta","text":"<pre><code>Beta(client: OpenAI)\n</code></pre> <p>Methods:</p> Name Description <code>assistants</code> <code>threads</code> <code>with_raw_response</code> <code>with_streaming_response</code>"},{"location":"reference/resources/beta/#src.openai.resources.beta.Beta.assistants","title":"assistants","text":"<pre><code>assistants() -&gt; Assistants\n</code></pre>"},{"location":"reference/resources/beta/#src.openai.resources.beta.Beta.threads","title":"threads","text":"<pre><code>threads() -&gt; Threads\n</code></pre>"},{"location":"reference/resources/beta/#src.openai.resources.beta.Beta.with_raw_response","title":"with_raw_response","text":"<pre><code>with_raw_response() -&gt; BetaWithRawResponse\n</code></pre>"},{"location":"reference/resources/beta/#src.openai.resources.beta.Beta.with_streaming_response","title":"with_streaming_response","text":"<pre><code>with_streaming_response() -&gt; BetaWithStreamingResponse\n</code></pre>"},{"location":"reference/resources/beta/#src.openai.resources.beta.BetaWithRawResponse","title":"BetaWithRawResponse","text":"<pre><code>BetaWithRawResponse(beta: Beta)\n</code></pre> <p>Methods:</p> Name Description <code>assistants</code> <code>threads</code>"},{"location":"reference/resources/beta/#src.openai.resources.beta.BetaWithRawResponse.assistants","title":"assistants","text":"<pre><code>assistants() -&gt; AssistantsWithRawResponse\n</code></pre>"},{"location":"reference/resources/beta/#src.openai.resources.beta.BetaWithRawResponse.threads","title":"threads","text":"<pre><code>threads() -&gt; ThreadsWithRawResponse\n</code></pre>"},{"location":"reference/resources/beta/#src.openai.resources.beta.BetaWithStreamingResponse","title":"BetaWithStreamingResponse","text":"<pre><code>BetaWithStreamingResponse(beta: Beta)\n</code></pre> <p>Methods:</p> Name Description <code>assistants</code> <code>threads</code>"},{"location":"reference/resources/beta/#src.openai.resources.beta.BetaWithStreamingResponse.assistants","title":"assistants","text":"<pre><code>assistants() -&gt; AssistantsWithStreamingResponse\n</code></pre>"},{"location":"reference/resources/beta/#src.openai.resources.beta.BetaWithStreamingResponse.threads","title":"threads","text":"<pre><code>threads() -&gt; ThreadsWithStreamingResponse\n</code></pre>"},{"location":"reference/resources/beta/#src.openai.resources.beta.Threads","title":"Threads","text":"<pre><code>Threads(client: OpenAI)\n</code></pre> <p>Methods:</p> Name Description <code>create</code> <p>Create a thread.</p> <code>create_and_run</code> <p>Create a thread and run it in one request.</p> <code>delete</code> <p>Delete a thread.</p> <code>messages</code> <code>retrieve</code> <p>Retrieves a thread.</p> <code>runs</code> <code>update</code> <p>Modifies a thread.</p> <code>with_raw_response</code> <code>with_streaming_response</code>"},{"location":"reference/resources/beta/#src.openai.resources.beta.Threads.create","title":"create","text":"<pre><code>create(\n    *,\n    messages: Iterable[Message] | NotGiven = NOT_GIVEN,\n    metadata: Optional[object] | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; Thread\n</code></pre> <p>Create a thread.</p> <p>Parameters:</p> Name Type Description Default <code>messages</code> <code>Iterable[Message] | NotGiven</code> <p>A list of messages to   start the thread with.</p> <code>NOT_GIVEN</code> <code>metadata</code> <code>Optional[object] | NotGiven</code> <p>Set of 16 key-value pairs that can be attached to an object. This can be useful   for storing additional information about the object in a structured format. Keys   can be a maximum of 64 characters long and values can be a maxium of 512   characters long.</p> <code>NOT_GIVEN</code> <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/beta/#src.openai.resources.beta.Threads.create_and_run","title":"create_and_run","text":"<pre><code>create_and_run(\n    *,\n    assistant_id: str,\n    instructions: Optional[str] | NotGiven = NOT_GIVEN,\n    metadata: Optional[object] | NotGiven = NOT_GIVEN,\n    model: Optional[str] | NotGiven = NOT_GIVEN,\n    thread: Thread | NotGiven = NOT_GIVEN,\n    tools: Optional[Iterable[Tool]] | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; Run\n</code></pre> <p>Create a thread and run it in one request.</p> <p>Parameters:</p> Name Type Description Default <code>assistant_id</code> <code>str</code> <p>The ID of the   assistant to use to   execute this run.</p> required <code>instructions</code> <code>Optional[str] | NotGiven</code> <p>Override the default system message of the assistant. This is useful for   modifying the behavior on a per-run basis.</p> <code>NOT_GIVEN</code> <code>metadata</code> <code>Optional[object] | NotGiven</code> <p>Set of 16 key-value pairs that can be attached to an object. This can be useful   for storing additional information about the object in a structured format. Keys   can be a maximum of 64 characters long and values can be a maxium of 512   characters long.</p> <code>NOT_GIVEN</code> <code>model</code> <code>Optional[str] | NotGiven</code> <p>The ID of the Model to   be used to execute this run. If a value is provided here, it will override the   model associated with the assistant. If not, the model associated with the   assistant will be used.</p> <code>NOT_GIVEN</code> <code>thread</code> <code>Thread | NotGiven</code> <p>If no thread is provided, an empty thread will be created.</p> <code>NOT_GIVEN</code> <code>tools</code> <code>Optional[Iterable[Tool]] | NotGiven</code> <p>Override the tools the assistant can use for this run. This is useful for   modifying the behavior on a per-run basis.</p> <code>NOT_GIVEN</code> <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/beta/#src.openai.resources.beta.Threads.delete","title":"delete","text":"<pre><code>delete(\n    thread_id: str,\n    *,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; ThreadDeleted\n</code></pre> <p>Delete a thread.</p> <p>Parameters:</p> Name Type Description Default <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/beta/#src.openai.resources.beta.Threads.messages","title":"messages","text":"<pre><code>messages() -&gt; Messages\n</code></pre>"},{"location":"reference/resources/beta/#src.openai.resources.beta.Threads.retrieve","title":"retrieve","text":"<pre><code>retrieve(\n    thread_id: str,\n    *,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; Thread\n</code></pre> <p>Retrieves a thread.</p> <p>Parameters:</p> Name Type Description Default <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/beta/#src.openai.resources.beta.Threads.runs","title":"runs","text":"<pre><code>runs() -&gt; Runs\n</code></pre>"},{"location":"reference/resources/beta/#src.openai.resources.beta.Threads.update","title":"update","text":"<pre><code>update(\n    thread_id: str,\n    *,\n    metadata: Optional[object] | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; Thread\n</code></pre> <p>Modifies a thread.</p> <p>Parameters:</p> Name Type Description Default <code>metadata</code> <code>Optional[object] | NotGiven</code> <p>Set of 16 key-value pairs that can be attached to an object. This can be useful   for storing additional information about the object in a structured format. Keys   can be a maximum of 64 characters long and values can be a maxium of 512   characters long.</p> <code>NOT_GIVEN</code> <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/beta/#src.openai.resources.beta.Threads.with_raw_response","title":"with_raw_response","text":"<pre><code>with_raw_response() -&gt; ThreadsWithRawResponse\n</code></pre>"},{"location":"reference/resources/beta/#src.openai.resources.beta.Threads.with_streaming_response","title":"with_streaming_response","text":"<pre><code>with_streaming_response() -&gt; ThreadsWithStreamingResponse\n</code></pre>"},{"location":"reference/resources/beta/#src.openai.resources.beta.ThreadsWithRawResponse","title":"ThreadsWithRawResponse","text":"<pre><code>ThreadsWithRawResponse(threads: Threads)\n</code></pre> <p>Methods:</p> Name Description <code>messages</code> <code>runs</code> <p>Attributes:</p> Name Type Description <code>create</code> <code>create_and_run</code> <code>delete</code> <code>retrieve</code> <code>update</code>"},{"location":"reference/resources/beta/#src.openai.resources.beta.ThreadsWithRawResponse.create","title":"create  <code>instance-attribute</code>","text":"<pre><code>create = to_raw_response_wrapper(create)\n</code></pre>"},{"location":"reference/resources/beta/#src.openai.resources.beta.ThreadsWithRawResponse.create_and_run","title":"create_and_run  <code>instance-attribute</code>","text":"<pre><code>create_and_run = to_raw_response_wrapper(create_and_run)\n</code></pre>"},{"location":"reference/resources/beta/#src.openai.resources.beta.ThreadsWithRawResponse.delete","title":"delete  <code>instance-attribute</code>","text":"<pre><code>delete = to_raw_response_wrapper(delete)\n</code></pre>"},{"location":"reference/resources/beta/#src.openai.resources.beta.ThreadsWithRawResponse.retrieve","title":"retrieve  <code>instance-attribute</code>","text":"<pre><code>retrieve = to_raw_response_wrapper(retrieve)\n</code></pre>"},{"location":"reference/resources/beta/#src.openai.resources.beta.ThreadsWithRawResponse.update","title":"update  <code>instance-attribute</code>","text":"<pre><code>update = to_raw_response_wrapper(update)\n</code></pre>"},{"location":"reference/resources/beta/#src.openai.resources.beta.ThreadsWithRawResponse.messages","title":"messages","text":"<pre><code>messages() -&gt; MessagesWithRawResponse\n</code></pre>"},{"location":"reference/resources/beta/#src.openai.resources.beta.ThreadsWithRawResponse.runs","title":"runs","text":"<pre><code>runs() -&gt; RunsWithRawResponse\n</code></pre>"},{"location":"reference/resources/beta/#src.openai.resources.beta.ThreadsWithStreamingResponse","title":"ThreadsWithStreamingResponse","text":"<pre><code>ThreadsWithStreamingResponse(threads: Threads)\n</code></pre> <p>Methods:</p> Name Description <code>messages</code> <code>runs</code> <p>Attributes:</p> Name Type Description <code>create</code> <code>create_and_run</code> <code>delete</code> <code>retrieve</code> <code>update</code>"},{"location":"reference/resources/beta/#src.openai.resources.beta.ThreadsWithStreamingResponse.create","title":"create  <code>instance-attribute</code>","text":"<pre><code>create = to_streamed_response_wrapper(create)\n</code></pre>"},{"location":"reference/resources/beta/#src.openai.resources.beta.ThreadsWithStreamingResponse.create_and_run","title":"create_and_run  <code>instance-attribute</code>","text":"<pre><code>create_and_run = to_streamed_response_wrapper(\n    create_and_run\n)\n</code></pre>"},{"location":"reference/resources/beta/#src.openai.resources.beta.ThreadsWithStreamingResponse.delete","title":"delete  <code>instance-attribute</code>","text":"<pre><code>delete = to_streamed_response_wrapper(delete)\n</code></pre>"},{"location":"reference/resources/beta/#src.openai.resources.beta.ThreadsWithStreamingResponse.retrieve","title":"retrieve  <code>instance-attribute</code>","text":"<pre><code>retrieve = to_streamed_response_wrapper(retrieve)\n</code></pre>"},{"location":"reference/resources/beta/#src.openai.resources.beta.ThreadsWithStreamingResponse.update","title":"update  <code>instance-attribute</code>","text":"<pre><code>update = to_streamed_response_wrapper(update)\n</code></pre>"},{"location":"reference/resources/beta/#src.openai.resources.beta.ThreadsWithStreamingResponse.messages","title":"messages","text":"<pre><code>messages() -&gt; MessagesWithStreamingResponse\n</code></pre>"},{"location":"reference/resources/beta/#src.openai.resources.beta.ThreadsWithStreamingResponse.runs","title":"runs","text":"<pre><code>runs() -&gt; RunsWithStreamingResponse\n</code></pre>"},{"location":"reference/resources/beta/beta/","title":"beta","text":"<p>The <code>beta</code> modules provides a unified interface for accessing beta features of the API, encapsulating synchronous and asynchronous access to resources in beta.</p> <p>The module aggregates the beta functionalities related to features like yet considered generally available (GA), offering a simplified entry point for interacting with these resources. It is designed to facilitate easy access to the cutting-edge features still under development, enabling developers to experiment with and leverage new capabilities before they become GA.</p> <p>Classes:</p> Name Description <code>AsyncBeta</code> <code>AsyncBetaWithRawResponse</code> <code>AsyncBetaWithStreamingResponse</code> <code>Beta</code> <code>BetaWithRawResponse</code> <code>BetaWithStreamingResponse</code>"},{"location":"reference/resources/beta/beta/#src.openai.resources.beta.beta.AsyncBeta","title":"AsyncBeta","text":"<pre><code>AsyncBeta(client: AsyncOpenAI)\n</code></pre> <p>Methods:</p> Name Description <code>assistants</code> <code>threads</code> <code>with_raw_response</code> <code>with_streaming_response</code>"},{"location":"reference/resources/beta/beta/#src.openai.resources.beta.beta.AsyncBeta.assistants","title":"assistants","text":"<pre><code>assistants() -&gt; AsyncAssistants\n</code></pre>"},{"location":"reference/resources/beta/beta/#src.openai.resources.beta.beta.AsyncBeta.threads","title":"threads","text":"<pre><code>threads() -&gt; AsyncThreads\n</code></pre>"},{"location":"reference/resources/beta/beta/#src.openai.resources.beta.beta.AsyncBeta.with_raw_response","title":"with_raw_response","text":"<pre><code>with_raw_response() -&gt; AsyncBetaWithRawResponse\n</code></pre>"},{"location":"reference/resources/beta/beta/#src.openai.resources.beta.beta.AsyncBeta.with_streaming_response","title":"with_streaming_response","text":"<pre><code>with_streaming_response() -&gt; AsyncBetaWithStreamingResponse\n</code></pre>"},{"location":"reference/resources/beta/beta/#src.openai.resources.beta.beta.AsyncBetaWithRawResponse","title":"AsyncBetaWithRawResponse","text":"<pre><code>AsyncBetaWithRawResponse(beta: AsyncBeta)\n</code></pre> <p>Methods:</p> Name Description <code>assistants</code> <code>threads</code>"},{"location":"reference/resources/beta/beta/#src.openai.resources.beta.beta.AsyncBetaWithRawResponse.assistants","title":"assistants","text":"<pre><code>assistants() -&gt; AsyncAssistantsWithRawResponse\n</code></pre>"},{"location":"reference/resources/beta/beta/#src.openai.resources.beta.beta.AsyncBetaWithRawResponse.threads","title":"threads","text":"<pre><code>threads() -&gt; AsyncThreadsWithRawResponse\n</code></pre>"},{"location":"reference/resources/beta/beta/#src.openai.resources.beta.beta.AsyncBetaWithStreamingResponse","title":"AsyncBetaWithStreamingResponse","text":"<pre><code>AsyncBetaWithStreamingResponse(beta: AsyncBeta)\n</code></pre> <p>Methods:</p> Name Description <code>assistants</code> <code>threads</code>"},{"location":"reference/resources/beta/beta/#src.openai.resources.beta.beta.AsyncBetaWithStreamingResponse.assistants","title":"assistants","text":"<pre><code>assistants() -&gt; AsyncAssistantsWithStreamingResponse\n</code></pre>"},{"location":"reference/resources/beta/beta/#src.openai.resources.beta.beta.AsyncBetaWithStreamingResponse.threads","title":"threads","text":"<pre><code>threads() -&gt; AsyncThreadsWithStreamingResponse\n</code></pre>"},{"location":"reference/resources/beta/beta/#src.openai.resources.beta.beta.Beta","title":"Beta","text":"<pre><code>Beta(client: OpenAI)\n</code></pre> <p>Methods:</p> Name Description <code>assistants</code> <code>threads</code> <code>with_raw_response</code> <code>with_streaming_response</code>"},{"location":"reference/resources/beta/beta/#src.openai.resources.beta.beta.Beta.assistants","title":"assistants","text":"<pre><code>assistants() -&gt; Assistants\n</code></pre>"},{"location":"reference/resources/beta/beta/#src.openai.resources.beta.beta.Beta.threads","title":"threads","text":"<pre><code>threads() -&gt; Threads\n</code></pre>"},{"location":"reference/resources/beta/beta/#src.openai.resources.beta.beta.Beta.with_raw_response","title":"with_raw_response","text":"<pre><code>with_raw_response() -&gt; BetaWithRawResponse\n</code></pre>"},{"location":"reference/resources/beta/beta/#src.openai.resources.beta.beta.Beta.with_streaming_response","title":"with_streaming_response","text":"<pre><code>with_streaming_response() -&gt; BetaWithStreamingResponse\n</code></pre>"},{"location":"reference/resources/beta/beta/#src.openai.resources.beta.beta.BetaWithRawResponse","title":"BetaWithRawResponse","text":"<pre><code>BetaWithRawResponse(beta: Beta)\n</code></pre> <p>Methods:</p> Name Description <code>assistants</code> <code>threads</code>"},{"location":"reference/resources/beta/beta/#src.openai.resources.beta.beta.BetaWithRawResponse.assistants","title":"assistants","text":"<pre><code>assistants() -&gt; AssistantsWithRawResponse\n</code></pre>"},{"location":"reference/resources/beta/beta/#src.openai.resources.beta.beta.BetaWithRawResponse.threads","title":"threads","text":"<pre><code>threads() -&gt; ThreadsWithRawResponse\n</code></pre>"},{"location":"reference/resources/beta/beta/#src.openai.resources.beta.beta.BetaWithStreamingResponse","title":"BetaWithStreamingResponse","text":"<pre><code>BetaWithStreamingResponse(beta: Beta)\n</code></pre> <p>Methods:</p> Name Description <code>assistants</code> <code>threads</code>"},{"location":"reference/resources/beta/beta/#src.openai.resources.beta.beta.BetaWithStreamingResponse.assistants","title":"assistants","text":"<pre><code>assistants() -&gt; AssistantsWithStreamingResponse\n</code></pre>"},{"location":"reference/resources/beta/beta/#src.openai.resources.beta.beta.BetaWithStreamingResponse.threads","title":"threads","text":"<pre><code>threads() -&gt; ThreadsWithStreamingResponse\n</code></pre>"},{"location":"reference/resources/beta/assistants/","title":"openai.resources.beta.assistants","text":"<p>Modules:</p> Name Description <code>assistants</code> <p>The <code>assistants</code> module offers functionalities to create, retrieve, update, list, and delete Assistants. Assistants are AI models configured to perform specific tasks based on instructions, files, and other parameters.</p> <code>files</code> <p>Classes:</p> Name Description <code>Assistants</code> <code>AssistantsWithRawResponse</code> <code>AssistantsWithStreamingResponse</code> <code>AsyncAssistants</code> <code>AsyncAssistantsWithRawResponse</code> <code>AsyncAssistantsWithStreamingResponse</code> <code>AsyncFiles</code> <code>AsyncFilesWithRawResponse</code> <code>AsyncFilesWithStreamingResponse</code> <code>Files</code> <code>FilesWithRawResponse</code> <code>FilesWithStreamingResponse</code>"},{"location":"reference/resources/beta/assistants/#src.openai.resources.beta.assistants.Assistants","title":"Assistants","text":"<pre><code>Assistants(client: OpenAI)\n</code></pre> <p>Methods:</p> Name Description <code>create</code> <p>Create an assistant with a model and instructions.</p> <code>delete</code> <p>Delete an assistant.</p> <code>files</code> <code>list</code> <p>Returns a list of assistants.</p> <code>retrieve</code> <p>Retrieves an assistant.</p> <code>update</code> <p>Modifies an assistant.</p> <code>with_raw_response</code> <code>with_streaming_response</code>"},{"location":"reference/resources/beta/assistants/#src.openai.resources.beta.assistants.Assistants.create","title":"create","text":"<pre><code>create(\n    *,\n    model: str,\n    description: Optional[str] | NotGiven = NOT_GIVEN,\n    file_ids: List[str] | NotGiven = NOT_GIVEN,\n    instructions: Optional[str] | NotGiven = NOT_GIVEN,\n    metadata: Optional[object] | NotGiven = NOT_GIVEN,\n    name: Optional[str] | NotGiven = NOT_GIVEN,\n    tools: Iterable[Tool] | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; Assistant\n</code></pre> <p>Create an assistant with a model and instructions.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>str</code> <p>ID of the model to use. You can use the   List models API to   see all of your available models, or see our   Model overview for   descriptions of them.</p> required <code>description</code> <code>Optional[str] | NotGiven</code> <p>The description of the assistant. The maximum length is 512 characters.</p> <code>NOT_GIVEN</code> <code>file_ids</code> <code>List[str] | NotGiven</code> <p>A list of file IDs   attached to this assistant. There can be a maximum of 20 files attached to the   assistant. Files are ordered by their creation date in ascending order.</p> <code>NOT_GIVEN</code> <code>instructions</code> <code>Optional[str] | NotGiven</code> <p>The system instructions that the assistant uses. The maximum length is 32768   characters.</p> <code>NOT_GIVEN</code> <code>metadata</code> <code>Optional[object] | NotGiven</code> <p>Set of 16 key-value pairs that can be attached to an object. This can be useful   for storing additional information about the object in a structured format. Keys   can be a maximum of 64 characters long and values can be a maxium of 512   characters long.</p> <code>NOT_GIVEN</code> <code>name</code> <code>Optional[str] | NotGiven</code> <p>The name of the assistant. The maximum length is 256 characters.</p> <code>NOT_GIVEN</code> <code>tools</code> <code>Iterable[Tool] | NotGiven</code> <p>A list of tool enabled on the assistant. There can be a maximum of 128 tools per   assistant. Tools can be of types <code>code_interpreter</code>, <code>retrieval</code>, or <code>function</code>.</p> <code>NOT_GIVEN</code> <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/beta/assistants/#src.openai.resources.beta.assistants.Assistants.delete","title":"delete","text":"<pre><code>delete(\n    assistant_id: str,\n    *,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; AssistantDeleted\n</code></pre> <p>Delete an assistant.</p> <p>Parameters:</p> Name Type Description Default <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/beta/assistants/#src.openai.resources.beta.assistants.Assistants.files","title":"files","text":"<pre><code>files() -&gt; Files\n</code></pre>"},{"location":"reference/resources/beta/assistants/#src.openai.resources.beta.assistants.Assistants.list","title":"list","text":"<pre><code>list(\n    *,\n    after: str | NotGiven = NOT_GIVEN,\n    before: str | NotGiven = NOT_GIVEN,\n    limit: int | NotGiven = NOT_GIVEN,\n    order: Literal[\"asc\", \"desc\"] | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; SyncCursorPage[Assistant]\n</code></pre> <p>Returns a list of assistants.</p> <p>Parameters:</p> Name Type Description Default <code>after</code> <code>str | NotGiven</code> <p>A cursor for use in pagination.</p> <code>NOT_GIVEN</code> <p><code>after</code> is an object ID that defines your place       in the list. For instance, if you make a list request and receive 100 objects,       ending with obj_foo, your subsequent call can include after=obj_foo in order to       fetch the next page of the list.</p> <p>before: A cursor for use in pagination. <code>before</code> is an object ID that defines your place       in the list. For instance, if you make a list request and receive 100 objects,       ending with obj_foo, your subsequent call can include before=obj_foo in order to       fetch the previous page of the list.</p> <p>limit: A limit on the number of objects to be returned. Limit can range between 1 and       100, and the default is 20.</p> <p>order: Sort order by the <code>created_at</code> timestamp of the objects. <code>asc</code> for ascending       order and <code>desc</code> for descending order.</p> <p>extra_headers: Send extra headers</p> <p>extra_query: Add additional query parameters to the request</p> <p>extra_body: Add additional JSON properties to the request</p> <p>timeout: Override the client-level default timeout for this request, in seconds</p>"},{"location":"reference/resources/beta/assistants/#src.openai.resources.beta.assistants.Assistants.retrieve","title":"retrieve","text":"<pre><code>retrieve(\n    assistant_id: str,\n    *,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; Assistant\n</code></pre> <p>Retrieves an assistant.</p> <p>Parameters:</p> Name Type Description Default <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/beta/assistants/#src.openai.resources.beta.assistants.Assistants.update","title":"update","text":"<pre><code>update(\n    assistant_id: str,\n    *,\n    description: Optional[str] | NotGiven = NOT_GIVEN,\n    file_ids: List[str] | NotGiven = NOT_GIVEN,\n    instructions: Optional[str] | NotGiven = NOT_GIVEN,\n    metadata: Optional[object] | NotGiven = NOT_GIVEN,\n    model: str | NotGiven = NOT_GIVEN,\n    name: Optional[str] | NotGiven = NOT_GIVEN,\n    tools: Iterable[Tool] | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; Assistant\n</code></pre> <p>Modifies an assistant.</p> <p>Parameters:</p> Name Type Description Default <code>description</code> <code>Optional[str] | NotGiven</code> <p>The description of the assistant.</p> <code>NOT_GIVEN</code> <p>The maximum length is 512 characters.</p> <p>file_ids: A list of File IDs       attached to this assistant. There can be a maximum of 20 files attached to the       assistant. Files are ordered by their creation date in ascending order. If a       file was previously attached to the list but does not show up in the list, it       will be deleted from the assistant.</p> <p>instructions: The system instructions that the assistant uses. The maximum length is 32768       characters.</p> <p>metadata: Set of 16 key-value pairs that can be attached to an object. This can be useful       for storing additional information about the object in a structured format. Keys       can be a maximum of 64 characters long and values can be a maxium of 512       characters long.</p> <p>model: ID of the model to use. You can use the       List models API to       see all of your available models, or see our       Model overview for       descriptions of them.</p> <p>name: The name of the assistant. The maximum length is 256 characters.</p> <p>tools: A list of tool enabled on the assistant. There can be a maximum of 128 tools per       assistant. Tools can be of types <code>code_interpreter</code>, <code>retrieval</code>, or <code>function</code>.</p> <p>extra_headers: Send extra headers</p> <p>extra_query: Add additional query parameters to the request</p> <p>extra_body: Add additional JSON properties to the request</p> <p>timeout: Override the client-level default timeout for this request, in seconds</p>"},{"location":"reference/resources/beta/assistants/#src.openai.resources.beta.assistants.Assistants.with_raw_response","title":"with_raw_response","text":"<pre><code>with_raw_response() -&gt; AssistantsWithRawResponse\n</code></pre>"},{"location":"reference/resources/beta/assistants/#src.openai.resources.beta.assistants.Assistants.with_streaming_response","title":"with_streaming_response","text":"<pre><code>with_streaming_response() -&gt; (\n    AssistantsWithStreamingResponse\n)\n</code></pre>"},{"location":"reference/resources/beta/assistants/#src.openai.resources.beta.assistants.AssistantsWithRawResponse","title":"AssistantsWithRawResponse","text":"<pre><code>AssistantsWithRawResponse(assistants: Assistants)\n</code></pre> <p>Methods:</p> Name Description <code>files</code> <p>Attributes:</p> Name Type Description <code>create</code> <code>delete</code> <code>list</code> <code>retrieve</code> <code>update</code>"},{"location":"reference/resources/beta/assistants/#src.openai.resources.beta.assistants.AssistantsWithRawResponse.create","title":"create  <code>instance-attribute</code>","text":"<pre><code>create = to_raw_response_wrapper(create)\n</code></pre>"},{"location":"reference/resources/beta/assistants/#src.openai.resources.beta.assistants.AssistantsWithRawResponse.delete","title":"delete  <code>instance-attribute</code>","text":"<pre><code>delete = to_raw_response_wrapper(delete)\n</code></pre>"},{"location":"reference/resources/beta/assistants/#src.openai.resources.beta.assistants.AssistantsWithRawResponse.list","title":"list  <code>instance-attribute</code>","text":"<pre><code>list = to_raw_response_wrapper(list)\n</code></pre>"},{"location":"reference/resources/beta/assistants/#src.openai.resources.beta.assistants.AssistantsWithRawResponse.retrieve","title":"retrieve  <code>instance-attribute</code>","text":"<pre><code>retrieve = to_raw_response_wrapper(retrieve)\n</code></pre>"},{"location":"reference/resources/beta/assistants/#src.openai.resources.beta.assistants.AssistantsWithRawResponse.update","title":"update  <code>instance-attribute</code>","text":"<pre><code>update = to_raw_response_wrapper(update)\n</code></pre>"},{"location":"reference/resources/beta/assistants/#src.openai.resources.beta.assistants.AssistantsWithRawResponse.files","title":"files","text":"<pre><code>files() -&gt; FilesWithRawResponse\n</code></pre>"},{"location":"reference/resources/beta/assistants/#src.openai.resources.beta.assistants.AssistantsWithStreamingResponse","title":"AssistantsWithStreamingResponse","text":"<pre><code>AssistantsWithStreamingResponse(assistants: Assistants)\n</code></pre> <p>Methods:</p> Name Description <code>files</code> <p>Attributes:</p> Name Type Description <code>create</code> <code>delete</code> <code>list</code> <code>retrieve</code> <code>update</code>"},{"location":"reference/resources/beta/assistants/#src.openai.resources.beta.assistants.AssistantsWithStreamingResponse.create","title":"create  <code>instance-attribute</code>","text":"<pre><code>create = to_streamed_response_wrapper(create)\n</code></pre>"},{"location":"reference/resources/beta/assistants/#src.openai.resources.beta.assistants.AssistantsWithStreamingResponse.delete","title":"delete  <code>instance-attribute</code>","text":"<pre><code>delete = to_streamed_response_wrapper(delete)\n</code></pre>"},{"location":"reference/resources/beta/assistants/#src.openai.resources.beta.assistants.AssistantsWithStreamingResponse.list","title":"list  <code>instance-attribute</code>","text":"<pre><code>list = to_streamed_response_wrapper(list)\n</code></pre>"},{"location":"reference/resources/beta/assistants/#src.openai.resources.beta.assistants.AssistantsWithStreamingResponse.retrieve","title":"retrieve  <code>instance-attribute</code>","text":"<pre><code>retrieve = to_streamed_response_wrapper(retrieve)\n</code></pre>"},{"location":"reference/resources/beta/assistants/#src.openai.resources.beta.assistants.AssistantsWithStreamingResponse.update","title":"update  <code>instance-attribute</code>","text":"<pre><code>update = to_streamed_response_wrapper(update)\n</code></pre>"},{"location":"reference/resources/beta/assistants/#src.openai.resources.beta.assistants.AssistantsWithStreamingResponse.files","title":"files","text":"<pre><code>files() -&gt; FilesWithStreamingResponse\n</code></pre>"},{"location":"reference/resources/beta/assistants/#src.openai.resources.beta.assistants.AsyncAssistants","title":"AsyncAssistants","text":"<pre><code>AsyncAssistants(client: AsyncOpenAI)\n</code></pre> <p>Methods:</p> Name Description <code>create</code> <p>Create an assistant with a model and instructions.</p> <code>delete</code> <p>Delete an assistant.</p> <code>files</code> <code>list</code> <p>Returns a list of assistants.</p> <code>retrieve</code> <p>Retrieves an assistant.</p> <code>update</code> <p>Modifies an assistant.</p> <code>with_raw_response</code> <code>with_streaming_response</code>"},{"location":"reference/resources/beta/assistants/#src.openai.resources.beta.assistants.AsyncAssistants.create","title":"create  <code>async</code>","text":"<pre><code>create(\n    *,\n    model: str,\n    description: Optional[str] | NotGiven = NOT_GIVEN,\n    file_ids: List[str] | NotGiven = NOT_GIVEN,\n    instructions: Optional[str] | NotGiven = NOT_GIVEN,\n    metadata: Optional[object] | NotGiven = NOT_GIVEN,\n    name: Optional[str] | NotGiven = NOT_GIVEN,\n    tools: Iterable[Tool] | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; Assistant\n</code></pre> <p>Create an assistant with a model and instructions.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>str</code> <p>ID of the model to use. You can use the   List models API to   see all of your available models, or see our   Model overview for   descriptions of them.</p> required <code>description</code> <code>Optional[str] | NotGiven</code> <p>The description of the assistant. The maximum length is 512 characters.</p> <code>NOT_GIVEN</code> <code>file_ids</code> <code>List[str] | NotGiven</code> <p>A list of file IDs   attached to this assistant. There can be a maximum of 20 files attached to the   assistant. Files are ordered by their creation date in ascending order.</p> <code>NOT_GIVEN</code> <code>instructions</code> <code>Optional[str] | NotGiven</code> <p>The system instructions that the assistant uses. The maximum length is 32768   characters.</p> <code>NOT_GIVEN</code> <code>metadata</code> <code>Optional[object] | NotGiven</code> <p>Set of 16 key-value pairs that can be attached to an object. This can be useful   for storing additional information about the object in a structured format. Keys   can be a maximum of 64 characters long and values can be a maxium of 512   characters long.</p> <code>NOT_GIVEN</code> <code>name</code> <code>Optional[str] | NotGiven</code> <p>The name of the assistant. The maximum length is 256 characters.</p> <code>NOT_GIVEN</code> <code>tools</code> <code>Iterable[Tool] | NotGiven</code> <p>A list of tool enabled on the assistant. There can be a maximum of 128 tools per   assistant. Tools can be of types <code>code_interpreter</code>, <code>retrieval</code>, or <code>function</code>.</p> <code>NOT_GIVEN</code> <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/beta/assistants/#src.openai.resources.beta.assistants.AsyncAssistants.delete","title":"delete  <code>async</code>","text":"<pre><code>delete(\n    assistant_id: str,\n    *,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; AssistantDeleted\n</code></pre> <p>Delete an assistant.</p> <p>Parameters:</p> Name Type Description Default <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/beta/assistants/#src.openai.resources.beta.assistants.AsyncAssistants.files","title":"files","text":"<pre><code>files() -&gt; AsyncFiles\n</code></pre>"},{"location":"reference/resources/beta/assistants/#src.openai.resources.beta.assistants.AsyncAssistants.list","title":"list","text":"<pre><code>list(\n    *,\n    after: str | NotGiven = NOT_GIVEN,\n    before: str | NotGiven = NOT_GIVEN,\n    limit: int | NotGiven = NOT_GIVEN,\n    order: Literal[\"asc\", \"desc\"] | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; AsyncPaginator[Assistant, AsyncCursorPage[Assistant]]\n</code></pre> <p>Returns a list of assistants.</p> <p>Parameters:</p> Name Type Description Default <code>after</code> <code>str | NotGiven</code> <p>A cursor for use in pagination.</p> <code>NOT_GIVEN</code> <p><code>after</code> is an object ID that defines your place       in the list. For instance, if you make a list request and receive 100 objects,       ending with obj_foo, your subsequent call can include after=obj_foo in order to       fetch the next page of the list.</p> <p>before: A cursor for use in pagination. <code>before</code> is an object ID that defines your place       in the list. For instance, if you make a list request and receive 100 objects,       ending with obj_foo, your subsequent call can include before=obj_foo in order to       fetch the previous page of the list.</p> <p>limit: A limit on the number of objects to be returned. Limit can range between 1 and       100, and the default is 20.</p> <p>order: Sort order by the <code>created_at</code> timestamp of the objects. <code>asc</code> for ascending       order and <code>desc</code> for descending order.</p> <p>extra_headers: Send extra headers</p> <p>extra_query: Add additional query parameters to the request</p> <p>extra_body: Add additional JSON properties to the request</p> <p>timeout: Override the client-level default timeout for this request, in seconds</p>"},{"location":"reference/resources/beta/assistants/#src.openai.resources.beta.assistants.AsyncAssistants.retrieve","title":"retrieve  <code>async</code>","text":"<pre><code>retrieve(\n    assistant_id: str,\n    *,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; Assistant\n</code></pre> <p>Retrieves an assistant.</p> <p>Parameters:</p> Name Type Description Default <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/beta/assistants/#src.openai.resources.beta.assistants.AsyncAssistants.update","title":"update  <code>async</code>","text":"<pre><code>update(\n    assistant_id: str,\n    *,\n    description: Optional[str] | NotGiven = NOT_GIVEN,\n    file_ids: List[str] | NotGiven = NOT_GIVEN,\n    instructions: Optional[str] | NotGiven = NOT_GIVEN,\n    metadata: Optional[object] | NotGiven = NOT_GIVEN,\n    model: str | NotGiven = NOT_GIVEN,\n    name: Optional[str] | NotGiven = NOT_GIVEN,\n    tools: Iterable[Tool] | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; Assistant\n</code></pre> <p>Modifies an assistant.</p> <p>Parameters:</p> Name Type Description Default <code>description</code> <code>Optional[str] | NotGiven</code> <p>The description of the assistant.</p> <code>NOT_GIVEN</code> <p>The maximum length is 512 characters.</p> <p>file_ids: A list of File IDs       attached to this assistant. There can be a maximum of 20 files attached to the       assistant. Files are ordered by their creation date in ascending order. If a       file was previously attached to the list but does not show up in the list, it       will be deleted from the assistant.</p> <p>instructions: The system instructions that the assistant uses. The maximum length is 32768       characters.</p> <p>metadata: Set of 16 key-value pairs that can be attached to an object. This can be useful       for storing additional information about the object in a structured format. Keys       can be a maximum of 64 characters long and values can be a maxium of 512       characters long.</p> <p>model: ID of the model to use. You can use the       List models API to       see all of your available models, or see our       Model overview for       descriptions of them.</p> <p>name: The name of the assistant. The maximum length is 256 characters.</p> <p>tools: A list of tool enabled on the assistant. There can be a maximum of 128 tools per       assistant. Tools can be of types <code>code_interpreter</code>, <code>retrieval</code>, or <code>function</code>.</p> <p>extra_headers: Send extra headers</p> <p>extra_query: Add additional query parameters to the request</p> <p>extra_body: Add additional JSON properties to the request</p> <p>timeout: Override the client-level default timeout for this request, in seconds</p>"},{"location":"reference/resources/beta/assistants/#src.openai.resources.beta.assistants.AsyncAssistants.with_raw_response","title":"with_raw_response","text":"<pre><code>with_raw_response() -&gt; AsyncAssistantsWithRawResponse\n</code></pre>"},{"location":"reference/resources/beta/assistants/#src.openai.resources.beta.assistants.AsyncAssistants.with_streaming_response","title":"with_streaming_response","text":"<pre><code>with_streaming_response() -&gt; (\n    AsyncAssistantsWithStreamingResponse\n)\n</code></pre>"},{"location":"reference/resources/beta/assistants/#src.openai.resources.beta.assistants.AsyncAssistantsWithRawResponse","title":"AsyncAssistantsWithRawResponse","text":"<pre><code>AsyncAssistantsWithRawResponse(assistants: AsyncAssistants)\n</code></pre> <p>Methods:</p> Name Description <code>files</code> <p>Attributes:</p> Name Type Description <code>create</code> <code>delete</code> <code>list</code> <code>retrieve</code> <code>update</code>"},{"location":"reference/resources/beta/assistants/#src.openai.resources.beta.assistants.AsyncAssistantsWithRawResponse.create","title":"create  <code>instance-attribute</code>","text":"<pre><code>create = async_to_raw_response_wrapper(create)\n</code></pre>"},{"location":"reference/resources/beta/assistants/#src.openai.resources.beta.assistants.AsyncAssistantsWithRawResponse.delete","title":"delete  <code>instance-attribute</code>","text":"<pre><code>delete = async_to_raw_response_wrapper(delete)\n</code></pre>"},{"location":"reference/resources/beta/assistants/#src.openai.resources.beta.assistants.AsyncAssistantsWithRawResponse.list","title":"list  <code>instance-attribute</code>","text":"<pre><code>list = async_to_raw_response_wrapper(list)\n</code></pre>"},{"location":"reference/resources/beta/assistants/#src.openai.resources.beta.assistants.AsyncAssistantsWithRawResponse.retrieve","title":"retrieve  <code>instance-attribute</code>","text":"<pre><code>retrieve = async_to_raw_response_wrapper(retrieve)\n</code></pre>"},{"location":"reference/resources/beta/assistants/#src.openai.resources.beta.assistants.AsyncAssistantsWithRawResponse.update","title":"update  <code>instance-attribute</code>","text":"<pre><code>update = async_to_raw_response_wrapper(update)\n</code></pre>"},{"location":"reference/resources/beta/assistants/#src.openai.resources.beta.assistants.AsyncAssistantsWithRawResponse.files","title":"files","text":"<pre><code>files() -&gt; AsyncFilesWithRawResponse\n</code></pre>"},{"location":"reference/resources/beta/assistants/#src.openai.resources.beta.assistants.AsyncAssistantsWithStreamingResponse","title":"AsyncAssistantsWithStreamingResponse","text":"<pre><code>AsyncAssistantsWithStreamingResponse(\n    assistants: AsyncAssistants,\n)\n</code></pre> <p>Methods:</p> Name Description <code>files</code> <p>Attributes:</p> Name Type Description <code>create</code> <code>delete</code> <code>list</code> <code>retrieve</code> <code>update</code>"},{"location":"reference/resources/beta/assistants/#src.openai.resources.beta.assistants.AsyncAssistantsWithStreamingResponse.create","title":"create  <code>instance-attribute</code>","text":"<pre><code>create = async_to_streamed_response_wrapper(create)\n</code></pre>"},{"location":"reference/resources/beta/assistants/#src.openai.resources.beta.assistants.AsyncAssistantsWithStreamingResponse.delete","title":"delete  <code>instance-attribute</code>","text":"<pre><code>delete = async_to_streamed_response_wrapper(delete)\n</code></pre>"},{"location":"reference/resources/beta/assistants/#src.openai.resources.beta.assistants.AsyncAssistantsWithStreamingResponse.list","title":"list  <code>instance-attribute</code>","text":"<pre><code>list = async_to_streamed_response_wrapper(list)\n</code></pre>"},{"location":"reference/resources/beta/assistants/#src.openai.resources.beta.assistants.AsyncAssistantsWithStreamingResponse.retrieve","title":"retrieve  <code>instance-attribute</code>","text":"<pre><code>retrieve = async_to_streamed_response_wrapper(retrieve)\n</code></pre>"},{"location":"reference/resources/beta/assistants/#src.openai.resources.beta.assistants.AsyncAssistantsWithStreamingResponse.update","title":"update  <code>instance-attribute</code>","text":"<pre><code>update = async_to_streamed_response_wrapper(update)\n</code></pre>"},{"location":"reference/resources/beta/assistants/#src.openai.resources.beta.assistants.AsyncAssistantsWithStreamingResponse.files","title":"files","text":"<pre><code>files() -&gt; AsyncFilesWithStreamingResponse\n</code></pre>"},{"location":"reference/resources/beta/assistants/#src.openai.resources.beta.assistants.AsyncFiles","title":"AsyncFiles","text":"<pre><code>AsyncFiles(client: AsyncOpenAI)\n</code></pre> <p>Methods:</p> Name Description <code>create</code> <p>Create an assistant file by attaching a</p> <code>delete</code> <p>Delete an assistant file.</p> <code>list</code> <p>Returns a list of assistant files.</p> <code>retrieve</code> <p>Retrieves an AssistantFile.</p> <code>with_raw_response</code> <code>with_streaming_response</code>"},{"location":"reference/resources/beta/assistants/#src.openai.resources.beta.assistants.AsyncFiles.create","title":"create  <code>async</code>","text":"<pre><code>create(\n    assistant_id: str,\n    *,\n    file_id: str,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; AssistantFile\n</code></pre> <p>Create an assistant file by attaching a File to an assistant.</p> <p>Parameters:</p> Name Type Description Default <code>file_id</code> <code>str</code> <p>A File ID (with   <code>purpose=\"assistants\"</code>) that the assistant should use. Useful for tools like   <code>retrieval</code> and <code>code_interpreter</code> that can access files.</p> required <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/beta/assistants/#src.openai.resources.beta.assistants.AsyncFiles.delete","title":"delete  <code>async</code>","text":"<pre><code>delete(\n    file_id: str,\n    *,\n    assistant_id: str,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; FileDeleteResponse\n</code></pre> <p>Delete an assistant file.</p> <p>Parameters:</p> Name Type Description Default <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/beta/assistants/#src.openai.resources.beta.assistants.AsyncFiles.list","title":"list","text":"<pre><code>list(\n    assistant_id: str,\n    *,\n    after: str | NotGiven = NOT_GIVEN,\n    before: str | NotGiven = NOT_GIVEN,\n    limit: int | NotGiven = NOT_GIVEN,\n    order: Literal[\"asc\", \"desc\"] | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; AsyncPaginator[\n    AssistantFile, AsyncCursorPage[AssistantFile]\n]\n</code></pre> <p>Returns a list of assistant files.</p> <p>Parameters:</p> Name Type Description Default <code>after</code> <code>str | NotGiven</code> <p>A cursor for use in pagination. <code>after</code> is an object ID that defines your place   in the list. For instance, if you make a list request and receive 100 objects,   ending with obj_foo, your subsequent call can include after=obj_foo in order to   fetch the next page of the list.</p> <code>NOT_GIVEN</code> <code>before</code> <code>str | NotGiven</code> <p>A cursor for use in pagination. <code>before</code> is an object ID that defines your place   in the list. For instance, if you make a list request and receive 100 objects,   ending with obj_foo, your subsequent call can include before=obj_foo in order to   fetch the previous page of the list.</p> <code>NOT_GIVEN</code> <code>limit</code> <code>int | NotGiven</code> <p>A limit on the number of objects to be returned. Limit can range between 1 and   100, and the default is 20.</p> <code>NOT_GIVEN</code> <code>order</code> <code>Literal['asc', 'desc'] | NotGiven</code> <p>Sort order by the <code>created_at</code> timestamp of the objects. <code>asc</code> for ascending   order and <code>desc</code> for descending order.</p> <code>NOT_GIVEN</code> <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/beta/assistants/#src.openai.resources.beta.assistants.AsyncFiles.retrieve","title":"retrieve  <code>async</code>","text":"<pre><code>retrieve(\n    file_id: str,\n    *,\n    assistant_id: str,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; AssistantFile\n</code></pre> <p>Retrieves an AssistantFile.</p> <p>Parameters:</p> Name Type Description Default <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/beta/assistants/#src.openai.resources.beta.assistants.AsyncFiles.with_raw_response","title":"with_raw_response","text":"<pre><code>with_raw_response() -&gt; AsyncFilesWithRawResponse\n</code></pre>"},{"location":"reference/resources/beta/assistants/#src.openai.resources.beta.assistants.AsyncFiles.with_streaming_response","title":"with_streaming_response","text":"<pre><code>with_streaming_response() -&gt; (\n    AsyncFilesWithStreamingResponse\n)\n</code></pre>"},{"location":"reference/resources/beta/assistants/#src.openai.resources.beta.assistants.AsyncFilesWithRawResponse","title":"AsyncFilesWithRawResponse","text":"<pre><code>AsyncFilesWithRawResponse(files: AsyncFiles)\n</code></pre> <p>Attributes:</p> Name Type Description <code>create</code> <code>delete</code> <code>list</code> <code>retrieve</code>"},{"location":"reference/resources/beta/assistants/#src.openai.resources.beta.assistants.AsyncFilesWithRawResponse.create","title":"create  <code>instance-attribute</code>","text":"<pre><code>create = async_to_raw_response_wrapper(create)\n</code></pre>"},{"location":"reference/resources/beta/assistants/#src.openai.resources.beta.assistants.AsyncFilesWithRawResponse.delete","title":"delete  <code>instance-attribute</code>","text":"<pre><code>delete = async_to_raw_response_wrapper(delete)\n</code></pre>"},{"location":"reference/resources/beta/assistants/#src.openai.resources.beta.assistants.AsyncFilesWithRawResponse.list","title":"list  <code>instance-attribute</code>","text":"<pre><code>list = async_to_raw_response_wrapper(list)\n</code></pre>"},{"location":"reference/resources/beta/assistants/#src.openai.resources.beta.assistants.AsyncFilesWithRawResponse.retrieve","title":"retrieve  <code>instance-attribute</code>","text":"<pre><code>retrieve = async_to_raw_response_wrapper(retrieve)\n</code></pre>"},{"location":"reference/resources/beta/assistants/#src.openai.resources.beta.assistants.AsyncFilesWithStreamingResponse","title":"AsyncFilesWithStreamingResponse","text":"<pre><code>AsyncFilesWithStreamingResponse(files: AsyncFiles)\n</code></pre> <p>Attributes:</p> Name Type Description <code>create</code> <code>delete</code> <code>list</code> <code>retrieve</code>"},{"location":"reference/resources/beta/assistants/#src.openai.resources.beta.assistants.AsyncFilesWithStreamingResponse.create","title":"create  <code>instance-attribute</code>","text":"<pre><code>create = async_to_streamed_response_wrapper(create)\n</code></pre>"},{"location":"reference/resources/beta/assistants/#src.openai.resources.beta.assistants.AsyncFilesWithStreamingResponse.delete","title":"delete  <code>instance-attribute</code>","text":"<pre><code>delete = async_to_streamed_response_wrapper(delete)\n</code></pre>"},{"location":"reference/resources/beta/assistants/#src.openai.resources.beta.assistants.AsyncFilesWithStreamingResponse.list","title":"list  <code>instance-attribute</code>","text":"<pre><code>list = async_to_streamed_response_wrapper(list)\n</code></pre>"},{"location":"reference/resources/beta/assistants/#src.openai.resources.beta.assistants.AsyncFilesWithStreamingResponse.retrieve","title":"retrieve  <code>instance-attribute</code>","text":"<pre><code>retrieve = async_to_streamed_response_wrapper(retrieve)\n</code></pre>"},{"location":"reference/resources/beta/assistants/#src.openai.resources.beta.assistants.Files","title":"Files","text":"<pre><code>Files(client: OpenAI)\n</code></pre> <p>Methods:</p> Name Description <code>create</code> <p>Create an assistant file by attaching a</p> <code>delete</code> <p>Delete an assistant file.</p> <code>list</code> <p>Returns a list of assistant files.</p> <code>retrieve</code> <p>Retrieves an AssistantFile.</p> <code>with_raw_response</code> <code>with_streaming_response</code>"},{"location":"reference/resources/beta/assistants/#src.openai.resources.beta.assistants.Files.create","title":"create","text":"<pre><code>create(\n    assistant_id: str,\n    *,\n    file_id: str,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; AssistantFile\n</code></pre> <p>Create an assistant file by attaching a File to an assistant.</p> <p>Parameters:</p> Name Type Description Default <code>file_id</code> <code>str</code> <p>A File ID (with   <code>purpose=\"assistants\"</code>) that the assistant should use. Useful for tools like   <code>retrieval</code> and <code>code_interpreter</code> that can access files.</p> required <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/beta/assistants/#src.openai.resources.beta.assistants.Files.delete","title":"delete","text":"<pre><code>delete(\n    file_id: str,\n    *,\n    assistant_id: str,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; FileDeleteResponse\n</code></pre> <p>Delete an assistant file.</p> <p>Parameters:</p> Name Type Description Default <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/beta/assistants/#src.openai.resources.beta.assistants.Files.list","title":"list","text":"<pre><code>list(\n    assistant_id: str,\n    *,\n    after: str | NotGiven = NOT_GIVEN,\n    before: str | NotGiven = NOT_GIVEN,\n    limit: int | NotGiven = NOT_GIVEN,\n    order: Literal[\"asc\", \"desc\"] | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; SyncCursorPage[AssistantFile]\n</code></pre> <p>Returns a list of assistant files.</p> <p>Parameters:</p> Name Type Description Default <code>after</code> <code>str | NotGiven</code> <p>A cursor for use in pagination. <code>after</code> is an object ID that defines your place   in the list. For instance, if you make a list request and receive 100 objects,   ending with obj_foo, your subsequent call can include after=obj_foo in order to   fetch the next page of the list.</p> <code>NOT_GIVEN</code> <code>before</code> <code>str | NotGiven</code> <p>A cursor for use in pagination. <code>before</code> is an object ID that defines your place   in the list. For instance, if you make a list request and receive 100 objects,   ending with obj_foo, your subsequent call can include before=obj_foo in order to   fetch the previous page of the list.</p> <code>NOT_GIVEN</code> <code>limit</code> <code>int | NotGiven</code> <p>A limit on the number of objects to be returned. Limit can range between 1 and   100, and the default is 20.</p> <code>NOT_GIVEN</code> <code>order</code> <code>Literal['asc', 'desc'] | NotGiven</code> <p>Sort order by the <code>created_at</code> timestamp of the objects. <code>asc</code> for ascending   order and <code>desc</code> for descending order.</p> <code>NOT_GIVEN</code> <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/beta/assistants/#src.openai.resources.beta.assistants.Files.retrieve","title":"retrieve","text":"<pre><code>retrieve(\n    file_id: str,\n    *,\n    assistant_id: str,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; AssistantFile\n</code></pre> <p>Retrieves an AssistantFile.</p> <p>Parameters:</p> Name Type Description Default <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/beta/assistants/#src.openai.resources.beta.assistants.Files.with_raw_response","title":"with_raw_response","text":"<pre><code>with_raw_response() -&gt; FilesWithRawResponse\n</code></pre>"},{"location":"reference/resources/beta/assistants/#src.openai.resources.beta.assistants.Files.with_streaming_response","title":"with_streaming_response","text":"<pre><code>with_streaming_response() -&gt; FilesWithStreamingResponse\n</code></pre>"},{"location":"reference/resources/beta/assistants/#src.openai.resources.beta.assistants.FilesWithRawResponse","title":"FilesWithRawResponse","text":"<pre><code>FilesWithRawResponse(files: Files)\n</code></pre> <p>Attributes:</p> Name Type Description <code>create</code> <code>delete</code> <code>list</code> <code>retrieve</code>"},{"location":"reference/resources/beta/assistants/#src.openai.resources.beta.assistants.FilesWithRawResponse.create","title":"create  <code>instance-attribute</code>","text":"<pre><code>create = to_raw_response_wrapper(create)\n</code></pre>"},{"location":"reference/resources/beta/assistants/#src.openai.resources.beta.assistants.FilesWithRawResponse.delete","title":"delete  <code>instance-attribute</code>","text":"<pre><code>delete = to_raw_response_wrapper(delete)\n</code></pre>"},{"location":"reference/resources/beta/assistants/#src.openai.resources.beta.assistants.FilesWithRawResponse.list","title":"list  <code>instance-attribute</code>","text":"<pre><code>list = to_raw_response_wrapper(list)\n</code></pre>"},{"location":"reference/resources/beta/assistants/#src.openai.resources.beta.assistants.FilesWithRawResponse.retrieve","title":"retrieve  <code>instance-attribute</code>","text":"<pre><code>retrieve = to_raw_response_wrapper(retrieve)\n</code></pre>"},{"location":"reference/resources/beta/assistants/#src.openai.resources.beta.assistants.FilesWithStreamingResponse","title":"FilesWithStreamingResponse","text":"<pre><code>FilesWithStreamingResponse(files: Files)\n</code></pre> <p>Attributes:</p> Name Type Description <code>create</code> <code>delete</code> <code>list</code> <code>retrieve</code>"},{"location":"reference/resources/beta/assistants/#src.openai.resources.beta.assistants.FilesWithStreamingResponse.create","title":"create  <code>instance-attribute</code>","text":"<pre><code>create = to_streamed_response_wrapper(create)\n</code></pre>"},{"location":"reference/resources/beta/assistants/#src.openai.resources.beta.assistants.FilesWithStreamingResponse.delete","title":"delete  <code>instance-attribute</code>","text":"<pre><code>delete = to_streamed_response_wrapper(delete)\n</code></pre>"},{"location":"reference/resources/beta/assistants/#src.openai.resources.beta.assistants.FilesWithStreamingResponse.list","title":"list  <code>instance-attribute</code>","text":"<pre><code>list = to_streamed_response_wrapper(list)\n</code></pre>"},{"location":"reference/resources/beta/assistants/#src.openai.resources.beta.assistants.FilesWithStreamingResponse.retrieve","title":"retrieve  <code>instance-attribute</code>","text":"<pre><code>retrieve = to_streamed_response_wrapper(retrieve)\n</code></pre>"},{"location":"reference/resources/beta/assistants/assistants/","title":"assistants","text":"<p>The <code>assistants</code> module offers functionalities to create, retrieve, update, list, and delete Assistants. Assistants are AI models configured to perform specific tasks based on instructions, files, and other parameters.</p> <p>Classes:</p> Name Description <code>Assistants</code> <code>AssistantsWithRawResponse</code> <code>AssistantsWithStreamingResponse</code> <code>AsyncAssistants</code> <code>AsyncAssistantsWithRawResponse</code> <code>AsyncAssistantsWithStreamingResponse</code>"},{"location":"reference/resources/beta/assistants/assistants/#src.openai.resources.beta.assistants.assistants.Assistants","title":"Assistants","text":"<pre><code>Assistants(client: OpenAI)\n</code></pre> <p>Methods:</p> Name Description <code>create</code> <p>Create an assistant with a model and instructions.</p> <code>delete</code> <p>Delete an assistant.</p> <code>files</code> <code>list</code> <p>Returns a list of assistants.</p> <code>retrieve</code> <p>Retrieves an assistant.</p> <code>update</code> <p>Modifies an assistant.</p> <code>with_raw_response</code> <code>with_streaming_response</code>"},{"location":"reference/resources/beta/assistants/assistants/#src.openai.resources.beta.assistants.assistants.Assistants.create","title":"create","text":"<pre><code>create(\n    *,\n    model: str,\n    description: Optional[str] | NotGiven = NOT_GIVEN,\n    file_ids: List[str] | NotGiven = NOT_GIVEN,\n    instructions: Optional[str] | NotGiven = NOT_GIVEN,\n    metadata: Optional[object] | NotGiven = NOT_GIVEN,\n    name: Optional[str] | NotGiven = NOT_GIVEN,\n    tools: Iterable[Tool] | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; Assistant\n</code></pre> <p>Create an assistant with a model and instructions.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>str</code> <p>ID of the model to use. You can use the   List models API to   see all of your available models, or see our   Model overview for   descriptions of them.</p> required <code>description</code> <code>Optional[str] | NotGiven</code> <p>The description of the assistant. The maximum length is 512 characters.</p> <code>NOT_GIVEN</code> <code>file_ids</code> <code>List[str] | NotGiven</code> <p>A list of file IDs   attached to this assistant. There can be a maximum of 20 files attached to the   assistant. Files are ordered by their creation date in ascending order.</p> <code>NOT_GIVEN</code> <code>instructions</code> <code>Optional[str] | NotGiven</code> <p>The system instructions that the assistant uses. The maximum length is 32768   characters.</p> <code>NOT_GIVEN</code> <code>metadata</code> <code>Optional[object] | NotGiven</code> <p>Set of 16 key-value pairs that can be attached to an object. This can be useful   for storing additional information about the object in a structured format. Keys   can be a maximum of 64 characters long and values can be a maxium of 512   characters long.</p> <code>NOT_GIVEN</code> <code>name</code> <code>Optional[str] | NotGiven</code> <p>The name of the assistant. The maximum length is 256 characters.</p> <code>NOT_GIVEN</code> <code>tools</code> <code>Iterable[Tool] | NotGiven</code> <p>A list of tool enabled on the assistant. There can be a maximum of 128 tools per   assistant. Tools can be of types <code>code_interpreter</code>, <code>retrieval</code>, or <code>function</code>.</p> <code>NOT_GIVEN</code> <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/beta/assistants/assistants/#src.openai.resources.beta.assistants.assistants.Assistants.delete","title":"delete","text":"<pre><code>delete(\n    assistant_id: str,\n    *,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; AssistantDeleted\n</code></pre> <p>Delete an assistant.</p> <p>Parameters:</p> Name Type Description Default <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/beta/assistants/assistants/#src.openai.resources.beta.assistants.assistants.Assistants.files","title":"files","text":"<pre><code>files() -&gt; Files\n</code></pre>"},{"location":"reference/resources/beta/assistants/assistants/#src.openai.resources.beta.assistants.assistants.Assistants.list","title":"list","text":"<pre><code>list(\n    *,\n    after: str | NotGiven = NOT_GIVEN,\n    before: str | NotGiven = NOT_GIVEN,\n    limit: int | NotGiven = NOT_GIVEN,\n    order: Literal[\"asc\", \"desc\"] | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; SyncCursorPage[Assistant]\n</code></pre> <p>Returns a list of assistants.</p> <p>Parameters:</p> Name Type Description Default <code>after</code> <code>str | NotGiven</code> <p>A cursor for use in pagination.</p> <code>NOT_GIVEN</code> <p><code>after</code> is an object ID that defines your place       in the list. For instance, if you make a list request and receive 100 objects,       ending with obj_foo, your subsequent call can include after=obj_foo in order to       fetch the next page of the list.</p> <p>before: A cursor for use in pagination. <code>before</code> is an object ID that defines your place       in the list. For instance, if you make a list request and receive 100 objects,       ending with obj_foo, your subsequent call can include before=obj_foo in order to       fetch the previous page of the list.</p> <p>limit: A limit on the number of objects to be returned. Limit can range between 1 and       100, and the default is 20.</p> <p>order: Sort order by the <code>created_at</code> timestamp of the objects. <code>asc</code> for ascending       order and <code>desc</code> for descending order.</p> <p>extra_headers: Send extra headers</p> <p>extra_query: Add additional query parameters to the request</p> <p>extra_body: Add additional JSON properties to the request</p> <p>timeout: Override the client-level default timeout for this request, in seconds</p>"},{"location":"reference/resources/beta/assistants/assistants/#src.openai.resources.beta.assistants.assistants.Assistants.retrieve","title":"retrieve","text":"<pre><code>retrieve(\n    assistant_id: str,\n    *,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; Assistant\n</code></pre> <p>Retrieves an assistant.</p> <p>Parameters:</p> Name Type Description Default <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/beta/assistants/assistants/#src.openai.resources.beta.assistants.assistants.Assistants.update","title":"update","text":"<pre><code>update(\n    assistant_id: str,\n    *,\n    description: Optional[str] | NotGiven = NOT_GIVEN,\n    file_ids: List[str] | NotGiven = NOT_GIVEN,\n    instructions: Optional[str] | NotGiven = NOT_GIVEN,\n    metadata: Optional[object] | NotGiven = NOT_GIVEN,\n    model: str | NotGiven = NOT_GIVEN,\n    name: Optional[str] | NotGiven = NOT_GIVEN,\n    tools: Iterable[Tool] | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; Assistant\n</code></pre> <p>Modifies an assistant.</p> <p>Parameters:</p> Name Type Description Default <code>description</code> <code>Optional[str] | NotGiven</code> <p>The description of the assistant.</p> <code>NOT_GIVEN</code> <p>The maximum length is 512 characters.</p> <p>file_ids: A list of File IDs       attached to this assistant. There can be a maximum of 20 files attached to the       assistant. Files are ordered by their creation date in ascending order. If a       file was previously attached to the list but does not show up in the list, it       will be deleted from the assistant.</p> <p>instructions: The system instructions that the assistant uses. The maximum length is 32768       characters.</p> <p>metadata: Set of 16 key-value pairs that can be attached to an object. This can be useful       for storing additional information about the object in a structured format. Keys       can be a maximum of 64 characters long and values can be a maxium of 512       characters long.</p> <p>model: ID of the model to use. You can use the       List models API to       see all of your available models, or see our       Model overview for       descriptions of them.</p> <p>name: The name of the assistant. The maximum length is 256 characters.</p> <p>tools: A list of tool enabled on the assistant. There can be a maximum of 128 tools per       assistant. Tools can be of types <code>code_interpreter</code>, <code>retrieval</code>, or <code>function</code>.</p> <p>extra_headers: Send extra headers</p> <p>extra_query: Add additional query parameters to the request</p> <p>extra_body: Add additional JSON properties to the request</p> <p>timeout: Override the client-level default timeout for this request, in seconds</p>"},{"location":"reference/resources/beta/assistants/assistants/#src.openai.resources.beta.assistants.assistants.Assistants.with_raw_response","title":"with_raw_response","text":"<pre><code>with_raw_response() -&gt; AssistantsWithRawResponse\n</code></pre>"},{"location":"reference/resources/beta/assistants/assistants/#src.openai.resources.beta.assistants.assistants.Assistants.with_streaming_response","title":"with_streaming_response","text":"<pre><code>with_streaming_response() -&gt; (\n    AssistantsWithStreamingResponse\n)\n</code></pre>"},{"location":"reference/resources/beta/assistants/assistants/#src.openai.resources.beta.assistants.assistants.AssistantsWithRawResponse","title":"AssistantsWithRawResponse","text":"<pre><code>AssistantsWithRawResponse(assistants: Assistants)\n</code></pre> <p>Methods:</p> Name Description <code>files</code> <p>Attributes:</p> Name Type Description <code>create</code> <code>delete</code> <code>list</code> <code>retrieve</code> <code>update</code>"},{"location":"reference/resources/beta/assistants/assistants/#src.openai.resources.beta.assistants.assistants.AssistantsWithRawResponse.create","title":"create  <code>instance-attribute</code>","text":"<pre><code>create = to_raw_response_wrapper(create)\n</code></pre>"},{"location":"reference/resources/beta/assistants/assistants/#src.openai.resources.beta.assistants.assistants.AssistantsWithRawResponse.delete","title":"delete  <code>instance-attribute</code>","text":"<pre><code>delete = to_raw_response_wrapper(delete)\n</code></pre>"},{"location":"reference/resources/beta/assistants/assistants/#src.openai.resources.beta.assistants.assistants.AssistantsWithRawResponse.list","title":"list  <code>instance-attribute</code>","text":"<pre><code>list = to_raw_response_wrapper(list)\n</code></pre>"},{"location":"reference/resources/beta/assistants/assistants/#src.openai.resources.beta.assistants.assistants.AssistantsWithRawResponse.retrieve","title":"retrieve  <code>instance-attribute</code>","text":"<pre><code>retrieve = to_raw_response_wrapper(retrieve)\n</code></pre>"},{"location":"reference/resources/beta/assistants/assistants/#src.openai.resources.beta.assistants.assistants.AssistantsWithRawResponse.update","title":"update  <code>instance-attribute</code>","text":"<pre><code>update = to_raw_response_wrapper(update)\n</code></pre>"},{"location":"reference/resources/beta/assistants/assistants/#src.openai.resources.beta.assistants.assistants.AssistantsWithRawResponse.files","title":"files","text":"<pre><code>files() -&gt; FilesWithRawResponse\n</code></pre>"},{"location":"reference/resources/beta/assistants/assistants/#src.openai.resources.beta.assistants.assistants.AssistantsWithStreamingResponse","title":"AssistantsWithStreamingResponse","text":"<pre><code>AssistantsWithStreamingResponse(assistants: Assistants)\n</code></pre> <p>Methods:</p> Name Description <code>files</code> <p>Attributes:</p> Name Type Description <code>create</code> <code>delete</code> <code>list</code> <code>retrieve</code> <code>update</code>"},{"location":"reference/resources/beta/assistants/assistants/#src.openai.resources.beta.assistants.assistants.AssistantsWithStreamingResponse.create","title":"create  <code>instance-attribute</code>","text":"<pre><code>create = to_streamed_response_wrapper(create)\n</code></pre>"},{"location":"reference/resources/beta/assistants/assistants/#src.openai.resources.beta.assistants.assistants.AssistantsWithStreamingResponse.delete","title":"delete  <code>instance-attribute</code>","text":"<pre><code>delete = to_streamed_response_wrapper(delete)\n</code></pre>"},{"location":"reference/resources/beta/assistants/assistants/#src.openai.resources.beta.assistants.assistants.AssistantsWithStreamingResponse.list","title":"list  <code>instance-attribute</code>","text":"<pre><code>list = to_streamed_response_wrapper(list)\n</code></pre>"},{"location":"reference/resources/beta/assistants/assistants/#src.openai.resources.beta.assistants.assistants.AssistantsWithStreamingResponse.retrieve","title":"retrieve  <code>instance-attribute</code>","text":"<pre><code>retrieve = to_streamed_response_wrapper(retrieve)\n</code></pre>"},{"location":"reference/resources/beta/assistants/assistants/#src.openai.resources.beta.assistants.assistants.AssistantsWithStreamingResponse.update","title":"update  <code>instance-attribute</code>","text":"<pre><code>update = to_streamed_response_wrapper(update)\n</code></pre>"},{"location":"reference/resources/beta/assistants/assistants/#src.openai.resources.beta.assistants.assistants.AssistantsWithStreamingResponse.files","title":"files","text":"<pre><code>files() -&gt; FilesWithStreamingResponse\n</code></pre>"},{"location":"reference/resources/beta/assistants/assistants/#src.openai.resources.beta.assistants.assistants.AsyncAssistants","title":"AsyncAssistants","text":"<pre><code>AsyncAssistants(client: AsyncOpenAI)\n</code></pre> <p>Methods:</p> Name Description <code>create</code> <p>Create an assistant with a model and instructions.</p> <code>delete</code> <p>Delete an assistant.</p> <code>files</code> <code>list</code> <p>Returns a list of assistants.</p> <code>retrieve</code> <p>Retrieves an assistant.</p> <code>update</code> <p>Modifies an assistant.</p> <code>with_raw_response</code> <code>with_streaming_response</code>"},{"location":"reference/resources/beta/assistants/assistants/#src.openai.resources.beta.assistants.assistants.AsyncAssistants.create","title":"create  <code>async</code>","text":"<pre><code>create(\n    *,\n    model: str,\n    description: Optional[str] | NotGiven = NOT_GIVEN,\n    file_ids: List[str] | NotGiven = NOT_GIVEN,\n    instructions: Optional[str] | NotGiven = NOT_GIVEN,\n    metadata: Optional[object] | NotGiven = NOT_GIVEN,\n    name: Optional[str] | NotGiven = NOT_GIVEN,\n    tools: Iterable[Tool] | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; Assistant\n</code></pre> <p>Create an assistant with a model and instructions.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>str</code> <p>ID of the model to use. You can use the   List models API to   see all of your available models, or see our   Model overview for   descriptions of them.</p> required <code>description</code> <code>Optional[str] | NotGiven</code> <p>The description of the assistant. The maximum length is 512 characters.</p> <code>NOT_GIVEN</code> <code>file_ids</code> <code>List[str] | NotGiven</code> <p>A list of file IDs   attached to this assistant. There can be a maximum of 20 files attached to the   assistant. Files are ordered by their creation date in ascending order.</p> <code>NOT_GIVEN</code> <code>instructions</code> <code>Optional[str] | NotGiven</code> <p>The system instructions that the assistant uses. The maximum length is 32768   characters.</p> <code>NOT_GIVEN</code> <code>metadata</code> <code>Optional[object] | NotGiven</code> <p>Set of 16 key-value pairs that can be attached to an object. This can be useful   for storing additional information about the object in a structured format. Keys   can be a maximum of 64 characters long and values can be a maxium of 512   characters long.</p> <code>NOT_GIVEN</code> <code>name</code> <code>Optional[str] | NotGiven</code> <p>The name of the assistant. The maximum length is 256 characters.</p> <code>NOT_GIVEN</code> <code>tools</code> <code>Iterable[Tool] | NotGiven</code> <p>A list of tool enabled on the assistant. There can be a maximum of 128 tools per   assistant. Tools can be of types <code>code_interpreter</code>, <code>retrieval</code>, or <code>function</code>.</p> <code>NOT_GIVEN</code> <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/beta/assistants/assistants/#src.openai.resources.beta.assistants.assistants.AsyncAssistants.delete","title":"delete  <code>async</code>","text":"<pre><code>delete(\n    assistant_id: str,\n    *,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; AssistantDeleted\n</code></pre> <p>Delete an assistant.</p> <p>Parameters:</p> Name Type Description Default <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/beta/assistants/assistants/#src.openai.resources.beta.assistants.assistants.AsyncAssistants.files","title":"files","text":"<pre><code>files() -&gt; AsyncFiles\n</code></pre>"},{"location":"reference/resources/beta/assistants/assistants/#src.openai.resources.beta.assistants.assistants.AsyncAssistants.list","title":"list","text":"<pre><code>list(\n    *,\n    after: str | NotGiven = NOT_GIVEN,\n    before: str | NotGiven = NOT_GIVEN,\n    limit: int | NotGiven = NOT_GIVEN,\n    order: Literal[\"asc\", \"desc\"] | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; AsyncPaginator[Assistant, AsyncCursorPage[Assistant]]\n</code></pre> <p>Returns a list of assistants.</p> <p>Parameters:</p> Name Type Description Default <code>after</code> <code>str | NotGiven</code> <p>A cursor for use in pagination.</p> <code>NOT_GIVEN</code> <p><code>after</code> is an object ID that defines your place       in the list. For instance, if you make a list request and receive 100 objects,       ending with obj_foo, your subsequent call can include after=obj_foo in order to       fetch the next page of the list.</p> <p>before: A cursor for use in pagination. <code>before</code> is an object ID that defines your place       in the list. For instance, if you make a list request and receive 100 objects,       ending with obj_foo, your subsequent call can include before=obj_foo in order to       fetch the previous page of the list.</p> <p>limit: A limit on the number of objects to be returned. Limit can range between 1 and       100, and the default is 20.</p> <p>order: Sort order by the <code>created_at</code> timestamp of the objects. <code>asc</code> for ascending       order and <code>desc</code> for descending order.</p> <p>extra_headers: Send extra headers</p> <p>extra_query: Add additional query parameters to the request</p> <p>extra_body: Add additional JSON properties to the request</p> <p>timeout: Override the client-level default timeout for this request, in seconds</p>"},{"location":"reference/resources/beta/assistants/assistants/#src.openai.resources.beta.assistants.assistants.AsyncAssistants.retrieve","title":"retrieve  <code>async</code>","text":"<pre><code>retrieve(\n    assistant_id: str,\n    *,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; Assistant\n</code></pre> <p>Retrieves an assistant.</p> <p>Parameters:</p> Name Type Description Default <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/beta/assistants/assistants/#src.openai.resources.beta.assistants.assistants.AsyncAssistants.update","title":"update  <code>async</code>","text":"<pre><code>update(\n    assistant_id: str,\n    *,\n    description: Optional[str] | NotGiven = NOT_GIVEN,\n    file_ids: List[str] | NotGiven = NOT_GIVEN,\n    instructions: Optional[str] | NotGiven = NOT_GIVEN,\n    metadata: Optional[object] | NotGiven = NOT_GIVEN,\n    model: str | NotGiven = NOT_GIVEN,\n    name: Optional[str] | NotGiven = NOT_GIVEN,\n    tools: Iterable[Tool] | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; Assistant\n</code></pre> <p>Modifies an assistant.</p> <p>Parameters:</p> Name Type Description Default <code>description</code> <code>Optional[str] | NotGiven</code> <p>The description of the assistant.</p> <code>NOT_GIVEN</code> <p>The maximum length is 512 characters.</p> <p>file_ids: A list of File IDs       attached to this assistant. There can be a maximum of 20 files attached to the       assistant. Files are ordered by their creation date in ascending order. If a       file was previously attached to the list but does not show up in the list, it       will be deleted from the assistant.</p> <p>instructions: The system instructions that the assistant uses. The maximum length is 32768       characters.</p> <p>metadata: Set of 16 key-value pairs that can be attached to an object. This can be useful       for storing additional information about the object in a structured format. Keys       can be a maximum of 64 characters long and values can be a maxium of 512       characters long.</p> <p>model: ID of the model to use. You can use the       List models API to       see all of your available models, or see our       Model overview for       descriptions of them.</p> <p>name: The name of the assistant. The maximum length is 256 characters.</p> <p>tools: A list of tool enabled on the assistant. There can be a maximum of 128 tools per       assistant. Tools can be of types <code>code_interpreter</code>, <code>retrieval</code>, or <code>function</code>.</p> <p>extra_headers: Send extra headers</p> <p>extra_query: Add additional query parameters to the request</p> <p>extra_body: Add additional JSON properties to the request</p> <p>timeout: Override the client-level default timeout for this request, in seconds</p>"},{"location":"reference/resources/beta/assistants/assistants/#src.openai.resources.beta.assistants.assistants.AsyncAssistants.with_raw_response","title":"with_raw_response","text":"<pre><code>with_raw_response() -&gt; AsyncAssistantsWithRawResponse\n</code></pre>"},{"location":"reference/resources/beta/assistants/assistants/#src.openai.resources.beta.assistants.assistants.AsyncAssistants.with_streaming_response","title":"with_streaming_response","text":"<pre><code>with_streaming_response() -&gt; (\n    AsyncAssistantsWithStreamingResponse\n)\n</code></pre>"},{"location":"reference/resources/beta/assistants/assistants/#src.openai.resources.beta.assistants.assistants.AsyncAssistantsWithRawResponse","title":"AsyncAssistantsWithRawResponse","text":"<pre><code>AsyncAssistantsWithRawResponse(assistants: AsyncAssistants)\n</code></pre> <p>Methods:</p> Name Description <code>files</code> <p>Attributes:</p> Name Type Description <code>create</code> <code>delete</code> <code>list</code> <code>retrieve</code> <code>update</code>"},{"location":"reference/resources/beta/assistants/assistants/#src.openai.resources.beta.assistants.assistants.AsyncAssistantsWithRawResponse.create","title":"create  <code>instance-attribute</code>","text":"<pre><code>create = async_to_raw_response_wrapper(create)\n</code></pre>"},{"location":"reference/resources/beta/assistants/assistants/#src.openai.resources.beta.assistants.assistants.AsyncAssistantsWithRawResponse.delete","title":"delete  <code>instance-attribute</code>","text":"<pre><code>delete = async_to_raw_response_wrapper(delete)\n</code></pre>"},{"location":"reference/resources/beta/assistants/assistants/#src.openai.resources.beta.assistants.assistants.AsyncAssistantsWithRawResponse.list","title":"list  <code>instance-attribute</code>","text":"<pre><code>list = async_to_raw_response_wrapper(list)\n</code></pre>"},{"location":"reference/resources/beta/assistants/assistants/#src.openai.resources.beta.assistants.assistants.AsyncAssistantsWithRawResponse.retrieve","title":"retrieve  <code>instance-attribute</code>","text":"<pre><code>retrieve = async_to_raw_response_wrapper(retrieve)\n</code></pre>"},{"location":"reference/resources/beta/assistants/assistants/#src.openai.resources.beta.assistants.assistants.AsyncAssistantsWithRawResponse.update","title":"update  <code>instance-attribute</code>","text":"<pre><code>update = async_to_raw_response_wrapper(update)\n</code></pre>"},{"location":"reference/resources/beta/assistants/assistants/#src.openai.resources.beta.assistants.assistants.AsyncAssistantsWithRawResponse.files","title":"files","text":"<pre><code>files() -&gt; AsyncFilesWithRawResponse\n</code></pre>"},{"location":"reference/resources/beta/assistants/assistants/#src.openai.resources.beta.assistants.assistants.AsyncAssistantsWithStreamingResponse","title":"AsyncAssistantsWithStreamingResponse","text":"<pre><code>AsyncAssistantsWithStreamingResponse(\n    assistants: AsyncAssistants,\n)\n</code></pre> <p>Methods:</p> Name Description <code>files</code> <p>Attributes:</p> Name Type Description <code>create</code> <code>delete</code> <code>list</code> <code>retrieve</code> <code>update</code>"},{"location":"reference/resources/beta/assistants/assistants/#src.openai.resources.beta.assistants.assistants.AsyncAssistantsWithStreamingResponse.create","title":"create  <code>instance-attribute</code>","text":"<pre><code>create = async_to_streamed_response_wrapper(create)\n</code></pre>"},{"location":"reference/resources/beta/assistants/assistants/#src.openai.resources.beta.assistants.assistants.AsyncAssistantsWithStreamingResponse.delete","title":"delete  <code>instance-attribute</code>","text":"<pre><code>delete = async_to_streamed_response_wrapper(delete)\n</code></pre>"},{"location":"reference/resources/beta/assistants/assistants/#src.openai.resources.beta.assistants.assistants.AsyncAssistantsWithStreamingResponse.list","title":"list  <code>instance-attribute</code>","text":"<pre><code>list = async_to_streamed_response_wrapper(list)\n</code></pre>"},{"location":"reference/resources/beta/assistants/assistants/#src.openai.resources.beta.assistants.assistants.AsyncAssistantsWithStreamingResponse.retrieve","title":"retrieve  <code>instance-attribute</code>","text":"<pre><code>retrieve = async_to_streamed_response_wrapper(retrieve)\n</code></pre>"},{"location":"reference/resources/beta/assistants/assistants/#src.openai.resources.beta.assistants.assistants.AsyncAssistantsWithStreamingResponse.update","title":"update  <code>instance-attribute</code>","text":"<pre><code>update = async_to_streamed_response_wrapper(update)\n</code></pre>"},{"location":"reference/resources/beta/assistants/assistants/#src.openai.resources.beta.assistants.assistants.AsyncAssistantsWithStreamingResponse.files","title":"files","text":"<pre><code>files() -&gt; AsyncFilesWithStreamingResponse\n</code></pre>"},{"location":"reference/resources/beta/assistants/files/","title":"files","text":"<p>Classes:</p> Name Description <code>AsyncFiles</code> <code>AsyncFilesWithRawResponse</code> <code>AsyncFilesWithStreamingResponse</code> <code>Files</code> <code>FilesWithRawResponse</code> <code>FilesWithStreamingResponse</code>"},{"location":"reference/resources/beta/assistants/files/#src.openai.resources.beta.assistants.files.AsyncFiles","title":"AsyncFiles","text":"<pre><code>AsyncFiles(client: AsyncOpenAI)\n</code></pre> <p>Methods:</p> Name Description <code>create</code> <p>Create an assistant file by attaching a</p> <code>delete</code> <p>Delete an assistant file.</p> <code>list</code> <p>Returns a list of assistant files.</p> <code>retrieve</code> <p>Retrieves an AssistantFile.</p> <code>with_raw_response</code> <code>with_streaming_response</code>"},{"location":"reference/resources/beta/assistants/files/#src.openai.resources.beta.assistants.files.AsyncFiles.create","title":"create  <code>async</code>","text":"<pre><code>create(\n    assistant_id: str,\n    *,\n    file_id: str,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; AssistantFile\n</code></pre> <p>Create an assistant file by attaching a File to an assistant.</p> <p>Parameters:</p> Name Type Description Default <code>file_id</code> <code>str</code> <p>A File ID (with   <code>purpose=\"assistants\"</code>) that the assistant should use. Useful for tools like   <code>retrieval</code> and <code>code_interpreter</code> that can access files.</p> required <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/beta/assistants/files/#src.openai.resources.beta.assistants.files.AsyncFiles.delete","title":"delete  <code>async</code>","text":"<pre><code>delete(\n    file_id: str,\n    *,\n    assistant_id: str,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; FileDeleteResponse\n</code></pre> <p>Delete an assistant file.</p> <p>Parameters:</p> Name Type Description Default <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/beta/assistants/files/#src.openai.resources.beta.assistants.files.AsyncFiles.list","title":"list","text":"<pre><code>list(\n    assistant_id: str,\n    *,\n    after: str | NotGiven = NOT_GIVEN,\n    before: str | NotGiven = NOT_GIVEN,\n    limit: int | NotGiven = NOT_GIVEN,\n    order: Literal[\"asc\", \"desc\"] | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; AsyncPaginator[\n    AssistantFile, AsyncCursorPage[AssistantFile]\n]\n</code></pre> <p>Returns a list of assistant files.</p> <p>Parameters:</p> Name Type Description Default <code>after</code> <code>str | NotGiven</code> <p>A cursor for use in pagination. <code>after</code> is an object ID that defines your place   in the list. For instance, if you make a list request and receive 100 objects,   ending with obj_foo, your subsequent call can include after=obj_foo in order to   fetch the next page of the list.</p> <code>NOT_GIVEN</code> <code>before</code> <code>str | NotGiven</code> <p>A cursor for use in pagination. <code>before</code> is an object ID that defines your place   in the list. For instance, if you make a list request and receive 100 objects,   ending with obj_foo, your subsequent call can include before=obj_foo in order to   fetch the previous page of the list.</p> <code>NOT_GIVEN</code> <code>limit</code> <code>int | NotGiven</code> <p>A limit on the number of objects to be returned. Limit can range between 1 and   100, and the default is 20.</p> <code>NOT_GIVEN</code> <code>order</code> <code>Literal['asc', 'desc'] | NotGiven</code> <p>Sort order by the <code>created_at</code> timestamp of the objects. <code>asc</code> for ascending   order and <code>desc</code> for descending order.</p> <code>NOT_GIVEN</code> <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/beta/assistants/files/#src.openai.resources.beta.assistants.files.AsyncFiles.retrieve","title":"retrieve  <code>async</code>","text":"<pre><code>retrieve(\n    file_id: str,\n    *,\n    assistant_id: str,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; AssistantFile\n</code></pre> <p>Retrieves an AssistantFile.</p> <p>Parameters:</p> Name Type Description Default <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/beta/assistants/files/#src.openai.resources.beta.assistants.files.AsyncFiles.with_raw_response","title":"with_raw_response","text":"<pre><code>with_raw_response() -&gt; AsyncFilesWithRawResponse\n</code></pre>"},{"location":"reference/resources/beta/assistants/files/#src.openai.resources.beta.assistants.files.AsyncFiles.with_streaming_response","title":"with_streaming_response","text":"<pre><code>with_streaming_response() -&gt; (\n    AsyncFilesWithStreamingResponse\n)\n</code></pre>"},{"location":"reference/resources/beta/assistants/files/#src.openai.resources.beta.assistants.files.AsyncFilesWithRawResponse","title":"AsyncFilesWithRawResponse","text":"<pre><code>AsyncFilesWithRawResponse(files: AsyncFiles)\n</code></pre> <p>Attributes:</p> Name Type Description <code>create</code> <code>delete</code> <code>list</code> <code>retrieve</code>"},{"location":"reference/resources/beta/assistants/files/#src.openai.resources.beta.assistants.files.AsyncFilesWithRawResponse.create","title":"create  <code>instance-attribute</code>","text":"<pre><code>create = async_to_raw_response_wrapper(create)\n</code></pre>"},{"location":"reference/resources/beta/assistants/files/#src.openai.resources.beta.assistants.files.AsyncFilesWithRawResponse.delete","title":"delete  <code>instance-attribute</code>","text":"<pre><code>delete = async_to_raw_response_wrapper(delete)\n</code></pre>"},{"location":"reference/resources/beta/assistants/files/#src.openai.resources.beta.assistants.files.AsyncFilesWithRawResponse.list","title":"list  <code>instance-attribute</code>","text":"<pre><code>list = async_to_raw_response_wrapper(list)\n</code></pre>"},{"location":"reference/resources/beta/assistants/files/#src.openai.resources.beta.assistants.files.AsyncFilesWithRawResponse.retrieve","title":"retrieve  <code>instance-attribute</code>","text":"<pre><code>retrieve = async_to_raw_response_wrapper(retrieve)\n</code></pre>"},{"location":"reference/resources/beta/assistants/files/#src.openai.resources.beta.assistants.files.AsyncFilesWithStreamingResponse","title":"AsyncFilesWithStreamingResponse","text":"<pre><code>AsyncFilesWithStreamingResponse(files: AsyncFiles)\n</code></pre> <p>Attributes:</p> Name Type Description <code>create</code> <code>delete</code> <code>list</code> <code>retrieve</code>"},{"location":"reference/resources/beta/assistants/files/#src.openai.resources.beta.assistants.files.AsyncFilesWithStreamingResponse.create","title":"create  <code>instance-attribute</code>","text":"<pre><code>create = async_to_streamed_response_wrapper(create)\n</code></pre>"},{"location":"reference/resources/beta/assistants/files/#src.openai.resources.beta.assistants.files.AsyncFilesWithStreamingResponse.delete","title":"delete  <code>instance-attribute</code>","text":"<pre><code>delete = async_to_streamed_response_wrapper(delete)\n</code></pre>"},{"location":"reference/resources/beta/assistants/files/#src.openai.resources.beta.assistants.files.AsyncFilesWithStreamingResponse.list","title":"list  <code>instance-attribute</code>","text":"<pre><code>list = async_to_streamed_response_wrapper(list)\n</code></pre>"},{"location":"reference/resources/beta/assistants/files/#src.openai.resources.beta.assistants.files.AsyncFilesWithStreamingResponse.retrieve","title":"retrieve  <code>instance-attribute</code>","text":"<pre><code>retrieve = async_to_streamed_response_wrapper(retrieve)\n</code></pre>"},{"location":"reference/resources/beta/assistants/files/#src.openai.resources.beta.assistants.files.Files","title":"Files","text":"<pre><code>Files(client: OpenAI)\n</code></pre> <p>Methods:</p> Name Description <code>create</code> <p>Create an assistant file by attaching a</p> <code>delete</code> <p>Delete an assistant file.</p> <code>list</code> <p>Returns a list of assistant files.</p> <code>retrieve</code> <p>Retrieves an AssistantFile.</p> <code>with_raw_response</code> <code>with_streaming_response</code>"},{"location":"reference/resources/beta/assistants/files/#src.openai.resources.beta.assistants.files.Files.create","title":"create","text":"<pre><code>create(\n    assistant_id: str,\n    *,\n    file_id: str,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; AssistantFile\n</code></pre> <p>Create an assistant file by attaching a File to an assistant.</p> <p>Parameters:</p> Name Type Description Default <code>file_id</code> <code>str</code> <p>A File ID (with   <code>purpose=\"assistants\"</code>) that the assistant should use. Useful for tools like   <code>retrieval</code> and <code>code_interpreter</code> that can access files.</p> required <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/beta/assistants/files/#src.openai.resources.beta.assistants.files.Files.delete","title":"delete","text":"<pre><code>delete(\n    file_id: str,\n    *,\n    assistant_id: str,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; FileDeleteResponse\n</code></pre> <p>Delete an assistant file.</p> <p>Parameters:</p> Name Type Description Default <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/beta/assistants/files/#src.openai.resources.beta.assistants.files.Files.list","title":"list","text":"<pre><code>list(\n    assistant_id: str,\n    *,\n    after: str | NotGiven = NOT_GIVEN,\n    before: str | NotGiven = NOT_GIVEN,\n    limit: int | NotGiven = NOT_GIVEN,\n    order: Literal[\"asc\", \"desc\"] | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; SyncCursorPage[AssistantFile]\n</code></pre> <p>Returns a list of assistant files.</p> <p>Parameters:</p> Name Type Description Default <code>after</code> <code>str | NotGiven</code> <p>A cursor for use in pagination. <code>after</code> is an object ID that defines your place   in the list. For instance, if you make a list request and receive 100 objects,   ending with obj_foo, your subsequent call can include after=obj_foo in order to   fetch the next page of the list.</p> <code>NOT_GIVEN</code> <code>before</code> <code>str | NotGiven</code> <p>A cursor for use in pagination. <code>before</code> is an object ID that defines your place   in the list. For instance, if you make a list request and receive 100 objects,   ending with obj_foo, your subsequent call can include before=obj_foo in order to   fetch the previous page of the list.</p> <code>NOT_GIVEN</code> <code>limit</code> <code>int | NotGiven</code> <p>A limit on the number of objects to be returned. Limit can range between 1 and   100, and the default is 20.</p> <code>NOT_GIVEN</code> <code>order</code> <code>Literal['asc', 'desc'] | NotGiven</code> <p>Sort order by the <code>created_at</code> timestamp of the objects. <code>asc</code> for ascending   order and <code>desc</code> for descending order.</p> <code>NOT_GIVEN</code> <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/beta/assistants/files/#src.openai.resources.beta.assistants.files.Files.retrieve","title":"retrieve","text":"<pre><code>retrieve(\n    file_id: str,\n    *,\n    assistant_id: str,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; AssistantFile\n</code></pre> <p>Retrieves an AssistantFile.</p> <p>Parameters:</p> Name Type Description Default <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/beta/assistants/files/#src.openai.resources.beta.assistants.files.Files.with_raw_response","title":"with_raw_response","text":"<pre><code>with_raw_response() -&gt; FilesWithRawResponse\n</code></pre>"},{"location":"reference/resources/beta/assistants/files/#src.openai.resources.beta.assistants.files.Files.with_streaming_response","title":"with_streaming_response","text":"<pre><code>with_streaming_response() -&gt; FilesWithStreamingResponse\n</code></pre>"},{"location":"reference/resources/beta/assistants/files/#src.openai.resources.beta.assistants.files.FilesWithRawResponse","title":"FilesWithRawResponse","text":"<pre><code>FilesWithRawResponse(files: Files)\n</code></pre> <p>Attributes:</p> Name Type Description <code>create</code> <code>delete</code> <code>list</code> <code>retrieve</code>"},{"location":"reference/resources/beta/assistants/files/#src.openai.resources.beta.assistants.files.FilesWithRawResponse.create","title":"create  <code>instance-attribute</code>","text":"<pre><code>create = to_raw_response_wrapper(create)\n</code></pre>"},{"location":"reference/resources/beta/assistants/files/#src.openai.resources.beta.assistants.files.FilesWithRawResponse.delete","title":"delete  <code>instance-attribute</code>","text":"<pre><code>delete = to_raw_response_wrapper(delete)\n</code></pre>"},{"location":"reference/resources/beta/assistants/files/#src.openai.resources.beta.assistants.files.FilesWithRawResponse.list","title":"list  <code>instance-attribute</code>","text":"<pre><code>list = to_raw_response_wrapper(list)\n</code></pre>"},{"location":"reference/resources/beta/assistants/files/#src.openai.resources.beta.assistants.files.FilesWithRawResponse.retrieve","title":"retrieve  <code>instance-attribute</code>","text":"<pre><code>retrieve = to_raw_response_wrapper(retrieve)\n</code></pre>"},{"location":"reference/resources/beta/assistants/files/#src.openai.resources.beta.assistants.files.FilesWithStreamingResponse","title":"FilesWithStreamingResponse","text":"<pre><code>FilesWithStreamingResponse(files: Files)\n</code></pre> <p>Attributes:</p> Name Type Description <code>create</code> <code>delete</code> <code>list</code> <code>retrieve</code>"},{"location":"reference/resources/beta/assistants/files/#src.openai.resources.beta.assistants.files.FilesWithStreamingResponse.create","title":"create  <code>instance-attribute</code>","text":"<pre><code>create = to_streamed_response_wrapper(create)\n</code></pre>"},{"location":"reference/resources/beta/assistants/files/#src.openai.resources.beta.assistants.files.FilesWithStreamingResponse.delete","title":"delete  <code>instance-attribute</code>","text":"<pre><code>delete = to_streamed_response_wrapper(delete)\n</code></pre>"},{"location":"reference/resources/beta/assistants/files/#src.openai.resources.beta.assistants.files.FilesWithStreamingResponse.list","title":"list  <code>instance-attribute</code>","text":"<pre><code>list = to_streamed_response_wrapper(list)\n</code></pre>"},{"location":"reference/resources/beta/assistants/files/#src.openai.resources.beta.assistants.files.FilesWithStreamingResponse.retrieve","title":"retrieve  <code>instance-attribute</code>","text":"<pre><code>retrieve = to_streamed_response_wrapper(retrieve)\n</code></pre>"},{"location":"reference/resources/beta/threads/","title":"Index","text":"<p>Modules:</p> Name Description <code>messages</code> <code>runs</code> <code>threads</code> <p>The <code>threads</code> module facilitates the creation, retrieval, update, deletion, and execution of Threads. Threads represent a series of messages or interactions with an assistant and support a conversational context or a sequence of operations.</p> <p>Classes:</p> Name Description <code>AsyncMessages</code> <code>AsyncMessagesWithRawResponse</code> <code>AsyncMessagesWithStreamingResponse</code> <code>AsyncRuns</code> <code>AsyncRunsWithRawResponse</code> <code>AsyncRunsWithStreamingResponse</code> <code>AsyncThreads</code> <code>AsyncThreadsWithRawResponse</code> <code>AsyncThreadsWithStreamingResponse</code> <code>Messages</code> <code>MessagesWithRawResponse</code> <code>MessagesWithStreamingResponse</code> <code>Runs</code> <code>RunsWithRawResponse</code> <code>RunsWithStreamingResponse</code> <code>Threads</code> <code>ThreadsWithRawResponse</code> <code>ThreadsWithStreamingResponse</code>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.AsyncMessages","title":"AsyncMessages","text":"<pre><code>AsyncMessages(client: AsyncOpenAI)\n</code></pre> <p>Methods:</p> Name Description <code>create</code> <p>Create a message.</p> <code>files</code> <code>list</code> <p>Returns a list of messages for a given thread.</p> <code>retrieve</code> <p>Retrieve a message.</p> <code>update</code> <p>Modifies a message.</p> <code>with_raw_response</code> <code>with_streaming_response</code>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.AsyncMessages.create","title":"create  <code>async</code>","text":"<pre><code>create(\n    thread_id: str,\n    *,\n    content: str,\n    role: Literal[\"user\"],\n    file_ids: List[str] | NotGiven = NOT_GIVEN,\n    metadata: Optional[object] | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; ThreadMessage\n</code></pre> <p>Create a message.</p> <p>Parameters:</p> Name Type Description Default <code>content</code> <code>str</code> <p>The content of the message.</p> required <code>role</code> <code>Literal['user']</code> <p>The role of the entity that is creating the message. Currently only <code>user</code> is   supported.</p> required <code>file_ids</code> <code>List[str] | NotGiven</code> <p>A list of File IDs that   the message should use. There can be a maximum of 10 files attached to a   message. Useful for tools like <code>retrieval</code> and <code>code_interpreter</code> that can   access and use files.</p> <code>NOT_GIVEN</code> <code>metadata</code> <code>Optional[object] | NotGiven</code> <p>Set of 16 key-value pairs that can be attached to an object. This can be useful   for storing additional information about the object in a structured format. Keys   can be a maximum of 64 characters long and values can be a maxium of 512   characters long.</p> <code>NOT_GIVEN</code> <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.AsyncMessages.files","title":"files","text":"<pre><code>files() -&gt; AsyncFiles\n</code></pre>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.AsyncMessages.list","title":"list","text":"<pre><code>list(\n    thread_id: str,\n    *,\n    after: str | NotGiven = NOT_GIVEN,\n    before: str | NotGiven = NOT_GIVEN,\n    limit: int | NotGiven = NOT_GIVEN,\n    order: Literal[\"asc\", \"desc\"] | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; AsyncPaginator[\n    ThreadMessage, AsyncCursorPage[ThreadMessage]\n]\n</code></pre> <p>Returns a list of messages for a given thread.</p> <p>Parameters:</p> Name Type Description Default <code>after</code> <code>str | NotGiven</code> <p>A cursor for use in pagination. <code>after</code> is an object ID that defines your place   in the list. For instance, if you make a list request and receive 100 objects,   ending with obj_foo, your subsequent call can include after=obj_foo in order to   fetch the next page of the list.</p> <code>NOT_GIVEN</code> <code>before</code> <code>str | NotGiven</code> <p>A cursor for use in pagination. <code>before</code> is an object ID that defines your place   in the list. For instance, if you make a list request and receive 100 objects,   ending with obj_foo, your subsequent call can include before=obj_foo in order to   fetch the previous page of the list.</p> <code>NOT_GIVEN</code> <code>limit</code> <code>int | NotGiven</code> <p>A limit on the number of objects to be returned. Limit can range between 1 and   100, and the default is 20.</p> <code>NOT_GIVEN</code> <code>order</code> <code>Literal['asc', 'desc'] | NotGiven</code> <p>Sort order by the <code>created_at</code> timestamp of the objects. <code>asc</code> for ascending   order and <code>desc</code> for descending order.</p> <code>NOT_GIVEN</code> <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.AsyncMessages.retrieve","title":"retrieve  <code>async</code>","text":"<pre><code>retrieve(\n    message_id: str,\n    *,\n    thread_id: str,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; ThreadMessage\n</code></pre> <p>Retrieve a message.</p> <p>Parameters:</p> Name Type Description Default <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.AsyncMessages.update","title":"update  <code>async</code>","text":"<pre><code>update(\n    message_id: str,\n    *,\n    thread_id: str,\n    metadata: Optional[object] | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; ThreadMessage\n</code></pre> <p>Modifies a message.</p> <p>Parameters:</p> Name Type Description Default <code>metadata</code> <code>Optional[object] | NotGiven</code> <p>Set of 16 key-value pairs that can be attached to an object. This can be useful   for storing additional information about the object in a structured format. Keys   can be a maximum of 64 characters long and values can be a maxium of 512   characters long.</p> <code>NOT_GIVEN</code> <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.AsyncMessages.with_raw_response","title":"with_raw_response","text":"<pre><code>with_raw_response() -&gt; AsyncMessagesWithRawResponse\n</code></pre>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.AsyncMessages.with_streaming_response","title":"with_streaming_response","text":"<pre><code>with_streaming_response() -&gt; (\n    AsyncMessagesWithStreamingResponse\n)\n</code></pre>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.AsyncMessagesWithRawResponse","title":"AsyncMessagesWithRawResponse","text":"<pre><code>AsyncMessagesWithRawResponse(messages: AsyncMessages)\n</code></pre> <p>Methods:</p> Name Description <code>files</code> <p>Attributes:</p> Name Type Description <code>create</code> <code>list</code> <code>retrieve</code> <code>update</code>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.AsyncMessagesWithRawResponse.create","title":"create  <code>instance-attribute</code>","text":"<pre><code>create = async_to_raw_response_wrapper(create)\n</code></pre>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.AsyncMessagesWithRawResponse.list","title":"list  <code>instance-attribute</code>","text":"<pre><code>list = async_to_raw_response_wrapper(list)\n</code></pre>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.AsyncMessagesWithRawResponse.retrieve","title":"retrieve  <code>instance-attribute</code>","text":"<pre><code>retrieve = async_to_raw_response_wrapper(retrieve)\n</code></pre>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.AsyncMessagesWithRawResponse.update","title":"update  <code>instance-attribute</code>","text":"<pre><code>update = async_to_raw_response_wrapper(update)\n</code></pre>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.AsyncMessagesWithRawResponse.files","title":"files","text":"<pre><code>files() -&gt; AsyncFilesWithRawResponse\n</code></pre>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.AsyncMessagesWithStreamingResponse","title":"AsyncMessagesWithStreamingResponse","text":"<pre><code>AsyncMessagesWithStreamingResponse(messages: AsyncMessages)\n</code></pre> <p>Methods:</p> Name Description <code>files</code> <p>Attributes:</p> Name Type Description <code>create</code> <code>list</code> <code>retrieve</code> <code>update</code>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.AsyncMessagesWithStreamingResponse.create","title":"create  <code>instance-attribute</code>","text":"<pre><code>create = async_to_streamed_response_wrapper(create)\n</code></pre>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.AsyncMessagesWithStreamingResponse.list","title":"list  <code>instance-attribute</code>","text":"<pre><code>list = async_to_streamed_response_wrapper(list)\n</code></pre>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.AsyncMessagesWithStreamingResponse.retrieve","title":"retrieve  <code>instance-attribute</code>","text":"<pre><code>retrieve = async_to_streamed_response_wrapper(retrieve)\n</code></pre>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.AsyncMessagesWithStreamingResponse.update","title":"update  <code>instance-attribute</code>","text":"<pre><code>update = async_to_streamed_response_wrapper(update)\n</code></pre>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.AsyncMessagesWithStreamingResponse.files","title":"files","text":"<pre><code>files() -&gt; AsyncFilesWithStreamingResponse\n</code></pre>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.AsyncRuns","title":"AsyncRuns","text":"<pre><code>AsyncRuns(client: AsyncOpenAI)\n</code></pre> <p>Methods:</p> Name Description <code>cancel</code> <p>Cancels a run that is <code>in_progress</code>.</p> <code>create</code> <p>Create a run.</p> <code>list</code> <p>Returns a list of runs belonging to a thread.</p> <code>retrieve</code> <p>Retrieves a run.</p> <code>steps</code> <code>submit_tool_outputs</code> <p>When a run has the <code>status: \"requires_action\"</code> and <code>required_action.type</code> is</p> <code>update</code> <p>Modifies a run.</p> <code>with_raw_response</code> <code>with_streaming_response</code>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.AsyncRuns.cancel","title":"cancel  <code>async</code>","text":"<pre><code>cancel(\n    run_id: str,\n    *,\n    thread_id: str,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; Run\n</code></pre> <p>Cancels a run that is <code>in_progress</code>.</p> <p>Parameters:</p> Name Type Description Default <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.AsyncRuns.create","title":"create  <code>async</code>","text":"<pre><code>create(\n    thread_id: str,\n    *,\n    assistant_id: str,\n    additional_instructions: (\n        Optional[str] | NotGiven\n    ) = NOT_GIVEN,\n    instructions: Optional[str] | NotGiven = NOT_GIVEN,\n    metadata: Optional[object] | NotGiven = NOT_GIVEN,\n    model: Optional[str] | NotGiven = NOT_GIVEN,\n    tools: Optional[Iterable[Tool]] | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; Run\n</code></pre> <p>Create a run.</p> <p>Parameters:</p> Name Type Description Default <code>assistant_id</code> <code>str</code> <p>The ID of the   assistant to use to   execute this run.</p> required <code>additional_instructions</code> <code>Optional[str] | NotGiven</code> <p>Appends additional instructions at the end of the instructions for the run. This   is useful for modifying the behavior on a per-run basis without overriding other   instructions.</p> <code>NOT_GIVEN</code> <code>instructions</code> <code>Optional[str] | NotGiven</code> <p>Overrides the   instructions   of the assistant. This is useful for modifying the behavior on a per-run basis.</p> <code>NOT_GIVEN</code> <code>metadata</code> <code>Optional[object] | NotGiven</code> <p>Set of 16 key-value pairs that can be attached to an object. This can be useful   for storing additional information about the object in a structured format. Keys   can be a maximum of 64 characters long and values can be a maxium of 512   characters long.</p> <code>NOT_GIVEN</code> <code>model</code> <code>Optional[str] | NotGiven</code> <p>The ID of the Model to   be used to execute this run. If a value is provided here, it will override the   model associated with the assistant. If not, the model associated with the   assistant will be used.</p> <code>NOT_GIVEN</code> <code>tools</code> <code>Optional[Iterable[Tool]] | NotGiven</code> <p>Override the tools the assistant can use for this run. This is useful for   modifying the behavior on a per-run basis.</p> <code>NOT_GIVEN</code> <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.AsyncRuns.list","title":"list","text":"<pre><code>list(\n    thread_id: str,\n    *,\n    after: str | NotGiven = NOT_GIVEN,\n    before: str | NotGiven = NOT_GIVEN,\n    limit: int | NotGiven = NOT_GIVEN,\n    order: Literal[\"asc\", \"desc\"] | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; AsyncPaginator[Run, AsyncCursorPage[Run]]\n</code></pre> <p>Returns a list of runs belonging to a thread.</p> <p>Parameters:</p> Name Type Description Default <code>after</code> <code>str | NotGiven</code> <p>A cursor for use in pagination. <code>after</code> is an object ID that defines your place   in the list. For instance, if you make a list request and receive 100 objects,   ending with obj_foo, your subsequent call can include after=obj_foo in order to   fetch the next page of the list.</p> <code>NOT_GIVEN</code> <code>before</code> <code>str | NotGiven</code> <p>A cursor for use in pagination. <code>before</code> is an object ID that defines your place   in the list. For instance, if you make a list request and receive 100 objects,   ending with obj_foo, your subsequent call can include before=obj_foo in order to   fetch the previous page of the list.</p> <code>NOT_GIVEN</code> <code>limit</code> <code>int | NotGiven</code> <p>A limit on the number of objects to be returned. Limit can range between 1 and   100, and the default is 20.</p> <code>NOT_GIVEN</code> <code>order</code> <code>Literal['asc', 'desc'] | NotGiven</code> <p>Sort order by the <code>created_at</code> timestamp of the objects. <code>asc</code> for ascending   order and <code>desc</code> for descending order.</p> <code>NOT_GIVEN</code> <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.AsyncRuns.retrieve","title":"retrieve  <code>async</code>","text":"<pre><code>retrieve(\n    run_id: str,\n    *,\n    thread_id: str,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; Run\n</code></pre> <p>Retrieves a run.</p> <p>Parameters:</p> Name Type Description Default <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.AsyncRuns.steps","title":"steps","text":"<pre><code>steps() -&gt; AsyncSteps\n</code></pre>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.AsyncRuns.submit_tool_outputs","title":"submit_tool_outputs  <code>async</code>","text":"<pre><code>submit_tool_outputs(\n    run_id: str,\n    *,\n    thread_id: str,\n    tool_outputs: Iterable[ToolOutput],\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; Run\n</code></pre> <p>When a run has the <code>status: \"requires_action\"</code> and <code>required_action.type</code> is <code>submit_tool_outputs</code>, this endpoint can be used to submit the outputs from the tool calls once they're all completed. All outputs must be submitted in a single request.</p> <p>Parameters:</p> Name Type Description Default <code>tool_outputs</code> <code>Iterable[ToolOutput]</code> <p>A list of tools for which the outputs are being submitted.</p> required <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.AsyncRuns.update","title":"update  <code>async</code>","text":"<pre><code>update(\n    run_id: str,\n    *,\n    thread_id: str,\n    metadata: Optional[object] | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; Run\n</code></pre> <p>Modifies a run.</p> <p>Parameters:</p> Name Type Description Default <code>metadata</code> <code>Optional[object] | NotGiven</code> <p>Set of 16 key-value pairs that can be attached to an object. This can be useful   for storing additional information about the object in a structured format. Keys   can be a maximum of 64 characters long and values can be a maxium of 512   characters long.</p> <code>NOT_GIVEN</code> <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.AsyncRuns.with_raw_response","title":"with_raw_response","text":"<pre><code>with_raw_response() -&gt; AsyncRunsWithRawResponse\n</code></pre>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.AsyncRuns.with_streaming_response","title":"with_streaming_response","text":"<pre><code>with_streaming_response() -&gt; AsyncRunsWithStreamingResponse\n</code></pre>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.AsyncRunsWithRawResponse","title":"AsyncRunsWithRawResponse","text":"<pre><code>AsyncRunsWithRawResponse(runs: AsyncRuns)\n</code></pre> <p>Methods:</p> Name Description <code>steps</code> <p>Attributes:</p> Name Type Description <code>cancel</code> <code>create</code> <code>list</code> <code>retrieve</code> <code>submit_tool_outputs</code> <code>update</code>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.AsyncRunsWithRawResponse.cancel","title":"cancel  <code>instance-attribute</code>","text":"<pre><code>cancel = async_to_raw_response_wrapper(cancel)\n</code></pre>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.AsyncRunsWithRawResponse.create","title":"create  <code>instance-attribute</code>","text":"<pre><code>create = async_to_raw_response_wrapper(create)\n</code></pre>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.AsyncRunsWithRawResponse.list","title":"list  <code>instance-attribute</code>","text":"<pre><code>list = async_to_raw_response_wrapper(list)\n</code></pre>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.AsyncRunsWithRawResponse.retrieve","title":"retrieve  <code>instance-attribute</code>","text":"<pre><code>retrieve = async_to_raw_response_wrapper(retrieve)\n</code></pre>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.AsyncRunsWithRawResponse.submit_tool_outputs","title":"submit_tool_outputs  <code>instance-attribute</code>","text":"<pre><code>submit_tool_outputs = async_to_raw_response_wrapper(\n    submit_tool_outputs\n)\n</code></pre>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.AsyncRunsWithRawResponse.update","title":"update  <code>instance-attribute</code>","text":"<pre><code>update = async_to_raw_response_wrapper(update)\n</code></pre>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.AsyncRunsWithRawResponse.steps","title":"steps","text":"<pre><code>steps() -&gt; AsyncStepsWithRawResponse\n</code></pre>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.AsyncRunsWithStreamingResponse","title":"AsyncRunsWithStreamingResponse","text":"<pre><code>AsyncRunsWithStreamingResponse(runs: AsyncRuns)\n</code></pre> <p>Methods:</p> Name Description <code>steps</code> <p>Attributes:</p> Name Type Description <code>cancel</code> <code>create</code> <code>list</code> <code>retrieve</code> <code>submit_tool_outputs</code> <code>update</code>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.AsyncRunsWithStreamingResponse.cancel","title":"cancel  <code>instance-attribute</code>","text":"<pre><code>cancel = async_to_streamed_response_wrapper(cancel)\n</code></pre>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.AsyncRunsWithStreamingResponse.create","title":"create  <code>instance-attribute</code>","text":"<pre><code>create = async_to_streamed_response_wrapper(create)\n</code></pre>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.AsyncRunsWithStreamingResponse.list","title":"list  <code>instance-attribute</code>","text":"<pre><code>list = async_to_streamed_response_wrapper(list)\n</code></pre>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.AsyncRunsWithStreamingResponse.retrieve","title":"retrieve  <code>instance-attribute</code>","text":"<pre><code>retrieve = async_to_streamed_response_wrapper(retrieve)\n</code></pre>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.AsyncRunsWithStreamingResponse.submit_tool_outputs","title":"submit_tool_outputs  <code>instance-attribute</code>","text":"<pre><code>submit_tool_outputs = async_to_streamed_response_wrapper(\n    submit_tool_outputs\n)\n</code></pre>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.AsyncRunsWithStreamingResponse.update","title":"update  <code>instance-attribute</code>","text":"<pre><code>update = async_to_streamed_response_wrapper(update)\n</code></pre>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.AsyncRunsWithStreamingResponse.steps","title":"steps","text":"<pre><code>steps() -&gt; AsyncStepsWithStreamingResponse\n</code></pre>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.AsyncThreads","title":"AsyncThreads","text":"<pre><code>AsyncThreads(client: AsyncOpenAI)\n</code></pre> <p>Methods:</p> Name Description <code>create</code> <p>Create a thread.</p> <code>create_and_run</code> <p>Create a thread and run it in one request.</p> <code>delete</code> <p>Delete a thread.</p> <code>messages</code> <code>retrieve</code> <p>Retrieves a thread.</p> <code>runs</code> <code>update</code> <p>Modifies a thread.</p> <code>with_raw_response</code> <code>with_streaming_response</code>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.AsyncThreads.create","title":"create  <code>async</code>","text":"<pre><code>create(\n    *,\n    messages: Iterable[Message] | NotGiven = NOT_GIVEN,\n    metadata: Optional[object] | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; Thread\n</code></pre> <p>Create a thread.</p> <p>Parameters:</p> Name Type Description Default <code>messages</code> <code>Iterable[Message] | NotGiven</code> <p>A list of messages to   start the thread with.</p> <code>NOT_GIVEN</code> <code>metadata</code> <code>Optional[object] | NotGiven</code> <p>Set of 16 key-value pairs that can be attached to an object. This can be useful   for storing additional information about the object in a structured format. Keys   can be a maximum of 64 characters long and values can be a maxium of 512   characters long.</p> <code>NOT_GIVEN</code> <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.AsyncThreads.create_and_run","title":"create_and_run  <code>async</code>","text":"<pre><code>create_and_run(\n    *,\n    assistant_id: str,\n    instructions: Optional[str] | NotGiven = NOT_GIVEN,\n    metadata: Optional[object] | NotGiven = NOT_GIVEN,\n    model: Optional[str] | NotGiven = NOT_GIVEN,\n    thread: Thread | NotGiven = NOT_GIVEN,\n    tools: Optional[Iterable[Tool]] | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; Run\n</code></pre> <p>Create a thread and run it in one request.</p> <p>Parameters:</p> Name Type Description Default <code>assistant_id</code> <code>str</code> <p>The ID of the   assistant to use to   execute this run.</p> required <code>instructions</code> <code>Optional[str] | NotGiven</code> <p>Override the default system message of the assistant. This is useful for   modifying the behavior on a per-run basis.</p> <code>NOT_GIVEN</code> <code>metadata</code> <code>Optional[object] | NotGiven</code> <p>Set of 16 key-value pairs that can be attached to an object. This can be useful   for storing additional information about the object in a structured format. Keys   can be a maximum of 64 characters long and values can be a maxium of 512   characters long.</p> <code>NOT_GIVEN</code> <code>model</code> <code>Optional[str] | NotGiven</code> <p>The ID of the Model to   be used to execute this run. If a value is provided here, it will override the   model associated with the assistant. If not, the model associated with the   assistant will be used.</p> <code>NOT_GIVEN</code> <code>thread</code> <code>Thread | NotGiven</code> <p>If no thread is provided, an empty thread will be created.</p> <code>NOT_GIVEN</code> <code>tools</code> <code>Optional[Iterable[Tool]] | NotGiven</code> <p>Override the tools the assistant can use for this run. This is useful for   modifying the behavior on a per-run basis.</p> <code>NOT_GIVEN</code> <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.AsyncThreads.delete","title":"delete  <code>async</code>","text":"<pre><code>delete(\n    thread_id: str,\n    *,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; ThreadDeleted\n</code></pre> <p>Delete a thread.</p> <p>Parameters:</p> Name Type Description Default <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.AsyncThreads.messages","title":"messages","text":"<pre><code>messages() -&gt; AsyncMessages\n</code></pre>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.AsyncThreads.retrieve","title":"retrieve  <code>async</code>","text":"<pre><code>retrieve(\n    thread_id: str,\n    *,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; Thread\n</code></pre> <p>Retrieves a thread.</p> <p>Parameters:</p> Name Type Description Default <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.AsyncThreads.runs","title":"runs","text":"<pre><code>runs() -&gt; AsyncRuns\n</code></pre>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.AsyncThreads.update","title":"update  <code>async</code>","text":"<pre><code>update(\n    thread_id: str,\n    *,\n    metadata: Optional[object] | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; Thread\n</code></pre> <p>Modifies a thread.</p> <p>Parameters:</p> Name Type Description Default <code>metadata</code> <code>Optional[object] | NotGiven</code> <p>Set of 16 key-value pairs that can be attached to an object. This can be useful   for storing additional information about the object in a structured format. Keys   can be a maximum of 64 characters long and values can be a maxium of 512   characters long.</p> <code>NOT_GIVEN</code> <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.AsyncThreads.with_raw_response","title":"with_raw_response","text":"<pre><code>with_raw_response() -&gt; AsyncThreadsWithRawResponse\n</code></pre>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.AsyncThreads.with_streaming_response","title":"with_streaming_response","text":"<pre><code>with_streaming_response() -&gt; (\n    AsyncThreadsWithStreamingResponse\n)\n</code></pre>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.AsyncThreadsWithRawResponse","title":"AsyncThreadsWithRawResponse","text":"<pre><code>AsyncThreadsWithRawResponse(threads: AsyncThreads)\n</code></pre> <p>Methods:</p> Name Description <code>messages</code> <code>runs</code> <p>Attributes:</p> Name Type Description <code>create</code> <code>create_and_run</code> <code>delete</code> <code>retrieve</code> <code>update</code>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.AsyncThreadsWithRawResponse.create","title":"create  <code>instance-attribute</code>","text":"<pre><code>create = async_to_raw_response_wrapper(create)\n</code></pre>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.AsyncThreadsWithRawResponse.create_and_run","title":"create_and_run  <code>instance-attribute</code>","text":"<pre><code>create_and_run = async_to_raw_response_wrapper(\n    create_and_run\n)\n</code></pre>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.AsyncThreadsWithRawResponse.delete","title":"delete  <code>instance-attribute</code>","text":"<pre><code>delete = async_to_raw_response_wrapper(delete)\n</code></pre>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.AsyncThreadsWithRawResponse.retrieve","title":"retrieve  <code>instance-attribute</code>","text":"<pre><code>retrieve = async_to_raw_response_wrapper(retrieve)\n</code></pre>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.AsyncThreadsWithRawResponse.update","title":"update  <code>instance-attribute</code>","text":"<pre><code>update = async_to_raw_response_wrapper(update)\n</code></pre>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.AsyncThreadsWithRawResponse.messages","title":"messages","text":"<pre><code>messages() -&gt; AsyncMessagesWithRawResponse\n</code></pre>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.AsyncThreadsWithRawResponse.runs","title":"runs","text":"<pre><code>runs() -&gt; AsyncRunsWithRawResponse\n</code></pre>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.AsyncThreadsWithStreamingResponse","title":"AsyncThreadsWithStreamingResponse","text":"<pre><code>AsyncThreadsWithStreamingResponse(threads: AsyncThreads)\n</code></pre> <p>Methods:</p> Name Description <code>messages</code> <code>runs</code> <p>Attributes:</p> Name Type Description <code>create</code> <code>create_and_run</code> <code>delete</code> <code>retrieve</code> <code>update</code>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.AsyncThreadsWithStreamingResponse.create","title":"create  <code>instance-attribute</code>","text":"<pre><code>create = async_to_streamed_response_wrapper(create)\n</code></pre>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.AsyncThreadsWithStreamingResponse.create_and_run","title":"create_and_run  <code>instance-attribute</code>","text":"<pre><code>create_and_run = async_to_streamed_response_wrapper(\n    create_and_run\n)\n</code></pre>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.AsyncThreadsWithStreamingResponse.delete","title":"delete  <code>instance-attribute</code>","text":"<pre><code>delete = async_to_streamed_response_wrapper(delete)\n</code></pre>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.AsyncThreadsWithStreamingResponse.retrieve","title":"retrieve  <code>instance-attribute</code>","text":"<pre><code>retrieve = async_to_streamed_response_wrapper(retrieve)\n</code></pre>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.AsyncThreadsWithStreamingResponse.update","title":"update  <code>instance-attribute</code>","text":"<pre><code>update = async_to_streamed_response_wrapper(update)\n</code></pre>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.AsyncThreadsWithStreamingResponse.messages","title":"messages","text":"<pre><code>messages() -&gt; AsyncMessagesWithStreamingResponse\n</code></pre>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.AsyncThreadsWithStreamingResponse.runs","title":"runs","text":"<pre><code>runs() -&gt; AsyncRunsWithStreamingResponse\n</code></pre>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.Messages","title":"Messages","text":"<pre><code>Messages(client: OpenAI)\n</code></pre> <p>Methods:</p> Name Description <code>create</code> <p>Create a message.</p> <code>files</code> <code>list</code> <p>Returns a list of messages for a given thread.</p> <code>retrieve</code> <p>Retrieve a message.</p> <code>update</code> <p>Modifies a message.</p> <code>with_raw_response</code> <code>with_streaming_response</code>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.Messages.create","title":"create","text":"<pre><code>create(\n    thread_id: str,\n    *,\n    content: str,\n    role: Literal[\"user\"],\n    file_ids: List[str] | NotGiven = NOT_GIVEN,\n    metadata: Optional[object] | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; ThreadMessage\n</code></pre> <p>Create a message.</p> <p>Parameters:</p> Name Type Description Default <code>content</code> <code>str</code> <p>The content of the message.</p> required <code>role</code> <code>Literal['user']</code> <p>The role of the entity that is creating the message. Currently only <code>user</code> is   supported.</p> required <code>file_ids</code> <code>List[str] | NotGiven</code> <p>A list of File IDs that   the message should use. There can be a maximum of 10 files attached to a   message. Useful for tools like <code>retrieval</code> and <code>code_interpreter</code> that can   access and use files.</p> <code>NOT_GIVEN</code> <code>metadata</code> <code>Optional[object] | NotGiven</code> <p>Set of 16 key-value pairs that can be attached to an object. This can be useful   for storing additional information about the object in a structured format. Keys   can be a maximum of 64 characters long and values can be a maxium of 512   characters long.</p> <code>NOT_GIVEN</code> <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.Messages.files","title":"files","text":"<pre><code>files() -&gt; Files\n</code></pre>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.Messages.list","title":"list","text":"<pre><code>list(\n    thread_id: str,\n    *,\n    after: str | NotGiven = NOT_GIVEN,\n    before: str | NotGiven = NOT_GIVEN,\n    limit: int | NotGiven = NOT_GIVEN,\n    order: Literal[\"asc\", \"desc\"] | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; SyncCursorPage[ThreadMessage]\n</code></pre> <p>Returns a list of messages for a given thread.</p> <p>Parameters:</p> Name Type Description Default <code>after</code> <code>str | NotGiven</code> <p>A cursor for use in pagination. <code>after</code> is an object ID that defines your place   in the list. For instance, if you make a list request and receive 100 objects,   ending with obj_foo, your subsequent call can include after=obj_foo in order to   fetch the next page of the list.</p> <code>NOT_GIVEN</code> <code>before</code> <code>str | NotGiven</code> <p>A cursor for use in pagination. <code>before</code> is an object ID that defines your place   in the list. For instance, if you make a list request and receive 100 objects,   ending with obj_foo, your subsequent call can include before=obj_foo in order to   fetch the previous page of the list.</p> <code>NOT_GIVEN</code> <code>limit</code> <code>int | NotGiven</code> <p>A limit on the number of objects to be returned. Limit can range between 1 and   100, and the default is 20.</p> <code>NOT_GIVEN</code> <code>order</code> <code>Literal['asc', 'desc'] | NotGiven</code> <p>Sort order by the <code>created_at</code> timestamp of the objects. <code>asc</code> for ascending   order and <code>desc</code> for descending order.</p> <code>NOT_GIVEN</code> <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.Messages.retrieve","title":"retrieve","text":"<pre><code>retrieve(\n    message_id: str,\n    *,\n    thread_id: str,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; ThreadMessage\n</code></pre> <p>Retrieve a message.</p> <p>Parameters:</p> Name Type Description Default <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.Messages.update","title":"update","text":"<pre><code>update(\n    message_id: str,\n    *,\n    thread_id: str,\n    metadata: Optional[object] | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; ThreadMessage\n</code></pre> <p>Modifies a message.</p> <p>Parameters:</p> Name Type Description Default <code>metadata</code> <code>Optional[object] | NotGiven</code> <p>Set of 16 key-value pairs that can be attached to an object. This can be useful   for storing additional information about the object in a structured format. Keys   can be a maximum of 64 characters long and values can be a maxium of 512   characters long.</p> <code>NOT_GIVEN</code> <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.Messages.with_raw_response","title":"with_raw_response","text":"<pre><code>with_raw_response() -&gt; MessagesWithRawResponse\n</code></pre>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.Messages.with_streaming_response","title":"with_streaming_response","text":"<pre><code>with_streaming_response() -&gt; MessagesWithStreamingResponse\n</code></pre>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.MessagesWithRawResponse","title":"MessagesWithRawResponse","text":"<pre><code>MessagesWithRawResponse(messages: Messages)\n</code></pre> <p>Methods:</p> Name Description <code>files</code> <p>Attributes:</p> Name Type Description <code>create</code> <code>list</code> <code>retrieve</code> <code>update</code>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.MessagesWithRawResponse.create","title":"create  <code>instance-attribute</code>","text":"<pre><code>create = to_raw_response_wrapper(create)\n</code></pre>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.MessagesWithRawResponse.list","title":"list  <code>instance-attribute</code>","text":"<pre><code>list = to_raw_response_wrapper(list)\n</code></pre>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.MessagesWithRawResponse.retrieve","title":"retrieve  <code>instance-attribute</code>","text":"<pre><code>retrieve = to_raw_response_wrapper(retrieve)\n</code></pre>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.MessagesWithRawResponse.update","title":"update  <code>instance-attribute</code>","text":"<pre><code>update = to_raw_response_wrapper(update)\n</code></pre>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.MessagesWithRawResponse.files","title":"files","text":"<pre><code>files() -&gt; FilesWithRawResponse\n</code></pre>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.MessagesWithStreamingResponse","title":"MessagesWithStreamingResponse","text":"<pre><code>MessagesWithStreamingResponse(messages: Messages)\n</code></pre> <p>Methods:</p> Name Description <code>files</code> <p>Attributes:</p> Name Type Description <code>create</code> <code>list</code> <code>retrieve</code> <code>update</code>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.MessagesWithStreamingResponse.create","title":"create  <code>instance-attribute</code>","text":"<pre><code>create = to_streamed_response_wrapper(create)\n</code></pre>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.MessagesWithStreamingResponse.list","title":"list  <code>instance-attribute</code>","text":"<pre><code>list = to_streamed_response_wrapper(list)\n</code></pre>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.MessagesWithStreamingResponse.retrieve","title":"retrieve  <code>instance-attribute</code>","text":"<pre><code>retrieve = to_streamed_response_wrapper(retrieve)\n</code></pre>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.MessagesWithStreamingResponse.update","title":"update  <code>instance-attribute</code>","text":"<pre><code>update = to_streamed_response_wrapper(update)\n</code></pre>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.MessagesWithStreamingResponse.files","title":"files","text":"<pre><code>files() -&gt; FilesWithStreamingResponse\n</code></pre>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.Runs","title":"Runs","text":"<pre><code>Runs(client: OpenAI)\n</code></pre> <p>Methods:</p> Name Description <code>cancel</code> <p>Cancels a run that is <code>in_progress</code>.</p> <code>create</code> <p>Create a run.</p> <code>list</code> <p>Returns a list of runs belonging to a thread.</p> <code>retrieve</code> <p>Retrieves a run.</p> <code>steps</code> <code>submit_tool_outputs</code> <p>When a run has the <code>status: \"requires_action\"</code> and <code>required_action.type</code> is</p> <code>update</code> <p>Modifies a run.</p> <code>with_raw_response</code> <code>with_streaming_response</code>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.Runs.cancel","title":"cancel","text":"<pre><code>cancel(\n    run_id: str,\n    *,\n    thread_id: str,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; Run\n</code></pre> <p>Cancels a run that is <code>in_progress</code>.</p> <p>Parameters:</p> Name Type Description Default <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.Runs.create","title":"create","text":"<pre><code>create(\n    thread_id: str,\n    *,\n    assistant_id: str,\n    additional_instructions: (\n        Optional[str] | NotGiven\n    ) = NOT_GIVEN,\n    instructions: Optional[str] | NotGiven = NOT_GIVEN,\n    metadata: Optional[object] | NotGiven = NOT_GIVEN,\n    model: Optional[str] | NotGiven = NOT_GIVEN,\n    tools: Optional[Iterable[Tool]] | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; Run\n</code></pre> <p>Create a run.</p> <p>Parameters:</p> Name Type Description Default <code>assistant_id</code> <code>str</code> <p>The ID of the   assistant to use to   execute this run.</p> required <code>additional_instructions</code> <code>Optional[str] | NotGiven</code> <p>Appends additional instructions at the end of the instructions for the run. This   is useful for modifying the behavior on a per-run basis without overriding other   instructions.</p> <code>NOT_GIVEN</code> <code>instructions</code> <code>Optional[str] | NotGiven</code> <p>Overrides the   instructions   of the assistant. This is useful for modifying the behavior on a per-run basis.</p> <code>NOT_GIVEN</code> <code>metadata</code> <code>Optional[object] | NotGiven</code> <p>Set of 16 key-value pairs that can be attached to an object. This can be useful   for storing additional information about the object in a structured format. Keys   can be a maximum of 64 characters long and values can be a maxium of 512   characters long.</p> <code>NOT_GIVEN</code> <code>model</code> <code>Optional[str] | NotGiven</code> <p>The ID of the Model to   be used to execute this run. If a value is provided here, it will override the   model associated with the assistant. If not, the model associated with the   assistant will be used.</p> <code>NOT_GIVEN</code> <code>tools</code> <code>Optional[Iterable[Tool]] | NotGiven</code> <p>Override the tools the assistant can use for this run. This is useful for   modifying the behavior on a per-run basis.</p> <code>NOT_GIVEN</code> <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.Runs.list","title":"list","text":"<pre><code>list(\n    thread_id: str,\n    *,\n    after: str | NotGiven = NOT_GIVEN,\n    before: str | NotGiven = NOT_GIVEN,\n    limit: int | NotGiven = NOT_GIVEN,\n    order: Literal[\"asc\", \"desc\"] | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; SyncCursorPage[Run]\n</code></pre> <p>Returns a list of runs belonging to a thread.</p> <p>Parameters:</p> Name Type Description Default <code>after</code> <code>str | NotGiven</code> <p>A cursor for use in pagination. <code>after</code> is an object ID that defines your place   in the list. For instance, if you make a list request and receive 100 objects,   ending with obj_foo, your subsequent call can include after=obj_foo in order to   fetch the next page of the list.</p> <code>NOT_GIVEN</code> <code>before</code> <code>str | NotGiven</code> <p>A cursor for use in pagination. <code>before</code> is an object ID that defines your place   in the list. For instance, if you make a list request and receive 100 objects,   ending with obj_foo, your subsequent call can include before=obj_foo in order to   fetch the previous page of the list.</p> <code>NOT_GIVEN</code> <code>limit</code> <code>int | NotGiven</code> <p>A limit on the number of objects to be returned. Limit can range between 1 and   100, and the default is 20.</p> <code>NOT_GIVEN</code> <code>order</code> <code>Literal['asc', 'desc'] | NotGiven</code> <p>Sort order by the <code>created_at</code> timestamp of the objects. <code>asc</code> for ascending   order and <code>desc</code> for descending order.</p> <code>NOT_GIVEN</code> <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.Runs.retrieve","title":"retrieve","text":"<pre><code>retrieve(\n    run_id: str,\n    *,\n    thread_id: str,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; Run\n</code></pre> <p>Retrieves a run.</p> <p>Parameters:</p> Name Type Description Default <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.Runs.steps","title":"steps","text":"<pre><code>steps() -&gt; Steps\n</code></pre>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.Runs.submit_tool_outputs","title":"submit_tool_outputs","text":"<pre><code>submit_tool_outputs(\n    run_id: str,\n    *,\n    thread_id: str,\n    tool_outputs: Iterable[ToolOutput],\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; Run\n</code></pre> <p>When a run has the <code>status: \"requires_action\"</code> and <code>required_action.type</code> is <code>submit_tool_outputs</code>, this endpoint can be used to submit the outputs from the tool calls once they're all completed. All outputs must be submitted in a single request.</p> <p>Parameters:</p> Name Type Description Default <code>tool_outputs</code> <code>Iterable[ToolOutput]</code> <p>A list of tools for which the outputs are being submitted.</p> required <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.Runs.update","title":"update","text":"<pre><code>update(\n    run_id: str,\n    *,\n    thread_id: str,\n    metadata: Optional[object] | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; Run\n</code></pre> <p>Modifies a run.</p> <p>Parameters:</p> Name Type Description Default <code>metadata</code> <code>Optional[object] | NotGiven</code> <p>Set of 16 key-value pairs that can be attached to an object. This can be useful   for storing additional information about the object in a structured format. Keys   can be a maximum of 64 characters long and values can be a maxium of 512   characters long.</p> <code>NOT_GIVEN</code> <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.Runs.with_raw_response","title":"with_raw_response","text":"<pre><code>with_raw_response() -&gt; RunsWithRawResponse\n</code></pre>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.Runs.with_streaming_response","title":"with_streaming_response","text":"<pre><code>with_streaming_response() -&gt; RunsWithStreamingResponse\n</code></pre>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.RunsWithRawResponse","title":"RunsWithRawResponse","text":"<pre><code>RunsWithRawResponse(runs: Runs)\n</code></pre> <p>Methods:</p> Name Description <code>steps</code> <p>Attributes:</p> Name Type Description <code>cancel</code> <code>create</code> <code>list</code> <code>retrieve</code> <code>submit_tool_outputs</code> <code>update</code>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.RunsWithRawResponse.cancel","title":"cancel  <code>instance-attribute</code>","text":"<pre><code>cancel = to_raw_response_wrapper(cancel)\n</code></pre>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.RunsWithRawResponse.create","title":"create  <code>instance-attribute</code>","text":"<pre><code>create = to_raw_response_wrapper(create)\n</code></pre>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.RunsWithRawResponse.list","title":"list  <code>instance-attribute</code>","text":"<pre><code>list = to_raw_response_wrapper(list)\n</code></pre>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.RunsWithRawResponse.retrieve","title":"retrieve  <code>instance-attribute</code>","text":"<pre><code>retrieve = to_raw_response_wrapper(retrieve)\n</code></pre>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.RunsWithRawResponse.submit_tool_outputs","title":"submit_tool_outputs  <code>instance-attribute</code>","text":"<pre><code>submit_tool_outputs = to_raw_response_wrapper(\n    submit_tool_outputs\n)\n</code></pre>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.RunsWithRawResponse.update","title":"update  <code>instance-attribute</code>","text":"<pre><code>update = to_raw_response_wrapper(update)\n</code></pre>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.RunsWithRawResponse.steps","title":"steps","text":"<pre><code>steps() -&gt; StepsWithRawResponse\n</code></pre>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.RunsWithStreamingResponse","title":"RunsWithStreamingResponse","text":"<pre><code>RunsWithStreamingResponse(runs: Runs)\n</code></pre> <p>Methods:</p> Name Description <code>steps</code> <p>Attributes:</p> Name Type Description <code>cancel</code> <code>create</code> <code>list</code> <code>retrieve</code> <code>submit_tool_outputs</code> <code>update</code>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.RunsWithStreamingResponse.cancel","title":"cancel  <code>instance-attribute</code>","text":"<pre><code>cancel = to_streamed_response_wrapper(cancel)\n</code></pre>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.RunsWithStreamingResponse.create","title":"create  <code>instance-attribute</code>","text":"<pre><code>create = to_streamed_response_wrapper(create)\n</code></pre>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.RunsWithStreamingResponse.list","title":"list  <code>instance-attribute</code>","text":"<pre><code>list = to_streamed_response_wrapper(list)\n</code></pre>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.RunsWithStreamingResponse.retrieve","title":"retrieve  <code>instance-attribute</code>","text":"<pre><code>retrieve = to_streamed_response_wrapper(retrieve)\n</code></pre>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.RunsWithStreamingResponse.submit_tool_outputs","title":"submit_tool_outputs  <code>instance-attribute</code>","text":"<pre><code>submit_tool_outputs = to_streamed_response_wrapper(\n    submit_tool_outputs\n)\n</code></pre>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.RunsWithStreamingResponse.update","title":"update  <code>instance-attribute</code>","text":"<pre><code>update = to_streamed_response_wrapper(update)\n</code></pre>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.RunsWithStreamingResponse.steps","title":"steps","text":"<pre><code>steps() -&gt; StepsWithStreamingResponse\n</code></pre>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.Threads","title":"Threads","text":"<pre><code>Threads(client: OpenAI)\n</code></pre> <p>Methods:</p> Name Description <code>create</code> <p>Create a thread.</p> <code>create_and_run</code> <p>Create a thread and run it in one request.</p> <code>delete</code> <p>Delete a thread.</p> <code>messages</code> <code>retrieve</code> <p>Retrieves a thread.</p> <code>runs</code> <code>update</code> <p>Modifies a thread.</p> <code>with_raw_response</code> <code>with_streaming_response</code>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.Threads.create","title":"create","text":"<pre><code>create(\n    *,\n    messages: Iterable[Message] | NotGiven = NOT_GIVEN,\n    metadata: Optional[object] | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; Thread\n</code></pre> <p>Create a thread.</p> <p>Parameters:</p> Name Type Description Default <code>messages</code> <code>Iterable[Message] | NotGiven</code> <p>A list of messages to   start the thread with.</p> <code>NOT_GIVEN</code> <code>metadata</code> <code>Optional[object] | NotGiven</code> <p>Set of 16 key-value pairs that can be attached to an object. This can be useful   for storing additional information about the object in a structured format. Keys   can be a maximum of 64 characters long and values can be a maxium of 512   characters long.</p> <code>NOT_GIVEN</code> <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.Threads.create_and_run","title":"create_and_run","text":"<pre><code>create_and_run(\n    *,\n    assistant_id: str,\n    instructions: Optional[str] | NotGiven = NOT_GIVEN,\n    metadata: Optional[object] | NotGiven = NOT_GIVEN,\n    model: Optional[str] | NotGiven = NOT_GIVEN,\n    thread: Thread | NotGiven = NOT_GIVEN,\n    tools: Optional[Iterable[Tool]] | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; Run\n</code></pre> <p>Create a thread and run it in one request.</p> <p>Parameters:</p> Name Type Description Default <code>assistant_id</code> <code>str</code> <p>The ID of the   assistant to use to   execute this run.</p> required <code>instructions</code> <code>Optional[str] | NotGiven</code> <p>Override the default system message of the assistant. This is useful for   modifying the behavior on a per-run basis.</p> <code>NOT_GIVEN</code> <code>metadata</code> <code>Optional[object] | NotGiven</code> <p>Set of 16 key-value pairs that can be attached to an object. This can be useful   for storing additional information about the object in a structured format. Keys   can be a maximum of 64 characters long and values can be a maxium of 512   characters long.</p> <code>NOT_GIVEN</code> <code>model</code> <code>Optional[str] | NotGiven</code> <p>The ID of the Model to   be used to execute this run. If a value is provided here, it will override the   model associated with the assistant. If not, the model associated with the   assistant will be used.</p> <code>NOT_GIVEN</code> <code>thread</code> <code>Thread | NotGiven</code> <p>If no thread is provided, an empty thread will be created.</p> <code>NOT_GIVEN</code> <code>tools</code> <code>Optional[Iterable[Tool]] | NotGiven</code> <p>Override the tools the assistant can use for this run. This is useful for   modifying the behavior on a per-run basis.</p> <code>NOT_GIVEN</code> <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.Threads.delete","title":"delete","text":"<pre><code>delete(\n    thread_id: str,\n    *,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; ThreadDeleted\n</code></pre> <p>Delete a thread.</p> <p>Parameters:</p> Name Type Description Default <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.Threads.messages","title":"messages","text":"<pre><code>messages() -&gt; Messages\n</code></pre>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.Threads.retrieve","title":"retrieve","text":"<pre><code>retrieve(\n    thread_id: str,\n    *,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; Thread\n</code></pre> <p>Retrieves a thread.</p> <p>Parameters:</p> Name Type Description Default <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.Threads.runs","title":"runs","text":"<pre><code>runs() -&gt; Runs\n</code></pre>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.Threads.update","title":"update","text":"<pre><code>update(\n    thread_id: str,\n    *,\n    metadata: Optional[object] | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; Thread\n</code></pre> <p>Modifies a thread.</p> <p>Parameters:</p> Name Type Description Default <code>metadata</code> <code>Optional[object] | NotGiven</code> <p>Set of 16 key-value pairs that can be attached to an object. This can be useful   for storing additional information about the object in a structured format. Keys   can be a maximum of 64 characters long and values can be a maxium of 512   characters long.</p> <code>NOT_GIVEN</code> <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.Threads.with_raw_response","title":"with_raw_response","text":"<pre><code>with_raw_response() -&gt; ThreadsWithRawResponse\n</code></pre>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.Threads.with_streaming_response","title":"with_streaming_response","text":"<pre><code>with_streaming_response() -&gt; ThreadsWithStreamingResponse\n</code></pre>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.ThreadsWithRawResponse","title":"ThreadsWithRawResponse","text":"<pre><code>ThreadsWithRawResponse(threads: Threads)\n</code></pre> <p>Methods:</p> Name Description <code>messages</code> <code>runs</code> <p>Attributes:</p> Name Type Description <code>create</code> <code>create_and_run</code> <code>delete</code> <code>retrieve</code> <code>update</code>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.ThreadsWithRawResponse.create","title":"create  <code>instance-attribute</code>","text":"<pre><code>create = to_raw_response_wrapper(create)\n</code></pre>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.ThreadsWithRawResponse.create_and_run","title":"create_and_run  <code>instance-attribute</code>","text":"<pre><code>create_and_run = to_raw_response_wrapper(create_and_run)\n</code></pre>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.ThreadsWithRawResponse.delete","title":"delete  <code>instance-attribute</code>","text":"<pre><code>delete = to_raw_response_wrapper(delete)\n</code></pre>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.ThreadsWithRawResponse.retrieve","title":"retrieve  <code>instance-attribute</code>","text":"<pre><code>retrieve = to_raw_response_wrapper(retrieve)\n</code></pre>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.ThreadsWithRawResponse.update","title":"update  <code>instance-attribute</code>","text":"<pre><code>update = to_raw_response_wrapper(update)\n</code></pre>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.ThreadsWithRawResponse.messages","title":"messages","text":"<pre><code>messages() -&gt; MessagesWithRawResponse\n</code></pre>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.ThreadsWithRawResponse.runs","title":"runs","text":"<pre><code>runs() -&gt; RunsWithRawResponse\n</code></pre>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.ThreadsWithStreamingResponse","title":"ThreadsWithStreamingResponse","text":"<pre><code>ThreadsWithStreamingResponse(threads: Threads)\n</code></pre> <p>Methods:</p> Name Description <code>messages</code> <code>runs</code> <p>Attributes:</p> Name Type Description <code>create</code> <code>create_and_run</code> <code>delete</code> <code>retrieve</code> <code>update</code>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.ThreadsWithStreamingResponse.create","title":"create  <code>instance-attribute</code>","text":"<pre><code>create = to_streamed_response_wrapper(create)\n</code></pre>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.ThreadsWithStreamingResponse.create_and_run","title":"create_and_run  <code>instance-attribute</code>","text":"<pre><code>create_and_run = to_streamed_response_wrapper(\n    create_and_run\n)\n</code></pre>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.ThreadsWithStreamingResponse.delete","title":"delete  <code>instance-attribute</code>","text":"<pre><code>delete = to_streamed_response_wrapper(delete)\n</code></pre>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.ThreadsWithStreamingResponse.retrieve","title":"retrieve  <code>instance-attribute</code>","text":"<pre><code>retrieve = to_streamed_response_wrapper(retrieve)\n</code></pre>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.ThreadsWithStreamingResponse.update","title":"update  <code>instance-attribute</code>","text":"<pre><code>update = to_streamed_response_wrapper(update)\n</code></pre>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.ThreadsWithStreamingResponse.messages","title":"messages","text":"<pre><code>messages() -&gt; MessagesWithStreamingResponse\n</code></pre>"},{"location":"reference/resources/beta/threads/#src.openai.resources.beta.threads.ThreadsWithStreamingResponse.runs","title":"runs","text":"<pre><code>runs() -&gt; RunsWithStreamingResponse\n</code></pre>"},{"location":"reference/resources/beta/threads/threads/","title":"threads","text":"<p>The <code>threads</code> module facilitates the creation, retrieval, update, deletion, and execution of Threads. Threads represent a series of messages or interactions with an assistant and support a conversational context or a sequence of operations.</p> <p>Classes:</p> Name Description <code>AsyncThreads</code> <code>AsyncThreadsWithRawResponse</code> <code>AsyncThreadsWithStreamingResponse</code> <code>Threads</code> <code>ThreadsWithRawResponse</code> <code>ThreadsWithStreamingResponse</code>"},{"location":"reference/resources/beta/threads/threads/#src.openai.resources.beta.threads.threads.AsyncThreads","title":"AsyncThreads","text":"<pre><code>AsyncThreads(client: AsyncOpenAI)\n</code></pre> <p>Methods:</p> Name Description <code>create</code> <p>Create a thread.</p> <code>create_and_run</code> <p>Create a thread and run it in one request.</p> <code>delete</code> <p>Delete a thread.</p> <code>messages</code> <code>retrieve</code> <p>Retrieves a thread.</p> <code>runs</code> <code>update</code> <p>Modifies a thread.</p> <code>with_raw_response</code> <code>with_streaming_response</code>"},{"location":"reference/resources/beta/threads/threads/#src.openai.resources.beta.threads.threads.AsyncThreads.create","title":"create  <code>async</code>","text":"<pre><code>create(\n    *,\n    messages: Iterable[Message] | NotGiven = NOT_GIVEN,\n    metadata: Optional[object] | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; Thread\n</code></pre> <p>Create a thread.</p> <p>Parameters:</p> Name Type Description Default <code>messages</code> <code>Iterable[Message] | NotGiven</code> <p>A list of messages to   start the thread with.</p> <code>NOT_GIVEN</code> <code>metadata</code> <code>Optional[object] | NotGiven</code> <p>Set of 16 key-value pairs that can be attached to an object. This can be useful   for storing additional information about the object in a structured format. Keys   can be a maximum of 64 characters long and values can be a maxium of 512   characters long.</p> <code>NOT_GIVEN</code> <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/beta/threads/threads/#src.openai.resources.beta.threads.threads.AsyncThreads.create_and_run","title":"create_and_run  <code>async</code>","text":"<pre><code>create_and_run(\n    *,\n    assistant_id: str,\n    instructions: Optional[str] | NotGiven = NOT_GIVEN,\n    metadata: Optional[object] | NotGiven = NOT_GIVEN,\n    model: Optional[str] | NotGiven = NOT_GIVEN,\n    thread: Thread | NotGiven = NOT_GIVEN,\n    tools: Optional[Iterable[Tool]] | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; Run\n</code></pre> <p>Create a thread and run it in one request.</p> <p>Parameters:</p> Name Type Description Default <code>assistant_id</code> <code>str</code> <p>The ID of the   assistant to use to   execute this run.</p> required <code>instructions</code> <code>Optional[str] | NotGiven</code> <p>Override the default system message of the assistant. This is useful for   modifying the behavior on a per-run basis.</p> <code>NOT_GIVEN</code> <code>metadata</code> <code>Optional[object] | NotGiven</code> <p>Set of 16 key-value pairs that can be attached to an object. This can be useful   for storing additional information about the object in a structured format. Keys   can be a maximum of 64 characters long and values can be a maxium of 512   characters long.</p> <code>NOT_GIVEN</code> <code>model</code> <code>Optional[str] | NotGiven</code> <p>The ID of the Model to   be used to execute this run. If a value is provided here, it will override the   model associated with the assistant. If not, the model associated with the   assistant will be used.</p> <code>NOT_GIVEN</code> <code>thread</code> <code>Thread | NotGiven</code> <p>If no thread is provided, an empty thread will be created.</p> <code>NOT_GIVEN</code> <code>tools</code> <code>Optional[Iterable[Tool]] | NotGiven</code> <p>Override the tools the assistant can use for this run. This is useful for   modifying the behavior on a per-run basis.</p> <code>NOT_GIVEN</code> <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/beta/threads/threads/#src.openai.resources.beta.threads.threads.AsyncThreads.delete","title":"delete  <code>async</code>","text":"<pre><code>delete(\n    thread_id: str,\n    *,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; ThreadDeleted\n</code></pre> <p>Delete a thread.</p> <p>Parameters:</p> Name Type Description Default <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/beta/threads/threads/#src.openai.resources.beta.threads.threads.AsyncThreads.messages","title":"messages","text":"<pre><code>messages() -&gt; AsyncMessages\n</code></pre>"},{"location":"reference/resources/beta/threads/threads/#src.openai.resources.beta.threads.threads.AsyncThreads.retrieve","title":"retrieve  <code>async</code>","text":"<pre><code>retrieve(\n    thread_id: str,\n    *,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; Thread\n</code></pre> <p>Retrieves a thread.</p> <p>Parameters:</p> Name Type Description Default <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/beta/threads/threads/#src.openai.resources.beta.threads.threads.AsyncThreads.runs","title":"runs","text":"<pre><code>runs() -&gt; AsyncRuns\n</code></pre>"},{"location":"reference/resources/beta/threads/threads/#src.openai.resources.beta.threads.threads.AsyncThreads.update","title":"update  <code>async</code>","text":"<pre><code>update(\n    thread_id: str,\n    *,\n    metadata: Optional[object] | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; Thread\n</code></pre> <p>Modifies a thread.</p> <p>Parameters:</p> Name Type Description Default <code>metadata</code> <code>Optional[object] | NotGiven</code> <p>Set of 16 key-value pairs that can be attached to an object. This can be useful   for storing additional information about the object in a structured format. Keys   can be a maximum of 64 characters long and values can be a maxium of 512   characters long.</p> <code>NOT_GIVEN</code> <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/beta/threads/threads/#src.openai.resources.beta.threads.threads.AsyncThreads.with_raw_response","title":"with_raw_response","text":"<pre><code>with_raw_response() -&gt; AsyncThreadsWithRawResponse\n</code></pre>"},{"location":"reference/resources/beta/threads/threads/#src.openai.resources.beta.threads.threads.AsyncThreads.with_streaming_response","title":"with_streaming_response","text":"<pre><code>with_streaming_response() -&gt; (\n    AsyncThreadsWithStreamingResponse\n)\n</code></pre>"},{"location":"reference/resources/beta/threads/threads/#src.openai.resources.beta.threads.threads.AsyncThreadsWithRawResponse","title":"AsyncThreadsWithRawResponse","text":"<pre><code>AsyncThreadsWithRawResponse(threads: AsyncThreads)\n</code></pre> <p>Methods:</p> Name Description <code>messages</code> <code>runs</code> <p>Attributes:</p> Name Type Description <code>create</code> <code>create_and_run</code> <code>delete</code> <code>retrieve</code> <code>update</code>"},{"location":"reference/resources/beta/threads/threads/#src.openai.resources.beta.threads.threads.AsyncThreadsWithRawResponse.create","title":"create  <code>instance-attribute</code>","text":"<pre><code>create = async_to_raw_response_wrapper(create)\n</code></pre>"},{"location":"reference/resources/beta/threads/threads/#src.openai.resources.beta.threads.threads.AsyncThreadsWithRawResponse.create_and_run","title":"create_and_run  <code>instance-attribute</code>","text":"<pre><code>create_and_run = async_to_raw_response_wrapper(\n    create_and_run\n)\n</code></pre>"},{"location":"reference/resources/beta/threads/threads/#src.openai.resources.beta.threads.threads.AsyncThreadsWithRawResponse.delete","title":"delete  <code>instance-attribute</code>","text":"<pre><code>delete = async_to_raw_response_wrapper(delete)\n</code></pre>"},{"location":"reference/resources/beta/threads/threads/#src.openai.resources.beta.threads.threads.AsyncThreadsWithRawResponse.retrieve","title":"retrieve  <code>instance-attribute</code>","text":"<pre><code>retrieve = async_to_raw_response_wrapper(retrieve)\n</code></pre>"},{"location":"reference/resources/beta/threads/threads/#src.openai.resources.beta.threads.threads.AsyncThreadsWithRawResponse.update","title":"update  <code>instance-attribute</code>","text":"<pre><code>update = async_to_raw_response_wrapper(update)\n</code></pre>"},{"location":"reference/resources/beta/threads/threads/#src.openai.resources.beta.threads.threads.AsyncThreadsWithRawResponse.messages","title":"messages","text":"<pre><code>messages() -&gt; AsyncMessagesWithRawResponse\n</code></pre>"},{"location":"reference/resources/beta/threads/threads/#src.openai.resources.beta.threads.threads.AsyncThreadsWithRawResponse.runs","title":"runs","text":"<pre><code>runs() -&gt; AsyncRunsWithRawResponse\n</code></pre>"},{"location":"reference/resources/beta/threads/threads/#src.openai.resources.beta.threads.threads.AsyncThreadsWithStreamingResponse","title":"AsyncThreadsWithStreamingResponse","text":"<pre><code>AsyncThreadsWithStreamingResponse(threads: AsyncThreads)\n</code></pre> <p>Methods:</p> Name Description <code>messages</code> <code>runs</code> <p>Attributes:</p> Name Type Description <code>create</code> <code>create_and_run</code> <code>delete</code> <code>retrieve</code> <code>update</code>"},{"location":"reference/resources/beta/threads/threads/#src.openai.resources.beta.threads.threads.AsyncThreadsWithStreamingResponse.create","title":"create  <code>instance-attribute</code>","text":"<pre><code>create = async_to_streamed_response_wrapper(create)\n</code></pre>"},{"location":"reference/resources/beta/threads/threads/#src.openai.resources.beta.threads.threads.AsyncThreadsWithStreamingResponse.create_and_run","title":"create_and_run  <code>instance-attribute</code>","text":"<pre><code>create_and_run = async_to_streamed_response_wrapper(\n    create_and_run\n)\n</code></pre>"},{"location":"reference/resources/beta/threads/threads/#src.openai.resources.beta.threads.threads.AsyncThreadsWithStreamingResponse.delete","title":"delete  <code>instance-attribute</code>","text":"<pre><code>delete = async_to_streamed_response_wrapper(delete)\n</code></pre>"},{"location":"reference/resources/beta/threads/threads/#src.openai.resources.beta.threads.threads.AsyncThreadsWithStreamingResponse.retrieve","title":"retrieve  <code>instance-attribute</code>","text":"<pre><code>retrieve = async_to_streamed_response_wrapper(retrieve)\n</code></pre>"},{"location":"reference/resources/beta/threads/threads/#src.openai.resources.beta.threads.threads.AsyncThreadsWithStreamingResponse.update","title":"update  <code>instance-attribute</code>","text":"<pre><code>update = async_to_streamed_response_wrapper(update)\n</code></pre>"},{"location":"reference/resources/beta/threads/threads/#src.openai.resources.beta.threads.threads.AsyncThreadsWithStreamingResponse.messages","title":"messages","text":"<pre><code>messages() -&gt; AsyncMessagesWithStreamingResponse\n</code></pre>"},{"location":"reference/resources/beta/threads/threads/#src.openai.resources.beta.threads.threads.AsyncThreadsWithStreamingResponse.runs","title":"runs","text":"<pre><code>runs() -&gt; AsyncRunsWithStreamingResponse\n</code></pre>"},{"location":"reference/resources/beta/threads/threads/#src.openai.resources.beta.threads.threads.Threads","title":"Threads","text":"<pre><code>Threads(client: OpenAI)\n</code></pre> <p>Methods:</p> Name Description <code>create</code> <p>Create a thread.</p> <code>create_and_run</code> <p>Create a thread and run it in one request.</p> <code>delete</code> <p>Delete a thread.</p> <code>messages</code> <code>retrieve</code> <p>Retrieves a thread.</p> <code>runs</code> <code>update</code> <p>Modifies a thread.</p> <code>with_raw_response</code> <code>with_streaming_response</code>"},{"location":"reference/resources/beta/threads/threads/#src.openai.resources.beta.threads.threads.Threads.create","title":"create","text":"<pre><code>create(\n    *,\n    messages: Iterable[Message] | NotGiven = NOT_GIVEN,\n    metadata: Optional[object] | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; Thread\n</code></pre> <p>Create a thread.</p> <p>Parameters:</p> Name Type Description Default <code>messages</code> <code>Iterable[Message] | NotGiven</code> <p>A list of messages to   start the thread with.</p> <code>NOT_GIVEN</code> <code>metadata</code> <code>Optional[object] | NotGiven</code> <p>Set of 16 key-value pairs that can be attached to an object. This can be useful   for storing additional information about the object in a structured format. Keys   can be a maximum of 64 characters long and values can be a maxium of 512   characters long.</p> <code>NOT_GIVEN</code> <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/beta/threads/threads/#src.openai.resources.beta.threads.threads.Threads.create_and_run","title":"create_and_run","text":"<pre><code>create_and_run(\n    *,\n    assistant_id: str,\n    instructions: Optional[str] | NotGiven = NOT_GIVEN,\n    metadata: Optional[object] | NotGiven = NOT_GIVEN,\n    model: Optional[str] | NotGiven = NOT_GIVEN,\n    thread: Thread | NotGiven = NOT_GIVEN,\n    tools: Optional[Iterable[Tool]] | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; Run\n</code></pre> <p>Create a thread and run it in one request.</p> <p>Parameters:</p> Name Type Description Default <code>assistant_id</code> <code>str</code> <p>The ID of the   assistant to use to   execute this run.</p> required <code>instructions</code> <code>Optional[str] | NotGiven</code> <p>Override the default system message of the assistant. This is useful for   modifying the behavior on a per-run basis.</p> <code>NOT_GIVEN</code> <code>metadata</code> <code>Optional[object] | NotGiven</code> <p>Set of 16 key-value pairs that can be attached to an object. This can be useful   for storing additional information about the object in a structured format. Keys   can be a maximum of 64 characters long and values can be a maxium of 512   characters long.</p> <code>NOT_GIVEN</code> <code>model</code> <code>Optional[str] | NotGiven</code> <p>The ID of the Model to   be used to execute this run. If a value is provided here, it will override the   model associated with the assistant. If not, the model associated with the   assistant will be used.</p> <code>NOT_GIVEN</code> <code>thread</code> <code>Thread | NotGiven</code> <p>If no thread is provided, an empty thread will be created.</p> <code>NOT_GIVEN</code> <code>tools</code> <code>Optional[Iterable[Tool]] | NotGiven</code> <p>Override the tools the assistant can use for this run. This is useful for   modifying the behavior on a per-run basis.</p> <code>NOT_GIVEN</code> <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/beta/threads/threads/#src.openai.resources.beta.threads.threads.Threads.delete","title":"delete","text":"<pre><code>delete(\n    thread_id: str,\n    *,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; ThreadDeleted\n</code></pre> <p>Delete a thread.</p> <p>Parameters:</p> Name Type Description Default <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/beta/threads/threads/#src.openai.resources.beta.threads.threads.Threads.messages","title":"messages","text":"<pre><code>messages() -&gt; Messages\n</code></pre>"},{"location":"reference/resources/beta/threads/threads/#src.openai.resources.beta.threads.threads.Threads.retrieve","title":"retrieve","text":"<pre><code>retrieve(\n    thread_id: str,\n    *,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; Thread\n</code></pre> <p>Retrieves a thread.</p> <p>Parameters:</p> Name Type Description Default <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/beta/threads/threads/#src.openai.resources.beta.threads.threads.Threads.runs","title":"runs","text":"<pre><code>runs() -&gt; Runs\n</code></pre>"},{"location":"reference/resources/beta/threads/threads/#src.openai.resources.beta.threads.threads.Threads.update","title":"update","text":"<pre><code>update(\n    thread_id: str,\n    *,\n    metadata: Optional[object] | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; Thread\n</code></pre> <p>Modifies a thread.</p> <p>Parameters:</p> Name Type Description Default <code>metadata</code> <code>Optional[object] | NotGiven</code> <p>Set of 16 key-value pairs that can be attached to an object. This can be useful   for storing additional information about the object in a structured format. Keys   can be a maximum of 64 characters long and values can be a maxium of 512   characters long.</p> <code>NOT_GIVEN</code> <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/beta/threads/threads/#src.openai.resources.beta.threads.threads.Threads.with_raw_response","title":"with_raw_response","text":"<pre><code>with_raw_response() -&gt; ThreadsWithRawResponse\n</code></pre>"},{"location":"reference/resources/beta/threads/threads/#src.openai.resources.beta.threads.threads.Threads.with_streaming_response","title":"with_streaming_response","text":"<pre><code>with_streaming_response() -&gt; ThreadsWithStreamingResponse\n</code></pre>"},{"location":"reference/resources/beta/threads/threads/#src.openai.resources.beta.threads.threads.ThreadsWithRawResponse","title":"ThreadsWithRawResponse","text":"<pre><code>ThreadsWithRawResponse(threads: Threads)\n</code></pre> <p>Methods:</p> Name Description <code>messages</code> <code>runs</code> <p>Attributes:</p> Name Type Description <code>create</code> <code>create_and_run</code> <code>delete</code> <code>retrieve</code> <code>update</code>"},{"location":"reference/resources/beta/threads/threads/#src.openai.resources.beta.threads.threads.ThreadsWithRawResponse.create","title":"create  <code>instance-attribute</code>","text":"<pre><code>create = to_raw_response_wrapper(create)\n</code></pre>"},{"location":"reference/resources/beta/threads/threads/#src.openai.resources.beta.threads.threads.ThreadsWithRawResponse.create_and_run","title":"create_and_run  <code>instance-attribute</code>","text":"<pre><code>create_and_run = to_raw_response_wrapper(create_and_run)\n</code></pre>"},{"location":"reference/resources/beta/threads/threads/#src.openai.resources.beta.threads.threads.ThreadsWithRawResponse.delete","title":"delete  <code>instance-attribute</code>","text":"<pre><code>delete = to_raw_response_wrapper(delete)\n</code></pre>"},{"location":"reference/resources/beta/threads/threads/#src.openai.resources.beta.threads.threads.ThreadsWithRawResponse.retrieve","title":"retrieve  <code>instance-attribute</code>","text":"<pre><code>retrieve = to_raw_response_wrapper(retrieve)\n</code></pre>"},{"location":"reference/resources/beta/threads/threads/#src.openai.resources.beta.threads.threads.ThreadsWithRawResponse.update","title":"update  <code>instance-attribute</code>","text":"<pre><code>update = to_raw_response_wrapper(update)\n</code></pre>"},{"location":"reference/resources/beta/threads/threads/#src.openai.resources.beta.threads.threads.ThreadsWithRawResponse.messages","title":"messages","text":"<pre><code>messages() -&gt; MessagesWithRawResponse\n</code></pre>"},{"location":"reference/resources/beta/threads/threads/#src.openai.resources.beta.threads.threads.ThreadsWithRawResponse.runs","title":"runs","text":"<pre><code>runs() -&gt; RunsWithRawResponse\n</code></pre>"},{"location":"reference/resources/beta/threads/threads/#src.openai.resources.beta.threads.threads.ThreadsWithStreamingResponse","title":"ThreadsWithStreamingResponse","text":"<pre><code>ThreadsWithStreamingResponse(threads: Threads)\n</code></pre> <p>Methods:</p> Name Description <code>messages</code> <code>runs</code> <p>Attributes:</p> Name Type Description <code>create</code> <code>create_and_run</code> <code>delete</code> <code>retrieve</code> <code>update</code>"},{"location":"reference/resources/beta/threads/threads/#src.openai.resources.beta.threads.threads.ThreadsWithStreamingResponse.create","title":"create  <code>instance-attribute</code>","text":"<pre><code>create = to_streamed_response_wrapper(create)\n</code></pre>"},{"location":"reference/resources/beta/threads/threads/#src.openai.resources.beta.threads.threads.ThreadsWithStreamingResponse.create_and_run","title":"create_and_run  <code>instance-attribute</code>","text":"<pre><code>create_and_run = to_streamed_response_wrapper(\n    create_and_run\n)\n</code></pre>"},{"location":"reference/resources/beta/threads/threads/#src.openai.resources.beta.threads.threads.ThreadsWithStreamingResponse.delete","title":"delete  <code>instance-attribute</code>","text":"<pre><code>delete = to_streamed_response_wrapper(delete)\n</code></pre>"},{"location":"reference/resources/beta/threads/threads/#src.openai.resources.beta.threads.threads.ThreadsWithStreamingResponse.retrieve","title":"retrieve  <code>instance-attribute</code>","text":"<pre><code>retrieve = to_streamed_response_wrapper(retrieve)\n</code></pre>"},{"location":"reference/resources/beta/threads/threads/#src.openai.resources.beta.threads.threads.ThreadsWithStreamingResponse.update","title":"update  <code>instance-attribute</code>","text":"<pre><code>update = to_streamed_response_wrapper(update)\n</code></pre>"},{"location":"reference/resources/beta/threads/threads/#src.openai.resources.beta.threads.threads.ThreadsWithStreamingResponse.messages","title":"messages","text":"<pre><code>messages() -&gt; MessagesWithStreamingResponse\n</code></pre>"},{"location":"reference/resources/beta/threads/threads/#src.openai.resources.beta.threads.threads.ThreadsWithStreamingResponse.runs","title":"runs","text":"<pre><code>runs() -&gt; RunsWithStreamingResponse\n</code></pre>"},{"location":"reference/resources/beta/threads/messages/","title":"Index","text":"<p>Modules:</p> Name Description <code>files</code> <code>messages</code> <p>Classes:</p> Name Description <code>AsyncFiles</code> <code>AsyncFilesWithRawResponse</code> <code>AsyncFilesWithStreamingResponse</code> <code>AsyncMessages</code> <code>AsyncMessagesWithRawResponse</code> <code>AsyncMessagesWithStreamingResponse</code> <code>Files</code> <code>FilesWithRawResponse</code> <code>FilesWithStreamingResponse</code> <code>Messages</code> <code>MessagesWithRawResponse</code> <code>MessagesWithStreamingResponse</code>"},{"location":"reference/resources/beta/threads/messages/#src.openai.resources.beta.threads.messages.AsyncFiles","title":"AsyncFiles","text":"<pre><code>AsyncFiles(client: AsyncOpenAI)\n</code></pre> <p>Methods:</p> Name Description <code>list</code> <p>Returns a list of message files.</p> <code>retrieve</code> <p>Retrieves a message file.</p> <code>with_raw_response</code> <code>with_streaming_response</code>"},{"location":"reference/resources/beta/threads/messages/#src.openai.resources.beta.threads.messages.AsyncFiles.list","title":"list","text":"<pre><code>list(\n    message_id: str,\n    *,\n    thread_id: str,\n    after: str | NotGiven = NOT_GIVEN,\n    before: str | NotGiven = NOT_GIVEN,\n    limit: int | NotGiven = NOT_GIVEN,\n    order: Literal[\"asc\", \"desc\"] | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; AsyncPaginator[\n    MessageFile, AsyncCursorPage[MessageFile]\n]\n</code></pre> <p>Returns a list of message files.</p> <p>Parameters:</p> Name Type Description Default <code>after</code> <code>str | NotGiven</code> <p>A cursor for use in pagination.</p> <code>NOT_GIVEN</code> <p><code>after</code> is an object ID that defines your place       in the list. For instance, if you make a list request and receive 100 objects,       ending with obj_foo, your subsequent call can include after=obj_foo in order to       fetch the next page of the list.</p> <p>before: A cursor for use in pagination. <code>before</code> is an object ID that defines your place       in the list. For instance, if you make a list request and receive 100 objects,       ending with obj_foo, your subsequent call can include before=obj_foo in order to       fetch the previous page of the list.</p> <p>limit: A limit on the number of objects to be returned. Limit can range between 1 and       100, and the default is 20.</p> <p>order: Sort order by the <code>created_at</code> timestamp of the objects. <code>asc</code> for ascending       order and <code>desc</code> for descending order.</p> <p>extra_headers: Send extra headers</p> <p>extra_query: Add additional query parameters to the request</p> <p>extra_body: Add additional JSON properties to the request</p> <p>timeout: Override the client-level default timeout for this request, in seconds</p>"},{"location":"reference/resources/beta/threads/messages/#src.openai.resources.beta.threads.messages.AsyncFiles.retrieve","title":"retrieve  <code>async</code>","text":"<pre><code>retrieve(\n    file_id: str,\n    *,\n    thread_id: str,\n    message_id: str,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; MessageFile\n</code></pre> <p>Retrieves a message file.</p> <p>Parameters:</p> Name Type Description Default <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/beta/threads/messages/#src.openai.resources.beta.threads.messages.AsyncFiles.with_raw_response","title":"with_raw_response","text":"<pre><code>with_raw_response() -&gt; AsyncFilesWithRawResponse\n</code></pre>"},{"location":"reference/resources/beta/threads/messages/#src.openai.resources.beta.threads.messages.AsyncFiles.with_streaming_response","title":"with_streaming_response","text":"<pre><code>with_streaming_response() -&gt; (\n    AsyncFilesWithStreamingResponse\n)\n</code></pre>"},{"location":"reference/resources/beta/threads/messages/#src.openai.resources.beta.threads.messages.AsyncFilesWithRawResponse","title":"AsyncFilesWithRawResponse","text":"<pre><code>AsyncFilesWithRawResponse(files: AsyncFiles)\n</code></pre> <p>Attributes:</p> Name Type Description <code>list</code> <code>retrieve</code>"},{"location":"reference/resources/beta/threads/messages/#src.openai.resources.beta.threads.messages.AsyncFilesWithRawResponse.list","title":"list  <code>instance-attribute</code>","text":"<pre><code>list = async_to_raw_response_wrapper(list)\n</code></pre>"},{"location":"reference/resources/beta/threads/messages/#src.openai.resources.beta.threads.messages.AsyncFilesWithRawResponse.retrieve","title":"retrieve  <code>instance-attribute</code>","text":"<pre><code>retrieve = async_to_raw_response_wrapper(retrieve)\n</code></pre>"},{"location":"reference/resources/beta/threads/messages/#src.openai.resources.beta.threads.messages.AsyncFilesWithStreamingResponse","title":"AsyncFilesWithStreamingResponse","text":"<pre><code>AsyncFilesWithStreamingResponse(files: AsyncFiles)\n</code></pre> <p>Attributes:</p> Name Type Description <code>list</code> <code>retrieve</code>"},{"location":"reference/resources/beta/threads/messages/#src.openai.resources.beta.threads.messages.AsyncFilesWithStreamingResponse.list","title":"list  <code>instance-attribute</code>","text":"<pre><code>list = async_to_streamed_response_wrapper(list)\n</code></pre>"},{"location":"reference/resources/beta/threads/messages/#src.openai.resources.beta.threads.messages.AsyncFilesWithStreamingResponse.retrieve","title":"retrieve  <code>instance-attribute</code>","text":"<pre><code>retrieve = async_to_streamed_response_wrapper(retrieve)\n</code></pre>"},{"location":"reference/resources/beta/threads/messages/#src.openai.resources.beta.threads.messages.AsyncMessages","title":"AsyncMessages","text":"<pre><code>AsyncMessages(client: AsyncOpenAI)\n</code></pre> <p>Methods:</p> Name Description <code>create</code> <p>Create a message.</p> <code>files</code> <code>list</code> <p>Returns a list of messages for a given thread.</p> <code>retrieve</code> <p>Retrieve a message.</p> <code>update</code> <p>Modifies a message.</p> <code>with_raw_response</code> <code>with_streaming_response</code>"},{"location":"reference/resources/beta/threads/messages/#src.openai.resources.beta.threads.messages.AsyncMessages.create","title":"create  <code>async</code>","text":"<pre><code>create(\n    thread_id: str,\n    *,\n    content: str,\n    role: Literal[\"user\"],\n    file_ids: List[str] | NotGiven = NOT_GIVEN,\n    metadata: Optional[object] | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; ThreadMessage\n</code></pre> <p>Create a message.</p> <p>Parameters:</p> Name Type Description Default <code>content</code> <code>str</code> <p>The content of the message.</p> required <code>role</code> <code>Literal['user']</code> <p>The role of the entity that is creating the message. Currently only <code>user</code> is   supported.</p> required <code>file_ids</code> <code>List[str] | NotGiven</code> <p>A list of File IDs that   the message should use. There can be a maximum of 10 files attached to a   message. Useful for tools like <code>retrieval</code> and <code>code_interpreter</code> that can   access and use files.</p> <code>NOT_GIVEN</code> <code>metadata</code> <code>Optional[object] | NotGiven</code> <p>Set of 16 key-value pairs that can be attached to an object. This can be useful   for storing additional information about the object in a structured format. Keys   can be a maximum of 64 characters long and values can be a maxium of 512   characters long.</p> <code>NOT_GIVEN</code> <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/beta/threads/messages/#src.openai.resources.beta.threads.messages.AsyncMessages.files","title":"files","text":"<pre><code>files() -&gt; AsyncFiles\n</code></pre>"},{"location":"reference/resources/beta/threads/messages/#src.openai.resources.beta.threads.messages.AsyncMessages.list","title":"list","text":"<pre><code>list(\n    thread_id: str,\n    *,\n    after: str | NotGiven = NOT_GIVEN,\n    before: str | NotGiven = NOT_GIVEN,\n    limit: int | NotGiven = NOT_GIVEN,\n    order: Literal[\"asc\", \"desc\"] | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; AsyncPaginator[\n    ThreadMessage, AsyncCursorPage[ThreadMessage]\n]\n</code></pre> <p>Returns a list of messages for a given thread.</p> <p>Parameters:</p> Name Type Description Default <code>after</code> <code>str | NotGiven</code> <p>A cursor for use in pagination. <code>after</code> is an object ID that defines your place   in the list. For instance, if you make a list request and receive 100 objects,   ending with obj_foo, your subsequent call can include after=obj_foo in order to   fetch the next page of the list.</p> <code>NOT_GIVEN</code> <code>before</code> <code>str | NotGiven</code> <p>A cursor for use in pagination. <code>before</code> is an object ID that defines your place   in the list. For instance, if you make a list request and receive 100 objects,   ending with obj_foo, your subsequent call can include before=obj_foo in order to   fetch the previous page of the list.</p> <code>NOT_GIVEN</code> <code>limit</code> <code>int | NotGiven</code> <p>A limit on the number of objects to be returned. Limit can range between 1 and   100, and the default is 20.</p> <code>NOT_GIVEN</code> <code>order</code> <code>Literal['asc', 'desc'] | NotGiven</code> <p>Sort order by the <code>created_at</code> timestamp of the objects. <code>asc</code> for ascending   order and <code>desc</code> for descending order.</p> <code>NOT_GIVEN</code> <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/beta/threads/messages/#src.openai.resources.beta.threads.messages.AsyncMessages.retrieve","title":"retrieve  <code>async</code>","text":"<pre><code>retrieve(\n    message_id: str,\n    *,\n    thread_id: str,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; ThreadMessage\n</code></pre> <p>Retrieve a message.</p> <p>Parameters:</p> Name Type Description Default <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/beta/threads/messages/#src.openai.resources.beta.threads.messages.AsyncMessages.update","title":"update  <code>async</code>","text":"<pre><code>update(\n    message_id: str,\n    *,\n    thread_id: str,\n    metadata: Optional[object] | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; ThreadMessage\n</code></pre> <p>Modifies a message.</p> <p>Parameters:</p> Name Type Description Default <code>metadata</code> <code>Optional[object] | NotGiven</code> <p>Set of 16 key-value pairs that can be attached to an object. This can be useful   for storing additional information about the object in a structured format. Keys   can be a maximum of 64 characters long and values can be a maxium of 512   characters long.</p> <code>NOT_GIVEN</code> <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/beta/threads/messages/#src.openai.resources.beta.threads.messages.AsyncMessages.with_raw_response","title":"with_raw_response","text":"<pre><code>with_raw_response() -&gt; AsyncMessagesWithRawResponse\n</code></pre>"},{"location":"reference/resources/beta/threads/messages/#src.openai.resources.beta.threads.messages.AsyncMessages.with_streaming_response","title":"with_streaming_response","text":"<pre><code>with_streaming_response() -&gt; (\n    AsyncMessagesWithStreamingResponse\n)\n</code></pre>"},{"location":"reference/resources/beta/threads/messages/#src.openai.resources.beta.threads.messages.AsyncMessagesWithRawResponse","title":"AsyncMessagesWithRawResponse","text":"<pre><code>AsyncMessagesWithRawResponse(messages: AsyncMessages)\n</code></pre> <p>Methods:</p> Name Description <code>files</code> <p>Attributes:</p> Name Type Description <code>create</code> <code>list</code> <code>retrieve</code> <code>update</code>"},{"location":"reference/resources/beta/threads/messages/#src.openai.resources.beta.threads.messages.AsyncMessagesWithRawResponse.create","title":"create  <code>instance-attribute</code>","text":"<pre><code>create = async_to_raw_response_wrapper(create)\n</code></pre>"},{"location":"reference/resources/beta/threads/messages/#src.openai.resources.beta.threads.messages.AsyncMessagesWithRawResponse.list","title":"list  <code>instance-attribute</code>","text":"<pre><code>list = async_to_raw_response_wrapper(list)\n</code></pre>"},{"location":"reference/resources/beta/threads/messages/#src.openai.resources.beta.threads.messages.AsyncMessagesWithRawResponse.retrieve","title":"retrieve  <code>instance-attribute</code>","text":"<pre><code>retrieve = async_to_raw_response_wrapper(retrieve)\n</code></pre>"},{"location":"reference/resources/beta/threads/messages/#src.openai.resources.beta.threads.messages.AsyncMessagesWithRawResponse.update","title":"update  <code>instance-attribute</code>","text":"<pre><code>update = async_to_raw_response_wrapper(update)\n</code></pre>"},{"location":"reference/resources/beta/threads/messages/#src.openai.resources.beta.threads.messages.AsyncMessagesWithRawResponse.files","title":"files","text":"<pre><code>files() -&gt; AsyncFilesWithRawResponse\n</code></pre>"},{"location":"reference/resources/beta/threads/messages/#src.openai.resources.beta.threads.messages.AsyncMessagesWithStreamingResponse","title":"AsyncMessagesWithStreamingResponse","text":"<pre><code>AsyncMessagesWithStreamingResponse(messages: AsyncMessages)\n</code></pre> <p>Methods:</p> Name Description <code>files</code> <p>Attributes:</p> Name Type Description <code>create</code> <code>list</code> <code>retrieve</code> <code>update</code>"},{"location":"reference/resources/beta/threads/messages/#src.openai.resources.beta.threads.messages.AsyncMessagesWithStreamingResponse.create","title":"create  <code>instance-attribute</code>","text":"<pre><code>create = async_to_streamed_response_wrapper(create)\n</code></pre>"},{"location":"reference/resources/beta/threads/messages/#src.openai.resources.beta.threads.messages.AsyncMessagesWithStreamingResponse.list","title":"list  <code>instance-attribute</code>","text":"<pre><code>list = async_to_streamed_response_wrapper(list)\n</code></pre>"},{"location":"reference/resources/beta/threads/messages/#src.openai.resources.beta.threads.messages.AsyncMessagesWithStreamingResponse.retrieve","title":"retrieve  <code>instance-attribute</code>","text":"<pre><code>retrieve = async_to_streamed_response_wrapper(retrieve)\n</code></pre>"},{"location":"reference/resources/beta/threads/messages/#src.openai.resources.beta.threads.messages.AsyncMessagesWithStreamingResponse.update","title":"update  <code>instance-attribute</code>","text":"<pre><code>update = async_to_streamed_response_wrapper(update)\n</code></pre>"},{"location":"reference/resources/beta/threads/messages/#src.openai.resources.beta.threads.messages.AsyncMessagesWithStreamingResponse.files","title":"files","text":"<pre><code>files() -&gt; AsyncFilesWithStreamingResponse\n</code></pre>"},{"location":"reference/resources/beta/threads/messages/#src.openai.resources.beta.threads.messages.Files","title":"Files","text":"<pre><code>Files(client: OpenAI)\n</code></pre> <p>Methods:</p> Name Description <code>list</code> <p>Returns a list of message files.</p> <code>retrieve</code> <p>Retrieves a message file.</p> <code>with_raw_response</code> <code>with_streaming_response</code>"},{"location":"reference/resources/beta/threads/messages/#src.openai.resources.beta.threads.messages.Files.list","title":"list","text":"<pre><code>list(\n    message_id: str,\n    *,\n    thread_id: str,\n    after: str | NotGiven = NOT_GIVEN,\n    before: str | NotGiven = NOT_GIVEN,\n    limit: int | NotGiven = NOT_GIVEN,\n    order: Literal[\"asc\", \"desc\"] | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; SyncCursorPage[MessageFile]\n</code></pre> <p>Returns a list of message files.</p> <p>Parameters:</p> Name Type Description Default <code>after</code> <code>str | NotGiven</code> <p>A cursor for use in pagination.</p> <code>NOT_GIVEN</code> <p><code>after</code> is an object ID that defines your place       in the list. For instance, if you make a list request and receive 100 objects,       ending with obj_foo, your subsequent call can include after=obj_foo in order to       fetch the next page of the list.</p> <p>before: A cursor for use in pagination. <code>before</code> is an object ID that defines your place       in the list. For instance, if you make a list request and receive 100 objects,       ending with obj_foo, your subsequent call can include before=obj_foo in order to       fetch the previous page of the list.</p> <p>limit: A limit on the number of objects to be returned. Limit can range between 1 and       100, and the default is 20.</p> <p>order: Sort order by the <code>created_at</code> timestamp of the objects. <code>asc</code> for ascending       order and <code>desc</code> for descending order.</p> <p>extra_headers: Send extra headers</p> <p>extra_query: Add additional query parameters to the request</p> <p>extra_body: Add additional JSON properties to the request</p> <p>timeout: Override the client-level default timeout for this request, in seconds</p>"},{"location":"reference/resources/beta/threads/messages/#src.openai.resources.beta.threads.messages.Files.retrieve","title":"retrieve","text":"<pre><code>retrieve(\n    file_id: str,\n    *,\n    thread_id: str,\n    message_id: str,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; MessageFile\n</code></pre> <p>Retrieves a message file.</p> <p>Parameters:</p> Name Type Description Default <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/beta/threads/messages/#src.openai.resources.beta.threads.messages.Files.with_raw_response","title":"with_raw_response","text":"<pre><code>with_raw_response() -&gt; FilesWithRawResponse\n</code></pre>"},{"location":"reference/resources/beta/threads/messages/#src.openai.resources.beta.threads.messages.Files.with_streaming_response","title":"with_streaming_response","text":"<pre><code>with_streaming_response() -&gt; FilesWithStreamingResponse\n</code></pre>"},{"location":"reference/resources/beta/threads/messages/#src.openai.resources.beta.threads.messages.FilesWithRawResponse","title":"FilesWithRawResponse","text":"<pre><code>FilesWithRawResponse(files: Files)\n</code></pre> <p>Attributes:</p> Name Type Description <code>list</code> <code>retrieve</code>"},{"location":"reference/resources/beta/threads/messages/#src.openai.resources.beta.threads.messages.FilesWithRawResponse.list","title":"list  <code>instance-attribute</code>","text":"<pre><code>list = to_raw_response_wrapper(list)\n</code></pre>"},{"location":"reference/resources/beta/threads/messages/#src.openai.resources.beta.threads.messages.FilesWithRawResponse.retrieve","title":"retrieve  <code>instance-attribute</code>","text":"<pre><code>retrieve = to_raw_response_wrapper(retrieve)\n</code></pre>"},{"location":"reference/resources/beta/threads/messages/#src.openai.resources.beta.threads.messages.FilesWithStreamingResponse","title":"FilesWithStreamingResponse","text":"<pre><code>FilesWithStreamingResponse(files: Files)\n</code></pre> <p>Attributes:</p> Name Type Description <code>list</code> <code>retrieve</code>"},{"location":"reference/resources/beta/threads/messages/#src.openai.resources.beta.threads.messages.FilesWithStreamingResponse.list","title":"list  <code>instance-attribute</code>","text":"<pre><code>list = to_streamed_response_wrapper(list)\n</code></pre>"},{"location":"reference/resources/beta/threads/messages/#src.openai.resources.beta.threads.messages.FilesWithStreamingResponse.retrieve","title":"retrieve  <code>instance-attribute</code>","text":"<pre><code>retrieve = to_streamed_response_wrapper(retrieve)\n</code></pre>"},{"location":"reference/resources/beta/threads/messages/#src.openai.resources.beta.threads.messages.Messages","title":"Messages","text":"<pre><code>Messages(client: OpenAI)\n</code></pre> <p>Methods:</p> Name Description <code>create</code> <p>Create a message.</p> <code>files</code> <code>list</code> <p>Returns a list of messages for a given thread.</p> <code>retrieve</code> <p>Retrieve a message.</p> <code>update</code> <p>Modifies a message.</p> <code>with_raw_response</code> <code>with_streaming_response</code>"},{"location":"reference/resources/beta/threads/messages/#src.openai.resources.beta.threads.messages.Messages.create","title":"create","text":"<pre><code>create(\n    thread_id: str,\n    *,\n    content: str,\n    role: Literal[\"user\"],\n    file_ids: List[str] | NotGiven = NOT_GIVEN,\n    metadata: Optional[object] | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; ThreadMessage\n</code></pre> <p>Create a message.</p> <p>Parameters:</p> Name Type Description Default <code>content</code> <code>str</code> <p>The content of the message.</p> required <code>role</code> <code>Literal['user']</code> <p>The role of the entity that is creating the message. Currently only <code>user</code> is   supported.</p> required <code>file_ids</code> <code>List[str] | NotGiven</code> <p>A list of File IDs that   the message should use. There can be a maximum of 10 files attached to a   message. Useful for tools like <code>retrieval</code> and <code>code_interpreter</code> that can   access and use files.</p> <code>NOT_GIVEN</code> <code>metadata</code> <code>Optional[object] | NotGiven</code> <p>Set of 16 key-value pairs that can be attached to an object. This can be useful   for storing additional information about the object in a structured format. Keys   can be a maximum of 64 characters long and values can be a maxium of 512   characters long.</p> <code>NOT_GIVEN</code> <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/beta/threads/messages/#src.openai.resources.beta.threads.messages.Messages.files","title":"files","text":"<pre><code>files() -&gt; Files\n</code></pre>"},{"location":"reference/resources/beta/threads/messages/#src.openai.resources.beta.threads.messages.Messages.list","title":"list","text":"<pre><code>list(\n    thread_id: str,\n    *,\n    after: str | NotGiven = NOT_GIVEN,\n    before: str | NotGiven = NOT_GIVEN,\n    limit: int | NotGiven = NOT_GIVEN,\n    order: Literal[\"asc\", \"desc\"] | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; SyncCursorPage[ThreadMessage]\n</code></pre> <p>Returns a list of messages for a given thread.</p> <p>Parameters:</p> Name Type Description Default <code>after</code> <code>str | NotGiven</code> <p>A cursor for use in pagination. <code>after</code> is an object ID that defines your place   in the list. For instance, if you make a list request and receive 100 objects,   ending with obj_foo, your subsequent call can include after=obj_foo in order to   fetch the next page of the list.</p> <code>NOT_GIVEN</code> <code>before</code> <code>str | NotGiven</code> <p>A cursor for use in pagination. <code>before</code> is an object ID that defines your place   in the list. For instance, if you make a list request and receive 100 objects,   ending with obj_foo, your subsequent call can include before=obj_foo in order to   fetch the previous page of the list.</p> <code>NOT_GIVEN</code> <code>limit</code> <code>int | NotGiven</code> <p>A limit on the number of objects to be returned. Limit can range between 1 and   100, and the default is 20.</p> <code>NOT_GIVEN</code> <code>order</code> <code>Literal['asc', 'desc'] | NotGiven</code> <p>Sort order by the <code>created_at</code> timestamp of the objects. <code>asc</code> for ascending   order and <code>desc</code> for descending order.</p> <code>NOT_GIVEN</code> <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/beta/threads/messages/#src.openai.resources.beta.threads.messages.Messages.retrieve","title":"retrieve","text":"<pre><code>retrieve(\n    message_id: str,\n    *,\n    thread_id: str,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; ThreadMessage\n</code></pre> <p>Retrieve a message.</p> <p>Parameters:</p> Name Type Description Default <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/beta/threads/messages/#src.openai.resources.beta.threads.messages.Messages.update","title":"update","text":"<pre><code>update(\n    message_id: str,\n    *,\n    thread_id: str,\n    metadata: Optional[object] | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; ThreadMessage\n</code></pre> <p>Modifies a message.</p> <p>Parameters:</p> Name Type Description Default <code>metadata</code> <code>Optional[object] | NotGiven</code> <p>Set of 16 key-value pairs that can be attached to an object. This can be useful   for storing additional information about the object in a structured format. Keys   can be a maximum of 64 characters long and values can be a maxium of 512   characters long.</p> <code>NOT_GIVEN</code> <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/beta/threads/messages/#src.openai.resources.beta.threads.messages.Messages.with_raw_response","title":"with_raw_response","text":"<pre><code>with_raw_response() -&gt; MessagesWithRawResponse\n</code></pre>"},{"location":"reference/resources/beta/threads/messages/#src.openai.resources.beta.threads.messages.Messages.with_streaming_response","title":"with_streaming_response","text":"<pre><code>with_streaming_response() -&gt; MessagesWithStreamingResponse\n</code></pre>"},{"location":"reference/resources/beta/threads/messages/#src.openai.resources.beta.threads.messages.MessagesWithRawResponse","title":"MessagesWithRawResponse","text":"<pre><code>MessagesWithRawResponse(messages: Messages)\n</code></pre> <p>Methods:</p> Name Description <code>files</code> <p>Attributes:</p> Name Type Description <code>create</code> <code>list</code> <code>retrieve</code> <code>update</code>"},{"location":"reference/resources/beta/threads/messages/#src.openai.resources.beta.threads.messages.MessagesWithRawResponse.create","title":"create  <code>instance-attribute</code>","text":"<pre><code>create = to_raw_response_wrapper(create)\n</code></pre>"},{"location":"reference/resources/beta/threads/messages/#src.openai.resources.beta.threads.messages.MessagesWithRawResponse.list","title":"list  <code>instance-attribute</code>","text":"<pre><code>list = to_raw_response_wrapper(list)\n</code></pre>"},{"location":"reference/resources/beta/threads/messages/#src.openai.resources.beta.threads.messages.MessagesWithRawResponse.retrieve","title":"retrieve  <code>instance-attribute</code>","text":"<pre><code>retrieve = to_raw_response_wrapper(retrieve)\n</code></pre>"},{"location":"reference/resources/beta/threads/messages/#src.openai.resources.beta.threads.messages.MessagesWithRawResponse.update","title":"update  <code>instance-attribute</code>","text":"<pre><code>update = to_raw_response_wrapper(update)\n</code></pre>"},{"location":"reference/resources/beta/threads/messages/#src.openai.resources.beta.threads.messages.MessagesWithRawResponse.files","title":"files","text":"<pre><code>files() -&gt; FilesWithRawResponse\n</code></pre>"},{"location":"reference/resources/beta/threads/messages/#src.openai.resources.beta.threads.messages.MessagesWithStreamingResponse","title":"MessagesWithStreamingResponse","text":"<pre><code>MessagesWithStreamingResponse(messages: Messages)\n</code></pre> <p>Methods:</p> Name Description <code>files</code> <p>Attributes:</p> Name Type Description <code>create</code> <code>list</code> <code>retrieve</code> <code>update</code>"},{"location":"reference/resources/beta/threads/messages/#src.openai.resources.beta.threads.messages.MessagesWithStreamingResponse.create","title":"create  <code>instance-attribute</code>","text":"<pre><code>create = to_streamed_response_wrapper(create)\n</code></pre>"},{"location":"reference/resources/beta/threads/messages/#src.openai.resources.beta.threads.messages.MessagesWithStreamingResponse.list","title":"list  <code>instance-attribute</code>","text":"<pre><code>list = to_streamed_response_wrapper(list)\n</code></pre>"},{"location":"reference/resources/beta/threads/messages/#src.openai.resources.beta.threads.messages.MessagesWithStreamingResponse.retrieve","title":"retrieve  <code>instance-attribute</code>","text":"<pre><code>retrieve = to_streamed_response_wrapper(retrieve)\n</code></pre>"},{"location":"reference/resources/beta/threads/messages/#src.openai.resources.beta.threads.messages.MessagesWithStreamingResponse.update","title":"update  <code>instance-attribute</code>","text":"<pre><code>update = to_streamed_response_wrapper(update)\n</code></pre>"},{"location":"reference/resources/beta/threads/messages/#src.openai.resources.beta.threads.messages.MessagesWithStreamingResponse.files","title":"files","text":"<pre><code>files() -&gt; FilesWithStreamingResponse\n</code></pre>"},{"location":"reference/resources/beta/threads/messages/files/","title":"files","text":"<p>Classes:</p> Name Description <code>AsyncFiles</code> <code>AsyncFilesWithRawResponse</code> <code>AsyncFilesWithStreamingResponse</code> <code>Files</code> <code>FilesWithRawResponse</code> <code>FilesWithStreamingResponse</code>"},{"location":"reference/resources/beta/threads/messages/files/#src.openai.resources.beta.threads.messages.files.AsyncFiles","title":"AsyncFiles","text":"<pre><code>AsyncFiles(client: AsyncOpenAI)\n</code></pre> <p>Methods:</p> Name Description <code>list</code> <p>Returns a list of message files.</p> <code>retrieve</code> <p>Retrieves a message file.</p> <code>with_raw_response</code> <code>with_streaming_response</code>"},{"location":"reference/resources/beta/threads/messages/files/#src.openai.resources.beta.threads.messages.files.AsyncFiles.list","title":"list","text":"<pre><code>list(\n    message_id: str,\n    *,\n    thread_id: str,\n    after: str | NotGiven = NOT_GIVEN,\n    before: str | NotGiven = NOT_GIVEN,\n    limit: int | NotGiven = NOT_GIVEN,\n    order: Literal[\"asc\", \"desc\"] | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; AsyncPaginator[\n    MessageFile, AsyncCursorPage[MessageFile]\n]\n</code></pre> <p>Returns a list of message files.</p> <p>Parameters:</p> Name Type Description Default <code>after</code> <code>str | NotGiven</code> <p>A cursor for use in pagination.</p> <code>NOT_GIVEN</code> <p><code>after</code> is an object ID that defines your place       in the list. For instance, if you make a list request and receive 100 objects,       ending with obj_foo, your subsequent call can include after=obj_foo in order to       fetch the next page of the list.</p> <p>before: A cursor for use in pagination. <code>before</code> is an object ID that defines your place       in the list. For instance, if you make a list request and receive 100 objects,       ending with obj_foo, your subsequent call can include before=obj_foo in order to       fetch the previous page of the list.</p> <p>limit: A limit on the number of objects to be returned. Limit can range between 1 and       100, and the default is 20.</p> <p>order: Sort order by the <code>created_at</code> timestamp of the objects. <code>asc</code> for ascending       order and <code>desc</code> for descending order.</p> <p>extra_headers: Send extra headers</p> <p>extra_query: Add additional query parameters to the request</p> <p>extra_body: Add additional JSON properties to the request</p> <p>timeout: Override the client-level default timeout for this request, in seconds</p>"},{"location":"reference/resources/beta/threads/messages/files/#src.openai.resources.beta.threads.messages.files.AsyncFiles.retrieve","title":"retrieve  <code>async</code>","text":"<pre><code>retrieve(\n    file_id: str,\n    *,\n    thread_id: str,\n    message_id: str,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; MessageFile\n</code></pre> <p>Retrieves a message file.</p> <p>Parameters:</p> Name Type Description Default <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/beta/threads/messages/files/#src.openai.resources.beta.threads.messages.files.AsyncFiles.with_raw_response","title":"with_raw_response","text":"<pre><code>with_raw_response() -&gt; AsyncFilesWithRawResponse\n</code></pre>"},{"location":"reference/resources/beta/threads/messages/files/#src.openai.resources.beta.threads.messages.files.AsyncFiles.with_streaming_response","title":"with_streaming_response","text":"<pre><code>with_streaming_response() -&gt; (\n    AsyncFilesWithStreamingResponse\n)\n</code></pre>"},{"location":"reference/resources/beta/threads/messages/files/#src.openai.resources.beta.threads.messages.files.AsyncFilesWithRawResponse","title":"AsyncFilesWithRawResponse","text":"<pre><code>AsyncFilesWithRawResponse(files: AsyncFiles)\n</code></pre> <p>Attributes:</p> Name Type Description <code>list</code> <code>retrieve</code>"},{"location":"reference/resources/beta/threads/messages/files/#src.openai.resources.beta.threads.messages.files.AsyncFilesWithRawResponse.list","title":"list  <code>instance-attribute</code>","text":"<pre><code>list = async_to_raw_response_wrapper(list)\n</code></pre>"},{"location":"reference/resources/beta/threads/messages/files/#src.openai.resources.beta.threads.messages.files.AsyncFilesWithRawResponse.retrieve","title":"retrieve  <code>instance-attribute</code>","text":"<pre><code>retrieve = async_to_raw_response_wrapper(retrieve)\n</code></pre>"},{"location":"reference/resources/beta/threads/messages/files/#src.openai.resources.beta.threads.messages.files.AsyncFilesWithStreamingResponse","title":"AsyncFilesWithStreamingResponse","text":"<pre><code>AsyncFilesWithStreamingResponse(files: AsyncFiles)\n</code></pre> <p>Attributes:</p> Name Type Description <code>list</code> <code>retrieve</code>"},{"location":"reference/resources/beta/threads/messages/files/#src.openai.resources.beta.threads.messages.files.AsyncFilesWithStreamingResponse.list","title":"list  <code>instance-attribute</code>","text":"<pre><code>list = async_to_streamed_response_wrapper(list)\n</code></pre>"},{"location":"reference/resources/beta/threads/messages/files/#src.openai.resources.beta.threads.messages.files.AsyncFilesWithStreamingResponse.retrieve","title":"retrieve  <code>instance-attribute</code>","text":"<pre><code>retrieve = async_to_streamed_response_wrapper(retrieve)\n</code></pre>"},{"location":"reference/resources/beta/threads/messages/files/#src.openai.resources.beta.threads.messages.files.Files","title":"Files","text":"<pre><code>Files(client: OpenAI)\n</code></pre> <p>Methods:</p> Name Description <code>list</code> <p>Returns a list of message files.</p> <code>retrieve</code> <p>Retrieves a message file.</p> <code>with_raw_response</code> <code>with_streaming_response</code>"},{"location":"reference/resources/beta/threads/messages/files/#src.openai.resources.beta.threads.messages.files.Files.list","title":"list","text":"<pre><code>list(\n    message_id: str,\n    *,\n    thread_id: str,\n    after: str | NotGiven = NOT_GIVEN,\n    before: str | NotGiven = NOT_GIVEN,\n    limit: int | NotGiven = NOT_GIVEN,\n    order: Literal[\"asc\", \"desc\"] | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; SyncCursorPage[MessageFile]\n</code></pre> <p>Returns a list of message files.</p> <p>Parameters:</p> Name Type Description Default <code>after</code> <code>str | NotGiven</code> <p>A cursor for use in pagination.</p> <code>NOT_GIVEN</code> <p><code>after</code> is an object ID that defines your place       in the list. For instance, if you make a list request and receive 100 objects,       ending with obj_foo, your subsequent call can include after=obj_foo in order to       fetch the next page of the list.</p> <p>before: A cursor for use in pagination. <code>before</code> is an object ID that defines your place       in the list. For instance, if you make a list request and receive 100 objects,       ending with obj_foo, your subsequent call can include before=obj_foo in order to       fetch the previous page of the list.</p> <p>limit: A limit on the number of objects to be returned. Limit can range between 1 and       100, and the default is 20.</p> <p>order: Sort order by the <code>created_at</code> timestamp of the objects. <code>asc</code> for ascending       order and <code>desc</code> for descending order.</p> <p>extra_headers: Send extra headers</p> <p>extra_query: Add additional query parameters to the request</p> <p>extra_body: Add additional JSON properties to the request</p> <p>timeout: Override the client-level default timeout for this request, in seconds</p>"},{"location":"reference/resources/beta/threads/messages/files/#src.openai.resources.beta.threads.messages.files.Files.retrieve","title":"retrieve","text":"<pre><code>retrieve(\n    file_id: str,\n    *,\n    thread_id: str,\n    message_id: str,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; MessageFile\n</code></pre> <p>Retrieves a message file.</p> <p>Parameters:</p> Name Type Description Default <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/beta/threads/messages/files/#src.openai.resources.beta.threads.messages.files.Files.with_raw_response","title":"with_raw_response","text":"<pre><code>with_raw_response() -&gt; FilesWithRawResponse\n</code></pre>"},{"location":"reference/resources/beta/threads/messages/files/#src.openai.resources.beta.threads.messages.files.Files.with_streaming_response","title":"with_streaming_response","text":"<pre><code>with_streaming_response() -&gt; FilesWithStreamingResponse\n</code></pre>"},{"location":"reference/resources/beta/threads/messages/files/#src.openai.resources.beta.threads.messages.files.FilesWithRawResponse","title":"FilesWithRawResponse","text":"<pre><code>FilesWithRawResponse(files: Files)\n</code></pre> <p>Attributes:</p> Name Type Description <code>list</code> <code>retrieve</code>"},{"location":"reference/resources/beta/threads/messages/files/#src.openai.resources.beta.threads.messages.files.FilesWithRawResponse.list","title":"list  <code>instance-attribute</code>","text":"<pre><code>list = to_raw_response_wrapper(list)\n</code></pre>"},{"location":"reference/resources/beta/threads/messages/files/#src.openai.resources.beta.threads.messages.files.FilesWithRawResponse.retrieve","title":"retrieve  <code>instance-attribute</code>","text":"<pre><code>retrieve = to_raw_response_wrapper(retrieve)\n</code></pre>"},{"location":"reference/resources/beta/threads/messages/files/#src.openai.resources.beta.threads.messages.files.FilesWithStreamingResponse","title":"FilesWithStreamingResponse","text":"<pre><code>FilesWithStreamingResponse(files: Files)\n</code></pre> <p>Attributes:</p> Name Type Description <code>list</code> <code>retrieve</code>"},{"location":"reference/resources/beta/threads/messages/files/#src.openai.resources.beta.threads.messages.files.FilesWithStreamingResponse.list","title":"list  <code>instance-attribute</code>","text":"<pre><code>list = to_streamed_response_wrapper(list)\n</code></pre>"},{"location":"reference/resources/beta/threads/messages/files/#src.openai.resources.beta.threads.messages.files.FilesWithStreamingResponse.retrieve","title":"retrieve  <code>instance-attribute</code>","text":"<pre><code>retrieve = to_streamed_response_wrapper(retrieve)\n</code></pre>"},{"location":"reference/resources/beta/threads/messages/messages/","title":"messages","text":"<p>Classes:</p> Name Description <code>AsyncMessages</code> <code>AsyncMessagesWithRawResponse</code> <code>AsyncMessagesWithStreamingResponse</code> <code>Messages</code> <code>MessagesWithRawResponse</code> <code>MessagesWithStreamingResponse</code>"},{"location":"reference/resources/beta/threads/messages/messages/#src.openai.resources.beta.threads.messages.messages.AsyncMessages","title":"AsyncMessages","text":"<pre><code>AsyncMessages(client: AsyncOpenAI)\n</code></pre> <p>Methods:</p> Name Description <code>create</code> <p>Create a message.</p> <code>files</code> <code>list</code> <p>Returns a list of messages for a given thread.</p> <code>retrieve</code> <p>Retrieve a message.</p> <code>update</code> <p>Modifies a message.</p> <code>with_raw_response</code> <code>with_streaming_response</code>"},{"location":"reference/resources/beta/threads/messages/messages/#src.openai.resources.beta.threads.messages.messages.AsyncMessages.create","title":"create  <code>async</code>","text":"<pre><code>create(\n    thread_id: str,\n    *,\n    content: str,\n    role: Literal[\"user\"],\n    file_ids: List[str] | NotGiven = NOT_GIVEN,\n    metadata: Optional[object] | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; ThreadMessage\n</code></pre> <p>Create a message.</p> <p>Parameters:</p> Name Type Description Default <code>content</code> <code>str</code> <p>The content of the message.</p> required <code>role</code> <code>Literal['user']</code> <p>The role of the entity that is creating the message. Currently only <code>user</code> is   supported.</p> required <code>file_ids</code> <code>List[str] | NotGiven</code> <p>A list of File IDs that   the message should use. There can be a maximum of 10 files attached to a   message. Useful for tools like <code>retrieval</code> and <code>code_interpreter</code> that can   access and use files.</p> <code>NOT_GIVEN</code> <code>metadata</code> <code>Optional[object] | NotGiven</code> <p>Set of 16 key-value pairs that can be attached to an object. This can be useful   for storing additional information about the object in a structured format. Keys   can be a maximum of 64 characters long and values can be a maxium of 512   characters long.</p> <code>NOT_GIVEN</code> <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/beta/threads/messages/messages/#src.openai.resources.beta.threads.messages.messages.AsyncMessages.files","title":"files","text":"<pre><code>files() -&gt; AsyncFiles\n</code></pre>"},{"location":"reference/resources/beta/threads/messages/messages/#src.openai.resources.beta.threads.messages.messages.AsyncMessages.list","title":"list","text":"<pre><code>list(\n    thread_id: str,\n    *,\n    after: str | NotGiven = NOT_GIVEN,\n    before: str | NotGiven = NOT_GIVEN,\n    limit: int | NotGiven = NOT_GIVEN,\n    order: Literal[\"asc\", \"desc\"] | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; AsyncPaginator[\n    ThreadMessage, AsyncCursorPage[ThreadMessage]\n]\n</code></pre> <p>Returns a list of messages for a given thread.</p> <p>Parameters:</p> Name Type Description Default <code>after</code> <code>str | NotGiven</code> <p>A cursor for use in pagination. <code>after</code> is an object ID that defines your place   in the list. For instance, if you make a list request and receive 100 objects,   ending with obj_foo, your subsequent call can include after=obj_foo in order to   fetch the next page of the list.</p> <code>NOT_GIVEN</code> <code>before</code> <code>str | NotGiven</code> <p>A cursor for use in pagination. <code>before</code> is an object ID that defines your place   in the list. For instance, if you make a list request and receive 100 objects,   ending with obj_foo, your subsequent call can include before=obj_foo in order to   fetch the previous page of the list.</p> <code>NOT_GIVEN</code> <code>limit</code> <code>int | NotGiven</code> <p>A limit on the number of objects to be returned. Limit can range between 1 and   100, and the default is 20.</p> <code>NOT_GIVEN</code> <code>order</code> <code>Literal['asc', 'desc'] | NotGiven</code> <p>Sort order by the <code>created_at</code> timestamp of the objects. <code>asc</code> for ascending   order and <code>desc</code> for descending order.</p> <code>NOT_GIVEN</code> <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/beta/threads/messages/messages/#src.openai.resources.beta.threads.messages.messages.AsyncMessages.retrieve","title":"retrieve  <code>async</code>","text":"<pre><code>retrieve(\n    message_id: str,\n    *,\n    thread_id: str,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; ThreadMessage\n</code></pre> <p>Retrieve a message.</p> <p>Parameters:</p> Name Type Description Default <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/beta/threads/messages/messages/#src.openai.resources.beta.threads.messages.messages.AsyncMessages.update","title":"update  <code>async</code>","text":"<pre><code>update(\n    message_id: str,\n    *,\n    thread_id: str,\n    metadata: Optional[object] | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; ThreadMessage\n</code></pre> <p>Modifies a message.</p> <p>Parameters:</p> Name Type Description Default <code>metadata</code> <code>Optional[object] | NotGiven</code> <p>Set of 16 key-value pairs that can be attached to an object. This can be useful   for storing additional information about the object in a structured format. Keys   can be a maximum of 64 characters long and values can be a maxium of 512   characters long.</p> <code>NOT_GIVEN</code> <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/beta/threads/messages/messages/#src.openai.resources.beta.threads.messages.messages.AsyncMessages.with_raw_response","title":"with_raw_response","text":"<pre><code>with_raw_response() -&gt; AsyncMessagesWithRawResponse\n</code></pre>"},{"location":"reference/resources/beta/threads/messages/messages/#src.openai.resources.beta.threads.messages.messages.AsyncMessages.with_streaming_response","title":"with_streaming_response","text":"<pre><code>with_streaming_response() -&gt; (\n    AsyncMessagesWithStreamingResponse\n)\n</code></pre>"},{"location":"reference/resources/beta/threads/messages/messages/#src.openai.resources.beta.threads.messages.messages.AsyncMessagesWithRawResponse","title":"AsyncMessagesWithRawResponse","text":"<pre><code>AsyncMessagesWithRawResponse(messages: AsyncMessages)\n</code></pre> <p>Methods:</p> Name Description <code>files</code> <p>Attributes:</p> Name Type Description <code>create</code> <code>list</code> <code>retrieve</code> <code>update</code>"},{"location":"reference/resources/beta/threads/messages/messages/#src.openai.resources.beta.threads.messages.messages.AsyncMessagesWithRawResponse.create","title":"create  <code>instance-attribute</code>","text":"<pre><code>create = async_to_raw_response_wrapper(create)\n</code></pre>"},{"location":"reference/resources/beta/threads/messages/messages/#src.openai.resources.beta.threads.messages.messages.AsyncMessagesWithRawResponse.list","title":"list  <code>instance-attribute</code>","text":"<pre><code>list = async_to_raw_response_wrapper(list)\n</code></pre>"},{"location":"reference/resources/beta/threads/messages/messages/#src.openai.resources.beta.threads.messages.messages.AsyncMessagesWithRawResponse.retrieve","title":"retrieve  <code>instance-attribute</code>","text":"<pre><code>retrieve = async_to_raw_response_wrapper(retrieve)\n</code></pre>"},{"location":"reference/resources/beta/threads/messages/messages/#src.openai.resources.beta.threads.messages.messages.AsyncMessagesWithRawResponse.update","title":"update  <code>instance-attribute</code>","text":"<pre><code>update = async_to_raw_response_wrapper(update)\n</code></pre>"},{"location":"reference/resources/beta/threads/messages/messages/#src.openai.resources.beta.threads.messages.messages.AsyncMessagesWithRawResponse.files","title":"files","text":"<pre><code>files() -&gt; AsyncFilesWithRawResponse\n</code></pre>"},{"location":"reference/resources/beta/threads/messages/messages/#src.openai.resources.beta.threads.messages.messages.AsyncMessagesWithStreamingResponse","title":"AsyncMessagesWithStreamingResponse","text":"<pre><code>AsyncMessagesWithStreamingResponse(messages: AsyncMessages)\n</code></pre> <p>Methods:</p> Name Description <code>files</code> <p>Attributes:</p> Name Type Description <code>create</code> <code>list</code> <code>retrieve</code> <code>update</code>"},{"location":"reference/resources/beta/threads/messages/messages/#src.openai.resources.beta.threads.messages.messages.AsyncMessagesWithStreamingResponse.create","title":"create  <code>instance-attribute</code>","text":"<pre><code>create = async_to_streamed_response_wrapper(create)\n</code></pre>"},{"location":"reference/resources/beta/threads/messages/messages/#src.openai.resources.beta.threads.messages.messages.AsyncMessagesWithStreamingResponse.list","title":"list  <code>instance-attribute</code>","text":"<pre><code>list = async_to_streamed_response_wrapper(list)\n</code></pre>"},{"location":"reference/resources/beta/threads/messages/messages/#src.openai.resources.beta.threads.messages.messages.AsyncMessagesWithStreamingResponse.retrieve","title":"retrieve  <code>instance-attribute</code>","text":"<pre><code>retrieve = async_to_streamed_response_wrapper(retrieve)\n</code></pre>"},{"location":"reference/resources/beta/threads/messages/messages/#src.openai.resources.beta.threads.messages.messages.AsyncMessagesWithStreamingResponse.update","title":"update  <code>instance-attribute</code>","text":"<pre><code>update = async_to_streamed_response_wrapper(update)\n</code></pre>"},{"location":"reference/resources/beta/threads/messages/messages/#src.openai.resources.beta.threads.messages.messages.AsyncMessagesWithStreamingResponse.files","title":"files","text":"<pre><code>files() -&gt; AsyncFilesWithStreamingResponse\n</code></pre>"},{"location":"reference/resources/beta/threads/messages/messages/#src.openai.resources.beta.threads.messages.messages.Messages","title":"Messages","text":"<pre><code>Messages(client: OpenAI)\n</code></pre> <p>Methods:</p> Name Description <code>create</code> <p>Create a message.</p> <code>files</code> <code>list</code> <p>Returns a list of messages for a given thread.</p> <code>retrieve</code> <p>Retrieve a message.</p> <code>update</code> <p>Modifies a message.</p> <code>with_raw_response</code> <code>with_streaming_response</code>"},{"location":"reference/resources/beta/threads/messages/messages/#src.openai.resources.beta.threads.messages.messages.Messages.create","title":"create","text":"<pre><code>create(\n    thread_id: str,\n    *,\n    content: str,\n    role: Literal[\"user\"],\n    file_ids: List[str] | NotGiven = NOT_GIVEN,\n    metadata: Optional[object] | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; ThreadMessage\n</code></pre> <p>Create a message.</p> <p>Parameters:</p> Name Type Description Default <code>content</code> <code>str</code> <p>The content of the message.</p> required <code>role</code> <code>Literal['user']</code> <p>The role of the entity that is creating the message. Currently only <code>user</code> is   supported.</p> required <code>file_ids</code> <code>List[str] | NotGiven</code> <p>A list of File IDs that   the message should use. There can be a maximum of 10 files attached to a   message. Useful for tools like <code>retrieval</code> and <code>code_interpreter</code> that can   access and use files.</p> <code>NOT_GIVEN</code> <code>metadata</code> <code>Optional[object] | NotGiven</code> <p>Set of 16 key-value pairs that can be attached to an object. This can be useful   for storing additional information about the object in a structured format. Keys   can be a maximum of 64 characters long and values can be a maxium of 512   characters long.</p> <code>NOT_GIVEN</code> <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/beta/threads/messages/messages/#src.openai.resources.beta.threads.messages.messages.Messages.files","title":"files","text":"<pre><code>files() -&gt; Files\n</code></pre>"},{"location":"reference/resources/beta/threads/messages/messages/#src.openai.resources.beta.threads.messages.messages.Messages.list","title":"list","text":"<pre><code>list(\n    thread_id: str,\n    *,\n    after: str | NotGiven = NOT_GIVEN,\n    before: str | NotGiven = NOT_GIVEN,\n    limit: int | NotGiven = NOT_GIVEN,\n    order: Literal[\"asc\", \"desc\"] | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; SyncCursorPage[ThreadMessage]\n</code></pre> <p>Returns a list of messages for a given thread.</p> <p>Parameters:</p> Name Type Description Default <code>after</code> <code>str | NotGiven</code> <p>A cursor for use in pagination. <code>after</code> is an object ID that defines your place   in the list. For instance, if you make a list request and receive 100 objects,   ending with obj_foo, your subsequent call can include after=obj_foo in order to   fetch the next page of the list.</p> <code>NOT_GIVEN</code> <code>before</code> <code>str | NotGiven</code> <p>A cursor for use in pagination. <code>before</code> is an object ID that defines your place   in the list. For instance, if you make a list request and receive 100 objects,   ending with obj_foo, your subsequent call can include before=obj_foo in order to   fetch the previous page of the list.</p> <code>NOT_GIVEN</code> <code>limit</code> <code>int | NotGiven</code> <p>A limit on the number of objects to be returned. Limit can range between 1 and   100, and the default is 20.</p> <code>NOT_GIVEN</code> <code>order</code> <code>Literal['asc', 'desc'] | NotGiven</code> <p>Sort order by the <code>created_at</code> timestamp of the objects. <code>asc</code> for ascending   order and <code>desc</code> for descending order.</p> <code>NOT_GIVEN</code> <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/beta/threads/messages/messages/#src.openai.resources.beta.threads.messages.messages.Messages.retrieve","title":"retrieve","text":"<pre><code>retrieve(\n    message_id: str,\n    *,\n    thread_id: str,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; ThreadMessage\n</code></pre> <p>Retrieve a message.</p> <p>Parameters:</p> Name Type Description Default <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/beta/threads/messages/messages/#src.openai.resources.beta.threads.messages.messages.Messages.update","title":"update","text":"<pre><code>update(\n    message_id: str,\n    *,\n    thread_id: str,\n    metadata: Optional[object] | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; ThreadMessage\n</code></pre> <p>Modifies a message.</p> <p>Parameters:</p> Name Type Description Default <code>metadata</code> <code>Optional[object] | NotGiven</code> <p>Set of 16 key-value pairs that can be attached to an object. This can be useful   for storing additional information about the object in a structured format. Keys   can be a maximum of 64 characters long and values can be a maxium of 512   characters long.</p> <code>NOT_GIVEN</code> <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/beta/threads/messages/messages/#src.openai.resources.beta.threads.messages.messages.Messages.with_raw_response","title":"with_raw_response","text":"<pre><code>with_raw_response() -&gt; MessagesWithRawResponse\n</code></pre>"},{"location":"reference/resources/beta/threads/messages/messages/#src.openai.resources.beta.threads.messages.messages.Messages.with_streaming_response","title":"with_streaming_response","text":"<pre><code>with_streaming_response() -&gt; MessagesWithStreamingResponse\n</code></pre>"},{"location":"reference/resources/beta/threads/messages/messages/#src.openai.resources.beta.threads.messages.messages.MessagesWithRawResponse","title":"MessagesWithRawResponse","text":"<pre><code>MessagesWithRawResponse(messages: Messages)\n</code></pre> <p>Methods:</p> Name Description <code>files</code> <p>Attributes:</p> Name Type Description <code>create</code> <code>list</code> <code>retrieve</code> <code>update</code>"},{"location":"reference/resources/beta/threads/messages/messages/#src.openai.resources.beta.threads.messages.messages.MessagesWithRawResponse.create","title":"create  <code>instance-attribute</code>","text":"<pre><code>create = to_raw_response_wrapper(create)\n</code></pre>"},{"location":"reference/resources/beta/threads/messages/messages/#src.openai.resources.beta.threads.messages.messages.MessagesWithRawResponse.list","title":"list  <code>instance-attribute</code>","text":"<pre><code>list = to_raw_response_wrapper(list)\n</code></pre>"},{"location":"reference/resources/beta/threads/messages/messages/#src.openai.resources.beta.threads.messages.messages.MessagesWithRawResponse.retrieve","title":"retrieve  <code>instance-attribute</code>","text":"<pre><code>retrieve = to_raw_response_wrapper(retrieve)\n</code></pre>"},{"location":"reference/resources/beta/threads/messages/messages/#src.openai.resources.beta.threads.messages.messages.MessagesWithRawResponse.update","title":"update  <code>instance-attribute</code>","text":"<pre><code>update = to_raw_response_wrapper(update)\n</code></pre>"},{"location":"reference/resources/beta/threads/messages/messages/#src.openai.resources.beta.threads.messages.messages.MessagesWithRawResponse.files","title":"files","text":"<pre><code>files() -&gt; FilesWithRawResponse\n</code></pre>"},{"location":"reference/resources/beta/threads/messages/messages/#src.openai.resources.beta.threads.messages.messages.MessagesWithStreamingResponse","title":"MessagesWithStreamingResponse","text":"<pre><code>MessagesWithStreamingResponse(messages: Messages)\n</code></pre> <p>Methods:</p> Name Description <code>files</code> <p>Attributes:</p> Name Type Description <code>create</code> <code>list</code> <code>retrieve</code> <code>update</code>"},{"location":"reference/resources/beta/threads/messages/messages/#src.openai.resources.beta.threads.messages.messages.MessagesWithStreamingResponse.create","title":"create  <code>instance-attribute</code>","text":"<pre><code>create = to_streamed_response_wrapper(create)\n</code></pre>"},{"location":"reference/resources/beta/threads/messages/messages/#src.openai.resources.beta.threads.messages.messages.MessagesWithStreamingResponse.list","title":"list  <code>instance-attribute</code>","text":"<pre><code>list = to_streamed_response_wrapper(list)\n</code></pre>"},{"location":"reference/resources/beta/threads/messages/messages/#src.openai.resources.beta.threads.messages.messages.MessagesWithStreamingResponse.retrieve","title":"retrieve  <code>instance-attribute</code>","text":"<pre><code>retrieve = to_streamed_response_wrapper(retrieve)\n</code></pre>"},{"location":"reference/resources/beta/threads/messages/messages/#src.openai.resources.beta.threads.messages.messages.MessagesWithStreamingResponse.update","title":"update  <code>instance-attribute</code>","text":"<pre><code>update = to_streamed_response_wrapper(update)\n</code></pre>"},{"location":"reference/resources/beta/threads/messages/messages/#src.openai.resources.beta.threads.messages.messages.MessagesWithStreamingResponse.files","title":"files","text":"<pre><code>files() -&gt; FilesWithStreamingResponse\n</code></pre>"},{"location":"reference/resources/beta/threads/runs/","title":"Index","text":"<p>Modules:</p> Name Description <code>runs</code> <code>steps</code> <p>Classes:</p> Name Description <code>AsyncRuns</code> <code>AsyncRunsWithRawResponse</code> <code>AsyncRunsWithStreamingResponse</code> <code>AsyncSteps</code> <code>AsyncStepsWithRawResponse</code> <code>AsyncStepsWithStreamingResponse</code> <code>Runs</code> <code>RunsWithRawResponse</code> <code>RunsWithStreamingResponse</code> <code>Steps</code> <code>StepsWithRawResponse</code> <code>StepsWithStreamingResponse</code>"},{"location":"reference/resources/beta/threads/runs/#src.openai.resources.beta.threads.runs.AsyncRuns","title":"AsyncRuns","text":"<pre><code>AsyncRuns(client: AsyncOpenAI)\n</code></pre> <p>Methods:</p> Name Description <code>cancel</code> <p>Cancels a run that is <code>in_progress</code>.</p> <code>create</code> <p>Create a run.</p> <code>list</code> <p>Returns a list of runs belonging to a thread.</p> <code>retrieve</code> <p>Retrieves a run.</p> <code>steps</code> <code>submit_tool_outputs</code> <p>When a run has the <code>status: \"requires_action\"</code> and <code>required_action.type</code> is</p> <code>update</code> <p>Modifies a run.</p> <code>with_raw_response</code> <code>with_streaming_response</code>"},{"location":"reference/resources/beta/threads/runs/#src.openai.resources.beta.threads.runs.AsyncRuns.cancel","title":"cancel  <code>async</code>","text":"<pre><code>cancel(\n    run_id: str,\n    *,\n    thread_id: str,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; Run\n</code></pre> <p>Cancels a run that is <code>in_progress</code>.</p> <p>Parameters:</p> Name Type Description Default <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/beta/threads/runs/#src.openai.resources.beta.threads.runs.AsyncRuns.create","title":"create  <code>async</code>","text":"<pre><code>create(\n    thread_id: str,\n    *,\n    assistant_id: str,\n    additional_instructions: (\n        Optional[str] | NotGiven\n    ) = NOT_GIVEN,\n    instructions: Optional[str] | NotGiven = NOT_GIVEN,\n    metadata: Optional[object] | NotGiven = NOT_GIVEN,\n    model: Optional[str] | NotGiven = NOT_GIVEN,\n    tools: Optional[Iterable[Tool]] | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; Run\n</code></pre> <p>Create a run.</p> <p>Parameters:</p> Name Type Description Default <code>assistant_id</code> <code>str</code> <p>The ID of the   assistant to use to   execute this run.</p> required <code>additional_instructions</code> <code>Optional[str] | NotGiven</code> <p>Appends additional instructions at the end of the instructions for the run. This   is useful for modifying the behavior on a per-run basis without overriding other   instructions.</p> <code>NOT_GIVEN</code> <code>instructions</code> <code>Optional[str] | NotGiven</code> <p>Overrides the   instructions   of the assistant. This is useful for modifying the behavior on a per-run basis.</p> <code>NOT_GIVEN</code> <code>metadata</code> <code>Optional[object] | NotGiven</code> <p>Set of 16 key-value pairs that can be attached to an object. This can be useful   for storing additional information about the object in a structured format. Keys   can be a maximum of 64 characters long and values can be a maxium of 512   characters long.</p> <code>NOT_GIVEN</code> <code>model</code> <code>Optional[str] | NotGiven</code> <p>The ID of the Model to   be used to execute this run. If a value is provided here, it will override the   model associated with the assistant. If not, the model associated with the   assistant will be used.</p> <code>NOT_GIVEN</code> <code>tools</code> <code>Optional[Iterable[Tool]] | NotGiven</code> <p>Override the tools the assistant can use for this run. This is useful for   modifying the behavior on a per-run basis.</p> <code>NOT_GIVEN</code> <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/beta/threads/runs/#src.openai.resources.beta.threads.runs.AsyncRuns.list","title":"list","text":"<pre><code>list(\n    thread_id: str,\n    *,\n    after: str | NotGiven = NOT_GIVEN,\n    before: str | NotGiven = NOT_GIVEN,\n    limit: int | NotGiven = NOT_GIVEN,\n    order: Literal[\"asc\", \"desc\"] | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; AsyncPaginator[Run, AsyncCursorPage[Run]]\n</code></pre> <p>Returns a list of runs belonging to a thread.</p> <p>Parameters:</p> Name Type Description Default <code>after</code> <code>str | NotGiven</code> <p>A cursor for use in pagination. <code>after</code> is an object ID that defines your place   in the list. For instance, if you make a list request and receive 100 objects,   ending with obj_foo, your subsequent call can include after=obj_foo in order to   fetch the next page of the list.</p> <code>NOT_GIVEN</code> <code>before</code> <code>str | NotGiven</code> <p>A cursor for use in pagination. <code>before</code> is an object ID that defines your place   in the list. For instance, if you make a list request and receive 100 objects,   ending with obj_foo, your subsequent call can include before=obj_foo in order to   fetch the previous page of the list.</p> <code>NOT_GIVEN</code> <code>limit</code> <code>int | NotGiven</code> <p>A limit on the number of objects to be returned. Limit can range between 1 and   100, and the default is 20.</p> <code>NOT_GIVEN</code> <code>order</code> <code>Literal['asc', 'desc'] | NotGiven</code> <p>Sort order by the <code>created_at</code> timestamp of the objects. <code>asc</code> for ascending   order and <code>desc</code> for descending order.</p> <code>NOT_GIVEN</code> <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/beta/threads/runs/#src.openai.resources.beta.threads.runs.AsyncRuns.retrieve","title":"retrieve  <code>async</code>","text":"<pre><code>retrieve(\n    run_id: str,\n    *,\n    thread_id: str,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; Run\n</code></pre> <p>Retrieves a run.</p> <p>Parameters:</p> Name Type Description Default <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/beta/threads/runs/#src.openai.resources.beta.threads.runs.AsyncRuns.steps","title":"steps","text":"<pre><code>steps() -&gt; AsyncSteps\n</code></pre>"},{"location":"reference/resources/beta/threads/runs/#src.openai.resources.beta.threads.runs.AsyncRuns.submit_tool_outputs","title":"submit_tool_outputs  <code>async</code>","text":"<pre><code>submit_tool_outputs(\n    run_id: str,\n    *,\n    thread_id: str,\n    tool_outputs: Iterable[ToolOutput],\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; Run\n</code></pre> <p>When a run has the <code>status: \"requires_action\"</code> and <code>required_action.type</code> is <code>submit_tool_outputs</code>, this endpoint can be used to submit the outputs from the tool calls once they're all completed. All outputs must be submitted in a single request.</p> <p>Parameters:</p> Name Type Description Default <code>tool_outputs</code> <code>Iterable[ToolOutput]</code> <p>A list of tools for which the outputs are being submitted.</p> required <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/beta/threads/runs/#src.openai.resources.beta.threads.runs.AsyncRuns.update","title":"update  <code>async</code>","text":"<pre><code>update(\n    run_id: str,\n    *,\n    thread_id: str,\n    metadata: Optional[object] | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; Run\n</code></pre> <p>Modifies a run.</p> <p>Parameters:</p> Name Type Description Default <code>metadata</code> <code>Optional[object] | NotGiven</code> <p>Set of 16 key-value pairs that can be attached to an object. This can be useful   for storing additional information about the object in a structured format. Keys   can be a maximum of 64 characters long and values can be a maxium of 512   characters long.</p> <code>NOT_GIVEN</code> <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/beta/threads/runs/#src.openai.resources.beta.threads.runs.AsyncRuns.with_raw_response","title":"with_raw_response","text":"<pre><code>with_raw_response() -&gt; AsyncRunsWithRawResponse\n</code></pre>"},{"location":"reference/resources/beta/threads/runs/#src.openai.resources.beta.threads.runs.AsyncRuns.with_streaming_response","title":"with_streaming_response","text":"<pre><code>with_streaming_response() -&gt; AsyncRunsWithStreamingResponse\n</code></pre>"},{"location":"reference/resources/beta/threads/runs/#src.openai.resources.beta.threads.runs.AsyncRunsWithRawResponse","title":"AsyncRunsWithRawResponse","text":"<pre><code>AsyncRunsWithRawResponse(runs: AsyncRuns)\n</code></pre> <p>Methods:</p> Name Description <code>steps</code> <p>Attributes:</p> Name Type Description <code>cancel</code> <code>create</code> <code>list</code> <code>retrieve</code> <code>submit_tool_outputs</code> <code>update</code>"},{"location":"reference/resources/beta/threads/runs/#src.openai.resources.beta.threads.runs.AsyncRunsWithRawResponse.cancel","title":"cancel  <code>instance-attribute</code>","text":"<pre><code>cancel = async_to_raw_response_wrapper(cancel)\n</code></pre>"},{"location":"reference/resources/beta/threads/runs/#src.openai.resources.beta.threads.runs.AsyncRunsWithRawResponse.create","title":"create  <code>instance-attribute</code>","text":"<pre><code>create = async_to_raw_response_wrapper(create)\n</code></pre>"},{"location":"reference/resources/beta/threads/runs/#src.openai.resources.beta.threads.runs.AsyncRunsWithRawResponse.list","title":"list  <code>instance-attribute</code>","text":"<pre><code>list = async_to_raw_response_wrapper(list)\n</code></pre>"},{"location":"reference/resources/beta/threads/runs/#src.openai.resources.beta.threads.runs.AsyncRunsWithRawResponse.retrieve","title":"retrieve  <code>instance-attribute</code>","text":"<pre><code>retrieve = async_to_raw_response_wrapper(retrieve)\n</code></pre>"},{"location":"reference/resources/beta/threads/runs/#src.openai.resources.beta.threads.runs.AsyncRunsWithRawResponse.submit_tool_outputs","title":"submit_tool_outputs  <code>instance-attribute</code>","text":"<pre><code>submit_tool_outputs = async_to_raw_response_wrapper(\n    submit_tool_outputs\n)\n</code></pre>"},{"location":"reference/resources/beta/threads/runs/#src.openai.resources.beta.threads.runs.AsyncRunsWithRawResponse.update","title":"update  <code>instance-attribute</code>","text":"<pre><code>update = async_to_raw_response_wrapper(update)\n</code></pre>"},{"location":"reference/resources/beta/threads/runs/#src.openai.resources.beta.threads.runs.AsyncRunsWithRawResponse.steps","title":"steps","text":"<pre><code>steps() -&gt; AsyncStepsWithRawResponse\n</code></pre>"},{"location":"reference/resources/beta/threads/runs/#src.openai.resources.beta.threads.runs.AsyncRunsWithStreamingResponse","title":"AsyncRunsWithStreamingResponse","text":"<pre><code>AsyncRunsWithStreamingResponse(runs: AsyncRuns)\n</code></pre> <p>Methods:</p> Name Description <code>steps</code> <p>Attributes:</p> Name Type Description <code>cancel</code> <code>create</code> <code>list</code> <code>retrieve</code> <code>submit_tool_outputs</code> <code>update</code>"},{"location":"reference/resources/beta/threads/runs/#src.openai.resources.beta.threads.runs.AsyncRunsWithStreamingResponse.cancel","title":"cancel  <code>instance-attribute</code>","text":"<pre><code>cancel = async_to_streamed_response_wrapper(cancel)\n</code></pre>"},{"location":"reference/resources/beta/threads/runs/#src.openai.resources.beta.threads.runs.AsyncRunsWithStreamingResponse.create","title":"create  <code>instance-attribute</code>","text":"<pre><code>create = async_to_streamed_response_wrapper(create)\n</code></pre>"},{"location":"reference/resources/beta/threads/runs/#src.openai.resources.beta.threads.runs.AsyncRunsWithStreamingResponse.list","title":"list  <code>instance-attribute</code>","text":"<pre><code>list = async_to_streamed_response_wrapper(list)\n</code></pre>"},{"location":"reference/resources/beta/threads/runs/#src.openai.resources.beta.threads.runs.AsyncRunsWithStreamingResponse.retrieve","title":"retrieve  <code>instance-attribute</code>","text":"<pre><code>retrieve = async_to_streamed_response_wrapper(retrieve)\n</code></pre>"},{"location":"reference/resources/beta/threads/runs/#src.openai.resources.beta.threads.runs.AsyncRunsWithStreamingResponse.submit_tool_outputs","title":"submit_tool_outputs  <code>instance-attribute</code>","text":"<pre><code>submit_tool_outputs = async_to_streamed_response_wrapper(\n    submit_tool_outputs\n)\n</code></pre>"},{"location":"reference/resources/beta/threads/runs/#src.openai.resources.beta.threads.runs.AsyncRunsWithStreamingResponse.update","title":"update  <code>instance-attribute</code>","text":"<pre><code>update = async_to_streamed_response_wrapper(update)\n</code></pre>"},{"location":"reference/resources/beta/threads/runs/#src.openai.resources.beta.threads.runs.AsyncRunsWithStreamingResponse.steps","title":"steps","text":"<pre><code>steps() -&gt; AsyncStepsWithStreamingResponse\n</code></pre>"},{"location":"reference/resources/beta/threads/runs/#src.openai.resources.beta.threads.runs.AsyncSteps","title":"AsyncSteps","text":"<pre><code>AsyncSteps(client: AsyncOpenAI)\n</code></pre> <p>Methods:</p> Name Description <code>list</code> <p>Returns a list of run steps belonging to a run.</p> <code>retrieve</code> <p>Retrieves a run step.</p> <code>with_raw_response</code> <code>with_streaming_response</code>"},{"location":"reference/resources/beta/threads/runs/#src.openai.resources.beta.threads.runs.AsyncSteps.list","title":"list","text":"<pre><code>list(\n    run_id: str,\n    *,\n    thread_id: str,\n    after: str | NotGiven = NOT_GIVEN,\n    before: str | NotGiven = NOT_GIVEN,\n    limit: int | NotGiven = NOT_GIVEN,\n    order: Literal[\"asc\", \"desc\"] | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; AsyncPaginator[RunStep, AsyncCursorPage[RunStep]]\n</code></pre> <p>Returns a list of run steps belonging to a run.</p> <p>Parameters:</p> Name Type Description Default <code>after</code> <code>str | NotGiven</code> <p>A cursor for use in pagination. <code>after</code> is an object ID that defines your place   in the list. For instance, if you make a list request and receive 100 objects,   ending with obj_foo, your subsequent call can include after=obj_foo in order to   fetch the next page of the list.</p> <code>NOT_GIVEN</code> <code>before</code> <code>str | NotGiven</code> <p>A cursor for use in pagination. <code>before</code> is an object ID that defines your place   in the list. For instance, if you make a list request and receive 100 objects,   ending with obj_foo, your subsequent call can include before=obj_foo in order to   fetch the previous page of the list.</p> <code>NOT_GIVEN</code> <code>limit</code> <code>int | NotGiven</code> <p>A limit on the number of objects to be returned. Limit can range between 1 and   100, and the default is 20.</p> <code>NOT_GIVEN</code> <code>order</code> <code>Literal['asc', 'desc'] | NotGiven</code> <p>Sort order by the <code>created_at</code> timestamp of the objects. <code>asc</code> for ascending   order and <code>desc</code> for descending order.</p> <code>NOT_GIVEN</code> <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/beta/threads/runs/#src.openai.resources.beta.threads.runs.AsyncSteps.retrieve","title":"retrieve  <code>async</code>","text":"<pre><code>retrieve(\n    step_id: str,\n    *,\n    thread_id: str,\n    run_id: str,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; RunStep\n</code></pre> <p>Retrieves a run step.</p> <p>Parameters:</p> Name Type Description Default <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/beta/threads/runs/#src.openai.resources.beta.threads.runs.AsyncSteps.with_raw_response","title":"with_raw_response","text":"<pre><code>with_raw_response() -&gt; AsyncStepsWithRawResponse\n</code></pre>"},{"location":"reference/resources/beta/threads/runs/#src.openai.resources.beta.threads.runs.AsyncSteps.with_streaming_response","title":"with_streaming_response","text":"<pre><code>with_streaming_response() -&gt; (\n    AsyncStepsWithStreamingResponse\n)\n</code></pre>"},{"location":"reference/resources/beta/threads/runs/#src.openai.resources.beta.threads.runs.AsyncStepsWithRawResponse","title":"AsyncStepsWithRawResponse","text":"<pre><code>AsyncStepsWithRawResponse(steps: AsyncSteps)\n</code></pre> <p>Attributes:</p> Name Type Description <code>list</code> <code>retrieve</code>"},{"location":"reference/resources/beta/threads/runs/#src.openai.resources.beta.threads.runs.AsyncStepsWithRawResponse.list","title":"list  <code>instance-attribute</code>","text":"<pre><code>list = async_to_raw_response_wrapper(list)\n</code></pre>"},{"location":"reference/resources/beta/threads/runs/#src.openai.resources.beta.threads.runs.AsyncStepsWithRawResponse.retrieve","title":"retrieve  <code>instance-attribute</code>","text":"<pre><code>retrieve = async_to_raw_response_wrapper(retrieve)\n</code></pre>"},{"location":"reference/resources/beta/threads/runs/#src.openai.resources.beta.threads.runs.AsyncStepsWithStreamingResponse","title":"AsyncStepsWithStreamingResponse","text":"<pre><code>AsyncStepsWithStreamingResponse(steps: AsyncSteps)\n</code></pre> <p>Attributes:</p> Name Type Description <code>list</code> <code>retrieve</code>"},{"location":"reference/resources/beta/threads/runs/#src.openai.resources.beta.threads.runs.AsyncStepsWithStreamingResponse.list","title":"list  <code>instance-attribute</code>","text":"<pre><code>list = async_to_streamed_response_wrapper(list)\n</code></pre>"},{"location":"reference/resources/beta/threads/runs/#src.openai.resources.beta.threads.runs.AsyncStepsWithStreamingResponse.retrieve","title":"retrieve  <code>instance-attribute</code>","text":"<pre><code>retrieve = async_to_streamed_response_wrapper(retrieve)\n</code></pre>"},{"location":"reference/resources/beta/threads/runs/#src.openai.resources.beta.threads.runs.Runs","title":"Runs","text":"<pre><code>Runs(client: OpenAI)\n</code></pre> <p>Methods:</p> Name Description <code>cancel</code> <p>Cancels a run that is <code>in_progress</code>.</p> <code>create</code> <p>Create a run.</p> <code>list</code> <p>Returns a list of runs belonging to a thread.</p> <code>retrieve</code> <p>Retrieves a run.</p> <code>steps</code> <code>submit_tool_outputs</code> <p>When a run has the <code>status: \"requires_action\"</code> and <code>required_action.type</code> is</p> <code>update</code> <p>Modifies a run.</p> <code>with_raw_response</code> <code>with_streaming_response</code>"},{"location":"reference/resources/beta/threads/runs/#src.openai.resources.beta.threads.runs.Runs.cancel","title":"cancel","text":"<pre><code>cancel(\n    run_id: str,\n    *,\n    thread_id: str,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; Run\n</code></pre> <p>Cancels a run that is <code>in_progress</code>.</p> <p>Parameters:</p> Name Type Description Default <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/beta/threads/runs/#src.openai.resources.beta.threads.runs.Runs.create","title":"create","text":"<pre><code>create(\n    thread_id: str,\n    *,\n    assistant_id: str,\n    additional_instructions: (\n        Optional[str] | NotGiven\n    ) = NOT_GIVEN,\n    instructions: Optional[str] | NotGiven = NOT_GIVEN,\n    metadata: Optional[object] | NotGiven = NOT_GIVEN,\n    model: Optional[str] | NotGiven = NOT_GIVEN,\n    tools: Optional[Iterable[Tool]] | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; Run\n</code></pre> <p>Create a run.</p> <p>Parameters:</p> Name Type Description Default <code>assistant_id</code> <code>str</code> <p>The ID of the   assistant to use to   execute this run.</p> required <code>additional_instructions</code> <code>Optional[str] | NotGiven</code> <p>Appends additional instructions at the end of the instructions for the run. This   is useful for modifying the behavior on a per-run basis without overriding other   instructions.</p> <code>NOT_GIVEN</code> <code>instructions</code> <code>Optional[str] | NotGiven</code> <p>Overrides the   instructions   of the assistant. This is useful for modifying the behavior on a per-run basis.</p> <code>NOT_GIVEN</code> <code>metadata</code> <code>Optional[object] | NotGiven</code> <p>Set of 16 key-value pairs that can be attached to an object. This can be useful   for storing additional information about the object in a structured format. Keys   can be a maximum of 64 characters long and values can be a maxium of 512   characters long.</p> <code>NOT_GIVEN</code> <code>model</code> <code>Optional[str] | NotGiven</code> <p>The ID of the Model to   be used to execute this run. If a value is provided here, it will override the   model associated with the assistant. If not, the model associated with the   assistant will be used.</p> <code>NOT_GIVEN</code> <code>tools</code> <code>Optional[Iterable[Tool]] | NotGiven</code> <p>Override the tools the assistant can use for this run. This is useful for   modifying the behavior on a per-run basis.</p> <code>NOT_GIVEN</code> <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/beta/threads/runs/#src.openai.resources.beta.threads.runs.Runs.list","title":"list","text":"<pre><code>list(\n    thread_id: str,\n    *,\n    after: str | NotGiven = NOT_GIVEN,\n    before: str | NotGiven = NOT_GIVEN,\n    limit: int | NotGiven = NOT_GIVEN,\n    order: Literal[\"asc\", \"desc\"] | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; SyncCursorPage[Run]\n</code></pre> <p>Returns a list of runs belonging to a thread.</p> <p>Parameters:</p> Name Type Description Default <code>after</code> <code>str | NotGiven</code> <p>A cursor for use in pagination. <code>after</code> is an object ID that defines your place   in the list. For instance, if you make a list request and receive 100 objects,   ending with obj_foo, your subsequent call can include after=obj_foo in order to   fetch the next page of the list.</p> <code>NOT_GIVEN</code> <code>before</code> <code>str | NotGiven</code> <p>A cursor for use in pagination. <code>before</code> is an object ID that defines your place   in the list. For instance, if you make a list request and receive 100 objects,   ending with obj_foo, your subsequent call can include before=obj_foo in order to   fetch the previous page of the list.</p> <code>NOT_GIVEN</code> <code>limit</code> <code>int | NotGiven</code> <p>A limit on the number of objects to be returned. Limit can range between 1 and   100, and the default is 20.</p> <code>NOT_GIVEN</code> <code>order</code> <code>Literal['asc', 'desc'] | NotGiven</code> <p>Sort order by the <code>created_at</code> timestamp of the objects. <code>asc</code> for ascending   order and <code>desc</code> for descending order.</p> <code>NOT_GIVEN</code> <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/beta/threads/runs/#src.openai.resources.beta.threads.runs.Runs.retrieve","title":"retrieve","text":"<pre><code>retrieve(\n    run_id: str,\n    *,\n    thread_id: str,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; Run\n</code></pre> <p>Retrieves a run.</p> <p>Parameters:</p> Name Type Description Default <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/beta/threads/runs/#src.openai.resources.beta.threads.runs.Runs.steps","title":"steps","text":"<pre><code>steps() -&gt; Steps\n</code></pre>"},{"location":"reference/resources/beta/threads/runs/#src.openai.resources.beta.threads.runs.Runs.submit_tool_outputs","title":"submit_tool_outputs","text":"<pre><code>submit_tool_outputs(\n    run_id: str,\n    *,\n    thread_id: str,\n    tool_outputs: Iterable[ToolOutput],\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; Run\n</code></pre> <p>When a run has the <code>status: \"requires_action\"</code> and <code>required_action.type</code> is <code>submit_tool_outputs</code>, this endpoint can be used to submit the outputs from the tool calls once they're all completed. All outputs must be submitted in a single request.</p> <p>Parameters:</p> Name Type Description Default <code>tool_outputs</code> <code>Iterable[ToolOutput]</code> <p>A list of tools for which the outputs are being submitted.</p> required <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/beta/threads/runs/#src.openai.resources.beta.threads.runs.Runs.update","title":"update","text":"<pre><code>update(\n    run_id: str,\n    *,\n    thread_id: str,\n    metadata: Optional[object] | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; Run\n</code></pre> <p>Modifies a run.</p> <p>Parameters:</p> Name Type Description Default <code>metadata</code> <code>Optional[object] | NotGiven</code> <p>Set of 16 key-value pairs that can be attached to an object. This can be useful   for storing additional information about the object in a structured format. Keys   can be a maximum of 64 characters long and values can be a maxium of 512   characters long.</p> <code>NOT_GIVEN</code> <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/beta/threads/runs/#src.openai.resources.beta.threads.runs.Runs.with_raw_response","title":"with_raw_response","text":"<pre><code>with_raw_response() -&gt; RunsWithRawResponse\n</code></pre>"},{"location":"reference/resources/beta/threads/runs/#src.openai.resources.beta.threads.runs.Runs.with_streaming_response","title":"with_streaming_response","text":"<pre><code>with_streaming_response() -&gt; RunsWithStreamingResponse\n</code></pre>"},{"location":"reference/resources/beta/threads/runs/#src.openai.resources.beta.threads.runs.RunsWithRawResponse","title":"RunsWithRawResponse","text":"<pre><code>RunsWithRawResponse(runs: Runs)\n</code></pre> <p>Methods:</p> Name Description <code>steps</code> <p>Attributes:</p> Name Type Description <code>cancel</code> <code>create</code> <code>list</code> <code>retrieve</code> <code>submit_tool_outputs</code> <code>update</code>"},{"location":"reference/resources/beta/threads/runs/#src.openai.resources.beta.threads.runs.RunsWithRawResponse.cancel","title":"cancel  <code>instance-attribute</code>","text":"<pre><code>cancel = to_raw_response_wrapper(cancel)\n</code></pre>"},{"location":"reference/resources/beta/threads/runs/#src.openai.resources.beta.threads.runs.RunsWithRawResponse.create","title":"create  <code>instance-attribute</code>","text":"<pre><code>create = to_raw_response_wrapper(create)\n</code></pre>"},{"location":"reference/resources/beta/threads/runs/#src.openai.resources.beta.threads.runs.RunsWithRawResponse.list","title":"list  <code>instance-attribute</code>","text":"<pre><code>list = to_raw_response_wrapper(list)\n</code></pre>"},{"location":"reference/resources/beta/threads/runs/#src.openai.resources.beta.threads.runs.RunsWithRawResponse.retrieve","title":"retrieve  <code>instance-attribute</code>","text":"<pre><code>retrieve = to_raw_response_wrapper(retrieve)\n</code></pre>"},{"location":"reference/resources/beta/threads/runs/#src.openai.resources.beta.threads.runs.RunsWithRawResponse.submit_tool_outputs","title":"submit_tool_outputs  <code>instance-attribute</code>","text":"<pre><code>submit_tool_outputs = to_raw_response_wrapper(\n    submit_tool_outputs\n)\n</code></pre>"},{"location":"reference/resources/beta/threads/runs/#src.openai.resources.beta.threads.runs.RunsWithRawResponse.update","title":"update  <code>instance-attribute</code>","text":"<pre><code>update = to_raw_response_wrapper(update)\n</code></pre>"},{"location":"reference/resources/beta/threads/runs/#src.openai.resources.beta.threads.runs.RunsWithRawResponse.steps","title":"steps","text":"<pre><code>steps() -&gt; StepsWithRawResponse\n</code></pre>"},{"location":"reference/resources/beta/threads/runs/#src.openai.resources.beta.threads.runs.RunsWithStreamingResponse","title":"RunsWithStreamingResponse","text":"<pre><code>RunsWithStreamingResponse(runs: Runs)\n</code></pre> <p>Methods:</p> Name Description <code>steps</code> <p>Attributes:</p> Name Type Description <code>cancel</code> <code>create</code> <code>list</code> <code>retrieve</code> <code>submit_tool_outputs</code> <code>update</code>"},{"location":"reference/resources/beta/threads/runs/#src.openai.resources.beta.threads.runs.RunsWithStreamingResponse.cancel","title":"cancel  <code>instance-attribute</code>","text":"<pre><code>cancel = to_streamed_response_wrapper(cancel)\n</code></pre>"},{"location":"reference/resources/beta/threads/runs/#src.openai.resources.beta.threads.runs.RunsWithStreamingResponse.create","title":"create  <code>instance-attribute</code>","text":"<pre><code>create = to_streamed_response_wrapper(create)\n</code></pre>"},{"location":"reference/resources/beta/threads/runs/#src.openai.resources.beta.threads.runs.RunsWithStreamingResponse.list","title":"list  <code>instance-attribute</code>","text":"<pre><code>list = to_streamed_response_wrapper(list)\n</code></pre>"},{"location":"reference/resources/beta/threads/runs/#src.openai.resources.beta.threads.runs.RunsWithStreamingResponse.retrieve","title":"retrieve  <code>instance-attribute</code>","text":"<pre><code>retrieve = to_streamed_response_wrapper(retrieve)\n</code></pre>"},{"location":"reference/resources/beta/threads/runs/#src.openai.resources.beta.threads.runs.RunsWithStreamingResponse.submit_tool_outputs","title":"submit_tool_outputs  <code>instance-attribute</code>","text":"<pre><code>submit_tool_outputs = to_streamed_response_wrapper(\n    submit_tool_outputs\n)\n</code></pre>"},{"location":"reference/resources/beta/threads/runs/#src.openai.resources.beta.threads.runs.RunsWithStreamingResponse.update","title":"update  <code>instance-attribute</code>","text":"<pre><code>update = to_streamed_response_wrapper(update)\n</code></pre>"},{"location":"reference/resources/beta/threads/runs/#src.openai.resources.beta.threads.runs.RunsWithStreamingResponse.steps","title":"steps","text":"<pre><code>steps() -&gt; StepsWithStreamingResponse\n</code></pre>"},{"location":"reference/resources/beta/threads/runs/#src.openai.resources.beta.threads.runs.Steps","title":"Steps","text":"<pre><code>Steps(client: OpenAI)\n</code></pre> <p>Methods:</p> Name Description <code>list</code> <p>Returns a list of run steps belonging to a run.</p> <code>retrieve</code> <p>Retrieves a run step.</p> <code>with_raw_response</code> <code>with_streaming_response</code>"},{"location":"reference/resources/beta/threads/runs/#src.openai.resources.beta.threads.runs.Steps.list","title":"list","text":"<pre><code>list(\n    run_id: str,\n    *,\n    thread_id: str,\n    after: str | NotGiven = NOT_GIVEN,\n    before: str | NotGiven = NOT_GIVEN,\n    limit: int | NotGiven = NOT_GIVEN,\n    order: Literal[\"asc\", \"desc\"] | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; SyncCursorPage[RunStep]\n</code></pre> <p>Returns a list of run steps belonging to a run.</p> <p>Parameters:</p> Name Type Description Default <code>after</code> <code>str | NotGiven</code> <p>A cursor for use in pagination. <code>after</code> is an object ID that defines your place   in the list. For instance, if you make a list request and receive 100 objects,   ending with obj_foo, your subsequent call can include after=obj_foo in order to   fetch the next page of the list.</p> <code>NOT_GIVEN</code> <code>before</code> <code>str | NotGiven</code> <p>A cursor for use in pagination. <code>before</code> is an object ID that defines your place   in the list. For instance, if you make a list request and receive 100 objects,   ending with obj_foo, your subsequent call can include before=obj_foo in order to   fetch the previous page of the list.</p> <code>NOT_GIVEN</code> <code>limit</code> <code>int | NotGiven</code> <p>A limit on the number of objects to be returned. Limit can range between 1 and   100, and the default is 20.</p> <code>NOT_GIVEN</code> <code>order</code> <code>Literal['asc', 'desc'] | NotGiven</code> <p>Sort order by the <code>created_at</code> timestamp of the objects. <code>asc</code> for ascending   order and <code>desc</code> for descending order.</p> <code>NOT_GIVEN</code> <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/beta/threads/runs/#src.openai.resources.beta.threads.runs.Steps.retrieve","title":"retrieve","text":"<pre><code>retrieve(\n    step_id: str,\n    *,\n    thread_id: str,\n    run_id: str,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; RunStep\n</code></pre> <p>Retrieves a run step.</p> <p>Parameters:</p> Name Type Description Default <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/beta/threads/runs/#src.openai.resources.beta.threads.runs.Steps.with_raw_response","title":"with_raw_response","text":"<pre><code>with_raw_response() -&gt; StepsWithRawResponse\n</code></pre>"},{"location":"reference/resources/beta/threads/runs/#src.openai.resources.beta.threads.runs.Steps.with_streaming_response","title":"with_streaming_response","text":"<pre><code>with_streaming_response() -&gt; StepsWithStreamingResponse\n</code></pre>"},{"location":"reference/resources/beta/threads/runs/#src.openai.resources.beta.threads.runs.StepsWithRawResponse","title":"StepsWithRawResponse","text":"<pre><code>StepsWithRawResponse(steps: Steps)\n</code></pre> <p>Attributes:</p> Name Type Description <code>list</code> <code>retrieve</code>"},{"location":"reference/resources/beta/threads/runs/#src.openai.resources.beta.threads.runs.StepsWithRawResponse.list","title":"list  <code>instance-attribute</code>","text":"<pre><code>list = to_raw_response_wrapper(list)\n</code></pre>"},{"location":"reference/resources/beta/threads/runs/#src.openai.resources.beta.threads.runs.StepsWithRawResponse.retrieve","title":"retrieve  <code>instance-attribute</code>","text":"<pre><code>retrieve = to_raw_response_wrapper(retrieve)\n</code></pre>"},{"location":"reference/resources/beta/threads/runs/#src.openai.resources.beta.threads.runs.StepsWithStreamingResponse","title":"StepsWithStreamingResponse","text":"<pre><code>StepsWithStreamingResponse(steps: Steps)\n</code></pre> <p>Attributes:</p> Name Type Description <code>list</code> <code>retrieve</code>"},{"location":"reference/resources/beta/threads/runs/#src.openai.resources.beta.threads.runs.StepsWithStreamingResponse.list","title":"list  <code>instance-attribute</code>","text":"<pre><code>list = to_streamed_response_wrapper(list)\n</code></pre>"},{"location":"reference/resources/beta/threads/runs/#src.openai.resources.beta.threads.runs.StepsWithStreamingResponse.retrieve","title":"retrieve  <code>instance-attribute</code>","text":"<pre><code>retrieve = to_streamed_response_wrapper(retrieve)\n</code></pre>"},{"location":"reference/resources/beta/threads/runs/runs/","title":"runs","text":"<p>Classes:</p> Name Description <code>AsyncRuns</code> <code>AsyncRunsWithRawResponse</code> <code>AsyncRunsWithStreamingResponse</code> <code>Runs</code> <code>RunsWithRawResponse</code> <code>RunsWithStreamingResponse</code>"},{"location":"reference/resources/beta/threads/runs/runs/#src.openai.resources.beta.threads.runs.runs.AsyncRuns","title":"AsyncRuns","text":"<pre><code>AsyncRuns(client: AsyncOpenAI)\n</code></pre> <p>Methods:</p> Name Description <code>cancel</code> <p>Cancels a run that is <code>in_progress</code>.</p> <code>create</code> <p>Create a run.</p> <code>list</code> <p>Returns a list of runs belonging to a thread.</p> <code>retrieve</code> <p>Retrieves a run.</p> <code>steps</code> <code>submit_tool_outputs</code> <p>When a run has the <code>status: \"requires_action\"</code> and <code>required_action.type</code> is</p> <code>update</code> <p>Modifies a run.</p> <code>with_raw_response</code> <code>with_streaming_response</code>"},{"location":"reference/resources/beta/threads/runs/runs/#src.openai.resources.beta.threads.runs.runs.AsyncRuns.cancel","title":"cancel  <code>async</code>","text":"<pre><code>cancel(\n    run_id: str,\n    *,\n    thread_id: str,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; Run\n</code></pre> <p>Cancels a run that is <code>in_progress</code>.</p> <p>Parameters:</p> Name Type Description Default <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/beta/threads/runs/runs/#src.openai.resources.beta.threads.runs.runs.AsyncRuns.create","title":"create  <code>async</code>","text":"<pre><code>create(\n    thread_id: str,\n    *,\n    assistant_id: str,\n    additional_instructions: (\n        Optional[str] | NotGiven\n    ) = NOT_GIVEN,\n    instructions: Optional[str] | NotGiven = NOT_GIVEN,\n    metadata: Optional[object] | NotGiven = NOT_GIVEN,\n    model: Optional[str] | NotGiven = NOT_GIVEN,\n    tools: Optional[Iterable[Tool]] | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; Run\n</code></pre> <p>Create a run.</p> <p>Parameters:</p> Name Type Description Default <code>assistant_id</code> <code>str</code> <p>The ID of the   assistant to use to   execute this run.</p> required <code>additional_instructions</code> <code>Optional[str] | NotGiven</code> <p>Appends additional instructions at the end of the instructions for the run. This   is useful for modifying the behavior on a per-run basis without overriding other   instructions.</p> <code>NOT_GIVEN</code> <code>instructions</code> <code>Optional[str] | NotGiven</code> <p>Overrides the   instructions   of the assistant. This is useful for modifying the behavior on a per-run basis.</p> <code>NOT_GIVEN</code> <code>metadata</code> <code>Optional[object] | NotGiven</code> <p>Set of 16 key-value pairs that can be attached to an object. This can be useful   for storing additional information about the object in a structured format. Keys   can be a maximum of 64 characters long and values can be a maxium of 512   characters long.</p> <code>NOT_GIVEN</code> <code>model</code> <code>Optional[str] | NotGiven</code> <p>The ID of the Model to   be used to execute this run. If a value is provided here, it will override the   model associated with the assistant. If not, the model associated with the   assistant will be used.</p> <code>NOT_GIVEN</code> <code>tools</code> <code>Optional[Iterable[Tool]] | NotGiven</code> <p>Override the tools the assistant can use for this run. This is useful for   modifying the behavior on a per-run basis.</p> <code>NOT_GIVEN</code> <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/beta/threads/runs/runs/#src.openai.resources.beta.threads.runs.runs.AsyncRuns.list","title":"list","text":"<pre><code>list(\n    thread_id: str,\n    *,\n    after: str | NotGiven = NOT_GIVEN,\n    before: str | NotGiven = NOT_GIVEN,\n    limit: int | NotGiven = NOT_GIVEN,\n    order: Literal[\"asc\", \"desc\"] | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; AsyncPaginator[Run, AsyncCursorPage[Run]]\n</code></pre> <p>Returns a list of runs belonging to a thread.</p> <p>Parameters:</p> Name Type Description Default <code>after</code> <code>str | NotGiven</code> <p>A cursor for use in pagination. <code>after</code> is an object ID that defines your place   in the list. For instance, if you make a list request and receive 100 objects,   ending with obj_foo, your subsequent call can include after=obj_foo in order to   fetch the next page of the list.</p> <code>NOT_GIVEN</code> <code>before</code> <code>str | NotGiven</code> <p>A cursor for use in pagination. <code>before</code> is an object ID that defines your place   in the list. For instance, if you make a list request and receive 100 objects,   ending with obj_foo, your subsequent call can include before=obj_foo in order to   fetch the previous page of the list.</p> <code>NOT_GIVEN</code> <code>limit</code> <code>int | NotGiven</code> <p>A limit on the number of objects to be returned. Limit can range between 1 and   100, and the default is 20.</p> <code>NOT_GIVEN</code> <code>order</code> <code>Literal['asc', 'desc'] | NotGiven</code> <p>Sort order by the <code>created_at</code> timestamp of the objects. <code>asc</code> for ascending   order and <code>desc</code> for descending order.</p> <code>NOT_GIVEN</code> <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/beta/threads/runs/runs/#src.openai.resources.beta.threads.runs.runs.AsyncRuns.retrieve","title":"retrieve  <code>async</code>","text":"<pre><code>retrieve(\n    run_id: str,\n    *,\n    thread_id: str,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; Run\n</code></pre> <p>Retrieves a run.</p> <p>Parameters:</p> Name Type Description Default <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/beta/threads/runs/runs/#src.openai.resources.beta.threads.runs.runs.AsyncRuns.steps","title":"steps","text":"<pre><code>steps() -&gt; AsyncSteps\n</code></pre>"},{"location":"reference/resources/beta/threads/runs/runs/#src.openai.resources.beta.threads.runs.runs.AsyncRuns.submit_tool_outputs","title":"submit_tool_outputs  <code>async</code>","text":"<pre><code>submit_tool_outputs(\n    run_id: str,\n    *,\n    thread_id: str,\n    tool_outputs: Iterable[ToolOutput],\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; Run\n</code></pre> <p>When a run has the <code>status: \"requires_action\"</code> and <code>required_action.type</code> is <code>submit_tool_outputs</code>, this endpoint can be used to submit the outputs from the tool calls once they're all completed. All outputs must be submitted in a single request.</p> <p>Parameters:</p> Name Type Description Default <code>tool_outputs</code> <code>Iterable[ToolOutput]</code> <p>A list of tools for which the outputs are being submitted.</p> required <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/beta/threads/runs/runs/#src.openai.resources.beta.threads.runs.runs.AsyncRuns.update","title":"update  <code>async</code>","text":"<pre><code>update(\n    run_id: str,\n    *,\n    thread_id: str,\n    metadata: Optional[object] | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; Run\n</code></pre> <p>Modifies a run.</p> <p>Parameters:</p> Name Type Description Default <code>metadata</code> <code>Optional[object] | NotGiven</code> <p>Set of 16 key-value pairs that can be attached to an object. This can be useful   for storing additional information about the object in a structured format. Keys   can be a maximum of 64 characters long and values can be a maxium of 512   characters long.</p> <code>NOT_GIVEN</code> <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/beta/threads/runs/runs/#src.openai.resources.beta.threads.runs.runs.AsyncRuns.with_raw_response","title":"with_raw_response","text":"<pre><code>with_raw_response() -&gt; AsyncRunsWithRawResponse\n</code></pre>"},{"location":"reference/resources/beta/threads/runs/runs/#src.openai.resources.beta.threads.runs.runs.AsyncRuns.with_streaming_response","title":"with_streaming_response","text":"<pre><code>with_streaming_response() -&gt; AsyncRunsWithStreamingResponse\n</code></pre>"},{"location":"reference/resources/beta/threads/runs/runs/#src.openai.resources.beta.threads.runs.runs.AsyncRunsWithRawResponse","title":"AsyncRunsWithRawResponse","text":"<pre><code>AsyncRunsWithRawResponse(runs: AsyncRuns)\n</code></pre> <p>Methods:</p> Name Description <code>steps</code> <p>Attributes:</p> Name Type Description <code>cancel</code> <code>create</code> <code>list</code> <code>retrieve</code> <code>submit_tool_outputs</code> <code>update</code>"},{"location":"reference/resources/beta/threads/runs/runs/#src.openai.resources.beta.threads.runs.runs.AsyncRunsWithRawResponse.cancel","title":"cancel  <code>instance-attribute</code>","text":"<pre><code>cancel = async_to_raw_response_wrapper(cancel)\n</code></pre>"},{"location":"reference/resources/beta/threads/runs/runs/#src.openai.resources.beta.threads.runs.runs.AsyncRunsWithRawResponse.create","title":"create  <code>instance-attribute</code>","text":"<pre><code>create = async_to_raw_response_wrapper(create)\n</code></pre>"},{"location":"reference/resources/beta/threads/runs/runs/#src.openai.resources.beta.threads.runs.runs.AsyncRunsWithRawResponse.list","title":"list  <code>instance-attribute</code>","text":"<pre><code>list = async_to_raw_response_wrapper(list)\n</code></pre>"},{"location":"reference/resources/beta/threads/runs/runs/#src.openai.resources.beta.threads.runs.runs.AsyncRunsWithRawResponse.retrieve","title":"retrieve  <code>instance-attribute</code>","text":"<pre><code>retrieve = async_to_raw_response_wrapper(retrieve)\n</code></pre>"},{"location":"reference/resources/beta/threads/runs/runs/#src.openai.resources.beta.threads.runs.runs.AsyncRunsWithRawResponse.submit_tool_outputs","title":"submit_tool_outputs  <code>instance-attribute</code>","text":"<pre><code>submit_tool_outputs = async_to_raw_response_wrapper(\n    submit_tool_outputs\n)\n</code></pre>"},{"location":"reference/resources/beta/threads/runs/runs/#src.openai.resources.beta.threads.runs.runs.AsyncRunsWithRawResponse.update","title":"update  <code>instance-attribute</code>","text":"<pre><code>update = async_to_raw_response_wrapper(update)\n</code></pre>"},{"location":"reference/resources/beta/threads/runs/runs/#src.openai.resources.beta.threads.runs.runs.AsyncRunsWithRawResponse.steps","title":"steps","text":"<pre><code>steps() -&gt; AsyncStepsWithRawResponse\n</code></pre>"},{"location":"reference/resources/beta/threads/runs/runs/#src.openai.resources.beta.threads.runs.runs.AsyncRunsWithStreamingResponse","title":"AsyncRunsWithStreamingResponse","text":"<pre><code>AsyncRunsWithStreamingResponse(runs: AsyncRuns)\n</code></pre> <p>Methods:</p> Name Description <code>steps</code> <p>Attributes:</p> Name Type Description <code>cancel</code> <code>create</code> <code>list</code> <code>retrieve</code> <code>submit_tool_outputs</code> <code>update</code>"},{"location":"reference/resources/beta/threads/runs/runs/#src.openai.resources.beta.threads.runs.runs.AsyncRunsWithStreamingResponse.cancel","title":"cancel  <code>instance-attribute</code>","text":"<pre><code>cancel = async_to_streamed_response_wrapper(cancel)\n</code></pre>"},{"location":"reference/resources/beta/threads/runs/runs/#src.openai.resources.beta.threads.runs.runs.AsyncRunsWithStreamingResponse.create","title":"create  <code>instance-attribute</code>","text":"<pre><code>create = async_to_streamed_response_wrapper(create)\n</code></pre>"},{"location":"reference/resources/beta/threads/runs/runs/#src.openai.resources.beta.threads.runs.runs.AsyncRunsWithStreamingResponse.list","title":"list  <code>instance-attribute</code>","text":"<pre><code>list = async_to_streamed_response_wrapper(list)\n</code></pre>"},{"location":"reference/resources/beta/threads/runs/runs/#src.openai.resources.beta.threads.runs.runs.AsyncRunsWithStreamingResponse.retrieve","title":"retrieve  <code>instance-attribute</code>","text":"<pre><code>retrieve = async_to_streamed_response_wrapper(retrieve)\n</code></pre>"},{"location":"reference/resources/beta/threads/runs/runs/#src.openai.resources.beta.threads.runs.runs.AsyncRunsWithStreamingResponse.submit_tool_outputs","title":"submit_tool_outputs  <code>instance-attribute</code>","text":"<pre><code>submit_tool_outputs = async_to_streamed_response_wrapper(\n    submit_tool_outputs\n)\n</code></pre>"},{"location":"reference/resources/beta/threads/runs/runs/#src.openai.resources.beta.threads.runs.runs.AsyncRunsWithStreamingResponse.update","title":"update  <code>instance-attribute</code>","text":"<pre><code>update = async_to_streamed_response_wrapper(update)\n</code></pre>"},{"location":"reference/resources/beta/threads/runs/runs/#src.openai.resources.beta.threads.runs.runs.AsyncRunsWithStreamingResponse.steps","title":"steps","text":"<pre><code>steps() -&gt; AsyncStepsWithStreamingResponse\n</code></pre>"},{"location":"reference/resources/beta/threads/runs/runs/#src.openai.resources.beta.threads.runs.runs.Runs","title":"Runs","text":"<pre><code>Runs(client: OpenAI)\n</code></pre> <p>Methods:</p> Name Description <code>cancel</code> <p>Cancels a run that is <code>in_progress</code>.</p> <code>create</code> <p>Create a run.</p> <code>list</code> <p>Returns a list of runs belonging to a thread.</p> <code>retrieve</code> <p>Retrieves a run.</p> <code>steps</code> <code>submit_tool_outputs</code> <p>When a run has the <code>status: \"requires_action\"</code> and <code>required_action.type</code> is</p> <code>update</code> <p>Modifies a run.</p> <code>with_raw_response</code> <code>with_streaming_response</code>"},{"location":"reference/resources/beta/threads/runs/runs/#src.openai.resources.beta.threads.runs.runs.Runs.cancel","title":"cancel","text":"<pre><code>cancel(\n    run_id: str,\n    *,\n    thread_id: str,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; Run\n</code></pre> <p>Cancels a run that is <code>in_progress</code>.</p> <p>Parameters:</p> Name Type Description Default <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/beta/threads/runs/runs/#src.openai.resources.beta.threads.runs.runs.Runs.create","title":"create","text":"<pre><code>create(\n    thread_id: str,\n    *,\n    assistant_id: str,\n    additional_instructions: (\n        Optional[str] | NotGiven\n    ) = NOT_GIVEN,\n    instructions: Optional[str] | NotGiven = NOT_GIVEN,\n    metadata: Optional[object] | NotGiven = NOT_GIVEN,\n    model: Optional[str] | NotGiven = NOT_GIVEN,\n    tools: Optional[Iterable[Tool]] | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; Run\n</code></pre> <p>Create a run.</p> <p>Parameters:</p> Name Type Description Default <code>assistant_id</code> <code>str</code> <p>The ID of the   assistant to use to   execute this run.</p> required <code>additional_instructions</code> <code>Optional[str] | NotGiven</code> <p>Appends additional instructions at the end of the instructions for the run. This   is useful for modifying the behavior on a per-run basis without overriding other   instructions.</p> <code>NOT_GIVEN</code> <code>instructions</code> <code>Optional[str] | NotGiven</code> <p>Overrides the   instructions   of the assistant. This is useful for modifying the behavior on a per-run basis.</p> <code>NOT_GIVEN</code> <code>metadata</code> <code>Optional[object] | NotGiven</code> <p>Set of 16 key-value pairs that can be attached to an object. This can be useful   for storing additional information about the object in a structured format. Keys   can be a maximum of 64 characters long and values can be a maxium of 512   characters long.</p> <code>NOT_GIVEN</code> <code>model</code> <code>Optional[str] | NotGiven</code> <p>The ID of the Model to   be used to execute this run. If a value is provided here, it will override the   model associated with the assistant. If not, the model associated with the   assistant will be used.</p> <code>NOT_GIVEN</code> <code>tools</code> <code>Optional[Iterable[Tool]] | NotGiven</code> <p>Override the tools the assistant can use for this run. This is useful for   modifying the behavior on a per-run basis.</p> <code>NOT_GIVEN</code> <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/beta/threads/runs/runs/#src.openai.resources.beta.threads.runs.runs.Runs.list","title":"list","text":"<pre><code>list(\n    thread_id: str,\n    *,\n    after: str | NotGiven = NOT_GIVEN,\n    before: str | NotGiven = NOT_GIVEN,\n    limit: int | NotGiven = NOT_GIVEN,\n    order: Literal[\"asc\", \"desc\"] | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; SyncCursorPage[Run]\n</code></pre> <p>Returns a list of runs belonging to a thread.</p> <p>Parameters:</p> Name Type Description Default <code>after</code> <code>str | NotGiven</code> <p>A cursor for use in pagination. <code>after</code> is an object ID that defines your place   in the list. For instance, if you make a list request and receive 100 objects,   ending with obj_foo, your subsequent call can include after=obj_foo in order to   fetch the next page of the list.</p> <code>NOT_GIVEN</code> <code>before</code> <code>str | NotGiven</code> <p>A cursor for use in pagination. <code>before</code> is an object ID that defines your place   in the list. For instance, if you make a list request and receive 100 objects,   ending with obj_foo, your subsequent call can include before=obj_foo in order to   fetch the previous page of the list.</p> <code>NOT_GIVEN</code> <code>limit</code> <code>int | NotGiven</code> <p>A limit on the number of objects to be returned. Limit can range between 1 and   100, and the default is 20.</p> <code>NOT_GIVEN</code> <code>order</code> <code>Literal['asc', 'desc'] | NotGiven</code> <p>Sort order by the <code>created_at</code> timestamp of the objects. <code>asc</code> for ascending   order and <code>desc</code> for descending order.</p> <code>NOT_GIVEN</code> <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/beta/threads/runs/runs/#src.openai.resources.beta.threads.runs.runs.Runs.retrieve","title":"retrieve","text":"<pre><code>retrieve(\n    run_id: str,\n    *,\n    thread_id: str,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; Run\n</code></pre> <p>Retrieves a run.</p> <p>Parameters:</p> Name Type Description Default <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/beta/threads/runs/runs/#src.openai.resources.beta.threads.runs.runs.Runs.steps","title":"steps","text":"<pre><code>steps() -&gt; Steps\n</code></pre>"},{"location":"reference/resources/beta/threads/runs/runs/#src.openai.resources.beta.threads.runs.runs.Runs.submit_tool_outputs","title":"submit_tool_outputs","text":"<pre><code>submit_tool_outputs(\n    run_id: str,\n    *,\n    thread_id: str,\n    tool_outputs: Iterable[ToolOutput],\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; Run\n</code></pre> <p>When a run has the <code>status: \"requires_action\"</code> and <code>required_action.type</code> is <code>submit_tool_outputs</code>, this endpoint can be used to submit the outputs from the tool calls once they're all completed. All outputs must be submitted in a single request.</p> <p>Parameters:</p> Name Type Description Default <code>tool_outputs</code> <code>Iterable[ToolOutput]</code> <p>A list of tools for which the outputs are being submitted.</p> required <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/beta/threads/runs/runs/#src.openai.resources.beta.threads.runs.runs.Runs.update","title":"update","text":"<pre><code>update(\n    run_id: str,\n    *,\n    thread_id: str,\n    metadata: Optional[object] | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; Run\n</code></pre> <p>Modifies a run.</p> <p>Parameters:</p> Name Type Description Default <code>metadata</code> <code>Optional[object] | NotGiven</code> <p>Set of 16 key-value pairs that can be attached to an object. This can be useful   for storing additional information about the object in a structured format. Keys   can be a maximum of 64 characters long and values can be a maxium of 512   characters long.</p> <code>NOT_GIVEN</code> <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/beta/threads/runs/runs/#src.openai.resources.beta.threads.runs.runs.Runs.with_raw_response","title":"with_raw_response","text":"<pre><code>with_raw_response() -&gt; RunsWithRawResponse\n</code></pre>"},{"location":"reference/resources/beta/threads/runs/runs/#src.openai.resources.beta.threads.runs.runs.Runs.with_streaming_response","title":"with_streaming_response","text":"<pre><code>with_streaming_response() -&gt; RunsWithStreamingResponse\n</code></pre>"},{"location":"reference/resources/beta/threads/runs/runs/#src.openai.resources.beta.threads.runs.runs.RunsWithRawResponse","title":"RunsWithRawResponse","text":"<pre><code>RunsWithRawResponse(runs: Runs)\n</code></pre> <p>Methods:</p> Name Description <code>steps</code> <p>Attributes:</p> Name Type Description <code>cancel</code> <code>create</code> <code>list</code> <code>retrieve</code> <code>submit_tool_outputs</code> <code>update</code>"},{"location":"reference/resources/beta/threads/runs/runs/#src.openai.resources.beta.threads.runs.runs.RunsWithRawResponse.cancel","title":"cancel  <code>instance-attribute</code>","text":"<pre><code>cancel = to_raw_response_wrapper(cancel)\n</code></pre>"},{"location":"reference/resources/beta/threads/runs/runs/#src.openai.resources.beta.threads.runs.runs.RunsWithRawResponse.create","title":"create  <code>instance-attribute</code>","text":"<pre><code>create = to_raw_response_wrapper(create)\n</code></pre>"},{"location":"reference/resources/beta/threads/runs/runs/#src.openai.resources.beta.threads.runs.runs.RunsWithRawResponse.list","title":"list  <code>instance-attribute</code>","text":"<pre><code>list = to_raw_response_wrapper(list)\n</code></pre>"},{"location":"reference/resources/beta/threads/runs/runs/#src.openai.resources.beta.threads.runs.runs.RunsWithRawResponse.retrieve","title":"retrieve  <code>instance-attribute</code>","text":"<pre><code>retrieve = to_raw_response_wrapper(retrieve)\n</code></pre>"},{"location":"reference/resources/beta/threads/runs/runs/#src.openai.resources.beta.threads.runs.runs.RunsWithRawResponse.submit_tool_outputs","title":"submit_tool_outputs  <code>instance-attribute</code>","text":"<pre><code>submit_tool_outputs = to_raw_response_wrapper(\n    submit_tool_outputs\n)\n</code></pre>"},{"location":"reference/resources/beta/threads/runs/runs/#src.openai.resources.beta.threads.runs.runs.RunsWithRawResponse.update","title":"update  <code>instance-attribute</code>","text":"<pre><code>update = to_raw_response_wrapper(update)\n</code></pre>"},{"location":"reference/resources/beta/threads/runs/runs/#src.openai.resources.beta.threads.runs.runs.RunsWithRawResponse.steps","title":"steps","text":"<pre><code>steps() -&gt; StepsWithRawResponse\n</code></pre>"},{"location":"reference/resources/beta/threads/runs/runs/#src.openai.resources.beta.threads.runs.runs.RunsWithStreamingResponse","title":"RunsWithStreamingResponse","text":"<pre><code>RunsWithStreamingResponse(runs: Runs)\n</code></pre> <p>Methods:</p> Name Description <code>steps</code> <p>Attributes:</p> Name Type Description <code>cancel</code> <code>create</code> <code>list</code> <code>retrieve</code> <code>submit_tool_outputs</code> <code>update</code>"},{"location":"reference/resources/beta/threads/runs/runs/#src.openai.resources.beta.threads.runs.runs.RunsWithStreamingResponse.cancel","title":"cancel  <code>instance-attribute</code>","text":"<pre><code>cancel = to_streamed_response_wrapper(cancel)\n</code></pre>"},{"location":"reference/resources/beta/threads/runs/runs/#src.openai.resources.beta.threads.runs.runs.RunsWithStreamingResponse.create","title":"create  <code>instance-attribute</code>","text":"<pre><code>create = to_streamed_response_wrapper(create)\n</code></pre>"},{"location":"reference/resources/beta/threads/runs/runs/#src.openai.resources.beta.threads.runs.runs.RunsWithStreamingResponse.list","title":"list  <code>instance-attribute</code>","text":"<pre><code>list = to_streamed_response_wrapper(list)\n</code></pre>"},{"location":"reference/resources/beta/threads/runs/runs/#src.openai.resources.beta.threads.runs.runs.RunsWithStreamingResponse.retrieve","title":"retrieve  <code>instance-attribute</code>","text":"<pre><code>retrieve = to_streamed_response_wrapper(retrieve)\n</code></pre>"},{"location":"reference/resources/beta/threads/runs/runs/#src.openai.resources.beta.threads.runs.runs.RunsWithStreamingResponse.submit_tool_outputs","title":"submit_tool_outputs  <code>instance-attribute</code>","text":"<pre><code>submit_tool_outputs = to_streamed_response_wrapper(\n    submit_tool_outputs\n)\n</code></pre>"},{"location":"reference/resources/beta/threads/runs/runs/#src.openai.resources.beta.threads.runs.runs.RunsWithStreamingResponse.update","title":"update  <code>instance-attribute</code>","text":"<pre><code>update = to_streamed_response_wrapper(update)\n</code></pre>"},{"location":"reference/resources/beta/threads/runs/runs/#src.openai.resources.beta.threads.runs.runs.RunsWithStreamingResponse.steps","title":"steps","text":"<pre><code>steps() -&gt; StepsWithStreamingResponse\n</code></pre>"},{"location":"reference/resources/beta/threads/runs/steps/","title":"steps","text":"<p>Classes:</p> Name Description <code>AsyncSteps</code> <code>AsyncStepsWithRawResponse</code> <code>AsyncStepsWithStreamingResponse</code> <code>Steps</code> <code>StepsWithRawResponse</code> <code>StepsWithStreamingResponse</code>"},{"location":"reference/resources/beta/threads/runs/steps/#src.openai.resources.beta.threads.runs.steps.AsyncSteps","title":"AsyncSteps","text":"<pre><code>AsyncSteps(client: AsyncOpenAI)\n</code></pre> <p>Methods:</p> Name Description <code>list</code> <p>Returns a list of run steps belonging to a run.</p> <code>retrieve</code> <p>Retrieves a run step.</p> <code>with_raw_response</code> <code>with_streaming_response</code>"},{"location":"reference/resources/beta/threads/runs/steps/#src.openai.resources.beta.threads.runs.steps.AsyncSteps.list","title":"list","text":"<pre><code>list(\n    run_id: str,\n    *,\n    thread_id: str,\n    after: str | NotGiven = NOT_GIVEN,\n    before: str | NotGiven = NOT_GIVEN,\n    limit: int | NotGiven = NOT_GIVEN,\n    order: Literal[\"asc\", \"desc\"] | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; AsyncPaginator[RunStep, AsyncCursorPage[RunStep]]\n</code></pre> <p>Returns a list of run steps belonging to a run.</p> <p>Parameters:</p> Name Type Description Default <code>after</code> <code>str | NotGiven</code> <p>A cursor for use in pagination. <code>after</code> is an object ID that defines your place   in the list. For instance, if you make a list request and receive 100 objects,   ending with obj_foo, your subsequent call can include after=obj_foo in order to   fetch the next page of the list.</p> <code>NOT_GIVEN</code> <code>before</code> <code>str | NotGiven</code> <p>A cursor for use in pagination. <code>before</code> is an object ID that defines your place   in the list. For instance, if you make a list request and receive 100 objects,   ending with obj_foo, your subsequent call can include before=obj_foo in order to   fetch the previous page of the list.</p> <code>NOT_GIVEN</code> <code>limit</code> <code>int | NotGiven</code> <p>A limit on the number of objects to be returned. Limit can range between 1 and   100, and the default is 20.</p> <code>NOT_GIVEN</code> <code>order</code> <code>Literal['asc', 'desc'] | NotGiven</code> <p>Sort order by the <code>created_at</code> timestamp of the objects. <code>asc</code> for ascending   order and <code>desc</code> for descending order.</p> <code>NOT_GIVEN</code> <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/beta/threads/runs/steps/#src.openai.resources.beta.threads.runs.steps.AsyncSteps.retrieve","title":"retrieve  <code>async</code>","text":"<pre><code>retrieve(\n    step_id: str,\n    *,\n    thread_id: str,\n    run_id: str,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; RunStep\n</code></pre> <p>Retrieves a run step.</p> <p>Parameters:</p> Name Type Description Default <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/beta/threads/runs/steps/#src.openai.resources.beta.threads.runs.steps.AsyncSteps.with_raw_response","title":"with_raw_response","text":"<pre><code>with_raw_response() -&gt; AsyncStepsWithRawResponse\n</code></pre>"},{"location":"reference/resources/beta/threads/runs/steps/#src.openai.resources.beta.threads.runs.steps.AsyncSteps.with_streaming_response","title":"with_streaming_response","text":"<pre><code>with_streaming_response() -&gt; (\n    AsyncStepsWithStreamingResponse\n)\n</code></pre>"},{"location":"reference/resources/beta/threads/runs/steps/#src.openai.resources.beta.threads.runs.steps.AsyncStepsWithRawResponse","title":"AsyncStepsWithRawResponse","text":"<pre><code>AsyncStepsWithRawResponse(steps: AsyncSteps)\n</code></pre> <p>Attributes:</p> Name Type Description <code>list</code> <code>retrieve</code>"},{"location":"reference/resources/beta/threads/runs/steps/#src.openai.resources.beta.threads.runs.steps.AsyncStepsWithRawResponse.list","title":"list  <code>instance-attribute</code>","text":"<pre><code>list = async_to_raw_response_wrapper(list)\n</code></pre>"},{"location":"reference/resources/beta/threads/runs/steps/#src.openai.resources.beta.threads.runs.steps.AsyncStepsWithRawResponse.retrieve","title":"retrieve  <code>instance-attribute</code>","text":"<pre><code>retrieve = async_to_raw_response_wrapper(retrieve)\n</code></pre>"},{"location":"reference/resources/beta/threads/runs/steps/#src.openai.resources.beta.threads.runs.steps.AsyncStepsWithStreamingResponse","title":"AsyncStepsWithStreamingResponse","text":"<pre><code>AsyncStepsWithStreamingResponse(steps: AsyncSteps)\n</code></pre> <p>Attributes:</p> Name Type Description <code>list</code> <code>retrieve</code>"},{"location":"reference/resources/beta/threads/runs/steps/#src.openai.resources.beta.threads.runs.steps.AsyncStepsWithStreamingResponse.list","title":"list  <code>instance-attribute</code>","text":"<pre><code>list = async_to_streamed_response_wrapper(list)\n</code></pre>"},{"location":"reference/resources/beta/threads/runs/steps/#src.openai.resources.beta.threads.runs.steps.AsyncStepsWithStreamingResponse.retrieve","title":"retrieve  <code>instance-attribute</code>","text":"<pre><code>retrieve = async_to_streamed_response_wrapper(retrieve)\n</code></pre>"},{"location":"reference/resources/beta/threads/runs/steps/#src.openai.resources.beta.threads.runs.steps.Steps","title":"Steps","text":"<pre><code>Steps(client: OpenAI)\n</code></pre> <p>Methods:</p> Name Description <code>list</code> <p>Returns a list of run steps belonging to a run.</p> <code>retrieve</code> <p>Retrieves a run step.</p> <code>with_raw_response</code> <code>with_streaming_response</code>"},{"location":"reference/resources/beta/threads/runs/steps/#src.openai.resources.beta.threads.runs.steps.Steps.list","title":"list","text":"<pre><code>list(\n    run_id: str,\n    *,\n    thread_id: str,\n    after: str | NotGiven = NOT_GIVEN,\n    before: str | NotGiven = NOT_GIVEN,\n    limit: int | NotGiven = NOT_GIVEN,\n    order: Literal[\"asc\", \"desc\"] | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; SyncCursorPage[RunStep]\n</code></pre> <p>Returns a list of run steps belonging to a run.</p> <p>Parameters:</p> Name Type Description Default <code>after</code> <code>str | NotGiven</code> <p>A cursor for use in pagination. <code>after</code> is an object ID that defines your place   in the list. For instance, if you make a list request and receive 100 objects,   ending with obj_foo, your subsequent call can include after=obj_foo in order to   fetch the next page of the list.</p> <code>NOT_GIVEN</code> <code>before</code> <code>str | NotGiven</code> <p>A cursor for use in pagination. <code>before</code> is an object ID that defines your place   in the list. For instance, if you make a list request and receive 100 objects,   ending with obj_foo, your subsequent call can include before=obj_foo in order to   fetch the previous page of the list.</p> <code>NOT_GIVEN</code> <code>limit</code> <code>int | NotGiven</code> <p>A limit on the number of objects to be returned. Limit can range between 1 and   100, and the default is 20.</p> <code>NOT_GIVEN</code> <code>order</code> <code>Literal['asc', 'desc'] | NotGiven</code> <p>Sort order by the <code>created_at</code> timestamp of the objects. <code>asc</code> for ascending   order and <code>desc</code> for descending order.</p> <code>NOT_GIVEN</code> <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/beta/threads/runs/steps/#src.openai.resources.beta.threads.runs.steps.Steps.retrieve","title":"retrieve","text":"<pre><code>retrieve(\n    step_id: str,\n    *,\n    thread_id: str,\n    run_id: str,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; RunStep\n</code></pre> <p>Retrieves a run step.</p> <p>Parameters:</p> Name Type Description Default <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/beta/threads/runs/steps/#src.openai.resources.beta.threads.runs.steps.Steps.with_raw_response","title":"with_raw_response","text":"<pre><code>with_raw_response() -&gt; StepsWithRawResponse\n</code></pre>"},{"location":"reference/resources/beta/threads/runs/steps/#src.openai.resources.beta.threads.runs.steps.Steps.with_streaming_response","title":"with_streaming_response","text":"<pre><code>with_streaming_response() -&gt; StepsWithStreamingResponse\n</code></pre>"},{"location":"reference/resources/beta/threads/runs/steps/#src.openai.resources.beta.threads.runs.steps.StepsWithRawResponse","title":"StepsWithRawResponse","text":"<pre><code>StepsWithRawResponse(steps: Steps)\n</code></pre> <p>Attributes:</p> Name Type Description <code>list</code> <code>retrieve</code>"},{"location":"reference/resources/beta/threads/runs/steps/#src.openai.resources.beta.threads.runs.steps.StepsWithRawResponse.list","title":"list  <code>instance-attribute</code>","text":"<pre><code>list = to_raw_response_wrapper(list)\n</code></pre>"},{"location":"reference/resources/beta/threads/runs/steps/#src.openai.resources.beta.threads.runs.steps.StepsWithRawResponse.retrieve","title":"retrieve  <code>instance-attribute</code>","text":"<pre><code>retrieve = to_raw_response_wrapper(retrieve)\n</code></pre>"},{"location":"reference/resources/beta/threads/runs/steps/#src.openai.resources.beta.threads.runs.steps.StepsWithStreamingResponse","title":"StepsWithStreamingResponse","text":"<pre><code>StepsWithStreamingResponse(steps: Steps)\n</code></pre> <p>Attributes:</p> Name Type Description <code>list</code> <code>retrieve</code>"},{"location":"reference/resources/beta/threads/runs/steps/#src.openai.resources.beta.threads.runs.steps.StepsWithStreamingResponse.list","title":"list  <code>instance-attribute</code>","text":"<pre><code>list = to_streamed_response_wrapper(list)\n</code></pre>"},{"location":"reference/resources/beta/threads/runs/steps/#src.openai.resources.beta.threads.runs.steps.StepsWithStreamingResponse.retrieve","title":"retrieve  <code>instance-attribute</code>","text":"<pre><code>retrieve = to_streamed_response_wrapper(retrieve)\n</code></pre>"},{"location":"reference/resources/chat/","title":"openai.resources.chat","text":"<p>The <code>chat</code> module provides classes for creating and managing chat sessions that leverage OpenAI's language models to generate conversational responses.</p> <p>The module supports both synchronous and asynchronous operations, offering interfaces for direct interaction with the completion endpoints tailored for chat applications. Designed for developers looking to integrate AI-powered chat functionalities into their applications and features like raw and streaming response handling for more flexible integration.</p> <p>Modules:</p> Name Description <code>chat</code> <p>The <code>chat</code> module provides classes for creating and managing chat sessions that leverage OpenAI's language models to generate conversational responses.</p> <p>The module supports both synchronous and asynchronous operations, offering interfaces for direct interaction with the completion endpoints tailored for chat applications. Designed for developers looking to integrate AI-powered chat functionalities into their applications and features like raw and streaming response handling for more flexible integration.</p> <code>completions</code> <p>The <code>chat.completions</code> module provides access to the chat completions endpoint of the OpenAI API. It supports the latest models including <code>gpt-4</code>, <code>gpt-4-turbo-preview</code>, <code>gpt-4-vision-preview</code>, <code>gpt-4-32k</code>, <code>gpt-3.5-turbo</code>, and their respective dated model releases, along with fine-tuned versions of <code>gpt-3.5-turbo</code>.</p> <p>This module interacts with the <code>/v1/chat/completions</code> endpoint and replaces the the legacy <code>resources.completions</code> module. You're strongly encouraged to migrate existing applications that use the legacy <code>resources.completions</code> module to this one before the expected deprecation of the <code>/v1/completions</code> endpoint.</p> <p>Classes:</p> Name Description <code>AsyncChat</code> <code>AsyncChatWithRawResponse</code> <code>AsyncChatWithStreamingResponse</code> <code>AsyncCompletions</code> <code>AsyncCompletionsWithRawResponse</code> <code>AsyncCompletionsWithStreamingResponse</code> <code>Chat</code> <code>ChatWithRawResponse</code> <code>ChatWithStreamingResponse</code> <code>Completions</code> <code>CompletionsWithRawResponse</code> <code>CompletionsWithStreamingResponse</code>"},{"location":"reference/resources/chat/#src.openai.resources.chat.AsyncChat","title":"AsyncChat","text":"<pre><code>AsyncChat(client: AsyncOpenAI)\n</code></pre> <p>Methods:</p> Name Description <code>completions</code> <code>with_raw_response</code> <code>with_streaming_response</code>"},{"location":"reference/resources/chat/#src.openai.resources.chat.AsyncChat.completions","title":"completions","text":"<pre><code>completions() -&gt; AsyncCompletions\n</code></pre>"},{"location":"reference/resources/chat/#src.openai.resources.chat.AsyncChat.with_raw_response","title":"with_raw_response","text":"<pre><code>with_raw_response() -&gt; AsyncChatWithRawResponse\n</code></pre>"},{"location":"reference/resources/chat/#src.openai.resources.chat.AsyncChat.with_streaming_response","title":"with_streaming_response","text":"<pre><code>with_streaming_response() -&gt; AsyncChatWithStreamingResponse\n</code></pre>"},{"location":"reference/resources/chat/#src.openai.resources.chat.AsyncChatWithRawResponse","title":"AsyncChatWithRawResponse","text":"<pre><code>AsyncChatWithRawResponse(chat: AsyncChat)\n</code></pre> <p>Methods:</p> Name Description <code>completions</code>"},{"location":"reference/resources/chat/#src.openai.resources.chat.AsyncChatWithRawResponse.completions","title":"completions","text":"<pre><code>completions() -&gt; AsyncCompletionsWithRawResponse\n</code></pre>"},{"location":"reference/resources/chat/#src.openai.resources.chat.AsyncChatWithStreamingResponse","title":"AsyncChatWithStreamingResponse","text":"<pre><code>AsyncChatWithStreamingResponse(chat: AsyncChat)\n</code></pre> <p>Methods:</p> Name Description <code>completions</code>"},{"location":"reference/resources/chat/#src.openai.resources.chat.AsyncChatWithStreamingResponse.completions","title":"completions","text":"<pre><code>completions() -&gt; AsyncCompletionsWithStreamingResponse\n</code></pre>"},{"location":"reference/resources/chat/#src.openai.resources.chat.AsyncCompletions","title":"AsyncCompletions","text":"<pre><code>AsyncCompletions(client: AsyncOpenAI)\n</code></pre> <p>Methods:</p> Name Description <code>create</code> <p>Generates a chat completion by submitting a conversation history and model parameters, supporting various configurations to tailor the chat completion process, including penalties, response formats, and streaming outputs.</p> <code>with_raw_response</code> <code>with_streaming_response</code>"},{"location":"reference/resources/chat/#src.openai.resources.chat.AsyncCompletions.create","title":"create  <code>async</code>","text":"<pre><code>create(\n    *,\n    messages: Iterable[ChatCompletionMessageParam],\n    model: Union[\n        str,\n        Literal[\n            \"gpt-4-0125-preview\",\n            \"gpt-4-turbo-preview\",\n            \"gpt-4-1106-preview\",\n            \"gpt-4-vision-preview\",\n            \"gpt-4\",\n            \"gpt-4-0314\",\n            \"gpt-4-0613\",\n            \"gpt-4-32k\",\n            \"gpt-4-32k-0314\",\n            \"gpt-4-32k-0613\",\n            \"gpt-3.5-turbo\",\n            \"gpt-3.5-turbo-16k\",\n            \"gpt-3.5-turbo-0301\",\n            \"gpt-3.5-turbo-0613\",\n            \"gpt-3.5-turbo-1106\",\n            \"gpt-3.5-turbo-0125\",\n            \"gpt-3.5-turbo-16k-0613\",\n        ],\n    ],\n    frequency_penalty: (\n        Optional[float] | NotGiven\n    ) = NOT_GIVEN,\n    function_call: FunctionCall | NotGiven = NOT_GIVEN,\n    functions: Iterable[Function] | NotGiven = NOT_GIVEN,\n    logit_bias: (\n        Optional[Dict[str, int]] | NotGiven\n    ) = NOT_GIVEN,\n    logprobs: Optional[bool] | NotGiven = NOT_GIVEN,\n    max_tokens: Optional[int] | NotGiven = NOT_GIVEN,\n    n: Optional[int] | NotGiven = NOT_GIVEN,\n    presence_penalty: (\n        Optional[float] | NotGiven\n    ) = NOT_GIVEN,\n    response_format: ResponseFormat | NotGiven = NOT_GIVEN,\n    seed: Optional[int] | NotGiven = NOT_GIVEN,\n    stop: (\n        Union[Optional[str], List[str]] | NotGiven\n    ) = NOT_GIVEN,\n    stream: Optional[Literal[False]] | NotGiven = NOT_GIVEN,\n    temperature: Optional[float] | NotGiven = NOT_GIVEN,\n    tool_choice: (\n        ChatCompletionToolChoiceOptionParam | NotGiven\n    ) = NOT_GIVEN,\n    tools: (\n        Iterable[ChatCompletionToolParam] | NotGiven\n    ) = NOT_GIVEN,\n    top_logprobs: Optional[int] | NotGiven = NOT_GIVEN,\n    top_p: Optional[float] | NotGiven = NOT_GIVEN,\n    user: str | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; ChatCompletion\n</code></pre><pre><code>create(\n    *,\n    messages: Iterable[ChatCompletionMessageParam],\n    model: Union[\n        str,\n        Literal[\n            \"gpt-4-0125-preview\",\n            \"gpt-4-turbo-preview\",\n            \"gpt-4-1106-preview\",\n            \"gpt-4-vision-preview\",\n            \"gpt-4\",\n            \"gpt-4-0314\",\n            \"gpt-4-0613\",\n            \"gpt-4-32k\",\n            \"gpt-4-32k-0314\",\n            \"gpt-4-32k-0613\",\n            \"gpt-3.5-turbo\",\n            \"gpt-3.5-turbo-16k\",\n            \"gpt-3.5-turbo-0301\",\n            \"gpt-3.5-turbo-0613\",\n            \"gpt-3.5-turbo-1106\",\n            \"gpt-3.5-turbo-0125\",\n            \"gpt-3.5-turbo-16k-0613\",\n        ],\n    ],\n    stream: Literal[True],\n    frequency_penalty: (\n        Optional[float] | NotGiven\n    ) = NOT_GIVEN,\n    function_call: FunctionCall | NotGiven = NOT_GIVEN,\n    functions: Iterable[Function] | NotGiven = NOT_GIVEN,\n    logit_bias: (\n        Optional[Dict[str, int]] | NotGiven\n    ) = NOT_GIVEN,\n    logprobs: Optional[bool] | NotGiven = NOT_GIVEN,\n    max_tokens: Optional[int] | NotGiven = NOT_GIVEN,\n    n: Optional[int] | NotGiven = NOT_GIVEN,\n    presence_penalty: (\n        Optional[float] | NotGiven\n    ) = NOT_GIVEN,\n    response_format: ResponseFormat | NotGiven = NOT_GIVEN,\n    seed: Optional[int] | NotGiven = NOT_GIVEN,\n    stop: (\n        Union[Optional[str], List[str]] | NotGiven\n    ) = NOT_GIVEN,\n    temperature: Optional[float] | NotGiven = NOT_GIVEN,\n    tool_choice: (\n        ChatCompletionToolChoiceOptionParam | NotGiven\n    ) = NOT_GIVEN,\n    tools: (\n        Iterable[ChatCompletionToolParam] | NotGiven\n    ) = NOT_GIVEN,\n    top_logprobs: Optional[int] | NotGiven = NOT_GIVEN,\n    top_p: Optional[float] | NotGiven = NOT_GIVEN,\n    user: str | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; AsyncStream[ChatCompletionChunk]\n</code></pre><pre><code>create(\n    *,\n    messages: Iterable[ChatCompletionMessageParam],\n    model: Union[\n        str,\n        Literal[\n            \"gpt-4-0125-preview\",\n            \"gpt-4-turbo-preview\",\n            \"gpt-4-1106-preview\",\n            \"gpt-4-vision-preview\",\n            \"gpt-4\",\n            \"gpt-4-0314\",\n            \"gpt-4-0613\",\n            \"gpt-4-32k\",\n            \"gpt-4-32k-0314\",\n            \"gpt-4-32k-0613\",\n            \"gpt-3.5-turbo\",\n            \"gpt-3.5-turbo-16k\",\n            \"gpt-3.5-turbo-0301\",\n            \"gpt-3.5-turbo-0613\",\n            \"gpt-3.5-turbo-1106\",\n            \"gpt-3.5-turbo-0125\",\n            \"gpt-3.5-turbo-16k-0613\",\n        ],\n    ],\n    stream: bool,\n    frequency_penalty: (\n        Optional[float] | NotGiven\n    ) = NOT_GIVEN,\n    function_call: FunctionCall | NotGiven = NOT_GIVEN,\n    functions: Iterable[Function] | NotGiven = NOT_GIVEN,\n    logit_bias: (\n        Optional[Dict[str, int]] | NotGiven\n    ) = NOT_GIVEN,\n    logprobs: Optional[bool] | NotGiven = NOT_GIVEN,\n    max_tokens: Optional[int] | NotGiven = NOT_GIVEN,\n    n: Optional[int] | NotGiven = NOT_GIVEN,\n    presence_penalty: (\n        Optional[float] | NotGiven\n    ) = NOT_GIVEN,\n    response_format: ResponseFormat | NotGiven = NOT_GIVEN,\n    seed: Optional[int] | NotGiven = NOT_GIVEN,\n    stop: (\n        Union[Optional[str], List[str]] | NotGiven\n    ) = NOT_GIVEN,\n    temperature: Optional[float] | NotGiven = NOT_GIVEN,\n    tool_choice: (\n        ChatCompletionToolChoiceOptionParam | NotGiven\n    ) = NOT_GIVEN,\n    tools: (\n        Iterable[ChatCompletionToolParam] | NotGiven\n    ) = NOT_GIVEN,\n    top_logprobs: Optional[int] | NotGiven = NOT_GIVEN,\n    top_p: Optional[float] | NotGiven = NOT_GIVEN,\n    user: str | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; ChatCompletion | AsyncStream[ChatCompletionChunk]\n</code></pre> <pre><code>create(\n    *,\n    messages: Iterable[ChatCompletionMessageParam],\n    model: Union[\n        str,\n        Literal[\n            \"gpt-4-0125-preview\",\n            \"gpt-4-turbo-preview\",\n            \"gpt-4-1106-preview\",\n            \"gpt-4-vision-preview\",\n            \"gpt-4\",\n            \"gpt-4-0314\",\n            \"gpt-4-0613\",\n            \"gpt-4-32k\",\n            \"gpt-4-32k-0314\",\n            \"gpt-4-32k-0613\",\n            \"gpt-3.5-turbo\",\n            \"gpt-3.5-turbo-16k\",\n            \"gpt-3.5-turbo-0301\",\n            \"gpt-3.5-turbo-0613\",\n            \"gpt-3.5-turbo-1106\",\n            \"gpt-3.5-turbo-0125\",\n            \"gpt-3.5-turbo-16k-0613\",\n        ],\n    ],\n    frequency_penalty: (\n        Optional[float] | NotGiven\n    ) = NOT_GIVEN,\n    function_call: FunctionCall | NotGiven = NOT_GIVEN,\n    functions: Iterable[Function] | NotGiven = NOT_GIVEN,\n    logit_bias: (\n        Optional[Dict[str, int]] | NotGiven\n    ) = NOT_GIVEN,\n    logprobs: Optional[bool] | NotGiven = NOT_GIVEN,\n    max_tokens: Optional[int] | NotGiven = NOT_GIVEN,\n    n: Optional[int] | NotGiven = NOT_GIVEN,\n    presence_penalty: (\n        Optional[float] | NotGiven\n    ) = NOT_GIVEN,\n    response_format: ResponseFormat | NotGiven = NOT_GIVEN,\n    seed: Optional[int] | NotGiven = NOT_GIVEN,\n    stop: (\n        Union[Optional[str], List[str]] | NotGiven\n    ) = NOT_GIVEN,\n    stream: (\n        Optional[Literal[False]] | Literal[True] | NotGiven\n    ) = NOT_GIVEN,\n    temperature: Optional[float] | NotGiven = NOT_GIVEN,\n    tool_choice: (\n        ChatCompletionToolChoiceOptionParam | NotGiven\n    ) = NOT_GIVEN,\n    tools: (\n        Iterable[ChatCompletionToolParam] | NotGiven\n    ) = NOT_GIVEN,\n    top_logprobs: Optional[int] | NotGiven = NOT_GIVEN,\n    top_p: Optional[float] | NotGiven = NOT_GIVEN,\n    user: str | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; ChatCompletion | AsyncStream[ChatCompletionChunk]\n</code></pre> <p>Generates a chat completion by submitting a conversation history and model parameters, supporting various configurations to tailor the chat completion process, including penalties, response formats, and streaming outputs.</p> <p>Returns:</p> Name Type Description <code>ChatCompletion | AsyncStream[ChatCompletionChunk]</code> <p>AsyncStream[ChatCompletionChunk]: Stream of chat completion chunks for incremental output consumption.</p> <code>ChatCompletion</code> <code>ChatCompletion | AsyncStream[ChatCompletionChunk]</code> <p>An object containing the generated chat completion and other relevant details, such as             the chosen tokens and any associated metadata.</p> <p>Raises:</p> Type Description <code>OpenAIError</code> <p>If there's an issue with API request or parsing the response.</p> <p>Examples: <pre><code>completion = client.Completions().create(\n    messages=[{\"role\": \"user\", \"content\": \"Tell me a joke.\"}],\n    model=\"text-davinci-003\",\n    max_tokens=60\n)\nprint(completion.choices[0].text)\n</code></pre></p> <pre><code>completion = client.Completions().create(\n    messages=[{\"role\": \"user\", \"content\": \"How do you make a latte?\"}],\n    model=\"gpt-3.5-turbo\",\n    max_tokens=150\n)\nprint(completion.choices[0].text)\n</code></pre> <pre><code>async with client.AsyncCompletions().create(\n    messages=[{\"role\": \"user\", \"content\": \"What's the weather like in Tokyo?\"}],\n    model=\"text-davinci-003\",\n    frequency_penalty=0.5,\n    presence_penalty=0.5\n) as stream:\n    async for chunk in stream:\n        print(chunk.text)\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>messages</code> <code>Iterable[ChatCompletionMessageParam]</code> <p>A sequence of message objects that make up the conversation so far. Each message is a dictionary that should include the keys <code>role</code> and <code>content</code>, where <code>role</code> is either <code>user</code> or <code>assistant</code>, indicating who is speaking, and <code>content</code> is a string containing the message text. This parameter is essential for constructing the conversational context for the model's response.</p> required <code>model</code> <code>Union[str, Literal[...]]</code> <p>The model ID of the OpenAI GPT model to use for generating the chat completion. This parameter specifies which version of the model to use, for example, <code>text-davinci-003</code> for general-purpose completions or <code>gpt-3.5-turbo</code> for optimized performance. The choice of model affects the quality, style, and capabilities of the generated content.</p> required <code>stream</code> <code>Optional[bool]</code> <p>Whether the response should be streamed. Streaming can be useful for receiving responses as they are generated, especially for long completions. This approach enables real-time interaction and processing of the model's output.</p> <code>NOT_GIVEN</code> <code>frequency_penalty</code> <code>Optional[float]</code> <p>Adjusts the likelihood of the model repeating the same line verbatim. Values can range from -2.0 to 2.0, with positive values making repeats less likely. This parameter helps in controlling the diversity of the generated text.</p> <code>NOT_GIVEN</code> <code>function_call</code> <code>Optional[FunctionCall]</code> <p>Deprecated. Originally used to specify whether the model should execute a function call. While it is still accepted for backward compatibility, the <code>tool_choice</code> parameter is recommended for new implementations.</p> <code>NOT_GIVEN</code> <code>functions</code> <code>Optional[Iterable[Function]]</code> <p>Deprecated. Originally provided a list of functions the model could choose to call during generation. Like <code>function_call</code>, this parameter has been superseded by <code>tools</code>.</p> <code>NOT_GIVEN</code> <code>logit_bias</code> <code>Optional[Dicst[str, int]]</code> <p>Modifies token likelihood, mapping token IDs to bias values (-100 to 100), influencing selection. This mechanism allows for fine-tuning the presence or avoidance of specific words or phrases in the generated text.</p> <code>NOT_GIVEN</code> <code>logprobs</code> <code>Optional[bool]</code> <p>Whether to return the log probabilities of the tokens generated in the completion. Useful for model introspection and understanding the model's decision-making process. Note: This feature might not be available for all models.</p> <code>NOT_GIVEN</code> <code>max_tokens</code> <code>Optional[int]</code> <p>The maximum number of tokens to generate in the completion. This limit includes the tokens in the prompt. Careful management of this parameter is crucial for controlling the length and computational cost of model operations.</p> <code>NOT_GIVEN</code> <code>n</code> <code>Optional[int]</code> <p>The number of completions to generate for each prompt. Higher values allow for more diversity in the responses but increase computational cost. Balancing this parameter is key to achieving desired output variability while managing resource use.</p> <code>NOT_GIVEN</code> <code>presence_penalty</code> <code>Optional[float]</code> <p>Encourages new content by penalizing token presence, with values from -2.0 to 2.0. This parameter influences the model to explore new topics and ideas, enhancing the creativity and variability of the output.</p> <code>NOT_GIVEN</code> <code>response_format</code> <code>Optional[ResponseFormat]</code> <p>Specifies how the model's responses should be formatted. For example, responses can be structured as plain text, JSON objects, or other formats depending on the model's capabilities. This flexibility allows for tailored outputs to suit different applications and processing needs.</p> <code>NOT_GIVEN</code> <code>seed</code> <code>Optional[int]</code> <p>Seed for deterministic randomness, ensuring same inputs yield consistent outputs. This feature is beneficial for reproducibility and debugging purposes, allowing users to obtain the same results from identical requests.</p> <code>NOT_GIVEN</code> <code>stop</code> <code>Optional[Union[str, List[str]]]</code> <p>Sequences where the API will stop generating further tokens. This can be used to indicate the end of a message or section, providing a mechanism to control the scope and completion of the generated content.</p> <code>NOT_GIVEN</code> <code>temperature</code> <code>Optional[float]</code> <p>Controls the randomness of the output. A lower temperature results in more deterministic output, while a higher temperature results in more diversity. Adjusting this parameter allows users to balance between predictability and creativity in the model's responses.</p> <code>NOT_GIVEN</code> <code>tool_choice</code> <code>Optional[ToolChoiceOptionParam]</code> <p>Specifies which tool the model should use if it decides to make an external call. This replaces <code>function_call</code> and offers more granular control over the model's interactive capabilities.</p> <code>NOT_GIVEN</code> <code>tools</code> <code>Optional[Iterable[ToolParam]]</code> <p>Lists tools available for response generation, including functions and APIs. This parameter expands the model's ability to incorporate external data and functionalities into its responses, broadening the scope of possible applications.</p> <code>NOT_GIVEN</code> <code>top_logprobs</code> <code>Optional[int]</code> <p>Specifies the number of top logits to return, providing insight into the model's decision-making process. This information can be valuable for analyzing the model's preferences and the statistical distribution of its predictions.</p> <code>NOT_GIVEN</code> <code>top_p</code> <code>Optional[float]</code> <p>Nucleus sampling strategy focusing on top P% probability mass, influencing token selection. This parameter adjusts the scope of the token set considered at each step, effectively adjusting the diversity and unpredictability of the output. A balance between coherence and variety can be achieved by tuning this parameter.</p> <code>NOT_GIVEN</code> <code>user</code> <code>Optional[str]</code> <p>Identifies the end user of the API, aiding in monitoring usage patterns and detecting potential misuse. This parameter helps maintain the security and integrity of the system, ensuring that the API is used responsibly and in accordance with OpenAI's guidelines. End user identification best practices</p> <code>NOT_GIVEN</code> <code>extra_headers</code> <code>Optional[Headers]</code> <p>Additional HTTP headers to send with the request. This allows for customizing the request headers for scenarios that require specific HTTP header entries.</p> <code>None</code> <code>extra_query</code> <code>Optional[Query]</code> <p>Extra query parameters for the request URL. These parameters are appended to the URL query string, providing a flexible way to extend the request with additional data.</p> <code>None</code> <code>extra_body</code> <code>Optional[Body]</code> <p>Additional body parameters to include in the POST request. This can be used to pass extra information that is not covered by the standard parameters.</p> <code>None</code> <code>timeout</code> <code>Optional[float | Timeout]</code> <p>Custom timeout for the request, overriding the default. Setting this parameter ensures that operations adhere to specific timing requirements, preventing excessively long waits or premature termination of requests.</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/chat/#src.openai.resources.chat.AsyncCompletions.with_raw_response","title":"with_raw_response","text":"<pre><code>with_raw_response() -&gt; AsyncCompletionsWithRawResponse\n</code></pre>"},{"location":"reference/resources/chat/#src.openai.resources.chat.AsyncCompletions.with_streaming_response","title":"with_streaming_response","text":"<pre><code>with_streaming_response() -&gt; (\n    AsyncCompletionsWithStreamingResponse\n)\n</code></pre>"},{"location":"reference/resources/chat/#src.openai.resources.chat.AsyncCompletionsWithRawResponse","title":"AsyncCompletionsWithRawResponse","text":"<pre><code>AsyncCompletionsWithRawResponse(\n    completions: AsyncCompletions,\n)\n</code></pre> <p>Attributes:</p> Name Type Description <code>create</code>"},{"location":"reference/resources/chat/#src.openai.resources.chat.AsyncCompletionsWithRawResponse.create","title":"create  <code>instance-attribute</code>","text":"<pre><code>create = async_to_raw_response_wrapper(create)\n</code></pre>"},{"location":"reference/resources/chat/#src.openai.resources.chat.AsyncCompletionsWithStreamingResponse","title":"AsyncCompletionsWithStreamingResponse","text":"<pre><code>AsyncCompletionsWithStreamingResponse(\n    completions: AsyncCompletions,\n)\n</code></pre> <p>Attributes:</p> Name Type Description <code>create</code>"},{"location":"reference/resources/chat/#src.openai.resources.chat.AsyncCompletionsWithStreamingResponse.create","title":"create  <code>instance-attribute</code>","text":"<pre><code>create = async_to_streamed_response_wrapper(create)\n</code></pre>"},{"location":"reference/resources/chat/#src.openai.resources.chat.Chat","title":"Chat","text":"<pre><code>Chat(client: OpenAI)\n</code></pre> <p>Methods:</p> Name Description <code>completions</code> <code>with_raw_response</code> <code>with_streaming_response</code>"},{"location":"reference/resources/chat/#src.openai.resources.chat.Chat.completions","title":"completions","text":"<pre><code>completions() -&gt; Completions\n</code></pre>"},{"location":"reference/resources/chat/#src.openai.resources.chat.Chat.with_raw_response","title":"with_raw_response","text":"<pre><code>with_raw_response() -&gt; ChatWithRawResponse\n</code></pre>"},{"location":"reference/resources/chat/#src.openai.resources.chat.Chat.with_streaming_response","title":"with_streaming_response","text":"<pre><code>with_streaming_response() -&gt; ChatWithStreamingResponse\n</code></pre>"},{"location":"reference/resources/chat/#src.openai.resources.chat.ChatWithRawResponse","title":"ChatWithRawResponse","text":"<pre><code>ChatWithRawResponse(chat: Chat)\n</code></pre> <p>Methods:</p> Name Description <code>completions</code>"},{"location":"reference/resources/chat/#src.openai.resources.chat.ChatWithRawResponse.completions","title":"completions","text":"<pre><code>completions() -&gt; CompletionsWithRawResponse\n</code></pre>"},{"location":"reference/resources/chat/#src.openai.resources.chat.ChatWithStreamingResponse","title":"ChatWithStreamingResponse","text":"<pre><code>ChatWithStreamingResponse(chat: Chat)\n</code></pre> <p>Methods:</p> Name Description <code>completions</code>"},{"location":"reference/resources/chat/#src.openai.resources.chat.ChatWithStreamingResponse.completions","title":"completions","text":"<pre><code>completions() -&gt; CompletionsWithStreamingResponse\n</code></pre>"},{"location":"reference/resources/chat/#src.openai.resources.chat.Completions","title":"Completions","text":"<pre><code>Completions(client: OpenAI)\n</code></pre> <p>Methods:</p> Name Description <code>create</code> <p>Creates a model response for the given chat conversation, tailored by a variety of customizable parameters.</p> <code>with_raw_response</code> <code>with_streaming_response</code>"},{"location":"reference/resources/chat/#src.openai.resources.chat.Completions.create","title":"create","text":"<pre><code>create(\n    *,\n    messages: Iterable[ChatCompletionMessageParam],\n    model: Union[\n        str,\n        Literal[\n            \"gpt-4-0125-preview\",\n            \"gpt-4-turbo-preview\",\n            \"gpt-4-1106-preview\",\n            \"gpt-4-vision-preview\",\n            \"gpt-4\",\n            \"gpt-4-0314\",\n            \"gpt-4-0613\",\n            \"gpt-4-32k\",\n            \"gpt-4-32k-0314\",\n            \"gpt-4-32k-0613\",\n            \"gpt-3.5-turbo\",\n            \"gpt-3.5-turbo-16k\",\n            \"gpt-3.5-turbo-0301\",\n            \"gpt-3.5-turbo-0613\",\n            \"gpt-3.5-turbo-1106\",\n            \"gpt-3.5-turbo-0125\",\n            \"gpt-3.5-turbo-16k-0613\",\n        ],\n    ],\n    frequency_penalty: (\n        Optional[float] | NotGiven\n    ) = NOT_GIVEN,\n    function_call: FunctionCall | NotGiven = NOT_GIVEN,\n    functions: Iterable[Function] | NotGiven = NOT_GIVEN,\n    logit_bias: (\n        Optional[Dict[str, int]] | NotGiven\n    ) = NOT_GIVEN,\n    logprobs: Optional[bool] | NotGiven = NOT_GIVEN,\n    max_tokens: Optional[int] | NotGiven = NOT_GIVEN,\n    n: Optional[int] | NotGiven = NOT_GIVEN,\n    presence_penalty: (\n        Optional[float] | NotGiven\n    ) = NOT_GIVEN,\n    response_format: ResponseFormat | NotGiven = NOT_GIVEN,\n    seed: Optional[int] | NotGiven = NOT_GIVEN,\n    stop: (\n        Union[Optional[str], List[str]] | NotGiven\n    ) = NOT_GIVEN,\n    stream: Optional[Literal[False]] | NotGiven = NOT_GIVEN,\n    temperature: Optional[float] | NotGiven = NOT_GIVEN,\n    tool_choice: (\n        ChatCompletionToolChoiceOptionParam | NotGiven\n    ) = NOT_GIVEN,\n    tools: (\n        Iterable[ChatCompletionToolParam] | NotGiven\n    ) = NOT_GIVEN,\n    top_logprobs: Optional[int] | NotGiven = NOT_GIVEN,\n    top_p: Optional[float] | NotGiven = NOT_GIVEN,\n    user: str | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; ChatCompletion\n</code></pre><pre><code>create(\n    *,\n    messages: Iterable[ChatCompletionMessageParam],\n    model: Union[\n        str,\n        Literal[\n            \"gpt-4-0125-preview\",\n            \"gpt-4-turbo-preview\",\n            \"gpt-4-1106-preview\",\n            \"gpt-4-vision-preview\",\n            \"gpt-4\",\n            \"gpt-4-0314\",\n            \"gpt-4-0613\",\n            \"gpt-4-32k\",\n            \"gpt-4-32k-0314\",\n            \"gpt-4-32k-0613\",\n            \"gpt-3.5-turbo\",\n            \"gpt-3.5-turbo-16k\",\n            \"gpt-3.5-turbo-0301\",\n            \"gpt-3.5-turbo-0613\",\n            \"gpt-3.5-turbo-1106\",\n            \"gpt-3.5-turbo-0125\",\n            \"gpt-3.5-turbo-16k-0613\",\n        ],\n    ],\n    stream: Literal[True],\n    frequency_penalty: (\n        Optional[float] | NotGiven\n    ) = NOT_GIVEN,\n    function_call: FunctionCall | NotGiven = NOT_GIVEN,\n    functions: Iterable[Function] | NotGiven = NOT_GIVEN,\n    logit_bias: (\n        Optional[Dict[str, int]] | NotGiven\n    ) = NOT_GIVEN,\n    logprobs: Optional[bool] | NotGiven = NOT_GIVEN,\n    max_tokens: Optional[int] | NotGiven = NOT_GIVEN,\n    n: Optional[int] | NotGiven = NOT_GIVEN,\n    presence_penalty: (\n        Optional[float] | NotGiven\n    ) = NOT_GIVEN,\n    response_format: ResponseFormat | NotGiven = NOT_GIVEN,\n    seed: Optional[int] | NotGiven = NOT_GIVEN,\n    stop: (\n        Union[Optional[str], List[str]] | NotGiven\n    ) = NOT_GIVEN,\n    temperature: Optional[float] | NotGiven = NOT_GIVEN,\n    tool_choice: (\n        ChatCompletionToolChoiceOptionParam | NotGiven\n    ) = NOT_GIVEN,\n    tools: (\n        Iterable[ChatCompletionToolParam] | NotGiven\n    ) = NOT_GIVEN,\n    top_logprobs: Optional[int] | NotGiven = NOT_GIVEN,\n    top_p: Optional[float] | NotGiven = NOT_GIVEN,\n    user: str | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; Stream[ChatCompletionChunk]\n</code></pre><pre><code>create(\n    *,\n    messages: Iterable[ChatCompletionMessageParam],\n    model: Union[\n        str,\n        Literal[\n            \"gpt-4-0125-preview\",\n            \"gpt-4-turbo-preview\",\n            \"gpt-4-1106-preview\",\n            \"gpt-4-vision-preview\",\n            \"gpt-4\",\n            \"gpt-4-0314\",\n            \"gpt-4-0613\",\n            \"gpt-4-32k\",\n            \"gpt-4-32k-0314\",\n            \"gpt-4-32k-0613\",\n            \"gpt-3.5-turbo\",\n            \"gpt-3.5-turbo-16k\",\n            \"gpt-3.5-turbo-0301\",\n            \"gpt-3.5-turbo-0613\",\n            \"gpt-3.5-turbo-1106\",\n            \"gpt-3.5-turbo-0125\",\n            \"gpt-3.5-turbo-16k-0613\",\n        ],\n    ],\n    stream: bool,\n    frequency_penalty: (\n        Optional[float] | NotGiven\n    ) = NOT_GIVEN,\n    function_call: FunctionCall | NotGiven = NOT_GIVEN,\n    functions: Iterable[Function] | NotGiven = NOT_GIVEN,\n    logit_bias: (\n        Optional[Dict[str, int]] | NotGiven\n    ) = NOT_GIVEN,\n    logprobs: Optional[bool] | NotGiven = NOT_GIVEN,\n    max_tokens: Optional[int] | NotGiven = NOT_GIVEN,\n    n: Optional[int] | NotGiven = NOT_GIVEN,\n    presence_penalty: (\n        Optional[float] | NotGiven\n    ) = NOT_GIVEN,\n    response_format: ResponseFormat | NotGiven = NOT_GIVEN,\n    seed: Optional[int] | NotGiven = NOT_GIVEN,\n    stop: (\n        Union[Optional[str], List[str]] | NotGiven\n    ) = NOT_GIVEN,\n    temperature: Optional[float] | NotGiven = NOT_GIVEN,\n    tool_choice: (\n        ChatCompletionToolChoiceOptionParam | NotGiven\n    ) = NOT_GIVEN,\n    tools: (\n        Iterable[ChatCompletionToolParam] | NotGiven\n    ) = NOT_GIVEN,\n    top_logprobs: Optional[int] | NotGiven = NOT_GIVEN,\n    top_p: Optional[float] | NotGiven = NOT_GIVEN,\n    user: str | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; ChatCompletion | Stream[ChatCompletionChunk]\n</code></pre> <pre><code>create(\n    *,\n    messages: Iterable[ChatCompletionMessageParam],\n    model: Union[\n        str,\n        Literal[\n            \"gpt-4-0125-preview\",\n            \"gpt-4-turbo-preview\",\n            \"gpt-4-1106-preview\",\n            \"gpt-4-vision-preview\",\n            \"gpt-4\",\n            \"gpt-4-0314\",\n            \"gpt-4-0613\",\n            \"gpt-4-32k\",\n            \"gpt-4-32k-0314\",\n            \"gpt-4-32k-0613\",\n            \"gpt-3.5-turbo\",\n            \"gpt-3.5-turbo-16k\",\n            \"gpt-3.5-turbo-0301\",\n            \"gpt-3.5-turbo-0613\",\n            \"gpt-3.5-turbo-1106\",\n            \"gpt-3.5-turbo-0125\",\n            \"gpt-3.5-turbo-16k-0613\",\n        ],\n    ],\n    frequency_penalty: (\n        Optional[float] | NotGiven\n    ) = NOT_GIVEN,\n    function_call: FunctionCall | NotGiven = NOT_GIVEN,\n    functions: Iterable[Function] | NotGiven = NOT_GIVEN,\n    logit_bias: (\n        Optional[Dict[str, int]] | NotGiven\n    ) = NOT_GIVEN,\n    logprobs: Optional[bool] | NotGiven = NOT_GIVEN,\n    max_tokens: Optional[int] | NotGiven = NOT_GIVEN,\n    n: Optional[int] | NotGiven = NOT_GIVEN,\n    presence_penalty: (\n        Optional[float] | NotGiven\n    ) = NOT_GIVEN,\n    response_format: ResponseFormat | NotGiven = NOT_GIVEN,\n    seed: Optional[int] | NotGiven = NOT_GIVEN,\n    stop: (\n        Union[Optional[str], List[str]] | NotGiven\n    ) = NOT_GIVEN,\n    stream: (\n        Optional[Literal[False]] | Literal[True] | NotGiven\n    ) = NOT_GIVEN,\n    temperature: Optional[float] | NotGiven = NOT_GIVEN,\n    tool_choice: (\n        ChatCompletionToolChoiceOptionParam | NotGiven\n    ) = NOT_GIVEN,\n    tools: (\n        Iterable[ChatCompletionToolParam] | NotGiven\n    ) = NOT_GIVEN,\n    top_logprobs: Optional[int] | NotGiven = NOT_GIVEN,\n    top_p: Optional[float] | NotGiven = NOT_GIVEN,\n    user: str | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; ChatCompletion | Stream[ChatCompletionChunk]\n</code></pre> <p>Creates a model response for the given chat conversation, tailored by a variety of customizable parameters.</p> <p>This method allows for detailed control over the chat completion process, including model selection, response formatting, and dynamic interaction through streaming.</p> <p>Parameters:</p> Name Type Description Default <code>messages</code> <code>Iterable[ChatCompletionMessageParam]</code> <p>Messages comprising the conversation so far. Example Python code available at How to format inputs to ChatGPT models.</p> required <code>model</code> <code>str | Literal[...]</code> <p>ID of the model to use. Refer to the model endpoint compatibility table for details on which models are compatible with the Chat API.</p> required <code>stream</code> <code>Literal[True]</code> <p>If True, enables streaming of message deltas. Tokens are sent as server-sent events as they become available, terminating with a <code>data: [DONE]</code> message. See Using server-sent events for more on this format and How to stream completions for example Python code.</p> <code>NOT_GIVEN</code> <code>frequency_penalty</code> <code>Optional[float], default=NOT_GIVEN</code> <p>Adjusts token generation frequency to discourage repetition, with a range between -2.0 and 2.0. More details at frequency and presence penalties.</p> <code>NOT_GIVEN</code> <code>function_call</code> <code>FunctionCall</code> <p>Deprecated in favor of <code>tool_choice</code>. Controls the function call behavior within the model.</p> <code>NOT_GIVEN</code> <code>functions</code> <code>Iterable[Function]</code> <p>Deprecated in favor of <code>tools</code>. Lists functions the model can call.</p> <code>NOT_GIVEN</code> <code>logit_bias</code> <code>Optional[Dict[str, int]], default=NOT_GIVEN</code> <p>Modifies the likelihood of specified tokens. Accepts a dict mapping token IDs to bias values (-100 to 100).</p> <code>NOT_GIVEN</code> <code>logprobs</code> <code>Optional[bool], default=NOT_GIVEN</code> <p>Includes log probabilities of output tokens when True. Not available for <code>gpt-4-vision-preview</code>.</p> <code>NOT_GIVEN</code> <code>max_tokens</code> <code>Optional[int], default=NOT_GIVEN</code> <p>Sets the maximum token count for the chat completion. See How to count tokens with TikToken for token counting examples.</p> <code>NOT_GIVEN</code> <code>n</code> <code>Optional[int], default=NOT_GIVEN</code> <p>Number of chat completion choices to generate for each message. Affects cost.</p> <code>NOT_GIVEN</code> <code>presence_penalty</code> <code>Optional[float], default=NOT_GIVEN</code> <p>Adjusts for token presence to promote topic diversity, with a range between -2.0 and 2.0.</p> <code>NOT_GIVEN</code> <code>response_format</code> <code>ResponseFormat</code> <p>Specifies the model output format, compatible with GPT-4 Turbo and GPT-3.5 Turbo models newer than <code>gpt-3.5-turbo-1106</code>. JSON mode ensures valid JSON output.</p> <code>NOT_GIVEN</code> <code>seed</code> <code>Optional[int], default=NOT_GIVEN</code> <p>Seeds the RNG for deterministic outputs. Beta feature.</p> <code>NOT_GIVEN</code> <code>stop</code> <code>Union[Optional[str], List[str]], default=NOT_GIVEN</code> <p>Sequences indicating when to halt token generation.</p> <code>NOT_GIVEN</code> <code>temperature</code> <code>Optional[float], default=NOT_GIVEN</code> <p>Controls output randomness. Recommended to adjust this or <code>top_p</code>, but not both.</p> <code>NOT_GIVEN</code> <code>tool_choice</code> <code>ChatCompletionToolChoiceOptionParam</code> <p>Selects a tool or function for the model to use.</p> <code>NOT_GIVEN</code> <code>tools</code> <code>Iterable[ChatCompletionToolParam]</code> <p>Specifies available tools for the model, currently limited to functions.</p> <code>NOT_GIVEN</code> <code>top_logprobs</code> <code>Optional[int], default=NOT_GIVEN</code> <p>Returns top log probabilities for each token position. Requires <code>logprobs</code> to be True.</p> <code>NOT_GIVEN</code> <code>top_p</code> <code>Optional[float], default=NOT_GIVEN</code> <p>Nucleus sampling parameter, considering only the top probability mass for generation.</p> <code>NOT_GIVEN</code> <code>user</code> <code>str | NotGiven</code> <p>Unique identifier for the end-user, assisting in abuse monitoring. Learn more at End-user IDs.</p> <code>NOT_GIVEN</code> <code>extra_headers</code> <code>Headers</code> <p>Additional HTTP headers for the request.</p> <code>None</code> <code>extra_query</code> <code>Query</code> <p>Additional query parameters for the request.</p> <code>None</code> <code>extra_body</code> <code>Body</code> <p>Additional body content for the request.</p> <code>None</code> <code>timeout</code> <code>float | httpx.Timeout | None | NotGiven, default=NOT_GIVEN</code> <p>Custom timeout for this request, overriding the default settings.</p> <code>NOT_GIVEN</code> <p>Returns:</p> Type Description <code>ChatCompletion | Stream[ChatCompletionChunk]</code> <p>Stream[ChatCompletionChunk]: A stream of chat completion chunks for real-time interaction.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; create(\n...     messages=[{\"role\": \"user\", \"content\": \"Hello, world!\"}],\n...     model=\"gpt-3.5-turbo\",\n...     stream=True,\n...     frequency_penalty=0.5,\n...     # Additional parameters...\n... )\n&lt;Stream of ChatCompletionChunk&gt;\n</code></pre>"},{"location":"reference/resources/chat/#src.openai.resources.chat.Completions.with_raw_response","title":"with_raw_response","text":"<pre><code>with_raw_response() -&gt; CompletionsWithRawResponse\n</code></pre>"},{"location":"reference/resources/chat/#src.openai.resources.chat.Completions.with_streaming_response","title":"with_streaming_response","text":"<pre><code>with_streaming_response() -&gt; (\n    CompletionsWithStreamingResponse\n)\n</code></pre>"},{"location":"reference/resources/chat/#src.openai.resources.chat.CompletionsWithRawResponse","title":"CompletionsWithRawResponse","text":"<pre><code>CompletionsWithRawResponse(completions: Completions)\n</code></pre> <p>Attributes:</p> Name Type Description <code>create</code>"},{"location":"reference/resources/chat/#src.openai.resources.chat.CompletionsWithRawResponse.create","title":"create  <code>instance-attribute</code>","text":"<pre><code>create = to_raw_response_wrapper(create)\n</code></pre>"},{"location":"reference/resources/chat/#src.openai.resources.chat.CompletionsWithStreamingResponse","title":"CompletionsWithStreamingResponse","text":"<pre><code>CompletionsWithStreamingResponse(completions: Completions)\n</code></pre> <p>Attributes:</p> Name Type Description <code>create</code>"},{"location":"reference/resources/chat/#src.openai.resources.chat.CompletionsWithStreamingResponse.create","title":"create  <code>instance-attribute</code>","text":"<pre><code>create = to_streamed_response_wrapper(create)\n</code></pre>"},{"location":"reference/resources/chat/chat/","title":"chat","text":"<p>The <code>chat</code> module provides classes for creating and managing chat sessions that leverage OpenAI's language models to generate conversational responses.</p> <p>The module supports both synchronous and asynchronous operations, offering interfaces for direct interaction with the completion endpoints tailored for chat applications. Designed for developers looking to integrate AI-powered chat functionalities into their applications and features like raw and streaming response handling for more flexible integration.</p> <p>Classes:</p> Name Description <code>AsyncChat</code> <code>AsyncChatWithRawResponse</code> <code>AsyncChatWithStreamingResponse</code> <code>Chat</code> <code>ChatWithRawResponse</code> <code>ChatWithStreamingResponse</code>"},{"location":"reference/resources/chat/chat/#src.openai.resources.chat.chat.AsyncChat","title":"AsyncChat","text":"<pre><code>AsyncChat(client: AsyncOpenAI)\n</code></pre> <p>Methods:</p> Name Description <code>completions</code> <code>with_raw_response</code> <code>with_streaming_response</code>"},{"location":"reference/resources/chat/chat/#src.openai.resources.chat.chat.AsyncChat.completions","title":"completions","text":"<pre><code>completions() -&gt; AsyncCompletions\n</code></pre>"},{"location":"reference/resources/chat/chat/#src.openai.resources.chat.chat.AsyncChat.with_raw_response","title":"with_raw_response","text":"<pre><code>with_raw_response() -&gt; AsyncChatWithRawResponse\n</code></pre>"},{"location":"reference/resources/chat/chat/#src.openai.resources.chat.chat.AsyncChat.with_streaming_response","title":"with_streaming_response","text":"<pre><code>with_streaming_response() -&gt; AsyncChatWithStreamingResponse\n</code></pre>"},{"location":"reference/resources/chat/chat/#src.openai.resources.chat.chat.AsyncChatWithRawResponse","title":"AsyncChatWithRawResponse","text":"<pre><code>AsyncChatWithRawResponse(chat: AsyncChat)\n</code></pre> <p>Methods:</p> Name Description <code>completions</code>"},{"location":"reference/resources/chat/chat/#src.openai.resources.chat.chat.AsyncChatWithRawResponse.completions","title":"completions","text":"<pre><code>completions() -&gt; AsyncCompletionsWithRawResponse\n</code></pre>"},{"location":"reference/resources/chat/chat/#src.openai.resources.chat.chat.AsyncChatWithStreamingResponse","title":"AsyncChatWithStreamingResponse","text":"<pre><code>AsyncChatWithStreamingResponse(chat: AsyncChat)\n</code></pre> <p>Methods:</p> Name Description <code>completions</code>"},{"location":"reference/resources/chat/chat/#src.openai.resources.chat.chat.AsyncChatWithStreamingResponse.completions","title":"completions","text":"<pre><code>completions() -&gt; AsyncCompletionsWithStreamingResponse\n</code></pre>"},{"location":"reference/resources/chat/chat/#src.openai.resources.chat.chat.Chat","title":"Chat","text":"<pre><code>Chat(client: OpenAI)\n</code></pre> <p>Methods:</p> Name Description <code>completions</code> <code>with_raw_response</code> <code>with_streaming_response</code>"},{"location":"reference/resources/chat/chat/#src.openai.resources.chat.chat.Chat.completions","title":"completions","text":"<pre><code>completions() -&gt; Completions\n</code></pre>"},{"location":"reference/resources/chat/chat/#src.openai.resources.chat.chat.Chat.with_raw_response","title":"with_raw_response","text":"<pre><code>with_raw_response() -&gt; ChatWithRawResponse\n</code></pre>"},{"location":"reference/resources/chat/chat/#src.openai.resources.chat.chat.Chat.with_streaming_response","title":"with_streaming_response","text":"<pre><code>with_streaming_response() -&gt; ChatWithStreamingResponse\n</code></pre>"},{"location":"reference/resources/chat/chat/#src.openai.resources.chat.chat.ChatWithRawResponse","title":"ChatWithRawResponse","text":"<pre><code>ChatWithRawResponse(chat: Chat)\n</code></pre> <p>Methods:</p> Name Description <code>completions</code>"},{"location":"reference/resources/chat/chat/#src.openai.resources.chat.chat.ChatWithRawResponse.completions","title":"completions","text":"<pre><code>completions() -&gt; CompletionsWithRawResponse\n</code></pre>"},{"location":"reference/resources/chat/chat/#src.openai.resources.chat.chat.ChatWithStreamingResponse","title":"ChatWithStreamingResponse","text":"<pre><code>ChatWithStreamingResponse(chat: Chat)\n</code></pre> <p>Methods:</p> Name Description <code>completions</code>"},{"location":"reference/resources/chat/chat/#src.openai.resources.chat.chat.ChatWithStreamingResponse.completions","title":"completions","text":"<pre><code>completions() -&gt; CompletionsWithStreamingResponse\n</code></pre>"},{"location":"reference/resources/chat/completions/","title":"completions","text":"<p>The <code>chat.completions</code> module provides access to the chat completions endpoint of the OpenAI API. It supports the latest models including <code>gpt-4</code>, <code>gpt-4-turbo-preview</code>, <code>gpt-4-vision-preview</code>, <code>gpt-4-32k</code>, <code>gpt-3.5-turbo</code>, and their respective dated model releases, along with fine-tuned versions of <code>gpt-3.5-turbo</code>.</p> <p>This module interacts with the <code>/v1/chat/completions</code> endpoint and replaces the the legacy <code>resources.completions</code> module. You're strongly encouraged to migrate existing applications that use the legacy <code>resources.completions</code> module to this one before the expected deprecation of the <code>/v1/completions</code> endpoint.</p> CLASS DESCRIPTION <code>AsyncCompletions</code> <code>AsyncCompletionsWithRawResponse</code> <code>AsyncCompletionsWithStreamingResponse</code> <code>Completions</code> <code>CompletionsWithRawResponse</code> <code>CompletionsWithStreamingResponse</code>"},{"location":"reference/resources/chat/completions/#src.openai.resources.chat.completions.AsyncCompletions","title":"AsyncCompletions","text":"<pre><code>AsyncCompletions(client: AsyncOpenAI)\n</code></pre> METHOD DESCRIPTION <code>create</code> <p>Generates a chat completion by submitting a conversation history and model parameters, supporting various configurations to tailor the chat completion process, including penalties, response formats, and streaming outputs.</p> <code>with_raw_response</code> <code>with_streaming_response</code>"},{"location":"reference/resources/chat/completions/#src.openai.resources.chat.completions.AsyncCompletions.create","title":"create  <code>async</code>","text":"<pre><code>create(\n    *,\n    messages: Iterable[ChatCompletionMessageParam],\n    model: Union[\n        str,\n        Literal[\n            \"gpt-4-0125-preview\",\n            \"gpt-4-turbo-preview\",\n            \"gpt-4-1106-preview\",\n            \"gpt-4-vision-preview\",\n            \"gpt-4\",\n            \"gpt-4-0314\",\n            \"gpt-4-0613\",\n            \"gpt-4-32k\",\n            \"gpt-4-32k-0314\",\n            \"gpt-4-32k-0613\",\n            \"gpt-3.5-turbo\",\n            \"gpt-3.5-turbo-16k\",\n            \"gpt-3.5-turbo-0301\",\n            \"gpt-3.5-turbo-0613\",\n            \"gpt-3.5-turbo-1106\",\n            \"gpt-3.5-turbo-0125\",\n            \"gpt-3.5-turbo-16k-0613\",\n        ],\n    ],\n    frequency_penalty: (\n        Optional[float] | NotGiven\n    ) = NOT_GIVEN,\n    function_call: FunctionCall | NotGiven = NOT_GIVEN,\n    functions: Iterable[Function] | NotGiven = NOT_GIVEN,\n    logit_bias: (\n        Optional[Dict[str, int]] | NotGiven\n    ) = NOT_GIVEN,\n    logprobs: Optional[bool] | NotGiven = NOT_GIVEN,\n    max_tokens: Optional[int] | NotGiven = NOT_GIVEN,\n    n: Optional[int] | NotGiven = NOT_GIVEN,\n    presence_penalty: (\n        Optional[float] | NotGiven\n    ) = NOT_GIVEN,\n    response_format: ResponseFormat | NotGiven = NOT_GIVEN,\n    seed: Optional[int] | NotGiven = NOT_GIVEN,\n    stop: (\n        Union[Optional[str], List[str]] | NotGiven\n    ) = NOT_GIVEN,\n    stream: Optional[Literal[False]] | NotGiven = NOT_GIVEN,\n    temperature: Optional[float] | NotGiven = NOT_GIVEN,\n    tool_choice: (\n        ChatCompletionToolChoiceOptionParam | NotGiven\n    ) = NOT_GIVEN,\n    tools: (\n        Iterable[ChatCompletionToolParam] | NotGiven\n    ) = NOT_GIVEN,\n    top_logprobs: Optional[int] | NotGiven = NOT_GIVEN,\n    top_p: Optional[float] | NotGiven = NOT_GIVEN,\n    user: str | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; ChatCompletion\n</code></pre><pre><code>create(\n    *,\n    messages: Iterable[ChatCompletionMessageParam],\n    model: Union[\n        str,\n        Literal[\n            \"gpt-4-0125-preview\",\n            \"gpt-4-turbo-preview\",\n            \"gpt-4-1106-preview\",\n            \"gpt-4-vision-preview\",\n            \"gpt-4\",\n            \"gpt-4-0314\",\n            \"gpt-4-0613\",\n            \"gpt-4-32k\",\n            \"gpt-4-32k-0314\",\n            \"gpt-4-32k-0613\",\n            \"gpt-3.5-turbo\",\n            \"gpt-3.5-turbo-16k\",\n            \"gpt-3.5-turbo-0301\",\n            \"gpt-3.5-turbo-0613\",\n            \"gpt-3.5-turbo-1106\",\n            \"gpt-3.5-turbo-0125\",\n            \"gpt-3.5-turbo-16k-0613\",\n        ],\n    ],\n    stream: Literal[True],\n    frequency_penalty: (\n        Optional[float] | NotGiven\n    ) = NOT_GIVEN,\n    function_call: FunctionCall | NotGiven = NOT_GIVEN,\n    functions: Iterable[Function] | NotGiven = NOT_GIVEN,\n    logit_bias: (\n        Optional[Dict[str, int]] | NotGiven\n    ) = NOT_GIVEN,\n    logprobs: Optional[bool] | NotGiven = NOT_GIVEN,\n    max_tokens: Optional[int] | NotGiven = NOT_GIVEN,\n    n: Optional[int] | NotGiven = NOT_GIVEN,\n    presence_penalty: (\n        Optional[float] | NotGiven\n    ) = NOT_GIVEN,\n    response_format: ResponseFormat | NotGiven = NOT_GIVEN,\n    seed: Optional[int] | NotGiven = NOT_GIVEN,\n    stop: (\n        Union[Optional[str], List[str]] | NotGiven\n    ) = NOT_GIVEN,\n    temperature: Optional[float] | NotGiven = NOT_GIVEN,\n    tool_choice: (\n        ChatCompletionToolChoiceOptionParam | NotGiven\n    ) = NOT_GIVEN,\n    tools: (\n        Iterable[ChatCompletionToolParam] | NotGiven\n    ) = NOT_GIVEN,\n    top_logprobs: Optional[int] | NotGiven = NOT_GIVEN,\n    top_p: Optional[float] | NotGiven = NOT_GIVEN,\n    user: str | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; AsyncStream[ChatCompletionChunk]\n</code></pre><pre><code>create(\n    *,\n    messages: Iterable[ChatCompletionMessageParam],\n    model: Union[\n        str,\n        Literal[\n            \"gpt-4-0125-preview\",\n            \"gpt-4-turbo-preview\",\n            \"gpt-4-1106-preview\",\n            \"gpt-4-vision-preview\",\n            \"gpt-4\",\n            \"gpt-4-0314\",\n            \"gpt-4-0613\",\n            \"gpt-4-32k\",\n            \"gpt-4-32k-0314\",\n            \"gpt-4-32k-0613\",\n            \"gpt-3.5-turbo\",\n            \"gpt-3.5-turbo-16k\",\n            \"gpt-3.5-turbo-0301\",\n            \"gpt-3.5-turbo-0613\",\n            \"gpt-3.5-turbo-1106\",\n            \"gpt-3.5-turbo-0125\",\n            \"gpt-3.5-turbo-16k-0613\",\n        ],\n    ],\n    stream: bool,\n    frequency_penalty: (\n        Optional[float] | NotGiven\n    ) = NOT_GIVEN,\n    function_call: FunctionCall | NotGiven = NOT_GIVEN,\n    functions: Iterable[Function] | NotGiven = NOT_GIVEN,\n    logit_bias: (\n        Optional[Dict[str, int]] | NotGiven\n    ) = NOT_GIVEN,\n    logprobs: Optional[bool] | NotGiven = NOT_GIVEN,\n    max_tokens: Optional[int] | NotGiven = NOT_GIVEN,\n    n: Optional[int] | NotGiven = NOT_GIVEN,\n    presence_penalty: (\n        Optional[float] | NotGiven\n    ) = NOT_GIVEN,\n    response_format: ResponseFormat | NotGiven = NOT_GIVEN,\n    seed: Optional[int] | NotGiven = NOT_GIVEN,\n    stop: (\n        Union[Optional[str], List[str]] | NotGiven\n    ) = NOT_GIVEN,\n    temperature: Optional[float] | NotGiven = NOT_GIVEN,\n    tool_choice: (\n        ChatCompletionToolChoiceOptionParam | NotGiven\n    ) = NOT_GIVEN,\n    tools: (\n        Iterable[ChatCompletionToolParam] | NotGiven\n    ) = NOT_GIVEN,\n    top_logprobs: Optional[int] | NotGiven = NOT_GIVEN,\n    top_p: Optional[float] | NotGiven = NOT_GIVEN,\n    user: str | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; ChatCompletion | AsyncStream[ChatCompletionChunk]\n</code></pre> <pre><code>create(\n    *,\n    messages: Iterable[ChatCompletionMessageParam],\n    model: Union[\n        str,\n        Literal[\n            \"gpt-4-0125-preview\",\n            \"gpt-4-turbo-preview\",\n            \"gpt-4-1106-preview\",\n            \"gpt-4-vision-preview\",\n            \"gpt-4\",\n            \"gpt-4-0314\",\n            \"gpt-4-0613\",\n            \"gpt-4-32k\",\n            \"gpt-4-32k-0314\",\n            \"gpt-4-32k-0613\",\n            \"gpt-3.5-turbo\",\n            \"gpt-3.5-turbo-16k\",\n            \"gpt-3.5-turbo-0301\",\n            \"gpt-3.5-turbo-0613\",\n            \"gpt-3.5-turbo-1106\",\n            \"gpt-3.5-turbo-0125\",\n            \"gpt-3.5-turbo-16k-0613\",\n        ],\n    ],\n    frequency_penalty: (\n        Optional[float] | NotGiven\n    ) = NOT_GIVEN,\n    function_call: FunctionCall | NotGiven = NOT_GIVEN,\n    functions: Iterable[Function] | NotGiven = NOT_GIVEN,\n    logit_bias: (\n        Optional[Dict[str, int]] | NotGiven\n    ) = NOT_GIVEN,\n    logprobs: Optional[bool] | NotGiven = NOT_GIVEN,\n    max_tokens: Optional[int] | NotGiven = NOT_GIVEN,\n    n: Optional[int] | NotGiven = NOT_GIVEN,\n    presence_penalty: (\n        Optional[float] | NotGiven\n    ) = NOT_GIVEN,\n    response_format: ResponseFormat | NotGiven = NOT_GIVEN,\n    seed: Optional[int] | NotGiven = NOT_GIVEN,\n    stop: (\n        Union[Optional[str], List[str]] | NotGiven\n    ) = NOT_GIVEN,\n    stream: (\n        Optional[Literal[False]] | Literal[True] | NotGiven\n    ) = NOT_GIVEN,\n    temperature: Optional[float] | NotGiven = NOT_GIVEN,\n    tool_choice: (\n        ChatCompletionToolChoiceOptionParam | NotGiven\n    ) = NOT_GIVEN,\n    tools: (\n        Iterable[ChatCompletionToolParam] | NotGiven\n    ) = NOT_GIVEN,\n    top_logprobs: Optional[int] | NotGiven = NOT_GIVEN,\n    top_p: Optional[float] | NotGiven = NOT_GIVEN,\n    user: str | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; ChatCompletion | AsyncStream[ChatCompletionChunk]\n</code></pre> <p>Generates a chat completion by submitting a conversation history and model parameters, supporting various configurations to tailor the chat completion process, including penalties, response formats, and streaming outputs.</p> RETURNS DESCRIPTION <code>ChatCompletion | AsyncStream[ChatCompletionChunk]</code> <p>AsyncStream[ChatCompletionChunk]: Stream of chat completion chunks for incremental output consumption.</p> <code>ChatCompletion</code> <p>An object containing the generated chat completion and other relevant details, such as             the chosen tokens and any associated metadata.</p> <p> TYPE: <code>ChatCompletion | AsyncStream[ChatCompletionChunk]</code> </p> RAISES DESCRIPTION <code>OpenAIError</code> <p>If there's an issue with API request or parsing the response.</p> <p>Examples: <pre><code>completion = client.Completions().create(\n    messages=[{\"role\": \"user\", \"content\": \"Tell me a joke.\"}],\n    model=\"text-davinci-003\",\n    max_tokens=60\n)\nprint(completion.choices[0].text)\n</code></pre></p> <pre><code>completion = client.Completions().create(\n    messages=[{\"role\": \"user\", \"content\": \"How do you make a latte?\"}],\n    model=\"gpt-3.5-turbo\",\n    max_tokens=150\n)\nprint(completion.choices[0].text)\n</code></pre> <pre><code>async with client.AsyncCompletions().create(\n    messages=[{\"role\": \"user\", \"content\": \"What's the weather like in Tokyo?\"}],\n    model=\"text-davinci-003\",\n    frequency_penalty=0.5,\n    presence_penalty=0.5\n) as stream:\n    async for chunk in stream:\n        print(chunk.text)\n</code></pre> PARAMETER  DESCRIPTION <code>messages</code> <p>A sequence of message objects that make up the conversation so far. Each message is a dictionary that should include the keys <code>role</code> and <code>content</code>, where <code>role</code> is either <code>user</code> or <code>assistant</code>, indicating who is speaking, and <code>content</code> is a string containing the message text. This parameter is essential for constructing the conversational context for the model's response.</p> <p> TYPE: <code>Iterable[ChatCompletionMessageParam]</code> </p> <code>model</code> <p>The model ID of the OpenAI GPT model to use for generating the chat completion. This parameter specifies which version of the model to use, for example, <code>text-davinci-003</code> for general-purpose completions or <code>gpt-3.5-turbo</code> for optimized performance. The choice of model affects the quality, style, and capabilities of the generated content.</p> <p> TYPE: <code>Union[str, Literal[...]]</code> </p> <code>stream</code> <p>Whether the response should be streamed. Streaming can be useful for receiving responses as they are generated, especially for long completions. This approach enables real-time interaction and processing of the model's output.</p> <p> TYPE: <code>Optional[bool]</code> DEFAULT: <code>NOT_GIVEN</code> </p> <code>frequency_penalty</code> <p>Adjusts the likelihood of the model repeating the same line verbatim. Values can range from -2.0 to 2.0, with positive values making repeats less likely. This parameter helps in controlling the diversity of the generated text.</p> <p> TYPE: <code>Optional[float]</code> DEFAULT: <code>NOT_GIVEN</code> </p> <code>function_call</code> <p>Deprecated. Originally used to specify whether the model should execute a function call. While it is still accepted for backward compatibility, the <code>tool_choice</code> parameter is recommended for new implementations.</p> <p> TYPE: <code>Optional[FunctionCall]</code> DEFAULT: <code>NOT_GIVEN</code> </p> <code>functions</code> <p>Deprecated. Originally provided a list of functions the model could choose to call during generation. Like <code>function_call</code>, this parameter has been superseded by <code>tools</code>.</p> <p> TYPE: <code>Optional[Iterable[Function]]</code> DEFAULT: <code>NOT_GIVEN</code> </p> <code>logit_bias</code> <p>Modifies token likelihood, mapping token IDs to bias values (-100 to 100), influencing selection. This mechanism allows for fine-tuning the presence or avoidance of specific words or phrases in the generated text.</p> <p> TYPE: <code>Optional[Dicst[str, int]]</code> DEFAULT: <code>NOT_GIVEN</code> </p> <code>logprobs</code> <p>Whether to return the log probabilities of the tokens generated in the completion. Useful for model introspection and understanding the model's decision-making process. Note: This feature might not be available for all models.</p> <p> TYPE: <code>Optional[bool]</code> DEFAULT: <code>NOT_GIVEN</code> </p> <code>max_tokens</code> <p>The maximum number of tokens to generate in the completion. This limit includes the tokens in the prompt. Careful management of this parameter is crucial for controlling the length and computational cost of model operations.</p> <p> TYPE: <code>Optional[int]</code> DEFAULT: <code>NOT_GIVEN</code> </p> <code>n</code> <p>The number of completions to generate for each prompt. Higher values allow for more diversity in the responses but increase computational cost. Balancing this parameter is key to achieving desired output variability while managing resource use.</p> <p> TYPE: <code>Optional[int]</code> DEFAULT: <code>NOT_GIVEN</code> </p> <code>presence_penalty</code> <p>Encourages new content by penalizing token presence, with values from -2.0 to 2.0. This parameter influences the model to explore new topics and ideas, enhancing the creativity and variability of the output.</p> <p> TYPE: <code>Optional[float]</code> DEFAULT: <code>NOT_GIVEN</code> </p> <code>response_format</code> <p>Specifies how the model's responses should be formatted. For example, responses can be structured as plain text, JSON objects, or other formats depending on the model's capabilities. This flexibility allows for tailored outputs to suit different applications and processing needs.</p> <p> TYPE: <code>Optional[ResponseFormat]</code> DEFAULT: <code>NOT_GIVEN</code> </p> <code>seed</code> <p>Seed for deterministic randomness, ensuring same inputs yield consistent outputs. This feature is beneficial for reproducibility and debugging purposes, allowing users to obtain the same results from identical requests.</p> <p> TYPE: <code>Optional[int]</code> DEFAULT: <code>NOT_GIVEN</code> </p> <code>stop</code> <p>Sequences where the API will stop generating further tokens. This can be used to indicate the end of a message or section, providing a mechanism to control the scope and completion of the generated content.</p> <p> TYPE: <code>Optional[Union[str, List[str]]]</code> DEFAULT: <code>NOT_GIVEN</code> </p> <code>temperature</code> <p>Controls the randomness of the output. A lower temperature results in more deterministic output, while a higher temperature results in more diversity. Adjusting this parameter allows users to balance between predictability and creativity in the model's responses.</p> <p> TYPE: <code>Optional[float]</code> DEFAULT: <code>NOT_GIVEN</code> </p> <code>tool_choice</code> <p>Specifies which tool the model should use if it decides to make an external call. This replaces <code>function_call</code> and offers more granular control over the model's interactive capabilities.</p> <p> TYPE: <code>Optional[ToolChoiceOptionParam]</code> DEFAULT: <code>NOT_GIVEN</code> </p> <code>tools</code> <p>Lists tools available for response generation, including functions and APIs. This parameter expands the model's ability to incorporate external data and functionalities into its responses, broadening the scope of possible applications.</p> <p> TYPE: <code>Optional[Iterable[ToolParam]]</code> DEFAULT: <code>NOT_GIVEN</code> </p> <code>top_logprobs</code> <p>Specifies the number of top logits to return, providing insight into the model's decision-making process. This information can be valuable for analyzing the model's preferences and the statistical distribution of its predictions.</p> <p> TYPE: <code>Optional[int]</code> DEFAULT: <code>NOT_GIVEN</code> </p> <code>top_p</code> <p>Nucleus sampling strategy focusing on top P% probability mass, influencing token selection. This parameter adjusts the scope of the token set considered at each step, effectively adjusting the diversity and unpredictability of the output. A balance between coherence and variety can be achieved by tuning this parameter.</p> <p> TYPE: <code>Optional[float]</code> DEFAULT: <code>NOT_GIVEN</code> </p> <code>user</code> <p>Identifies the end user of the API, aiding in monitoring usage patterns and detecting potential misuse. This parameter helps maintain the security and integrity of the system, ensuring that the API is used responsibly and in accordance with OpenAI's guidelines. End user identification best practices</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>NOT_GIVEN</code> </p> <code>extra_headers</code> <p>Additional HTTP headers to send with the request. This allows for customizing the request headers for scenarios that require specific HTTP header entries.</p> <p> TYPE: <code>Optional[Headers]</code> DEFAULT: <code>None</code> </p> <code>extra_query</code> <p>Extra query parameters for the request URL. These parameters are appended to the URL query string, providing a flexible way to extend the request with additional data.</p> <p> TYPE: <code>Optional[Query]</code> DEFAULT: <code>None</code> </p> <code>extra_body</code> <p>Additional body parameters to include in the POST request. This can be used to pass extra information that is not covered by the standard parameters.</p> <p> TYPE: <code>Optional[Body]</code> DEFAULT: <code>None</code> </p> <code>timeout</code> <p>Custom timeout for the request, overriding the default. Setting this parameter ensures that operations adhere to specific timing requirements, preventing excessively long waits or premature termination of requests.</p> <p> TYPE: <code>Optional[float | Timeout]</code> DEFAULT: <code>NOT_GIVEN</code> </p>"},{"location":"reference/resources/chat/completions/#src.openai.resources.chat.completions.AsyncCompletions.with_raw_response","title":"with_raw_response","text":"<pre><code>with_raw_response() -&gt; AsyncCompletionsWithRawResponse\n</code></pre>"},{"location":"reference/resources/chat/completions/#src.openai.resources.chat.completions.AsyncCompletions.with_streaming_response","title":"with_streaming_response","text":"<pre><code>with_streaming_response() -&gt; (\n    AsyncCompletionsWithStreamingResponse\n)\n</code></pre>"},{"location":"reference/resources/chat/completions/#src.openai.resources.chat.completions.AsyncCompletionsWithRawResponse","title":"AsyncCompletionsWithRawResponse","text":"<pre><code>AsyncCompletionsWithRawResponse(\n    completions: AsyncCompletions,\n)\n</code></pre> ATTRIBUTE DESCRIPTION <code>create</code>"},{"location":"reference/resources/chat/completions/#src.openai.resources.chat.completions.AsyncCompletionsWithRawResponse.create","title":"create  <code>instance-attribute</code>","text":"<pre><code>create = async_to_raw_response_wrapper(create)\n</code></pre>"},{"location":"reference/resources/chat/completions/#src.openai.resources.chat.completions.AsyncCompletionsWithStreamingResponse","title":"AsyncCompletionsWithStreamingResponse","text":"<pre><code>AsyncCompletionsWithStreamingResponse(\n    completions: AsyncCompletions,\n)\n</code></pre> ATTRIBUTE DESCRIPTION <code>create</code>"},{"location":"reference/resources/chat/completions/#src.openai.resources.chat.completions.AsyncCompletionsWithStreamingResponse.create","title":"create  <code>instance-attribute</code>","text":"<pre><code>create = async_to_streamed_response_wrapper(create)\n</code></pre>"},{"location":"reference/resources/chat/completions/#src.openai.resources.chat.completions.Completions","title":"Completions","text":"<pre><code>Completions(client: OpenAI)\n</code></pre> METHOD DESCRIPTION <code>create</code> <p>Creates a model response for the given chat conversation, tailored by a variety of customizable parameters.</p> <code>with_raw_response</code> <code>with_streaming_response</code>"},{"location":"reference/resources/chat/completions/#src.openai.resources.chat.completions.Completions.create","title":"create","text":"<pre><code>create(\n    *,\n    messages: Iterable[ChatCompletionMessageParam],\n    model: Union[\n        str,\n        Literal[\n            \"gpt-4-0125-preview\",\n            \"gpt-4-turbo-preview\",\n            \"gpt-4-1106-preview\",\n            \"gpt-4-vision-preview\",\n            \"gpt-4\",\n            \"gpt-4-0314\",\n            \"gpt-4-0613\",\n            \"gpt-4-32k\",\n            \"gpt-4-32k-0314\",\n            \"gpt-4-32k-0613\",\n            \"gpt-3.5-turbo\",\n            \"gpt-3.5-turbo-16k\",\n            \"gpt-3.5-turbo-0301\",\n            \"gpt-3.5-turbo-0613\",\n            \"gpt-3.5-turbo-1106\",\n            \"gpt-3.5-turbo-0125\",\n            \"gpt-3.5-turbo-16k-0613\",\n        ],\n    ],\n    frequency_penalty: (\n        Optional[float] | NotGiven\n    ) = NOT_GIVEN,\n    function_call: FunctionCall | NotGiven = NOT_GIVEN,\n    functions: Iterable[Function] | NotGiven = NOT_GIVEN,\n    logit_bias: (\n        Optional[Dict[str, int]] | NotGiven\n    ) = NOT_GIVEN,\n    logprobs: Optional[bool] | NotGiven = NOT_GIVEN,\n    max_tokens: Optional[int] | NotGiven = NOT_GIVEN,\n    n: Optional[int] | NotGiven = NOT_GIVEN,\n    presence_penalty: (\n        Optional[float] | NotGiven\n    ) = NOT_GIVEN,\n    response_format: ResponseFormat | NotGiven = NOT_GIVEN,\n    seed: Optional[int] | NotGiven = NOT_GIVEN,\n    stop: (\n        Union[Optional[str], List[str]] | NotGiven\n    ) = NOT_GIVEN,\n    stream: Optional[Literal[False]] | NotGiven = NOT_GIVEN,\n    temperature: Optional[float] | NotGiven = NOT_GIVEN,\n    tool_choice: (\n        ChatCompletionToolChoiceOptionParam | NotGiven\n    ) = NOT_GIVEN,\n    tools: (\n        Iterable[ChatCompletionToolParam] | NotGiven\n    ) = NOT_GIVEN,\n    top_logprobs: Optional[int] | NotGiven = NOT_GIVEN,\n    top_p: Optional[float] | NotGiven = NOT_GIVEN,\n    user: str | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; ChatCompletion\n</code></pre><pre><code>create(\n    *,\n    messages: Iterable[ChatCompletionMessageParam],\n    model: Union[\n        str,\n        Literal[\n            \"gpt-4-0125-preview\",\n            \"gpt-4-turbo-preview\",\n            \"gpt-4-1106-preview\",\n            \"gpt-4-vision-preview\",\n            \"gpt-4\",\n            \"gpt-4-0314\",\n            \"gpt-4-0613\",\n            \"gpt-4-32k\",\n            \"gpt-4-32k-0314\",\n            \"gpt-4-32k-0613\",\n            \"gpt-3.5-turbo\",\n            \"gpt-3.5-turbo-16k\",\n            \"gpt-3.5-turbo-0301\",\n            \"gpt-3.5-turbo-0613\",\n            \"gpt-3.5-turbo-1106\",\n            \"gpt-3.5-turbo-0125\",\n            \"gpt-3.5-turbo-16k-0613\",\n        ],\n    ],\n    stream: Literal[True],\n    frequency_penalty: (\n        Optional[float] | NotGiven\n    ) = NOT_GIVEN,\n    function_call: FunctionCall | NotGiven = NOT_GIVEN,\n    functions: Iterable[Function] | NotGiven = NOT_GIVEN,\n    logit_bias: (\n        Optional[Dict[str, int]] | NotGiven\n    ) = NOT_GIVEN,\n    logprobs: Optional[bool] | NotGiven = NOT_GIVEN,\n    max_tokens: Optional[int] | NotGiven = NOT_GIVEN,\n    n: Optional[int] | NotGiven = NOT_GIVEN,\n    presence_penalty: (\n        Optional[float] | NotGiven\n    ) = NOT_GIVEN,\n    response_format: ResponseFormat | NotGiven = NOT_GIVEN,\n    seed: Optional[int] | NotGiven = NOT_GIVEN,\n    stop: (\n        Union[Optional[str], List[str]] | NotGiven\n    ) = NOT_GIVEN,\n    temperature: Optional[float] | NotGiven = NOT_GIVEN,\n    tool_choice: (\n        ChatCompletionToolChoiceOptionParam | NotGiven\n    ) = NOT_GIVEN,\n    tools: (\n        Iterable[ChatCompletionToolParam] | NotGiven\n    ) = NOT_GIVEN,\n    top_logprobs: Optional[int] | NotGiven = NOT_GIVEN,\n    top_p: Optional[float] | NotGiven = NOT_GIVEN,\n    user: str | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; Stream[ChatCompletionChunk]\n</code></pre><pre><code>create(\n    *,\n    messages: Iterable[ChatCompletionMessageParam],\n    model: Union[\n        str,\n        Literal[\n            \"gpt-4-0125-preview\",\n            \"gpt-4-turbo-preview\",\n            \"gpt-4-1106-preview\",\n            \"gpt-4-vision-preview\",\n            \"gpt-4\",\n            \"gpt-4-0314\",\n            \"gpt-4-0613\",\n            \"gpt-4-32k\",\n            \"gpt-4-32k-0314\",\n            \"gpt-4-32k-0613\",\n            \"gpt-3.5-turbo\",\n            \"gpt-3.5-turbo-16k\",\n            \"gpt-3.5-turbo-0301\",\n            \"gpt-3.5-turbo-0613\",\n            \"gpt-3.5-turbo-1106\",\n            \"gpt-3.5-turbo-0125\",\n            \"gpt-3.5-turbo-16k-0613\",\n        ],\n    ],\n    stream: bool,\n    frequency_penalty: (\n        Optional[float] | NotGiven\n    ) = NOT_GIVEN,\n    function_call: FunctionCall | NotGiven = NOT_GIVEN,\n    functions: Iterable[Function] | NotGiven = NOT_GIVEN,\n    logit_bias: (\n        Optional[Dict[str, int]] | NotGiven\n    ) = NOT_GIVEN,\n    logprobs: Optional[bool] | NotGiven = NOT_GIVEN,\n    max_tokens: Optional[int] | NotGiven = NOT_GIVEN,\n    n: Optional[int] | NotGiven = NOT_GIVEN,\n    presence_penalty: (\n        Optional[float] | NotGiven\n    ) = NOT_GIVEN,\n    response_format: ResponseFormat | NotGiven = NOT_GIVEN,\n    seed: Optional[int] | NotGiven = NOT_GIVEN,\n    stop: (\n        Union[Optional[str], List[str]] | NotGiven\n    ) = NOT_GIVEN,\n    temperature: Optional[float] | NotGiven = NOT_GIVEN,\n    tool_choice: (\n        ChatCompletionToolChoiceOptionParam | NotGiven\n    ) = NOT_GIVEN,\n    tools: (\n        Iterable[ChatCompletionToolParam] | NotGiven\n    ) = NOT_GIVEN,\n    top_logprobs: Optional[int] | NotGiven = NOT_GIVEN,\n    top_p: Optional[float] | NotGiven = NOT_GIVEN,\n    user: str | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; ChatCompletion | Stream[ChatCompletionChunk]\n</code></pre> <pre><code>create(\n    *,\n    messages: Iterable[ChatCompletionMessageParam],\n    model: Union[\n        str,\n        Literal[\n            \"gpt-4-0125-preview\",\n            \"gpt-4-turbo-preview\",\n            \"gpt-4-1106-preview\",\n            \"gpt-4-vision-preview\",\n            \"gpt-4\",\n            \"gpt-4-0314\",\n            \"gpt-4-0613\",\n            \"gpt-4-32k\",\n            \"gpt-4-32k-0314\",\n            \"gpt-4-32k-0613\",\n            \"gpt-3.5-turbo\",\n            \"gpt-3.5-turbo-16k\",\n            \"gpt-3.5-turbo-0301\",\n            \"gpt-3.5-turbo-0613\",\n            \"gpt-3.5-turbo-1106\",\n            \"gpt-3.5-turbo-0125\",\n            \"gpt-3.5-turbo-16k-0613\",\n        ],\n    ],\n    frequency_penalty: (\n        Optional[float] | NotGiven\n    ) = NOT_GIVEN,\n    function_call: FunctionCall | NotGiven = NOT_GIVEN,\n    functions: Iterable[Function] | NotGiven = NOT_GIVEN,\n    logit_bias: (\n        Optional[Dict[str, int]] | NotGiven\n    ) = NOT_GIVEN,\n    logprobs: Optional[bool] | NotGiven = NOT_GIVEN,\n    max_tokens: Optional[int] | NotGiven = NOT_GIVEN,\n    n: Optional[int] | NotGiven = NOT_GIVEN,\n    presence_penalty: (\n        Optional[float] | NotGiven\n    ) = NOT_GIVEN,\n    response_format: ResponseFormat | NotGiven = NOT_GIVEN,\n    seed: Optional[int] | NotGiven = NOT_GIVEN,\n    stop: (\n        Union[Optional[str], List[str]] | NotGiven\n    ) = NOT_GIVEN,\n    stream: (\n        Optional[Literal[False]] | Literal[True] | NotGiven\n    ) = NOT_GIVEN,\n    temperature: Optional[float] | NotGiven = NOT_GIVEN,\n    tool_choice: (\n        ChatCompletionToolChoiceOptionParam | NotGiven\n    ) = NOT_GIVEN,\n    tools: (\n        Iterable[ChatCompletionToolParam] | NotGiven\n    ) = NOT_GIVEN,\n    top_logprobs: Optional[int] | NotGiven = NOT_GIVEN,\n    top_p: Optional[float] | NotGiven = NOT_GIVEN,\n    user: str | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; ChatCompletion | Stream[ChatCompletionChunk]\n</code></pre> <p>Creates a model response for the given chat conversation, tailored by a variety of customizable parameters.</p> <p>This method allows for detailed control over the chat completion process, including model selection, response formatting, and dynamic interaction through streaming.</p> PARAMETER  DESCRIPTION <code>messages</code> <p>Messages comprising the conversation so far. Example Python code available at How to format inputs to ChatGPT models.</p> <p> TYPE: <code>Iterable[ChatCompletionMessageParam]</code> </p> <code>model</code> <p>ID of the model to use. Refer to the model endpoint compatibility table for details on which models are compatible with the Chat API.</p> <p> TYPE: <code>str | Literal[...]</code> </p> <code>stream</code> <p>If True, enables streaming of message deltas. Tokens are sent as server-sent events as they become available, terminating with a <code>data: [DONE]</code> message. See Using server-sent events for more on this format and How to stream completions for example Python code.</p> <p> TYPE: <code>Literal[True]</code> DEFAULT: <code>NOT_GIVEN</code> </p> <code>frequency_penalty</code> <p>Adjusts token generation frequency to discourage repetition, with a range between -2.0 and 2.0. More details at frequency and presence penalties.</p> <p> TYPE: <code>Optional[float], default=NOT_GIVEN</code> DEFAULT: <code>NOT_GIVEN</code> </p> <code>function_call</code> <p>Deprecated in favor of <code>tool_choice</code>. Controls the function call behavior within the model.</p> <p> TYPE: <code>FunctionCall</code> DEFAULT: <code>NOT_GIVEN</code> </p> <code>functions</code> <p>Deprecated in favor of <code>tools</code>. Lists functions the model can call.</p> <p> TYPE: <code>Iterable[Function]</code> DEFAULT: <code>NOT_GIVEN</code> </p> <code>logit_bias</code> <p>Modifies the likelihood of specified tokens. Accepts a dict mapping token IDs to bias values (-100 to 100).</p> <p> TYPE: <code>Optional[Dict[str, int]], default=NOT_GIVEN</code> DEFAULT: <code>NOT_GIVEN</code> </p> <code>logprobs</code> <p>Includes log probabilities of output tokens when True. Not available for <code>gpt-4-vision-preview</code>.</p> <p> TYPE: <code>Optional[bool], default=NOT_GIVEN</code> DEFAULT: <code>NOT_GIVEN</code> </p> <code>max_tokens</code> <p>Sets the maximum token count for the chat completion. See How to count tokens with TikToken for token counting examples.</p> <p> TYPE: <code>Optional[int], default=NOT_GIVEN</code> DEFAULT: <code>NOT_GIVEN</code> </p> <code>n</code> <p>Number of chat completion choices to generate for each message. Affects cost.</p> <p> TYPE: <code>Optional[int], default=NOT_GIVEN</code> DEFAULT: <code>NOT_GIVEN</code> </p> <code>presence_penalty</code> <p>Adjusts for token presence to promote topic diversity, with a range between -2.0 and 2.0.</p> <p> TYPE: <code>Optional[float], default=NOT_GIVEN</code> DEFAULT: <code>NOT_GIVEN</code> </p> <code>response_format</code> <p>Specifies the model output format, compatible with GPT-4 Turbo and GPT-3.5 Turbo models newer than <code>gpt-3.5-turbo-1106</code>. JSON mode ensures valid JSON output.</p> <p> TYPE: <code>ResponseFormat</code> DEFAULT: <code>NOT_GIVEN</code> </p> <code>seed</code> <p>Seeds the RNG for deterministic outputs. Beta feature.</p> <p> TYPE: <code>Optional[int], default=NOT_GIVEN</code> DEFAULT: <code>NOT_GIVEN</code> </p> <code>stop</code> <p>Sequences indicating when to halt token generation.</p> <p> TYPE: <code>Union[Optional[str], List[str]], default=NOT_GIVEN</code> DEFAULT: <code>NOT_GIVEN</code> </p> <code>temperature</code> <p>Controls output randomness. Recommended to adjust this or <code>top_p</code>, but not both.</p> <p> TYPE: <code>Optional[float], default=NOT_GIVEN</code> DEFAULT: <code>NOT_GIVEN</code> </p> <code>tool_choice</code> <p>Selects a tool or function for the model to use.</p> <p> TYPE: <code>ChatCompletionToolChoiceOptionParam</code> DEFAULT: <code>NOT_GIVEN</code> </p> <code>tools</code> <p>Specifies available tools for the model, currently limited to functions.</p> <p> TYPE: <code>Iterable[ChatCompletionToolParam]</code> DEFAULT: <code>NOT_GIVEN</code> </p> <code>top_logprobs</code> <p>Returns top log probabilities for each token position. Requires <code>logprobs</code> to be True.</p> <p> TYPE: <code>Optional[int], default=NOT_GIVEN</code> DEFAULT: <code>NOT_GIVEN</code> </p> <code>top_p</code> <p>Nucleus sampling parameter, considering only the top probability mass for generation.</p> <p> TYPE: <code>Optional[float], default=NOT_GIVEN</code> DEFAULT: <code>NOT_GIVEN</code> </p> <code>user</code> <p>Unique identifier for the end-user, assisting in abuse monitoring. Learn more at End-user IDs.</p> <p> TYPE: <code>str | NotGiven</code> DEFAULT: <code>NOT_GIVEN</code> </p> <code>extra_headers</code> <p>Additional HTTP headers for the request.</p> <p> TYPE: <code>Headers</code> DEFAULT: <code>None</code> </p> <code>extra_query</code> <p>Additional query parameters for the request.</p> <p> TYPE: <code>Query</code> DEFAULT: <code>None</code> </p> <code>extra_body</code> <p>Additional body content for the request.</p> <p> TYPE: <code>Body</code> DEFAULT: <code>None</code> </p> <code>timeout</code> <p>Custom timeout for this request, overriding the default settings.</p> <p> TYPE: <code>float | httpx.Timeout | None | NotGiven, default=NOT_GIVEN</code> DEFAULT: <code>NOT_GIVEN</code> </p> RETURNS DESCRIPTION <code>ChatCompletion | Stream[ChatCompletionChunk]</code> <p>Stream[ChatCompletionChunk]: A stream of chat completion chunks for real-time interaction.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; create(\n...     messages=[{\"role\": \"user\", \"content\": \"Hello, world!\"}],\n...     model=\"gpt-3.5-turbo\",\n...     stream=True,\n...     frequency_penalty=0.5,\n...     # Additional parameters...\n... )\n&lt;Stream of ChatCompletionChunk&gt;\n</code></pre>"},{"location":"reference/resources/chat/completions/#src.openai.resources.chat.completions.Completions.with_raw_response","title":"with_raw_response","text":"<pre><code>with_raw_response() -&gt; CompletionsWithRawResponse\n</code></pre>"},{"location":"reference/resources/chat/completions/#src.openai.resources.chat.completions.Completions.with_streaming_response","title":"with_streaming_response","text":"<pre><code>with_streaming_response() -&gt; (\n    CompletionsWithStreamingResponse\n)\n</code></pre>"},{"location":"reference/resources/chat/completions/#src.openai.resources.chat.completions.CompletionsWithRawResponse","title":"CompletionsWithRawResponse","text":"<pre><code>CompletionsWithRawResponse(completions: Completions)\n</code></pre> ATTRIBUTE DESCRIPTION <code>create</code>"},{"location":"reference/resources/chat/completions/#src.openai.resources.chat.completions.CompletionsWithRawResponse.create","title":"create  <code>instance-attribute</code>","text":"<pre><code>create = to_raw_response_wrapper(create)\n</code></pre>"},{"location":"reference/resources/chat/completions/#src.openai.resources.chat.completions.CompletionsWithStreamingResponse","title":"CompletionsWithStreamingResponse","text":"<pre><code>CompletionsWithStreamingResponse(completions: Completions)\n</code></pre> ATTRIBUTE DESCRIPTION <code>create</code>"},{"location":"reference/resources/chat/completions/#src.openai.resources.chat.completions.CompletionsWithStreamingResponse.create","title":"create  <code>instance-attribute</code>","text":"<pre><code>create = to_streamed_response_wrapper(create)\n</code></pre>"},{"location":"reference/resources/fine_tuning/","title":"openai.resources.fine_tuning","text":"<p>The <code>fine_tuning</code> module provides classes for handling fine-tuning operations, including the initiation, management, and retrieval of fine-tuning jobs.</p> <p>The module supports synchronous and asynchronous operations, offering interfaces for working with jobs directly, as well as with raw or streaming responses. Designed for use in applications requiring custom model training on specific datasets to improve model performance for tailored tasks.</p> <p>Modules:</p> Name Description <code>fine_tuning</code> <p>The <code>fine_tuning</code> module provides classes for handling fine-tuning operations, including the initiation, management, and retrieval of fine-tuning jobs.</p> <p>The module supports synchronous and asynchronous operations, offering interfaces for working with jobs directly, as well as with raw or streaming responses. Designed for use in applications requiring custom model training on specific datasets to improve model performance for tailored tasks.</p> <code>jobs</code> <p>The <code>jobs</code> module provides synchronous and asynchronous access to fine-tuning job resources and enables you to create, retrieve, list, and cancel fine-tuning jobs and list the events associated with them.</p> <p>Fine-tuning jobs allow you to customize pre-trained models with your own datasets, optimizing performance for specific tasks or improving understanding of particular data types. The classes in the <code>jobs</code> module includes methods for managing fine-tuning jobs, like creating a new job, fetching  details of an existing job, listing all jobs, canceling a job, and listing events associated with a job.</p> <p>Classes:</p> Name Description <code>AsyncFineTuning</code> <code>AsyncFineTuningWithRawResponse</code> <code>AsyncFineTuningWithStreamingResponse</code> <code>AsyncJobs</code> <code>AsyncJobsWithRawResponse</code> <code>AsyncJobsWithStreamingResponse</code> <code>FineTuning</code> <code>FineTuningWithRawResponse</code> <code>FineTuningWithStreamingResponse</code> <code>Jobs</code> <code>JobsWithRawResponse</code> <code>JobsWithStreamingResponse</code>"},{"location":"reference/resources/fine_tuning/#src.openai.resources.fine_tuning.AsyncFineTuning","title":"AsyncFineTuning","text":"<pre><code>AsyncFineTuning(client: AsyncOpenAI)\n</code></pre> <p>Methods:</p> Name Description <code>jobs</code> <code>with_raw_response</code> <code>with_streaming_response</code>"},{"location":"reference/resources/fine_tuning/#src.openai.resources.fine_tuning.AsyncFineTuning.jobs","title":"jobs","text":"<pre><code>jobs() -&gt; AsyncJobs\n</code></pre>"},{"location":"reference/resources/fine_tuning/#src.openai.resources.fine_tuning.AsyncFineTuning.with_raw_response","title":"with_raw_response","text":"<pre><code>with_raw_response() -&gt; AsyncFineTuningWithRawResponse\n</code></pre>"},{"location":"reference/resources/fine_tuning/#src.openai.resources.fine_tuning.AsyncFineTuning.with_streaming_response","title":"with_streaming_response","text":"<pre><code>with_streaming_response() -&gt; (\n    AsyncFineTuningWithStreamingResponse\n)\n</code></pre>"},{"location":"reference/resources/fine_tuning/#src.openai.resources.fine_tuning.AsyncFineTuningWithRawResponse","title":"AsyncFineTuningWithRawResponse","text":"<pre><code>AsyncFineTuningWithRawResponse(\n    fine_tuning: AsyncFineTuning,\n)\n</code></pre> <p>Methods:</p> Name Description <code>jobs</code>"},{"location":"reference/resources/fine_tuning/#src.openai.resources.fine_tuning.AsyncFineTuningWithRawResponse.jobs","title":"jobs","text":"<pre><code>jobs() -&gt; AsyncJobsWithRawResponse\n</code></pre>"},{"location":"reference/resources/fine_tuning/#src.openai.resources.fine_tuning.AsyncFineTuningWithStreamingResponse","title":"AsyncFineTuningWithStreamingResponse","text":"<pre><code>AsyncFineTuningWithStreamingResponse(\n    fine_tuning: AsyncFineTuning,\n)\n</code></pre> <p>Methods:</p> Name Description <code>jobs</code>"},{"location":"reference/resources/fine_tuning/#src.openai.resources.fine_tuning.AsyncFineTuningWithStreamingResponse.jobs","title":"jobs","text":"<pre><code>jobs() -&gt; AsyncJobsWithStreamingResponse\n</code></pre>"},{"location":"reference/resources/fine_tuning/#src.openai.resources.fine_tuning.AsyncJobs","title":"AsyncJobs","text":"<pre><code>AsyncJobs(client: AsyncOpenAI)\n</code></pre> <p>Methods:</p> Name Description <code>cancel</code> <p>Immediately cancel a fine-tune job.</p> <code>create</code> <p>Creates a fine-tuning job which begins the process of creating a new model from</p> <code>list</code> <p>List your organization's fine-tuning jobs</p> <code>list_events</code> <p>Get status updates for a fine-tuning job.</p> <code>retrieve</code> <p>Get info about a fine-tuning job.</p> <code>with_raw_response</code> <code>with_streaming_response</code>"},{"location":"reference/resources/fine_tuning/#src.openai.resources.fine_tuning.AsyncJobs.cancel","title":"cancel  <code>async</code>","text":"<pre><code>cancel(\n    fine_tuning_job_id: str,\n    *,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; FineTuningJob\n</code></pre> <p>Immediately cancel a fine-tune job.</p> <p>Parameters:</p> Name Type Description Default <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/fine_tuning/#src.openai.resources.fine_tuning.AsyncJobs.create","title":"create  <code>async</code>","text":"<pre><code>create(\n    *,\n    model: Union[\n        str,\n        Literal[\n            \"babbage-002\", \"davinci-002\", \"gpt-3.5-turbo\"\n        ],\n    ],\n    training_file: str,\n    hyperparameters: Hyperparameters | NotGiven = NOT_GIVEN,\n    suffix: Optional[str] | NotGiven = NOT_GIVEN,\n    validation_file: Optional[str] | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; FineTuningJob\n</code></pre> <p>Creates a fine-tuning job which begins the process of creating a new model from a given dataset.</p> <p>Response includes details of the enqueued job including job status and the name of the fine-tuned models once complete.</p> <p>Learn more about fine-tuning</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>Union[str, Literal['babbage-002', 'davinci-002', 'gpt-3.5-turbo']]</code> <p>The name of the model to fine-tune. You can select one of the   supported models.</p> required <code>training_file</code> <code>str</code> <p>The ID of an uploaded file that contains training data.</p> <p>See upload file   for how to upload a file.</p> <p>Your dataset must be formatted as a JSONL file. Additionally, you must upload   your file with the purpose <code>fine-tune</code>.</p> <p>See the fine-tuning guide   for more details.</p> required <code>hyperparameters</code> <code>Hyperparameters | NotGiven</code> <p>The hyperparameters used for the fine-tuning job.</p> <code>NOT_GIVEN</code> <code>suffix</code> <code>Optional[str] | NotGiven</code> <p>A string of up to 18 characters that will be added to your fine-tuned model   name.</p> <p>For example, a <code>suffix</code> of \"custom-model-name\" would produce a model name like   <code>ft:gpt-3.5-turbo:openai:custom-model-name:7p4lURel</code>.</p> <code>NOT_GIVEN</code> <code>validation_file</code> <code>Optional[str] | NotGiven</code> <p>The ID of an uploaded file that contains validation data.</p> <p>If you provide this file, the data is used to generate validation metrics   periodically during fine-tuning. These metrics can be viewed in the fine-tuning   results file. The same data should not be present in both train and validation   files.</p> <p>Your dataset must be formatted as a JSONL file. You must upload your file with   the purpose <code>fine-tune</code>.</p> <p>See the fine-tuning guide   for more details.</p> <code>NOT_GIVEN</code> <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/fine_tuning/#src.openai.resources.fine_tuning.AsyncJobs.list","title":"list","text":"<pre><code>list(\n    *,\n    after: str | NotGiven = NOT_GIVEN,\n    limit: int | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; AsyncPaginator[\n    FineTuningJob, AsyncCursorPage[FineTuningJob]\n]\n</code></pre> <p>List your organization's fine-tuning jobs</p> <p>Parameters:</p> Name Type Description Default <code>after</code> <code>str | NotGiven</code> <p>Identifier for the last job from the previous pagination request.</p> <code>NOT_GIVEN</code> <code>limit</code> <code>int | NotGiven</code> <p>Number of fine-tuning jobs to retrieve.</p> <code>NOT_GIVEN</code> <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/fine_tuning/#src.openai.resources.fine_tuning.AsyncJobs.list_events","title":"list_events","text":"<pre><code>list_events(\n    fine_tuning_job_id: str,\n    *,\n    after: str | NotGiven = NOT_GIVEN,\n    limit: int | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; AsyncPaginator[\n    FineTuningJobEvent, AsyncCursorPage[FineTuningJobEvent]\n]\n</code></pre> <p>Get status updates for a fine-tuning job.</p> <p>Parameters:</p> Name Type Description Default <code>after</code> <code>str | NotGiven</code> <p>Identifier for the last event from the previous pagination request.</p> <code>NOT_GIVEN</code> <code>limit</code> <code>int | NotGiven</code> <p>Number of events to retrieve.</p> <code>NOT_GIVEN</code> <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/fine_tuning/#src.openai.resources.fine_tuning.AsyncJobs.retrieve","title":"retrieve  <code>async</code>","text":"<pre><code>retrieve(\n    fine_tuning_job_id: str,\n    *,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; FineTuningJob\n</code></pre> <p>Get info about a fine-tuning job.</p> <p>Learn more about fine-tuning</p> <p>Parameters:</p> Name Type Description Default <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/fine_tuning/#src.openai.resources.fine_tuning.AsyncJobs.with_raw_response","title":"with_raw_response","text":"<pre><code>with_raw_response() -&gt; AsyncJobsWithRawResponse\n</code></pre>"},{"location":"reference/resources/fine_tuning/#src.openai.resources.fine_tuning.AsyncJobs.with_streaming_response","title":"with_streaming_response","text":"<pre><code>with_streaming_response() -&gt; AsyncJobsWithStreamingResponse\n</code></pre>"},{"location":"reference/resources/fine_tuning/#src.openai.resources.fine_tuning.AsyncJobsWithRawResponse","title":"AsyncJobsWithRawResponse","text":"<pre><code>AsyncJobsWithRawResponse(jobs: AsyncJobs)\n</code></pre> <p>Attributes:</p> Name Type Description <code>cancel</code> <code>create</code> <code>list</code> <code>list_events</code> <code>retrieve</code>"},{"location":"reference/resources/fine_tuning/#src.openai.resources.fine_tuning.AsyncJobsWithRawResponse.cancel","title":"cancel  <code>instance-attribute</code>","text":"<pre><code>cancel = async_to_raw_response_wrapper(cancel)\n</code></pre>"},{"location":"reference/resources/fine_tuning/#src.openai.resources.fine_tuning.AsyncJobsWithRawResponse.create","title":"create  <code>instance-attribute</code>","text":"<pre><code>create = async_to_raw_response_wrapper(create)\n</code></pre>"},{"location":"reference/resources/fine_tuning/#src.openai.resources.fine_tuning.AsyncJobsWithRawResponse.list","title":"list  <code>instance-attribute</code>","text":"<pre><code>list = async_to_raw_response_wrapper(list)\n</code></pre>"},{"location":"reference/resources/fine_tuning/#src.openai.resources.fine_tuning.AsyncJobsWithRawResponse.list_events","title":"list_events  <code>instance-attribute</code>","text":"<pre><code>list_events = async_to_raw_response_wrapper(list_events)\n</code></pre>"},{"location":"reference/resources/fine_tuning/#src.openai.resources.fine_tuning.AsyncJobsWithRawResponse.retrieve","title":"retrieve  <code>instance-attribute</code>","text":"<pre><code>retrieve = async_to_raw_response_wrapper(retrieve)\n</code></pre>"},{"location":"reference/resources/fine_tuning/#src.openai.resources.fine_tuning.AsyncJobsWithStreamingResponse","title":"AsyncJobsWithStreamingResponse","text":"<pre><code>AsyncJobsWithStreamingResponse(jobs: AsyncJobs)\n</code></pre> <p>Attributes:</p> Name Type Description <code>cancel</code> <code>create</code> <code>list</code> <code>list_events</code> <code>retrieve</code>"},{"location":"reference/resources/fine_tuning/#src.openai.resources.fine_tuning.AsyncJobsWithStreamingResponse.cancel","title":"cancel  <code>instance-attribute</code>","text":"<pre><code>cancel = async_to_streamed_response_wrapper(cancel)\n</code></pre>"},{"location":"reference/resources/fine_tuning/#src.openai.resources.fine_tuning.AsyncJobsWithStreamingResponse.create","title":"create  <code>instance-attribute</code>","text":"<pre><code>create = async_to_streamed_response_wrapper(create)\n</code></pre>"},{"location":"reference/resources/fine_tuning/#src.openai.resources.fine_tuning.AsyncJobsWithStreamingResponse.list","title":"list  <code>instance-attribute</code>","text":"<pre><code>list = async_to_streamed_response_wrapper(list)\n</code></pre>"},{"location":"reference/resources/fine_tuning/#src.openai.resources.fine_tuning.AsyncJobsWithStreamingResponse.list_events","title":"list_events  <code>instance-attribute</code>","text":"<pre><code>list_events = async_to_streamed_response_wrapper(\n    list_events\n)\n</code></pre>"},{"location":"reference/resources/fine_tuning/#src.openai.resources.fine_tuning.AsyncJobsWithStreamingResponse.retrieve","title":"retrieve  <code>instance-attribute</code>","text":"<pre><code>retrieve = async_to_streamed_response_wrapper(retrieve)\n</code></pre>"},{"location":"reference/resources/fine_tuning/#src.openai.resources.fine_tuning.FineTuning","title":"FineTuning","text":"<pre><code>FineTuning(client: OpenAI)\n</code></pre> <p>Methods:</p> Name Description <code>jobs</code> <code>with_raw_response</code> <code>with_streaming_response</code>"},{"location":"reference/resources/fine_tuning/#src.openai.resources.fine_tuning.FineTuning.jobs","title":"jobs","text":"<pre><code>jobs() -&gt; Jobs\n</code></pre>"},{"location":"reference/resources/fine_tuning/#src.openai.resources.fine_tuning.FineTuning.with_raw_response","title":"with_raw_response","text":"<pre><code>with_raw_response() -&gt; FineTuningWithRawResponse\n</code></pre>"},{"location":"reference/resources/fine_tuning/#src.openai.resources.fine_tuning.FineTuning.with_streaming_response","title":"with_streaming_response","text":"<pre><code>with_streaming_response() -&gt; (\n    FineTuningWithStreamingResponse\n)\n</code></pre>"},{"location":"reference/resources/fine_tuning/#src.openai.resources.fine_tuning.FineTuningWithRawResponse","title":"FineTuningWithRawResponse","text":"<pre><code>FineTuningWithRawResponse(fine_tuning: FineTuning)\n</code></pre> <p>Methods:</p> Name Description <code>jobs</code>"},{"location":"reference/resources/fine_tuning/#src.openai.resources.fine_tuning.FineTuningWithRawResponse.jobs","title":"jobs","text":"<pre><code>jobs() -&gt; JobsWithRawResponse\n</code></pre>"},{"location":"reference/resources/fine_tuning/#src.openai.resources.fine_tuning.FineTuningWithStreamingResponse","title":"FineTuningWithStreamingResponse","text":"<pre><code>FineTuningWithStreamingResponse(fine_tuning: FineTuning)\n</code></pre> <p>Methods:</p> Name Description <code>jobs</code>"},{"location":"reference/resources/fine_tuning/#src.openai.resources.fine_tuning.FineTuningWithStreamingResponse.jobs","title":"jobs","text":"<pre><code>jobs() -&gt; JobsWithStreamingResponse\n</code></pre>"},{"location":"reference/resources/fine_tuning/#src.openai.resources.fine_tuning.Jobs","title":"Jobs","text":"<pre><code>Jobs(client: OpenAI)\n</code></pre> <p>Methods:</p> Name Description <code>cancel</code> <p>Immediately cancel a fine-tune job.</p> <code>create</code> <p>Creates a fine-tuning job which begins the process of creating a new model from</p> <code>list</code> <p>List your organization's fine-tuning jobs</p> <code>list_events</code> <p>Get status updates for a fine-tuning job.</p> <code>retrieve</code> <p>Get info about a fine-tuning job.</p> <code>with_raw_response</code> <code>with_streaming_response</code>"},{"location":"reference/resources/fine_tuning/#src.openai.resources.fine_tuning.Jobs.cancel","title":"cancel","text":"<pre><code>cancel(\n    fine_tuning_job_id: str,\n    *,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; FineTuningJob\n</code></pre> <p>Immediately cancel a fine-tune job.</p> <p>Parameters:</p> Name Type Description Default <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/fine_tuning/#src.openai.resources.fine_tuning.Jobs.create","title":"create","text":"<pre><code>create(\n    *,\n    model: Union[\n        str,\n        Literal[\n            \"babbage-002\", \"davinci-002\", \"gpt-3.5-turbo\"\n        ],\n    ],\n    training_file: str,\n    hyperparameters: Hyperparameters | NotGiven = NOT_GIVEN,\n    suffix: Optional[str] | NotGiven = NOT_GIVEN,\n    validation_file: Optional[str] | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; FineTuningJob\n</code></pre> <p>Creates a fine-tuning job which begins the process of creating a new model from a given dataset.</p> <p>Response includes details of the enqueued job including job status and the name of the fine-tuned models once complete.</p> <p>Learn more about fine-tuning</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>Union[str, Literal['babbage-002', 'davinci-002', 'gpt-3.5-turbo']]</code> <p>The name of the model to fine-tune. You can select one of the   supported models.</p> required <code>training_file</code> <code>str</code> <p>The ID of an uploaded file that contains training data.</p> <p>See upload file   for how to upload a file.</p> <p>Your dataset must be formatted as a JSONL file. Additionally, you must upload   your file with the purpose <code>fine-tune</code>.</p> <p>See the fine-tuning guide   for more details.</p> required <code>hyperparameters</code> <code>Hyperparameters | NotGiven</code> <p>The hyperparameters used for the fine-tuning job.</p> <code>NOT_GIVEN</code> <code>suffix</code> <code>Optional[str] | NotGiven</code> <p>A string of up to 18 characters that will be added to your fine-tuned model   name.</p> <p>For example, a <code>suffix</code> of \"custom-model-name\" would produce a model name like   <code>ft:gpt-3.5-turbo:openai:custom-model-name:7p4lURel</code>.</p> <code>NOT_GIVEN</code> <code>validation_file</code> <code>Optional[str] | NotGiven</code> <p>The ID of an uploaded file that contains validation data.</p> <p>If you provide this file, the data is used to generate validation metrics   periodically during fine-tuning. These metrics can be viewed in the fine-tuning   results file. The same data should not be present in both train and validation   files.</p> <p>Your dataset must be formatted as a JSONL file. You must upload your file with   the purpose <code>fine-tune</code>.</p> <p>See the fine-tuning guide   for more details.</p> <code>NOT_GIVEN</code> <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/fine_tuning/#src.openai.resources.fine_tuning.Jobs.list","title":"list","text":"<pre><code>list(\n    *,\n    after: str | NotGiven = NOT_GIVEN,\n    limit: int | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; SyncCursorPage[FineTuningJob]\n</code></pre> <p>List your organization's fine-tuning jobs</p> <p>Parameters:</p> Name Type Description Default <code>after</code> <code>str | NotGiven</code> <p>Identifier for the last job from the previous pagination request.</p> <code>NOT_GIVEN</code> <code>limit</code> <code>int | NotGiven</code> <p>Number of fine-tuning jobs to retrieve.</p> <code>NOT_GIVEN</code> <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/fine_tuning/#src.openai.resources.fine_tuning.Jobs.list_events","title":"list_events","text":"<pre><code>list_events(\n    fine_tuning_job_id: str,\n    *,\n    after: str | NotGiven = NOT_GIVEN,\n    limit: int | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; SyncCursorPage[FineTuningJobEvent]\n</code></pre> <p>Get status updates for a fine-tuning job.</p> <p>Parameters:</p> Name Type Description Default <code>after</code> <code>str | NotGiven</code> <p>Identifier for the last event from the previous pagination request.</p> <code>NOT_GIVEN</code> <code>limit</code> <code>int | NotGiven</code> <p>Number of events to retrieve.</p> <code>NOT_GIVEN</code> <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/fine_tuning/#src.openai.resources.fine_tuning.Jobs.retrieve","title":"retrieve","text":"<pre><code>retrieve(\n    fine_tuning_job_id: str,\n    *,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; FineTuningJob\n</code></pre> <p>Get info about a fine-tuning job.</p> <p>Learn more about fine-tuning</p> <p>Parameters:</p> Name Type Description Default <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/fine_tuning/#src.openai.resources.fine_tuning.Jobs.with_raw_response","title":"with_raw_response","text":"<pre><code>with_raw_response() -&gt; JobsWithRawResponse\n</code></pre>"},{"location":"reference/resources/fine_tuning/#src.openai.resources.fine_tuning.Jobs.with_streaming_response","title":"with_streaming_response","text":"<pre><code>with_streaming_response() -&gt; JobsWithStreamingResponse\n</code></pre>"},{"location":"reference/resources/fine_tuning/#src.openai.resources.fine_tuning.JobsWithRawResponse","title":"JobsWithRawResponse","text":"<pre><code>JobsWithRawResponse(jobs: Jobs)\n</code></pre> <p>Attributes:</p> Name Type Description <code>cancel</code> <code>create</code> <code>list</code> <code>list_events</code> <code>retrieve</code>"},{"location":"reference/resources/fine_tuning/#src.openai.resources.fine_tuning.JobsWithRawResponse.cancel","title":"cancel  <code>instance-attribute</code>","text":"<pre><code>cancel = to_raw_response_wrapper(cancel)\n</code></pre>"},{"location":"reference/resources/fine_tuning/#src.openai.resources.fine_tuning.JobsWithRawResponse.create","title":"create  <code>instance-attribute</code>","text":"<pre><code>create = to_raw_response_wrapper(create)\n</code></pre>"},{"location":"reference/resources/fine_tuning/#src.openai.resources.fine_tuning.JobsWithRawResponse.list","title":"list  <code>instance-attribute</code>","text":"<pre><code>list = to_raw_response_wrapper(list)\n</code></pre>"},{"location":"reference/resources/fine_tuning/#src.openai.resources.fine_tuning.JobsWithRawResponse.list_events","title":"list_events  <code>instance-attribute</code>","text":"<pre><code>list_events = to_raw_response_wrapper(list_events)\n</code></pre>"},{"location":"reference/resources/fine_tuning/#src.openai.resources.fine_tuning.JobsWithRawResponse.retrieve","title":"retrieve  <code>instance-attribute</code>","text":"<pre><code>retrieve = to_raw_response_wrapper(retrieve)\n</code></pre>"},{"location":"reference/resources/fine_tuning/#src.openai.resources.fine_tuning.JobsWithStreamingResponse","title":"JobsWithStreamingResponse","text":"<pre><code>JobsWithStreamingResponse(jobs: Jobs)\n</code></pre> <p>Attributes:</p> Name Type Description <code>cancel</code> <code>create</code> <code>list</code> <code>list_events</code> <code>retrieve</code>"},{"location":"reference/resources/fine_tuning/#src.openai.resources.fine_tuning.JobsWithStreamingResponse.cancel","title":"cancel  <code>instance-attribute</code>","text":"<pre><code>cancel = to_streamed_response_wrapper(cancel)\n</code></pre>"},{"location":"reference/resources/fine_tuning/#src.openai.resources.fine_tuning.JobsWithStreamingResponse.create","title":"create  <code>instance-attribute</code>","text":"<pre><code>create = to_streamed_response_wrapper(create)\n</code></pre>"},{"location":"reference/resources/fine_tuning/#src.openai.resources.fine_tuning.JobsWithStreamingResponse.list","title":"list  <code>instance-attribute</code>","text":"<pre><code>list = to_streamed_response_wrapper(list)\n</code></pre>"},{"location":"reference/resources/fine_tuning/#src.openai.resources.fine_tuning.JobsWithStreamingResponse.list_events","title":"list_events  <code>instance-attribute</code>","text":"<pre><code>list_events = to_streamed_response_wrapper(list_events)\n</code></pre>"},{"location":"reference/resources/fine_tuning/#src.openai.resources.fine_tuning.JobsWithStreamingResponse.retrieve","title":"retrieve  <code>instance-attribute</code>","text":"<pre><code>retrieve = to_streamed_response_wrapper(retrieve)\n</code></pre>"},{"location":"reference/resources/fine_tuning/fine_tuning/","title":"fine_tuning","text":"<p>The <code>fine_tuning</code> module provides classes for handling fine-tuning operations, including the initiation, management, and retrieval of fine-tuning jobs.</p> <p>The module supports synchronous and asynchronous operations, offering interfaces for working with jobs directly, as well as with raw or streaming responses. Designed for use in applications requiring custom model training on specific datasets to improve model performance for tailored tasks.</p> <p>Classes:</p> Name Description <code>AsyncFineTuning</code> <code>AsyncFineTuningWithRawResponse</code> <code>AsyncFineTuningWithStreamingResponse</code> <code>FineTuning</code> <code>FineTuningWithRawResponse</code> <code>FineTuningWithStreamingResponse</code>"},{"location":"reference/resources/fine_tuning/fine_tuning/#src.openai.resources.fine_tuning.fine_tuning.AsyncFineTuning","title":"AsyncFineTuning","text":"<pre><code>AsyncFineTuning(client: AsyncOpenAI)\n</code></pre> <p>Methods:</p> Name Description <code>jobs</code> <code>with_raw_response</code> <code>with_streaming_response</code>"},{"location":"reference/resources/fine_tuning/fine_tuning/#src.openai.resources.fine_tuning.fine_tuning.AsyncFineTuning.jobs","title":"jobs","text":"<pre><code>jobs() -&gt; AsyncJobs\n</code></pre>"},{"location":"reference/resources/fine_tuning/fine_tuning/#src.openai.resources.fine_tuning.fine_tuning.AsyncFineTuning.with_raw_response","title":"with_raw_response","text":"<pre><code>with_raw_response() -&gt; AsyncFineTuningWithRawResponse\n</code></pre>"},{"location":"reference/resources/fine_tuning/fine_tuning/#src.openai.resources.fine_tuning.fine_tuning.AsyncFineTuning.with_streaming_response","title":"with_streaming_response","text":"<pre><code>with_streaming_response() -&gt; (\n    AsyncFineTuningWithStreamingResponse\n)\n</code></pre>"},{"location":"reference/resources/fine_tuning/fine_tuning/#src.openai.resources.fine_tuning.fine_tuning.AsyncFineTuningWithRawResponse","title":"AsyncFineTuningWithRawResponse","text":"<pre><code>AsyncFineTuningWithRawResponse(\n    fine_tuning: AsyncFineTuning,\n)\n</code></pre> <p>Methods:</p> Name Description <code>jobs</code>"},{"location":"reference/resources/fine_tuning/fine_tuning/#src.openai.resources.fine_tuning.fine_tuning.AsyncFineTuningWithRawResponse.jobs","title":"jobs","text":"<pre><code>jobs() -&gt; AsyncJobsWithRawResponse\n</code></pre>"},{"location":"reference/resources/fine_tuning/fine_tuning/#src.openai.resources.fine_tuning.fine_tuning.AsyncFineTuningWithStreamingResponse","title":"AsyncFineTuningWithStreamingResponse","text":"<pre><code>AsyncFineTuningWithStreamingResponse(\n    fine_tuning: AsyncFineTuning,\n)\n</code></pre> <p>Methods:</p> Name Description <code>jobs</code>"},{"location":"reference/resources/fine_tuning/fine_tuning/#src.openai.resources.fine_tuning.fine_tuning.AsyncFineTuningWithStreamingResponse.jobs","title":"jobs","text":"<pre><code>jobs() -&gt; AsyncJobsWithStreamingResponse\n</code></pre>"},{"location":"reference/resources/fine_tuning/fine_tuning/#src.openai.resources.fine_tuning.fine_tuning.FineTuning","title":"FineTuning","text":"<pre><code>FineTuning(client: OpenAI)\n</code></pre> <p>Methods:</p> Name Description <code>jobs</code> <code>with_raw_response</code> <code>with_streaming_response</code>"},{"location":"reference/resources/fine_tuning/fine_tuning/#src.openai.resources.fine_tuning.fine_tuning.FineTuning.jobs","title":"jobs","text":"<pre><code>jobs() -&gt; Jobs\n</code></pre>"},{"location":"reference/resources/fine_tuning/fine_tuning/#src.openai.resources.fine_tuning.fine_tuning.FineTuning.with_raw_response","title":"with_raw_response","text":"<pre><code>with_raw_response() -&gt; FineTuningWithRawResponse\n</code></pre>"},{"location":"reference/resources/fine_tuning/fine_tuning/#src.openai.resources.fine_tuning.fine_tuning.FineTuning.with_streaming_response","title":"with_streaming_response","text":"<pre><code>with_streaming_response() -&gt; (\n    FineTuningWithStreamingResponse\n)\n</code></pre>"},{"location":"reference/resources/fine_tuning/fine_tuning/#src.openai.resources.fine_tuning.fine_tuning.FineTuningWithRawResponse","title":"FineTuningWithRawResponse","text":"<pre><code>FineTuningWithRawResponse(fine_tuning: FineTuning)\n</code></pre> <p>Methods:</p> Name Description <code>jobs</code>"},{"location":"reference/resources/fine_tuning/fine_tuning/#src.openai.resources.fine_tuning.fine_tuning.FineTuningWithRawResponse.jobs","title":"jobs","text":"<pre><code>jobs() -&gt; JobsWithRawResponse\n</code></pre>"},{"location":"reference/resources/fine_tuning/fine_tuning/#src.openai.resources.fine_tuning.fine_tuning.FineTuningWithStreamingResponse","title":"FineTuningWithStreamingResponse","text":"<pre><code>FineTuningWithStreamingResponse(fine_tuning: FineTuning)\n</code></pre> <p>Methods:</p> Name Description <code>jobs</code>"},{"location":"reference/resources/fine_tuning/fine_tuning/#src.openai.resources.fine_tuning.fine_tuning.FineTuningWithStreamingResponse.jobs","title":"jobs","text":"<pre><code>jobs() -&gt; JobsWithStreamingResponse\n</code></pre>"},{"location":"reference/resources/fine_tuning/jobs/","title":"jobs","text":"<p>The <code>jobs</code> module provides synchronous and asynchronous access to fine-tuning job resources and enables you to create, retrieve, list, and cancel fine-tuning jobs and list the events associated with them.</p> <p>Fine-tuning jobs allow you to customize pre-trained models with your own datasets, optimizing performance for specific tasks or improving understanding of particular data types. The classes in the <code>jobs</code> module includes methods for managing fine-tuning jobs, like creating a new job, fetching  details of an existing job, listing all jobs, canceling a job, and listing events associated with a job.</p> <p>Classes:</p> Name Description <code>AsyncJobs</code> <code>AsyncJobsWithRawResponse</code> <code>AsyncJobsWithStreamingResponse</code> <code>Jobs</code> <code>JobsWithRawResponse</code> <code>JobsWithStreamingResponse</code>"},{"location":"reference/resources/fine_tuning/jobs/#src.openai.resources.fine_tuning.jobs.AsyncJobs","title":"AsyncJobs","text":"<pre><code>AsyncJobs(client: AsyncOpenAI)\n</code></pre> <p>Methods:</p> Name Description <code>cancel</code> <p>Immediately cancel a fine-tune job.</p> <code>create</code> <p>Creates a fine-tuning job which begins the process of creating a new model from</p> <code>list</code> <p>List your organization's fine-tuning jobs</p> <code>list_events</code> <p>Get status updates for a fine-tuning job.</p> <code>retrieve</code> <p>Get info about a fine-tuning job.</p> <code>with_raw_response</code> <code>with_streaming_response</code>"},{"location":"reference/resources/fine_tuning/jobs/#src.openai.resources.fine_tuning.jobs.AsyncJobs.cancel","title":"cancel  <code>async</code>","text":"<pre><code>cancel(\n    fine_tuning_job_id: str,\n    *,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; FineTuningJob\n</code></pre> <p>Immediately cancel a fine-tune job.</p> <p>Parameters:</p> Name Type Description Default <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/fine_tuning/jobs/#src.openai.resources.fine_tuning.jobs.AsyncJobs.create","title":"create  <code>async</code>","text":"<pre><code>create(\n    *,\n    model: Union[\n        str,\n        Literal[\n            \"babbage-002\", \"davinci-002\", \"gpt-3.5-turbo\"\n        ],\n    ],\n    training_file: str,\n    hyperparameters: Hyperparameters | NotGiven = NOT_GIVEN,\n    suffix: Optional[str] | NotGiven = NOT_GIVEN,\n    validation_file: Optional[str] | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; FineTuningJob\n</code></pre> <p>Creates a fine-tuning job which begins the process of creating a new model from a given dataset.</p> <p>Response includes details of the enqueued job including job status and the name of the fine-tuned models once complete.</p> <p>Learn more about fine-tuning</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>Union[str, Literal['babbage-002', 'davinci-002', 'gpt-3.5-turbo']]</code> <p>The name of the model to fine-tune. You can select one of the   supported models.</p> required <code>training_file</code> <code>str</code> <p>The ID of an uploaded file that contains training data.</p> <p>See upload file   for how to upload a file.</p> <p>Your dataset must be formatted as a JSONL file. Additionally, you must upload   your file with the purpose <code>fine-tune</code>.</p> <p>See the fine-tuning guide   for more details.</p> required <code>hyperparameters</code> <code>Hyperparameters | NotGiven</code> <p>The hyperparameters used for the fine-tuning job.</p> <code>NOT_GIVEN</code> <code>suffix</code> <code>Optional[str] | NotGiven</code> <p>A string of up to 18 characters that will be added to your fine-tuned model   name.</p> <p>For example, a <code>suffix</code> of \"custom-model-name\" would produce a model name like   <code>ft:gpt-3.5-turbo:openai:custom-model-name:7p4lURel</code>.</p> <code>NOT_GIVEN</code> <code>validation_file</code> <code>Optional[str] | NotGiven</code> <p>The ID of an uploaded file that contains validation data.</p> <p>If you provide this file, the data is used to generate validation metrics   periodically during fine-tuning. These metrics can be viewed in the fine-tuning   results file. The same data should not be present in both train and validation   files.</p> <p>Your dataset must be formatted as a JSONL file. You must upload your file with   the purpose <code>fine-tune</code>.</p> <p>See the fine-tuning guide   for more details.</p> <code>NOT_GIVEN</code> <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/fine_tuning/jobs/#src.openai.resources.fine_tuning.jobs.AsyncJobs.list","title":"list","text":"<pre><code>list(\n    *,\n    after: str | NotGiven = NOT_GIVEN,\n    limit: int | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; AsyncPaginator[\n    FineTuningJob, AsyncCursorPage[FineTuningJob]\n]\n</code></pre> <p>List your organization's fine-tuning jobs</p> <p>Parameters:</p> Name Type Description Default <code>after</code> <code>str | NotGiven</code> <p>Identifier for the last job from the previous pagination request.</p> <code>NOT_GIVEN</code> <code>limit</code> <code>int | NotGiven</code> <p>Number of fine-tuning jobs to retrieve.</p> <code>NOT_GIVEN</code> <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/fine_tuning/jobs/#src.openai.resources.fine_tuning.jobs.AsyncJobs.list_events","title":"list_events","text":"<pre><code>list_events(\n    fine_tuning_job_id: str,\n    *,\n    after: str | NotGiven = NOT_GIVEN,\n    limit: int | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; AsyncPaginator[\n    FineTuningJobEvent, AsyncCursorPage[FineTuningJobEvent]\n]\n</code></pre> <p>Get status updates for a fine-tuning job.</p> <p>Parameters:</p> Name Type Description Default <code>after</code> <code>str | NotGiven</code> <p>Identifier for the last event from the previous pagination request.</p> <code>NOT_GIVEN</code> <code>limit</code> <code>int | NotGiven</code> <p>Number of events to retrieve.</p> <code>NOT_GIVEN</code> <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/fine_tuning/jobs/#src.openai.resources.fine_tuning.jobs.AsyncJobs.retrieve","title":"retrieve  <code>async</code>","text":"<pre><code>retrieve(\n    fine_tuning_job_id: str,\n    *,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; FineTuningJob\n</code></pre> <p>Get info about a fine-tuning job.</p> <p>Learn more about fine-tuning</p> <p>Parameters:</p> Name Type Description Default <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/fine_tuning/jobs/#src.openai.resources.fine_tuning.jobs.AsyncJobs.with_raw_response","title":"with_raw_response","text":"<pre><code>with_raw_response() -&gt; AsyncJobsWithRawResponse\n</code></pre>"},{"location":"reference/resources/fine_tuning/jobs/#src.openai.resources.fine_tuning.jobs.AsyncJobs.with_streaming_response","title":"with_streaming_response","text":"<pre><code>with_streaming_response() -&gt; AsyncJobsWithStreamingResponse\n</code></pre>"},{"location":"reference/resources/fine_tuning/jobs/#src.openai.resources.fine_tuning.jobs.AsyncJobsWithRawResponse","title":"AsyncJobsWithRawResponse","text":"<pre><code>AsyncJobsWithRawResponse(jobs: AsyncJobs)\n</code></pre> <p>Attributes:</p> Name Type Description <code>cancel</code> <code>create</code> <code>list</code> <code>list_events</code> <code>retrieve</code>"},{"location":"reference/resources/fine_tuning/jobs/#src.openai.resources.fine_tuning.jobs.AsyncJobsWithRawResponse.cancel","title":"cancel  <code>instance-attribute</code>","text":"<pre><code>cancel = async_to_raw_response_wrapper(cancel)\n</code></pre>"},{"location":"reference/resources/fine_tuning/jobs/#src.openai.resources.fine_tuning.jobs.AsyncJobsWithRawResponse.create","title":"create  <code>instance-attribute</code>","text":"<pre><code>create = async_to_raw_response_wrapper(create)\n</code></pre>"},{"location":"reference/resources/fine_tuning/jobs/#src.openai.resources.fine_tuning.jobs.AsyncJobsWithRawResponse.list","title":"list  <code>instance-attribute</code>","text":"<pre><code>list = async_to_raw_response_wrapper(list)\n</code></pre>"},{"location":"reference/resources/fine_tuning/jobs/#src.openai.resources.fine_tuning.jobs.AsyncJobsWithRawResponse.list_events","title":"list_events  <code>instance-attribute</code>","text":"<pre><code>list_events = async_to_raw_response_wrapper(list_events)\n</code></pre>"},{"location":"reference/resources/fine_tuning/jobs/#src.openai.resources.fine_tuning.jobs.AsyncJobsWithRawResponse.retrieve","title":"retrieve  <code>instance-attribute</code>","text":"<pre><code>retrieve = async_to_raw_response_wrapper(retrieve)\n</code></pre>"},{"location":"reference/resources/fine_tuning/jobs/#src.openai.resources.fine_tuning.jobs.AsyncJobsWithStreamingResponse","title":"AsyncJobsWithStreamingResponse","text":"<pre><code>AsyncJobsWithStreamingResponse(jobs: AsyncJobs)\n</code></pre> <p>Attributes:</p> Name Type Description <code>cancel</code> <code>create</code> <code>list</code> <code>list_events</code> <code>retrieve</code>"},{"location":"reference/resources/fine_tuning/jobs/#src.openai.resources.fine_tuning.jobs.AsyncJobsWithStreamingResponse.cancel","title":"cancel  <code>instance-attribute</code>","text":"<pre><code>cancel = async_to_streamed_response_wrapper(cancel)\n</code></pre>"},{"location":"reference/resources/fine_tuning/jobs/#src.openai.resources.fine_tuning.jobs.AsyncJobsWithStreamingResponse.create","title":"create  <code>instance-attribute</code>","text":"<pre><code>create = async_to_streamed_response_wrapper(create)\n</code></pre>"},{"location":"reference/resources/fine_tuning/jobs/#src.openai.resources.fine_tuning.jobs.AsyncJobsWithStreamingResponse.list","title":"list  <code>instance-attribute</code>","text":"<pre><code>list = async_to_streamed_response_wrapper(list)\n</code></pre>"},{"location":"reference/resources/fine_tuning/jobs/#src.openai.resources.fine_tuning.jobs.AsyncJobsWithStreamingResponse.list_events","title":"list_events  <code>instance-attribute</code>","text":"<pre><code>list_events = async_to_streamed_response_wrapper(\n    list_events\n)\n</code></pre>"},{"location":"reference/resources/fine_tuning/jobs/#src.openai.resources.fine_tuning.jobs.AsyncJobsWithStreamingResponse.retrieve","title":"retrieve  <code>instance-attribute</code>","text":"<pre><code>retrieve = async_to_streamed_response_wrapper(retrieve)\n</code></pre>"},{"location":"reference/resources/fine_tuning/jobs/#src.openai.resources.fine_tuning.jobs.Jobs","title":"Jobs","text":"<pre><code>Jobs(client: OpenAI)\n</code></pre> <p>Methods:</p> Name Description <code>cancel</code> <p>Immediately cancel a fine-tune job.</p> <code>create</code> <p>Creates a fine-tuning job which begins the process of creating a new model from</p> <code>list</code> <p>List your organization's fine-tuning jobs</p> <code>list_events</code> <p>Get status updates for a fine-tuning job.</p> <code>retrieve</code> <p>Get info about a fine-tuning job.</p> <code>with_raw_response</code> <code>with_streaming_response</code>"},{"location":"reference/resources/fine_tuning/jobs/#src.openai.resources.fine_tuning.jobs.Jobs.cancel","title":"cancel","text":"<pre><code>cancel(\n    fine_tuning_job_id: str,\n    *,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; FineTuningJob\n</code></pre> <p>Immediately cancel a fine-tune job.</p> <p>Parameters:</p> Name Type Description Default <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/fine_tuning/jobs/#src.openai.resources.fine_tuning.jobs.Jobs.create","title":"create","text":"<pre><code>create(\n    *,\n    model: Union[\n        str,\n        Literal[\n            \"babbage-002\", \"davinci-002\", \"gpt-3.5-turbo\"\n        ],\n    ],\n    training_file: str,\n    hyperparameters: Hyperparameters | NotGiven = NOT_GIVEN,\n    suffix: Optional[str] | NotGiven = NOT_GIVEN,\n    validation_file: Optional[str] | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; FineTuningJob\n</code></pre> <p>Creates a fine-tuning job which begins the process of creating a new model from a given dataset.</p> <p>Response includes details of the enqueued job including job status and the name of the fine-tuned models once complete.</p> <p>Learn more about fine-tuning</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>Union[str, Literal['babbage-002', 'davinci-002', 'gpt-3.5-turbo']]</code> <p>The name of the model to fine-tune. You can select one of the   supported models.</p> required <code>training_file</code> <code>str</code> <p>The ID of an uploaded file that contains training data.</p> <p>See upload file   for how to upload a file.</p> <p>Your dataset must be formatted as a JSONL file. Additionally, you must upload   your file with the purpose <code>fine-tune</code>.</p> <p>See the fine-tuning guide   for more details.</p> required <code>hyperparameters</code> <code>Hyperparameters | NotGiven</code> <p>The hyperparameters used for the fine-tuning job.</p> <code>NOT_GIVEN</code> <code>suffix</code> <code>Optional[str] | NotGiven</code> <p>A string of up to 18 characters that will be added to your fine-tuned model   name.</p> <p>For example, a <code>suffix</code> of \"custom-model-name\" would produce a model name like   <code>ft:gpt-3.5-turbo:openai:custom-model-name:7p4lURel</code>.</p> <code>NOT_GIVEN</code> <code>validation_file</code> <code>Optional[str] | NotGiven</code> <p>The ID of an uploaded file that contains validation data.</p> <p>If you provide this file, the data is used to generate validation metrics   periodically during fine-tuning. These metrics can be viewed in the fine-tuning   results file. The same data should not be present in both train and validation   files.</p> <p>Your dataset must be formatted as a JSONL file. You must upload your file with   the purpose <code>fine-tune</code>.</p> <p>See the fine-tuning guide   for more details.</p> <code>NOT_GIVEN</code> <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/fine_tuning/jobs/#src.openai.resources.fine_tuning.jobs.Jobs.list","title":"list","text":"<pre><code>list(\n    *,\n    after: str | NotGiven = NOT_GIVEN,\n    limit: int | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; SyncCursorPage[FineTuningJob]\n</code></pre> <p>List your organization's fine-tuning jobs</p> <p>Parameters:</p> Name Type Description Default <code>after</code> <code>str | NotGiven</code> <p>Identifier for the last job from the previous pagination request.</p> <code>NOT_GIVEN</code> <code>limit</code> <code>int | NotGiven</code> <p>Number of fine-tuning jobs to retrieve.</p> <code>NOT_GIVEN</code> <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/fine_tuning/jobs/#src.openai.resources.fine_tuning.jobs.Jobs.list_events","title":"list_events","text":"<pre><code>list_events(\n    fine_tuning_job_id: str,\n    *,\n    after: str | NotGiven = NOT_GIVEN,\n    limit: int | NotGiven = NOT_GIVEN,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; SyncCursorPage[FineTuningJobEvent]\n</code></pre> <p>Get status updates for a fine-tuning job.</p> <p>Parameters:</p> Name Type Description Default <code>after</code> <code>str | NotGiven</code> <p>Identifier for the last event from the previous pagination request.</p> <code>NOT_GIVEN</code> <code>limit</code> <code>int | NotGiven</code> <p>Number of events to retrieve.</p> <code>NOT_GIVEN</code> <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/fine_tuning/jobs/#src.openai.resources.fine_tuning.jobs.Jobs.retrieve","title":"retrieve","text":"<pre><code>retrieve(\n    fine_tuning_job_id: str,\n    *,\n    extra_headers: Headers | None = None,\n    extra_query: Query | None = None,\n    extra_body: Body | None = None,\n    timeout: float | Timeout | None | NotGiven = NOT_GIVEN\n) -&gt; FineTuningJob\n</code></pre> <p>Get info about a fine-tuning job.</p> <p>Learn more about fine-tuning</p> <p>Parameters:</p> Name Type Description Default <code>extra_headers</code> <code>Headers | None</code> <p>Send extra headers</p> <code>None</code> <code>extra_query</code> <code>Query | None</code> <p>Add additional query parameters to the request</p> <code>None</code> <code>extra_body</code> <code>Body | None</code> <p>Add additional JSON properties to the request</p> <code>None</code> <code>timeout</code> <code>float | Timeout | None | NotGiven</code> <p>Override the client-level default timeout for this request, in seconds</p> <code>NOT_GIVEN</code>"},{"location":"reference/resources/fine_tuning/jobs/#src.openai.resources.fine_tuning.jobs.Jobs.with_raw_response","title":"with_raw_response","text":"<pre><code>with_raw_response() -&gt; JobsWithRawResponse\n</code></pre>"},{"location":"reference/resources/fine_tuning/jobs/#src.openai.resources.fine_tuning.jobs.Jobs.with_streaming_response","title":"with_streaming_response","text":"<pre><code>with_streaming_response() -&gt; JobsWithStreamingResponse\n</code></pre>"},{"location":"reference/resources/fine_tuning/jobs/#src.openai.resources.fine_tuning.jobs.JobsWithRawResponse","title":"JobsWithRawResponse","text":"<pre><code>JobsWithRawResponse(jobs: Jobs)\n</code></pre> <p>Attributes:</p> Name Type Description <code>cancel</code> <code>create</code> <code>list</code> <code>list_events</code> <code>retrieve</code>"},{"location":"reference/resources/fine_tuning/jobs/#src.openai.resources.fine_tuning.jobs.JobsWithRawResponse.cancel","title":"cancel  <code>instance-attribute</code>","text":"<pre><code>cancel = to_raw_response_wrapper(cancel)\n</code></pre>"},{"location":"reference/resources/fine_tuning/jobs/#src.openai.resources.fine_tuning.jobs.JobsWithRawResponse.create","title":"create  <code>instance-attribute</code>","text":"<pre><code>create = to_raw_response_wrapper(create)\n</code></pre>"},{"location":"reference/resources/fine_tuning/jobs/#src.openai.resources.fine_tuning.jobs.JobsWithRawResponse.list","title":"list  <code>instance-attribute</code>","text":"<pre><code>list = to_raw_response_wrapper(list)\n</code></pre>"},{"location":"reference/resources/fine_tuning/jobs/#src.openai.resources.fine_tuning.jobs.JobsWithRawResponse.list_events","title":"list_events  <code>instance-attribute</code>","text":"<pre><code>list_events = to_raw_response_wrapper(list_events)\n</code></pre>"},{"location":"reference/resources/fine_tuning/jobs/#src.openai.resources.fine_tuning.jobs.JobsWithRawResponse.retrieve","title":"retrieve  <code>instance-attribute</code>","text":"<pre><code>retrieve = to_raw_response_wrapper(retrieve)\n</code></pre>"},{"location":"reference/resources/fine_tuning/jobs/#src.openai.resources.fine_tuning.jobs.JobsWithStreamingResponse","title":"JobsWithStreamingResponse","text":"<pre><code>JobsWithStreamingResponse(jobs: Jobs)\n</code></pre> <p>Attributes:</p> Name Type Description <code>cancel</code> <code>create</code> <code>list</code> <code>list_events</code> <code>retrieve</code>"},{"location":"reference/resources/fine_tuning/jobs/#src.openai.resources.fine_tuning.jobs.JobsWithStreamingResponse.cancel","title":"cancel  <code>instance-attribute</code>","text":"<pre><code>cancel = to_streamed_response_wrapper(cancel)\n</code></pre>"},{"location":"reference/resources/fine_tuning/jobs/#src.openai.resources.fine_tuning.jobs.JobsWithStreamingResponse.create","title":"create  <code>instance-attribute</code>","text":"<pre><code>create = to_streamed_response_wrapper(create)\n</code></pre>"},{"location":"reference/resources/fine_tuning/jobs/#src.openai.resources.fine_tuning.jobs.JobsWithStreamingResponse.list","title":"list  <code>instance-attribute</code>","text":"<pre><code>list = to_streamed_response_wrapper(list)\n</code></pre>"},{"location":"reference/resources/fine_tuning/jobs/#src.openai.resources.fine_tuning.jobs.JobsWithStreamingResponse.list_events","title":"list_events  <code>instance-attribute</code>","text":"<pre><code>list_events = to_streamed_response_wrapper(list_events)\n</code></pre>"},{"location":"reference/resources/fine_tuning/jobs/#src.openai.resources.fine_tuning.jobs.JobsWithStreamingResponse.retrieve","title":"retrieve  <code>instance-attribute</code>","text":"<pre><code>retrieve = to_streamed_response_wrapper(retrieve)\n</code></pre>"},{"location":"reference/types/","title":"openai.types","text":"<p>Modules:</p> Name Description <code>audio</code> <code>beta</code> <code>chat</code> <code>completion</code> <code>completion_choice</code> <code>completion_create_params</code> <code>completion_usage</code> <code>create_embedding_response</code> <code>embedding</code> <code>embedding_create_params</code> <code>file_content</code> <code>file_create_params</code> <code>file_deleted</code> <code>file_list_params</code> <code>file_object</code> <code>fine_tuning</code> <code>image</code> <code>image_create_variation_params</code> <code>image_edit_params</code> <code>image_generate_params</code> <code>images_response</code> <code>model</code> <code>model_deleted</code> <code>moderation</code> <code>moderation_create_params</code> <code>moderation_create_response</code> <code>shared</code> <code>shared_params</code>"},{"location":"reference/types/completion/","title":"completion","text":"<p>Classes:</p> Name Description <code>Completion</code>"},{"location":"reference/types/completion/#src.openai.types.completion.Completion","title":"Completion","text":"<p>Attributes:</p> Name Type Description <code>choices</code> <code>List[CompletionChoice]</code> <p>The list of completion choices the model generated for the input prompt.</p> <code>created</code> <code>int</code> <p>The Unix timestamp (in seconds) of when the completion was created.</p> <code>id</code> <code>str</code> <p>A unique identifier for the completion.</p> <code>model</code> <code>str</code> <p>The model used for completion.</p> <code>object</code> <code>Literal['text_completion']</code> <p>The object type, which is always \"text_completion\"</p> <code>system_fingerprint</code> <code>Optional[str]</code> <p>This fingerprint represents the backend configuration that the model runs with.</p> <code>usage</code> <code>Optional[CompletionUsage]</code> <p>Usage statistics for the completion request.</p>"},{"location":"reference/types/completion/#src.openai.types.completion.Completion.choices","title":"choices  <code>instance-attribute</code>","text":"<pre><code>choices: List[CompletionChoice]\n</code></pre> <p>The list of completion choices the model generated for the input prompt.</p>"},{"location":"reference/types/completion/#src.openai.types.completion.Completion.created","title":"created  <code>instance-attribute</code>","text":"<pre><code>created: int\n</code></pre> <p>The Unix timestamp (in seconds) of when the completion was created.</p>"},{"location":"reference/types/completion/#src.openai.types.completion.Completion.id","title":"id  <code>instance-attribute</code>","text":"<pre><code>id: str\n</code></pre> <p>A unique identifier for the completion.</p>"},{"location":"reference/types/completion/#src.openai.types.completion.Completion.model","title":"model  <code>instance-attribute</code>","text":"<pre><code>model: str\n</code></pre> <p>The model used for completion.</p>"},{"location":"reference/types/completion/#src.openai.types.completion.Completion.object","title":"object  <code>instance-attribute</code>","text":"<pre><code>object: Literal['text_completion']\n</code></pre> <p>The object type, which is always \"text_completion\"</p>"},{"location":"reference/types/completion/#src.openai.types.completion.Completion.system_fingerprint","title":"system_fingerprint  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>system_fingerprint: Optional[str] = None\n</code></pre> <p>This fingerprint represents the backend configuration that the model runs with.</p> <p>Can be used in conjunction with the <code>seed</code> request parameter to understand when backend changes have been made that might impact determinism.</p>"},{"location":"reference/types/completion/#src.openai.types.completion.Completion.usage","title":"usage  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>usage: Optional[CompletionUsage] = None\n</code></pre> <p>Usage statistics for the completion request.</p>"},{"location":"reference/types/completion_choice/","title":"completion_choice","text":"<p>Classes:</p> Name Description <code>CompletionChoice</code> <code>Logprobs</code>"},{"location":"reference/types/completion_choice/#src.openai.types.completion_choice.CompletionChoice","title":"CompletionChoice","text":"<p>Attributes:</p> Name Type Description <code>finish_reason</code> <code>Literal['stop', 'length', 'content_filter']</code> <p>The reason the model stopped generating tokens.</p> <code>index</code> <code>int</code> <code>logprobs</code> <code>Optional[Logprobs]</code> <code>text</code> <code>str</code>"},{"location":"reference/types/completion_choice/#src.openai.types.completion_choice.CompletionChoice.finish_reason","title":"finish_reason  <code>instance-attribute</code>","text":"<pre><code>finish_reason: Literal['stop', 'length', 'content_filter']\n</code></pre> <p>The reason the model stopped generating tokens.</p> <p>This will be <code>stop</code> if the model hit a natural stop point or a provided stop sequence, <code>length</code> if the maximum number of tokens specified in the request was reached, or <code>content_filter</code> if content was omitted due to a flag from our content filters.</p>"},{"location":"reference/types/completion_choice/#src.openai.types.completion_choice.CompletionChoice.index","title":"index  <code>instance-attribute</code>","text":"<pre><code>index: int\n</code></pre>"},{"location":"reference/types/completion_choice/#src.openai.types.completion_choice.CompletionChoice.logprobs","title":"logprobs  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>logprobs: Optional[Logprobs] = None\n</code></pre>"},{"location":"reference/types/completion_choice/#src.openai.types.completion_choice.CompletionChoice.text","title":"text  <code>instance-attribute</code>","text":"<pre><code>text: str\n</code></pre>"},{"location":"reference/types/completion_choice/#src.openai.types.completion_choice.Logprobs","title":"Logprobs","text":"<p>Attributes:</p> Name Type Description <code>text_offset</code> <code>Optional[List[int]]</code> <code>token_logprobs</code> <code>Optional[List[float]]</code> <code>tokens</code> <code>Optional[List[str]]</code> <code>top_logprobs</code> <code>Optional[List[Dict[str, float]]]</code>"},{"location":"reference/types/completion_choice/#src.openai.types.completion_choice.Logprobs.text_offset","title":"text_offset  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>text_offset: Optional[List[int]] = None\n</code></pre>"},{"location":"reference/types/completion_choice/#src.openai.types.completion_choice.Logprobs.token_logprobs","title":"token_logprobs  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>token_logprobs: Optional[List[float]] = None\n</code></pre>"},{"location":"reference/types/completion_choice/#src.openai.types.completion_choice.Logprobs.tokens","title":"tokens  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>tokens: Optional[List[str]] = None\n</code></pre>"},{"location":"reference/types/completion_choice/#src.openai.types.completion_choice.Logprobs.top_logprobs","title":"top_logprobs  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>top_logprobs: Optional[List[Dict[str, float]]] = None\n</code></pre>"},{"location":"reference/types/completion_create_params/","title":"completion_create_params","text":"<p>Classes:</p> Name Description <code>CompletionCreateParamsBase</code> <code>CompletionCreateParamsNonStreaming</code> <code>CompletionCreateParamsStreaming</code> <p>Attributes:</p> Name Type Description <code>CompletionCreateParams</code>"},{"location":"reference/types/completion_create_params/#src.openai.types.completion_create_params.CompletionCreateParams","title":"CompletionCreateParams  <code>module-attribute</code>","text":"<pre><code>CompletionCreateParams = Union[\n    CompletionCreateParamsNonStreaming,\n    CompletionCreateParamsStreaming,\n]\n</code></pre>"},{"location":"reference/types/completion_create_params/#src.openai.types.completion_create_params.CompletionCreateParamsBase","title":"CompletionCreateParamsBase","text":"<p>Attributes:</p> Name Type Description <code>best_of</code> <code>Optional[int]</code> <p>Generates <code>best_of</code> completions server-side and returns the \"best\" (the one with</p> <code>echo</code> <code>Optional[bool]</code> <p>Echo back the prompt in addition to the completion</p> <code>frequency_penalty</code> <code>Optional[float]</code> <p>Number between -2.0 and 2.0.</p> <code>logit_bias</code> <code>Optional[Dict[str, int]]</code> <p>Modify the likelihood of specified tokens appearing in the completion.</p> <code>logprobs</code> <code>Optional[int]</code> <p>Include the log probabilities on the <code>logprobs</code> most likely output tokens, as</p> <code>max_tokens</code> <code>Optional[int]</code> <p>The maximum number of tokens that can be generated in the</p> <code>model</code> <code>Required[Union[str, Literal['gpt-3.5-turbo-instruct', 'davinci-002', 'babbage-002']]]</code> <p>ID of the model to use.</p> <code>n</code> <code>Optional[int]</code> <p>How many completions to generate for each prompt.</p> <code>presence_penalty</code> <code>Optional[float]</code> <p>Number between -2.0 and 2.0.</p> <code>prompt</code> <code>Required[Union[str, List[str], Iterable[int], Iterable[Iterable[int]], None]]</code> <p>The prompt(s) to generate completions for, encoded as a string, array of</p> <code>seed</code> <code>Optional[int]</code> <p>If specified, our system will make a best effort to sample deterministically,</p> <code>stop</code> <code>Union[Optional[str], List[str], None]</code> <p>Up to 4 sequences where the API will stop generating further tokens.</p> <code>suffix</code> <code>Optional[str]</code> <p>The suffix that comes after a completion of inserted text.</p> <code>temperature</code> <code>Optional[float]</code> <p>What sampling temperature to use, between 0 and 2.</p> <code>top_p</code> <code>Optional[float]</code> <p>An alternative to sampling with temperature, called nucleus sampling, where the</p> <code>user</code> <code>str</code> <p>A unique identifier representing your end-user, which can help OpenAI to monitor</p>"},{"location":"reference/types/completion_create_params/#src.openai.types.completion_create_params.CompletionCreateParamsBase.best_of","title":"best_of  <code>instance-attribute</code>","text":"<pre><code>best_of: Optional[int]\n</code></pre> <p>Generates <code>best_of</code> completions server-side and returns the \"best\" (the one with the highest log probability per token). Results cannot be streamed.</p> <p>When used with <code>n</code>, <code>best_of</code> controls the number of candidate completions and <code>n</code> specifies how many to return \u2013 <code>best_of</code> must be greater than <code>n</code>.</p> <p>Note: Because this parameter generates many completions, it can quickly consume your token quota. Use carefully and ensure that you have reasonable settings for <code>max_tokens</code> and <code>stop</code>.</p>"},{"location":"reference/types/completion_create_params/#src.openai.types.completion_create_params.CompletionCreateParamsBase.echo","title":"echo  <code>instance-attribute</code>","text":"<pre><code>echo: Optional[bool]\n</code></pre> <p>Echo back the prompt in addition to the completion</p>"},{"location":"reference/types/completion_create_params/#src.openai.types.completion_create_params.CompletionCreateParamsBase.frequency_penalty","title":"frequency_penalty  <code>instance-attribute</code>","text":"<pre><code>frequency_penalty: Optional[float]\n</code></pre> <p>Number between -2.0 and 2.0.</p> <p>Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim.</p> <p>See more information about frequency and presence penalties.</p>"},{"location":"reference/types/completion_create_params/#src.openai.types.completion_create_params.CompletionCreateParamsBase.logit_bias","title":"logit_bias  <code>instance-attribute</code>","text":"<pre><code>logit_bias: Optional[Dict[str, int]]\n</code></pre> <p>Modify the likelihood of specified tokens appearing in the completion.</p> <p>Accepts a JSON object that maps tokens (specified by their token ID in the GPT tokenizer) to an associated bias value from -100 to 100. You can use this tokenizer tool to convert text to token IDs. Mathematically, the bias is added to the logits generated by the model prior to sampling. The exact effect will vary per model, but values between -1 and 1 should decrease or increase likelihood of selection; values like -100 or 100 should result in a ban or exclusive selection of the relevant token.</p> <p>As an example, you can pass <code>{\"50256\": -100}</code> to prevent the &lt;|endoftext|&gt; token from being generated.</p>"},{"location":"reference/types/completion_create_params/#src.openai.types.completion_create_params.CompletionCreateParamsBase.logprobs","title":"logprobs  <code>instance-attribute</code>","text":"<pre><code>logprobs: Optional[int]\n</code></pre> <p>Include the log probabilities on the <code>logprobs</code> most likely output tokens, as well the chosen tokens. For example, if <code>logprobs</code> is 5, the API will return a list of the 5 most likely tokens. The API will always return the <code>logprob</code> of the sampled token, so there may be up to <code>logprobs+1</code> elements in the response.</p> <p>The maximum value for <code>logprobs</code> is 5.</p>"},{"location":"reference/types/completion_create_params/#src.openai.types.completion_create_params.CompletionCreateParamsBase.max_tokens","title":"max_tokens  <code>instance-attribute</code>","text":"<pre><code>max_tokens: Optional[int]\n</code></pre> <p>The maximum number of tokens that can be generated in the completion.</p> <p>The token count of your prompt plus <code>max_tokens</code> cannot exceed the model's context length. Example Python code for counting tokens.</p>"},{"location":"reference/types/completion_create_params/#src.openai.types.completion_create_params.CompletionCreateParamsBase.model","title":"model  <code>instance-attribute</code>","text":"<pre><code>model: Required[\n    Union[\n        str,\n        Literal[\n            \"gpt-3.5-turbo-instruct\",\n            \"davinci-002\",\n            \"babbage-002\",\n        ],\n    ]\n]\n</code></pre> <p>ID of the model to use.</p> <p>You can use the List models API to see all of your available models, or see our Model overview for descriptions of them.</p>"},{"location":"reference/types/completion_create_params/#src.openai.types.completion_create_params.CompletionCreateParamsBase.n","title":"n  <code>instance-attribute</code>","text":"<pre><code>n: Optional[int]\n</code></pre> <p>How many completions to generate for each prompt.</p> <p>Note: Because this parameter generates many completions, it can quickly consume your token quota. Use carefully and ensure that you have reasonable settings for <code>max_tokens</code> and <code>stop</code>.</p>"},{"location":"reference/types/completion_create_params/#src.openai.types.completion_create_params.CompletionCreateParamsBase.presence_penalty","title":"presence_penalty  <code>instance-attribute</code>","text":"<pre><code>presence_penalty: Optional[float]\n</code></pre> <p>Number between -2.0 and 2.0.</p> <p>Positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics.</p> <p>See more information about frequency and presence penalties.</p>"},{"location":"reference/types/completion_create_params/#src.openai.types.completion_create_params.CompletionCreateParamsBase.prompt","title":"prompt  <code>instance-attribute</code>","text":"<pre><code>prompt: Required[\n    Union[\n        str,\n        List[str],\n        Iterable[int],\n        Iterable[Iterable[int]],\n        None,\n    ]\n]\n</code></pre> <p>The prompt(s) to generate completions for, encoded as a string, array of strings, array of tokens, or array of token arrays.</p> <p>Note that &lt;|endoftext|&gt; is the document separator that the model sees during training, so if a prompt is not specified the model will generate as if from the beginning of a new document.</p>"},{"location":"reference/types/completion_create_params/#src.openai.types.completion_create_params.CompletionCreateParamsBase.seed","title":"seed  <code>instance-attribute</code>","text":"<pre><code>seed: Optional[int]\n</code></pre> <p>If specified, our system will make a best effort to sample deterministically, such that repeated requests with the same <code>seed</code> and parameters should return the same result.</p> <p>Determinism is not guaranteed, and you should refer to the <code>system_fingerprint</code> response parameter to monitor changes in the backend.</p>"},{"location":"reference/types/completion_create_params/#src.openai.types.completion_create_params.CompletionCreateParamsBase.stop","title":"stop  <code>instance-attribute</code>","text":"<pre><code>stop: Union[Optional[str], List[str], None]\n</code></pre> <p>Up to 4 sequences where the API will stop generating further tokens.</p> <p>The returned text will not contain the stop sequence.</p>"},{"location":"reference/types/completion_create_params/#src.openai.types.completion_create_params.CompletionCreateParamsBase.suffix","title":"suffix  <code>instance-attribute</code>","text":"<pre><code>suffix: Optional[str]\n</code></pre> <p>The suffix that comes after a completion of inserted text.</p>"},{"location":"reference/types/completion_create_params/#src.openai.types.completion_create_params.CompletionCreateParamsBase.temperature","title":"temperature  <code>instance-attribute</code>","text":"<pre><code>temperature: Optional[float]\n</code></pre> <p>What sampling temperature to use, between 0 and 2.</p> <p>Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.</p> <p>We generally recommend altering this or <code>top_p</code> but not both.</p>"},{"location":"reference/types/completion_create_params/#src.openai.types.completion_create_params.CompletionCreateParamsBase.top_p","title":"top_p  <code>instance-attribute</code>","text":"<pre><code>top_p: Optional[float]\n</code></pre> <p>An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.</p> <p>We generally recommend altering this or <code>temperature</code> but not both.</p>"},{"location":"reference/types/completion_create_params/#src.openai.types.completion_create_params.CompletionCreateParamsBase.user","title":"user  <code>instance-attribute</code>","text":"<pre><code>user: str\n</code></pre> <p>A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. Learn more.</p>"},{"location":"reference/types/completion_create_params/#src.openai.types.completion_create_params.CompletionCreateParamsNonStreaming","title":"CompletionCreateParamsNonStreaming","text":"<p>Attributes:</p> Name Type Description <code>stream</code> <code>Optional[Literal[False]]</code> <p>Whether to stream back partial progress.</p>"},{"location":"reference/types/completion_create_params/#src.openai.types.completion_create_params.CompletionCreateParamsNonStreaming.stream","title":"stream  <code>instance-attribute</code>","text":"<pre><code>stream: Optional[Literal[False]]\n</code></pre> <p>Whether to stream back partial progress.</p> <p>If set, tokens will be sent as data-only server-sent events as they become available, with the stream terminated by a <code>data: [DONE]</code> message. Example Python code.</p>"},{"location":"reference/types/completion_create_params/#src.openai.types.completion_create_params.CompletionCreateParamsStreaming","title":"CompletionCreateParamsStreaming","text":"<p>Attributes:</p> Name Type Description <code>stream</code> <code>Required[Literal[True]]</code> <p>Whether to stream back partial progress.</p>"},{"location":"reference/types/completion_create_params/#src.openai.types.completion_create_params.CompletionCreateParamsStreaming.stream","title":"stream  <code>instance-attribute</code>","text":"<pre><code>stream: Required[Literal[True]]\n</code></pre> <p>Whether to stream back partial progress.</p> <p>If set, tokens will be sent as data-only server-sent events as they become available, with the stream terminated by a <code>data: [DONE]</code> message. Example Python code.</p>"},{"location":"reference/types/completion_usage/","title":"completion_usage","text":"<p>Classes:</p> Name Description <code>CompletionUsage</code>"},{"location":"reference/types/completion_usage/#src.openai.types.completion_usage.CompletionUsage","title":"CompletionUsage","text":"<p>Attributes:</p> Name Type Description <code>completion_tokens</code> <code>int</code> <p>Number of tokens in the generated completion.</p> <code>prompt_tokens</code> <code>int</code> <p>Number of tokens in the prompt.</p> <code>total_tokens</code> <code>int</code> <p>Total number of tokens used in the request (prompt + completion).</p>"},{"location":"reference/types/completion_usage/#src.openai.types.completion_usage.CompletionUsage.completion_tokens","title":"completion_tokens  <code>instance-attribute</code>","text":"<pre><code>completion_tokens: int\n</code></pre> <p>Number of tokens in the generated completion.</p>"},{"location":"reference/types/completion_usage/#src.openai.types.completion_usage.CompletionUsage.prompt_tokens","title":"prompt_tokens  <code>instance-attribute</code>","text":"<pre><code>prompt_tokens: int\n</code></pre> <p>Number of tokens in the prompt.</p>"},{"location":"reference/types/completion_usage/#src.openai.types.completion_usage.CompletionUsage.total_tokens","title":"total_tokens  <code>instance-attribute</code>","text":"<pre><code>total_tokens: int\n</code></pre> <p>Total number of tokens used in the request (prompt + completion).</p>"},{"location":"reference/types/create_embedding_response/","title":"create_embedding_response","text":"<p>Classes:</p> Name Description <code>CreateEmbeddingResponse</code> <code>Usage</code>"},{"location":"reference/types/create_embedding_response/#src.openai.types.create_embedding_response.CreateEmbeddingResponse","title":"CreateEmbeddingResponse","text":"<p>Attributes:</p> Name Type Description <code>data</code> <code>List[Embedding]</code> <p>The list of embeddings generated by the model.</p> <code>model</code> <code>str</code> <p>The name of the model used to generate the embedding.</p> <code>object</code> <code>Literal['list']</code> <p>The object type, which is always \"list\".</p> <code>usage</code> <code>Usage</code> <p>The usage information for the request.</p>"},{"location":"reference/types/create_embedding_response/#src.openai.types.create_embedding_response.CreateEmbeddingResponse.data","title":"data  <code>instance-attribute</code>","text":"<pre><code>data: List[Embedding]\n</code></pre> <p>The list of embeddings generated by the model.</p>"},{"location":"reference/types/create_embedding_response/#src.openai.types.create_embedding_response.CreateEmbeddingResponse.model","title":"model  <code>instance-attribute</code>","text":"<pre><code>model: str\n</code></pre> <p>The name of the model used to generate the embedding.</p>"},{"location":"reference/types/create_embedding_response/#src.openai.types.create_embedding_response.CreateEmbeddingResponse.object","title":"object  <code>instance-attribute</code>","text":"<pre><code>object: Literal['list']\n</code></pre> <p>The object type, which is always \"list\".</p>"},{"location":"reference/types/create_embedding_response/#src.openai.types.create_embedding_response.CreateEmbeddingResponse.usage","title":"usage  <code>instance-attribute</code>","text":"<pre><code>usage: Usage\n</code></pre> <p>The usage information for the request.</p>"},{"location":"reference/types/create_embedding_response/#src.openai.types.create_embedding_response.Usage","title":"Usage","text":"<p>Attributes:</p> Name Type Description <code>prompt_tokens</code> <code>int</code> <p>The number of tokens used by the prompt.</p> <code>total_tokens</code> <code>int</code> <p>The total number of tokens used by the request.</p>"},{"location":"reference/types/create_embedding_response/#src.openai.types.create_embedding_response.Usage.prompt_tokens","title":"prompt_tokens  <code>instance-attribute</code>","text":"<pre><code>prompt_tokens: int\n</code></pre> <p>The number of tokens used by the prompt.</p>"},{"location":"reference/types/create_embedding_response/#src.openai.types.create_embedding_response.Usage.total_tokens","title":"total_tokens  <code>instance-attribute</code>","text":"<pre><code>total_tokens: int\n</code></pre> <p>The total number of tokens used by the request.</p>"},{"location":"reference/types/embedding/","title":"embedding","text":"<p>Classes:</p> Name Description <code>Embedding</code>"},{"location":"reference/types/embedding/#src.openai.types.embedding.Embedding","title":"Embedding","text":"<p>Attributes:</p> Name Type Description <code>embedding</code> <code>List[float]</code> <p>The embedding vector, which is a list of floats.</p> <code>index</code> <code>int</code> <p>The index of the embedding in the list of embeddings.</p> <code>object</code> <code>Literal['embedding']</code> <p>The object type, which is always \"embedding\".</p>"},{"location":"reference/types/embedding/#src.openai.types.embedding.Embedding.embedding","title":"embedding  <code>instance-attribute</code>","text":"<pre><code>embedding: List[float]\n</code></pre> <p>The embedding vector, which is a list of floats.</p> <p>The length of vector depends on the model as listed in the embedding guide.</p>"},{"location":"reference/types/embedding/#src.openai.types.embedding.Embedding.index","title":"index  <code>instance-attribute</code>","text":"<pre><code>index: int\n</code></pre> <p>The index of the embedding in the list of embeddings.</p>"},{"location":"reference/types/embedding/#src.openai.types.embedding.Embedding.object","title":"object  <code>instance-attribute</code>","text":"<pre><code>object: Literal['embedding']\n</code></pre> <p>The object type, which is always \"embedding\".</p>"},{"location":"reference/types/embedding_create_params/","title":"embedding_create_params","text":"<p>Classes:</p> Name Description <code>EmbeddingCreateParams</code>"},{"location":"reference/types/embedding_create_params/#src.openai.types.embedding_create_params.EmbeddingCreateParams","title":"EmbeddingCreateParams","text":"<p>Attributes:</p> Name Type Description <code>dimensions</code> <code>int</code> <p>The number of dimensions the resulting output embeddings should have.</p> <code>encoding_format</code> <code>Literal['float', 'base64']</code> <p>The format to return the embeddings in.</p> <code>input</code> <code>Required[Union[str, List[str], Iterable[int], Iterable[Iterable[int]]]]</code> <p>Input text to embed, encoded as a string or array of tokens.</p> <code>model</code> <code>Required[Union[str, Literal['text-embedding-ada-002', 'text-embedding-3-small', 'text-embedding-3-large']]]</code> <p>ID of the model to use.</p> <code>user</code> <code>str</code> <p>A unique identifier representing your end-user, which can help OpenAI to monitor</p>"},{"location":"reference/types/embedding_create_params/#src.openai.types.embedding_create_params.EmbeddingCreateParams.dimensions","title":"dimensions  <code>instance-attribute</code>","text":"<pre><code>dimensions: int\n</code></pre> <p>The number of dimensions the resulting output embeddings should have.</p> <p>Only supported in <code>text-embedding-3</code> and later models.</p>"},{"location":"reference/types/embedding_create_params/#src.openai.types.embedding_create_params.EmbeddingCreateParams.encoding_format","title":"encoding_format  <code>instance-attribute</code>","text":"<pre><code>encoding_format: Literal['float', 'base64']\n</code></pre> <p>The format to return the embeddings in.</p> <p>Can be either <code>float</code> or <code>base64</code>.</p>"},{"location":"reference/types/embedding_create_params/#src.openai.types.embedding_create_params.EmbeddingCreateParams.input","title":"input  <code>instance-attribute</code>","text":"<pre><code>input: Required[\n    Union[\n        str,\n        List[str],\n        Iterable[int],\n        Iterable[Iterable[int]],\n    ]\n]\n</code></pre> <p>Input text to embed, encoded as a string or array of tokens.</p> <p>To embed multiple inputs in a single request, pass an array of strings or array of token arrays. The input must not exceed the max input tokens for the model (8192 tokens for <code>text-embedding-ada-002</code>), cannot be an empty string, and any array must be 2048 dimensions or less. Example Python code for counting tokens.</p>"},{"location":"reference/types/embedding_create_params/#src.openai.types.embedding_create_params.EmbeddingCreateParams.model","title":"model  <code>instance-attribute</code>","text":"<pre><code>model: Required[\n    Union[\n        str,\n        Literal[\n            \"text-embedding-ada-002\",\n            \"text-embedding-3-small\",\n            \"text-embedding-3-large\",\n        ],\n    ]\n]\n</code></pre> <p>ID of the model to use.</p> <p>You can use the List models API to see all of your available models, or see our Model overview for descriptions of them.</p>"},{"location":"reference/types/embedding_create_params/#src.openai.types.embedding_create_params.EmbeddingCreateParams.user","title":"user  <code>instance-attribute</code>","text":"<pre><code>user: str\n</code></pre> <p>A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. Learn more.</p>"},{"location":"reference/types/file_content/","title":"file_content","text":"<p>Attributes:</p> Name Type Description <code>FileContent</code>"},{"location":"reference/types/file_content/#src.openai.types.file_content.FileContent","title":"FileContent  <code>module-attribute</code>","text":"<pre><code>FileContent = str\n</code></pre>"},{"location":"reference/types/file_create_params/","title":"file_create_params","text":"<p>Classes:</p> Name Description <code>FileCreateParams</code>"},{"location":"reference/types/file_create_params/#src.openai.types.file_create_params.FileCreateParams","title":"FileCreateParams","text":"<p>Attributes:</p> Name Type Description <code>file</code> <code>Required[FileTypes]</code> <p>The File object (not file name) to be uploaded.</p> <code>purpose</code> <code>Required[Literal['fine-tune', 'assistants']]</code> <p>The intended purpose of the uploaded file.</p>"},{"location":"reference/types/file_create_params/#src.openai.types.file_create_params.FileCreateParams.file","title":"file  <code>instance-attribute</code>","text":"<pre><code>file: Required[FileTypes]\n</code></pre> <p>The File object (not file name) to be uploaded.</p>"},{"location":"reference/types/file_create_params/#src.openai.types.file_create_params.FileCreateParams.purpose","title":"purpose  <code>instance-attribute</code>","text":"<pre><code>purpose: Required[Literal['fine-tune', 'assistants']]\n</code></pre> <p>The intended purpose of the uploaded file.</p> <p>Use \"fine-tune\" for Fine-tuning and \"assistants\" for Assistants and Messages. This allows us to validate the format of the uploaded file is correct for fine-tuning.</p>"},{"location":"reference/types/file_deleted/","title":"file_deleted","text":"<p>Classes:</p> Name Description <code>FileDeleted</code>"},{"location":"reference/types/file_deleted/#src.openai.types.file_deleted.FileDeleted","title":"FileDeleted","text":"<p>Attributes:</p> Name Type Description <code>deleted</code> <code>bool</code> <code>id</code> <code>str</code> <code>object</code> <code>Literal['file']</code>"},{"location":"reference/types/file_deleted/#src.openai.types.file_deleted.FileDeleted.deleted","title":"deleted  <code>instance-attribute</code>","text":"<pre><code>deleted: bool\n</code></pre>"},{"location":"reference/types/file_deleted/#src.openai.types.file_deleted.FileDeleted.id","title":"id  <code>instance-attribute</code>","text":"<pre><code>id: str\n</code></pre>"},{"location":"reference/types/file_deleted/#src.openai.types.file_deleted.FileDeleted.object","title":"object  <code>instance-attribute</code>","text":"<pre><code>object: Literal['file']\n</code></pre>"},{"location":"reference/types/file_list_params/","title":"file_list_params","text":"<p>Classes:</p> Name Description <code>FileListParams</code>"},{"location":"reference/types/file_list_params/#src.openai.types.file_list_params.FileListParams","title":"FileListParams","text":"<p>Attributes:</p> Name Type Description <code>purpose</code> <code>str</code> <p>Only return files with the given purpose.</p>"},{"location":"reference/types/file_list_params/#src.openai.types.file_list_params.FileListParams.purpose","title":"purpose  <code>instance-attribute</code>","text":"<pre><code>purpose: str\n</code></pre> <p>Only return files with the given purpose.</p>"},{"location":"reference/types/file_object/","title":"file_object","text":"<p>Classes:</p> Name Description <code>FileObject</code>"},{"location":"reference/types/file_object/#src.openai.types.file_object.FileObject","title":"FileObject","text":"<p>Attributes:</p> Name Type Description <code>bytes</code> <code>int</code> <p>The size of the file, in bytes.</p> <code>created_at</code> <code>int</code> <p>The Unix timestamp (in seconds) for when the file was created.</p> <code>filename</code> <code>str</code> <p>The name of the file.</p> <code>id</code> <code>str</code> <p>The file identifier, which can be referenced in the API endpoints.</p> <code>object</code> <code>Literal['file']</code> <p>The object type, which is always <code>file</code>.</p> <code>purpose</code> <code>Literal['fine-tune', 'fine-tune-results', 'assistants', 'assistants_output']</code> <p>The intended purpose of the file.</p> <code>status</code> <code>Literal['uploaded', 'processed', 'error']</code> <p>Deprecated.</p> <code>status_details</code> <code>Optional[str]</code> <p>Deprecated.</p>"},{"location":"reference/types/file_object/#src.openai.types.file_object.FileObject.bytes","title":"bytes  <code>instance-attribute</code>","text":"<pre><code>bytes: int\n</code></pre> <p>The size of the file, in bytes.</p>"},{"location":"reference/types/file_object/#src.openai.types.file_object.FileObject.created_at","title":"created_at  <code>instance-attribute</code>","text":"<pre><code>created_at: int\n</code></pre> <p>The Unix timestamp (in seconds) for when the file was created.</p>"},{"location":"reference/types/file_object/#src.openai.types.file_object.FileObject.filename","title":"filename  <code>instance-attribute</code>","text":"<pre><code>filename: str\n</code></pre> <p>The name of the file.</p>"},{"location":"reference/types/file_object/#src.openai.types.file_object.FileObject.id","title":"id  <code>instance-attribute</code>","text":"<pre><code>id: str\n</code></pre> <p>The file identifier, which can be referenced in the API endpoints.</p>"},{"location":"reference/types/file_object/#src.openai.types.file_object.FileObject.object","title":"object  <code>instance-attribute</code>","text":"<pre><code>object: Literal['file']\n</code></pre> <p>The object type, which is always <code>file</code>.</p>"},{"location":"reference/types/file_object/#src.openai.types.file_object.FileObject.purpose","title":"purpose  <code>instance-attribute</code>","text":"<pre><code>purpose: Literal[\n    \"fine-tune\",\n    \"fine-tune-results\",\n    \"assistants\",\n    \"assistants_output\",\n]\n</code></pre> <p>The intended purpose of the file.</p> <p>Supported values are <code>fine-tune</code>, <code>fine-tune-results</code>, <code>assistants</code>, and <code>assistants_output</code>.</p>"},{"location":"reference/types/file_object/#src.openai.types.file_object.FileObject.status","title":"status  <code>instance-attribute</code>","text":"<pre><code>status: Literal['uploaded', 'processed', 'error']\n</code></pre> <p>Deprecated.</p> <p>The current status of the file, which can be either <code>uploaded</code>, <code>processed</code>, or <code>error</code>.</p>"},{"location":"reference/types/file_object/#src.openai.types.file_object.FileObject.status_details","title":"status_details  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>status_details: Optional[str] = None\n</code></pre> <p>Deprecated.</p> <p>For details on why a fine-tuning training file failed validation, see the <code>error</code> field on <code>fine_tuning.job</code>.</p>"},{"location":"reference/types/image/","title":"image","text":"<p>Classes:</p> Name Description <code>Image</code>"},{"location":"reference/types/image/#src.openai.types.image.Image","title":"Image","text":"<p>Attributes:</p> Name Type Description <code>b64_json</code> <code>Optional[str]</code> <p>The base64-encoded JSON of the generated image, if <code>response_format</code> is</p> <code>revised_prompt</code> <code>Optional[str]</code> <p>The prompt that was used to generate the image, if there was any revision to the</p> <code>url</code> <code>Optional[str]</code> <p>The URL of the generated image, if <code>response_format</code> is <code>url</code> (default).</p>"},{"location":"reference/types/image/#src.openai.types.image.Image.b64_json","title":"b64_json  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>b64_json: Optional[str] = None\n</code></pre> <p>The base64-encoded JSON of the generated image, if <code>response_format</code> is <code>b64_json</code>.</p>"},{"location":"reference/types/image/#src.openai.types.image.Image.revised_prompt","title":"revised_prompt  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>revised_prompt: Optional[str] = None\n</code></pre> <p>The prompt that was used to generate the image, if there was any revision to the prompt.</p>"},{"location":"reference/types/image/#src.openai.types.image.Image.url","title":"url  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>url: Optional[str] = None\n</code></pre> <p>The URL of the generated image, if <code>response_format</code> is <code>url</code> (default).</p>"},{"location":"reference/types/image_create_variation_params/","title":"image_create_variation_params","text":"<p>Classes:</p> Name Description <code>ImageCreateVariationParams</code>"},{"location":"reference/types/image_create_variation_params/#src.openai.types.image_create_variation_params.ImageCreateVariationParams","title":"ImageCreateVariationParams","text":"<p>Attributes:</p> Name Type Description <code>image</code> <code>Required[FileTypes]</code> <p>The image to use as the basis for the variation(s).</p> <code>model</code> <code>Union[str, Literal['dall-e-2'], None]</code> <p>The model to use for image generation.</p> <code>n</code> <code>Optional[int]</code> <p>The number of images to generate.</p> <code>response_format</code> <code>Optional[Literal['url', 'b64_json']]</code> <p>The format in which the generated images are returned.</p> <code>size</code> <code>Optional[Literal['256x256', '512x512', '1024x1024']]</code> <p>The size of the generated images.</p> <code>user</code> <code>str</code> <p>A unique identifier representing your end-user, which can help OpenAI to monitor</p>"},{"location":"reference/types/image_create_variation_params/#src.openai.types.image_create_variation_params.ImageCreateVariationParams.image","title":"image  <code>instance-attribute</code>","text":"<pre><code>image: Required[FileTypes]\n</code></pre> <p>The image to use as the basis for the variation(s).</p> <p>Must be a valid PNG file, less than 4MB, and square.</p>"},{"location":"reference/types/image_create_variation_params/#src.openai.types.image_create_variation_params.ImageCreateVariationParams.model","title":"model  <code>instance-attribute</code>","text":"<pre><code>model: Union[str, Literal['dall-e-2'], None]\n</code></pre> <p>The model to use for image generation.</p> <p>Only <code>dall-e-2</code> is supported at this time.</p>"},{"location":"reference/types/image_create_variation_params/#src.openai.types.image_create_variation_params.ImageCreateVariationParams.n","title":"n  <code>instance-attribute</code>","text":"<pre><code>n: Optional[int]\n</code></pre> <p>The number of images to generate.</p> <p>Must be between 1 and 10. For <code>dall-e-3</code>, only <code>n=1</code> is supported.</p>"},{"location":"reference/types/image_create_variation_params/#src.openai.types.image_create_variation_params.ImageCreateVariationParams.response_format","title":"response_format  <code>instance-attribute</code>","text":"<pre><code>response_format: Optional[Literal['url', 'b64_json']]\n</code></pre> <p>The format in which the generated images are returned.</p> <p>Must be one of <code>url</code> or <code>b64_json</code>. URLs are only valid for 60 minutes after the image has been generated.</p>"},{"location":"reference/types/image_create_variation_params/#src.openai.types.image_create_variation_params.ImageCreateVariationParams.size","title":"size  <code>instance-attribute</code>","text":"<pre><code>size: Optional[Literal['256x256', '512x512', '1024x1024']]\n</code></pre> <p>The size of the generated images.</p> <p>Must be one of <code>256x256</code>, <code>512x512</code>, or <code>1024x1024</code>.</p>"},{"location":"reference/types/image_create_variation_params/#src.openai.types.image_create_variation_params.ImageCreateVariationParams.user","title":"user  <code>instance-attribute</code>","text":"<pre><code>user: str\n</code></pre> <p>A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. Learn more.</p>"},{"location":"reference/types/image_edit_params/","title":"image_edit_params","text":"<p>Classes:</p> Name Description <code>ImageEditParams</code>"},{"location":"reference/types/image_edit_params/#src.openai.types.image_edit_params.ImageEditParams","title":"ImageEditParams","text":"<p>Attributes:</p> Name Type Description <code>image</code> <code>Required[FileTypes]</code> <p>The image to edit.</p> <code>mask</code> <code>FileTypes</code> <p>An additional image whose fully transparent areas (e.g.</p> <code>model</code> <code>Union[str, Literal['dall-e-2'], None]</code> <p>The model to use for image generation.</p> <code>n</code> <code>Optional[int]</code> <p>The number of images to generate. Must be between 1 and 10.</p> <code>prompt</code> <code>Required[str]</code> <p>A text description of the desired image(s).</p> <code>response_format</code> <code>Optional[Literal['url', 'b64_json']]</code> <p>The format in which the generated images are returned.</p> <code>size</code> <code>Optional[Literal['256x256', '512x512', '1024x1024']]</code> <p>The size of the generated images.</p> <code>user</code> <code>str</code> <p>A unique identifier representing your end-user, which can help OpenAI to monitor</p>"},{"location":"reference/types/image_edit_params/#src.openai.types.image_edit_params.ImageEditParams.image","title":"image  <code>instance-attribute</code>","text":"<pre><code>image: Required[FileTypes]\n</code></pre> <p>The image to edit.</p> <p>Must be a valid PNG file, less than 4MB, and square. If mask is not provided, image must have transparency, which will be used as the mask.</p>"},{"location":"reference/types/image_edit_params/#src.openai.types.image_edit_params.ImageEditParams.mask","title":"mask  <code>instance-attribute</code>","text":"<pre><code>mask: FileTypes\n</code></pre> <p>An additional image whose fully transparent areas (e.g.</p> <p>where alpha is zero) indicate where <code>image</code> should be edited. Must be a valid PNG file, less than 4MB, and have the same dimensions as <code>image</code>.</p>"},{"location":"reference/types/image_edit_params/#src.openai.types.image_edit_params.ImageEditParams.model","title":"model  <code>instance-attribute</code>","text":"<pre><code>model: Union[str, Literal['dall-e-2'], None]\n</code></pre> <p>The model to use for image generation.</p> <p>Only <code>dall-e-2</code> is supported at this time.</p>"},{"location":"reference/types/image_edit_params/#src.openai.types.image_edit_params.ImageEditParams.n","title":"n  <code>instance-attribute</code>","text":"<pre><code>n: Optional[int]\n</code></pre> <p>The number of images to generate. Must be between 1 and 10.</p>"},{"location":"reference/types/image_edit_params/#src.openai.types.image_edit_params.ImageEditParams.prompt","title":"prompt  <code>instance-attribute</code>","text":"<pre><code>prompt: Required[str]\n</code></pre> <p>A text description of the desired image(s).</p> <p>The maximum length is 1000 characters.</p>"},{"location":"reference/types/image_edit_params/#src.openai.types.image_edit_params.ImageEditParams.response_format","title":"response_format  <code>instance-attribute</code>","text":"<pre><code>response_format: Optional[Literal['url', 'b64_json']]\n</code></pre> <p>The format in which the generated images are returned.</p> <p>Must be one of <code>url</code> or <code>b64_json</code>. URLs are only valid for 60 minutes after the image has been generated.</p>"},{"location":"reference/types/image_edit_params/#src.openai.types.image_edit_params.ImageEditParams.size","title":"size  <code>instance-attribute</code>","text":"<pre><code>size: Optional[Literal['256x256', '512x512', '1024x1024']]\n</code></pre> <p>The size of the generated images.</p> <p>Must be one of <code>256x256</code>, <code>512x512</code>, or <code>1024x1024</code>.</p>"},{"location":"reference/types/image_edit_params/#src.openai.types.image_edit_params.ImageEditParams.user","title":"user  <code>instance-attribute</code>","text":"<pre><code>user: str\n</code></pre> <p>A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. Learn more.</p>"},{"location":"reference/types/image_generate_params/","title":"image_generate_params","text":"<p>Classes:</p> Name Description <code>ImageGenerateParams</code>"},{"location":"reference/types/image_generate_params/#src.openai.types.image_generate_params.ImageGenerateParams","title":"ImageGenerateParams","text":"<p>Attributes:</p> Name Type Description <code>model</code> <code>Union[str, Literal['dall-e-2', 'dall-e-3'], None]</code> <p>The model to use for image generation.</p> <code>n</code> <code>Optional[int]</code> <p>The number of images to generate.</p> <code>prompt</code> <code>Required[str]</code> <p>A text description of the desired image(s).</p> <code>quality</code> <code>Literal['standard', 'hd']</code> <p>The quality of the image that will be generated.</p> <code>response_format</code> <code>Optional[Literal['url', 'b64_json']]</code> <p>The format in which the generated images are returned.</p> <code>size</code> <code>Optional[Literal['256x256', '512x512', '1024x1024', '1792x1024', '1024x1792']]</code> <p>The size of the generated images.</p> <code>style</code> <code>Optional[Literal['vivid', 'natural']]</code> <p>The style of the generated images.</p> <code>user</code> <code>str</code> <p>A unique identifier representing your end-user, which can help OpenAI to monitor</p>"},{"location":"reference/types/image_generate_params/#src.openai.types.image_generate_params.ImageGenerateParams.model","title":"model  <code>instance-attribute</code>","text":"<pre><code>model: Union[str, Literal['dall-e-2', 'dall-e-3'], None]\n</code></pre> <p>The model to use for image generation.</p>"},{"location":"reference/types/image_generate_params/#src.openai.types.image_generate_params.ImageGenerateParams.n","title":"n  <code>instance-attribute</code>","text":"<pre><code>n: Optional[int]\n</code></pre> <p>The number of images to generate.</p> <p>Must be between 1 and 10. For <code>dall-e-3</code>, only <code>n=1</code> is supported.</p>"},{"location":"reference/types/image_generate_params/#src.openai.types.image_generate_params.ImageGenerateParams.prompt","title":"prompt  <code>instance-attribute</code>","text":"<pre><code>prompt: Required[str]\n</code></pre> <p>A text description of the desired image(s).</p> <p>The maximum length is 1000 characters for <code>dall-e-2</code> and 4000 characters for <code>dall-e-3</code>.</p>"},{"location":"reference/types/image_generate_params/#src.openai.types.image_generate_params.ImageGenerateParams.quality","title":"quality  <code>instance-attribute</code>","text":"<pre><code>quality: Literal['standard', 'hd']\n</code></pre> <p>The quality of the image that will be generated.</p> <p><code>hd</code> creates images with finer details and greater consistency across the image. This param is only supported for <code>dall-e-3</code>.</p>"},{"location":"reference/types/image_generate_params/#src.openai.types.image_generate_params.ImageGenerateParams.response_format","title":"response_format  <code>instance-attribute</code>","text":"<pre><code>response_format: Optional[Literal['url', 'b64_json']]\n</code></pre> <p>The format in which the generated images are returned.</p> <p>Must be one of <code>url</code> or <code>b64_json</code>. URLs are only valid for 60 minutes after the image has been generated.</p>"},{"location":"reference/types/image_generate_params/#src.openai.types.image_generate_params.ImageGenerateParams.size","title":"size  <code>instance-attribute</code>","text":"<pre><code>size: Optional[\n    Literal[\n        \"256x256\",\n        \"512x512\",\n        \"1024x1024\",\n        \"1792x1024\",\n        \"1024x1792\",\n    ]\n]\n</code></pre> <p>The size of the generated images.</p> <p>Must be one of <code>256x256</code>, <code>512x512</code>, or <code>1024x1024</code> for <code>dall-e-2</code>. Must be one of <code>1024x1024</code>, <code>1792x1024</code>, or <code>1024x1792</code> for <code>dall-e-3</code> models.</p>"},{"location":"reference/types/image_generate_params/#src.openai.types.image_generate_params.ImageGenerateParams.style","title":"style  <code>instance-attribute</code>","text":"<pre><code>style: Optional[Literal['vivid', 'natural']]\n</code></pre> <p>The style of the generated images.</p> <p>Must be one of <code>vivid</code> or <code>natural</code>. Vivid causes the model to lean towards generating hyper-real and dramatic images. Natural causes the model to produce more natural, less hyper-real looking images. This param is only supported for <code>dall-e-3</code>.</p>"},{"location":"reference/types/image_generate_params/#src.openai.types.image_generate_params.ImageGenerateParams.user","title":"user  <code>instance-attribute</code>","text":"<pre><code>user: str\n</code></pre> <p>A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. Learn more.</p>"},{"location":"reference/types/images_response/","title":"images_response","text":"<p>Classes:</p> Name Description <code>ImagesResponse</code>"},{"location":"reference/types/images_response/#src.openai.types.images_response.ImagesResponse","title":"ImagesResponse","text":"<p>Attributes:</p> Name Type Description <code>created</code> <code>int</code> <code>data</code> <code>List[Image]</code>"},{"location":"reference/types/images_response/#src.openai.types.images_response.ImagesResponse.created","title":"created  <code>instance-attribute</code>","text":"<pre><code>created: int\n</code></pre>"},{"location":"reference/types/images_response/#src.openai.types.images_response.ImagesResponse.data","title":"data  <code>instance-attribute</code>","text":"<pre><code>data: List[Image]\n</code></pre>"},{"location":"reference/types/model/","title":"model","text":"<p>Classes:</p> Name Description <code>Model</code>"},{"location":"reference/types/model/#src.openai.types.model.Model","title":"Model","text":"<p>Attributes:</p> Name Type Description <code>created</code> <code>int</code> <p>The Unix timestamp (in seconds) when the model was created.</p> <code>id</code> <code>str</code> <p>The model identifier, which can be referenced in the API endpoints.</p> <code>object</code> <code>Literal['model']</code> <p>The object type, which is always \"model\".</p> <code>owned_by</code> <code>str</code> <p>The organization that owns the model.</p>"},{"location":"reference/types/model/#src.openai.types.model.Model.created","title":"created  <code>instance-attribute</code>","text":"<pre><code>created: int\n</code></pre> <p>The Unix timestamp (in seconds) when the model was created.</p>"},{"location":"reference/types/model/#src.openai.types.model.Model.id","title":"id  <code>instance-attribute</code>","text":"<pre><code>id: str\n</code></pre> <p>The model identifier, which can be referenced in the API endpoints.</p>"},{"location":"reference/types/model/#src.openai.types.model.Model.object","title":"object  <code>instance-attribute</code>","text":"<pre><code>object: Literal['model']\n</code></pre> <p>The object type, which is always \"model\".</p>"},{"location":"reference/types/model/#src.openai.types.model.Model.owned_by","title":"owned_by  <code>instance-attribute</code>","text":"<pre><code>owned_by: str\n</code></pre> <p>The organization that owns the model.</p>"},{"location":"reference/types/model_deleted/","title":"model_deleted","text":"<p>Classes:</p> Name Description <code>ModelDeleted</code>"},{"location":"reference/types/model_deleted/#src.openai.types.model_deleted.ModelDeleted","title":"ModelDeleted","text":"<p>Attributes:</p> Name Type Description <code>deleted</code> <code>bool</code> <code>id</code> <code>str</code> <code>object</code> <code>str</code>"},{"location":"reference/types/model_deleted/#src.openai.types.model_deleted.ModelDeleted.deleted","title":"deleted  <code>instance-attribute</code>","text":"<pre><code>deleted: bool\n</code></pre>"},{"location":"reference/types/model_deleted/#src.openai.types.model_deleted.ModelDeleted.id","title":"id  <code>instance-attribute</code>","text":"<pre><code>id: str\n</code></pre>"},{"location":"reference/types/model_deleted/#src.openai.types.model_deleted.ModelDeleted.object","title":"object  <code>instance-attribute</code>","text":"<pre><code>object: str\n</code></pre>"},{"location":"reference/types/moderation/","title":"moderation","text":"<p>Classes:</p> Name Description <code>Categories</code> <code>CategoryScores</code> <code>Moderation</code>"},{"location":"reference/types/moderation/#src.openai.types.moderation.Categories","title":"Categories","text":"<p>Attributes:</p> Name Type Description <code>harassment</code> <code>bool</code> <p>Content that expresses, incites, or promotes harassing language towards any</p> <code>harassment_threatening</code> <code>bool</code> <p>Harassment content that also includes violence or serious harm towards any</p> <code>hate</code> <code>bool</code> <p>Content that expresses, incites, or promotes hate based on race, gender,</p> <code>hate_threatening</code> <code>bool</code> <p>Hateful content that also includes violence or serious harm towards the targeted</p> <code>self_harm</code> <code>bool</code> <p>Content that promotes, encourages, or depicts acts of self-harm, such as</p> <code>self_harm_instructions</code> <code>bool</code> <p>Content that encourages performing acts of self-harm, such as suicide, cutting,</p> <code>self_harm_intent</code> <code>bool</code> <p>Content where the speaker expresses that they are engaging or intend to engage</p> <code>sexual</code> <code>bool</code> <p>Content meant to arouse sexual excitement, such as the description of sexual</p> <code>sexual_minors</code> <code>bool</code> <p>Sexual content that includes an individual who is under 18 years old.</p> <code>violence</code> <code>bool</code> <p>Content that depicts death, violence, or physical injury.</p> <code>violence_graphic</code> <code>bool</code> <p>Content that depicts death, violence, or physical injury in graphic detail.</p>"},{"location":"reference/types/moderation/#src.openai.types.moderation.Categories.harassment","title":"harassment  <code>instance-attribute</code>","text":"<pre><code>harassment: bool\n</code></pre> <p>Content that expresses, incites, or promotes harassing language towards any target.</p>"},{"location":"reference/types/moderation/#src.openai.types.moderation.Categories.harassment_threatening","title":"harassment_threatening  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>harassment_threatening: bool = Field(\n    alias=\"harassment/threatening\"\n)\n</code></pre> <p>Harassment content that also includes violence or serious harm towards any target.</p>"},{"location":"reference/types/moderation/#src.openai.types.moderation.Categories.hate","title":"hate  <code>instance-attribute</code>","text":"<pre><code>hate: bool\n</code></pre> <p>Content that expresses, incites, or promotes hate based on race, gender, ethnicity, religion, nationality, sexual orientation, disability status, or caste. Hateful content aimed at non-protected groups (e.g., chess players) is harassment.</p>"},{"location":"reference/types/moderation/#src.openai.types.moderation.Categories.hate_threatening","title":"hate_threatening  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>hate_threatening: bool = Field(alias='hate/threatening')\n</code></pre> <p>Hateful content that also includes violence or serious harm towards the targeted group based on race, gender, ethnicity, religion, nationality, sexual orientation, disability status, or caste.</p>"},{"location":"reference/types/moderation/#src.openai.types.moderation.Categories.self_harm","title":"self_harm  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>self_harm: bool = Field(alias='self-harm')\n</code></pre> <p>Content that promotes, encourages, or depicts acts of self-harm, such as suicide, cutting, and eating disorders.</p>"},{"location":"reference/types/moderation/#src.openai.types.moderation.Categories.self_harm_instructions","title":"self_harm_instructions  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>self_harm_instructions: bool = Field(\n    alias=\"self-harm/instructions\"\n)\n</code></pre> <p>Content that encourages performing acts of self-harm, such as suicide, cutting, and eating disorders, or that gives instructions or advice on how to commit such acts.</p>"},{"location":"reference/types/moderation/#src.openai.types.moderation.Categories.self_harm_intent","title":"self_harm_intent  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>self_harm_intent: bool = Field(alias='self-harm/intent')\n</code></pre> <p>Content where the speaker expresses that they are engaging or intend to engage in acts of self-harm, such as suicide, cutting, and eating disorders.</p>"},{"location":"reference/types/moderation/#src.openai.types.moderation.Categories.sexual","title":"sexual  <code>instance-attribute</code>","text":"<pre><code>sexual: bool\n</code></pre> <p>Content meant to arouse sexual excitement, such as the description of sexual activity, or that promotes sexual services (excluding sex education and wellness).</p>"},{"location":"reference/types/moderation/#src.openai.types.moderation.Categories.sexual_minors","title":"sexual_minors  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>sexual_minors: bool = Field(alias='sexual/minors')\n</code></pre> <p>Sexual content that includes an individual who is under 18 years old.</p>"},{"location":"reference/types/moderation/#src.openai.types.moderation.Categories.violence","title":"violence  <code>instance-attribute</code>","text":"<pre><code>violence: bool\n</code></pre> <p>Content that depicts death, violence, or physical injury.</p>"},{"location":"reference/types/moderation/#src.openai.types.moderation.Categories.violence_graphic","title":"violence_graphic  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>violence_graphic: bool = Field(alias='violence/graphic')\n</code></pre> <p>Content that depicts death, violence, or physical injury in graphic detail.</p>"},{"location":"reference/types/moderation/#src.openai.types.moderation.CategoryScores","title":"CategoryScores","text":"<p>Attributes:</p> Name Type Description <code>harassment</code> <code>float</code> <p>The score for the category 'harassment'.</p> <code>harassment_threatening</code> <code>float</code> <p>The score for the category 'harassment/threatening'.</p> <code>hate</code> <code>float</code> <p>The score for the category 'hate'.</p> <code>hate_threatening</code> <code>float</code> <p>The score for the category 'hate/threatening'.</p> <code>self_harm</code> <code>float</code> <p>The score for the category 'self-harm'.</p> <code>self_harm_instructions</code> <code>float</code> <p>The score for the category 'self-harm/instructions'.</p> <code>self_harm_intent</code> <code>float</code> <p>The score for the category 'self-harm/intent'.</p> <code>sexual</code> <code>float</code> <p>The score for the category 'sexual'.</p> <code>sexual_minors</code> <code>float</code> <p>The score for the category 'sexual/minors'.</p> <code>violence</code> <code>float</code> <p>The score for the category 'violence'.</p> <code>violence_graphic</code> <code>float</code> <p>The score for the category 'violence/graphic'.</p>"},{"location":"reference/types/moderation/#src.openai.types.moderation.CategoryScores.harassment","title":"harassment  <code>instance-attribute</code>","text":"<pre><code>harassment: float\n</code></pre> <p>The score for the category 'harassment'.</p>"},{"location":"reference/types/moderation/#src.openai.types.moderation.CategoryScores.harassment_threatening","title":"harassment_threatening  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>harassment_threatening: float = Field(\n    alias=\"harassment/threatening\"\n)\n</code></pre> <p>The score for the category 'harassment/threatening'.</p>"},{"location":"reference/types/moderation/#src.openai.types.moderation.CategoryScores.hate","title":"hate  <code>instance-attribute</code>","text":"<pre><code>hate: float\n</code></pre> <p>The score for the category 'hate'.</p>"},{"location":"reference/types/moderation/#src.openai.types.moderation.CategoryScores.hate_threatening","title":"hate_threatening  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>hate_threatening: float = Field(alias='hate/threatening')\n</code></pre> <p>The score for the category 'hate/threatening'.</p>"},{"location":"reference/types/moderation/#src.openai.types.moderation.CategoryScores.self_harm","title":"self_harm  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>self_harm: float = Field(alias='self-harm')\n</code></pre> <p>The score for the category 'self-harm'.</p>"},{"location":"reference/types/moderation/#src.openai.types.moderation.CategoryScores.self_harm_instructions","title":"self_harm_instructions  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>self_harm_instructions: float = Field(\n    alias=\"self-harm/instructions\"\n)\n</code></pre> <p>The score for the category 'self-harm/instructions'.</p>"},{"location":"reference/types/moderation/#src.openai.types.moderation.CategoryScores.self_harm_intent","title":"self_harm_intent  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>self_harm_intent: float = Field(alias='self-harm/intent')\n</code></pre> <p>The score for the category 'self-harm/intent'.</p>"},{"location":"reference/types/moderation/#src.openai.types.moderation.CategoryScores.sexual","title":"sexual  <code>instance-attribute</code>","text":"<pre><code>sexual: float\n</code></pre> <p>The score for the category 'sexual'.</p>"},{"location":"reference/types/moderation/#src.openai.types.moderation.CategoryScores.sexual_minors","title":"sexual_minors  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>sexual_minors: float = Field(alias='sexual/minors')\n</code></pre> <p>The score for the category 'sexual/minors'.</p>"},{"location":"reference/types/moderation/#src.openai.types.moderation.CategoryScores.violence","title":"violence  <code>instance-attribute</code>","text":"<pre><code>violence: float\n</code></pre> <p>The score for the category 'violence'.</p>"},{"location":"reference/types/moderation/#src.openai.types.moderation.CategoryScores.violence_graphic","title":"violence_graphic  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>violence_graphic: float = Field(alias='violence/graphic')\n</code></pre> <p>The score for the category 'violence/graphic'.</p>"},{"location":"reference/types/moderation/#src.openai.types.moderation.Moderation","title":"Moderation","text":"<p>Attributes:</p> Name Type Description <code>categories</code> <code>Categories</code> <p>A list of the categories, and whether they are flagged or not.</p> <code>category_scores</code> <code>CategoryScores</code> <p>A list of the categories along with their scores as predicted by model.</p> <code>flagged</code> <code>bool</code> <p>Whether any of the below categories are flagged.</p>"},{"location":"reference/types/moderation/#src.openai.types.moderation.Moderation.categories","title":"categories  <code>instance-attribute</code>","text":"<pre><code>categories: Categories\n</code></pre> <p>A list of the categories, and whether they are flagged or not.</p>"},{"location":"reference/types/moderation/#src.openai.types.moderation.Moderation.category_scores","title":"category_scores  <code>instance-attribute</code>","text":"<pre><code>category_scores: CategoryScores\n</code></pre> <p>A list of the categories along with their scores as predicted by model.</p>"},{"location":"reference/types/moderation/#src.openai.types.moderation.Moderation.flagged","title":"flagged  <code>instance-attribute</code>","text":"<pre><code>flagged: bool\n</code></pre> <p>Whether any of the below categories are flagged.</p>"},{"location":"reference/types/moderation_create_params/","title":"moderation_create_params","text":"<p>Classes:</p> Name Description <code>ModerationCreateParams</code>"},{"location":"reference/types/moderation_create_params/#src.openai.types.moderation_create_params.ModerationCreateParams","title":"ModerationCreateParams","text":"<p>Attributes:</p> Name Type Description <code>input</code> <code>Required[Union[str, List[str]]]</code> <p>The input text to classify</p> <code>model</code> <code>Union[str, Literal['text-moderation-latest', 'text-moderation-stable']]</code> <p>Two content moderations models are available: <code>text-moderation-stable</code> and</p>"},{"location":"reference/types/moderation_create_params/#src.openai.types.moderation_create_params.ModerationCreateParams.input","title":"input  <code>instance-attribute</code>","text":"<pre><code>input: Required[Union[str, List[str]]]\n</code></pre> <p>The input text to classify</p>"},{"location":"reference/types/moderation_create_params/#src.openai.types.moderation_create_params.ModerationCreateParams.model","title":"model  <code>instance-attribute</code>","text":"<pre><code>model: Union[\n    str,\n    Literal[\n        \"text-moderation-latest\", \"text-moderation-stable\"\n    ],\n]\n</code></pre> <p>Two content moderations models are available: <code>text-moderation-stable</code> and <code>text-moderation-latest</code>.</p> <p>The default is <code>text-moderation-latest</code> which will be automatically upgraded over time. This ensures you are always using our most accurate model. If you use <code>text-moderation-stable</code>, we will provide advanced notice before updating the model. Accuracy of <code>text-moderation-stable</code> may be slightly lower than for <code>text-moderation-latest</code>.</p>"},{"location":"reference/types/moderation_create_response/","title":"moderation_create_response","text":"<p>Classes:</p> Name Description <code>ModerationCreateResponse</code>"},{"location":"reference/types/moderation_create_response/#src.openai.types.moderation_create_response.ModerationCreateResponse","title":"ModerationCreateResponse","text":"<p>Attributes:</p> Name Type Description <code>id</code> <code>str</code> <p>The unique identifier for the moderation request.</p> <code>model</code> <code>str</code> <p>The model used to generate the moderation results.</p> <code>results</code> <code>List[Moderation]</code> <p>A list of moderation objects.</p>"},{"location":"reference/types/moderation_create_response/#src.openai.types.moderation_create_response.ModerationCreateResponse.id","title":"id  <code>instance-attribute</code>","text":"<pre><code>id: str\n</code></pre> <p>The unique identifier for the moderation request.</p>"},{"location":"reference/types/moderation_create_response/#src.openai.types.moderation_create_response.ModerationCreateResponse.model","title":"model  <code>instance-attribute</code>","text":"<pre><code>model: str\n</code></pre> <p>The model used to generate the moderation results.</p>"},{"location":"reference/types/moderation_create_response/#src.openai.types.moderation_create_response.ModerationCreateResponse.results","title":"results  <code>instance-attribute</code>","text":"<pre><code>results: List[Moderation]\n</code></pre> <p>A list of moderation objects.</p>"},{"location":"reference/types/audio/","title":"openai.types.audio","text":"<p>Modules:</p> Name Description <code>speech_create_params</code> <code>transcription</code> <code>transcription_create_params</code> <code>translation</code> <code>translation_create_params</code>"},{"location":"reference/types/audio/speech_create_params/","title":"speech_create_params","text":"<p>Classes:</p> Name Description <code>SpeechCreateParams</code>"},{"location":"reference/types/audio/speech_create_params/#src.openai.types.audio.speech_create_params.SpeechCreateParams","title":"SpeechCreateParams","text":"<p>Attributes:</p> Name Type Description <code>input</code> <code>Required[str]</code> <p>The text to generate audio for. The maximum length is 4096 characters.</p> <code>model</code> <code>Required[Union[str, Literal['tts-1', 'tts-1-hd']]]</code> <p>One of the available TTS models:</p> <code>response_format</code> <code>Literal['mp3', 'opus', 'aac', 'flac', 'wav', 'pcm']</code> <p>The format to audio in.</p> <code>speed</code> <code>float</code> <p>The speed of the generated audio.</p> <code>voice</code> <code>Required[Literal['alloy', 'echo', 'fable', 'onyx', 'nova', 'shimmer']]</code> <p>The voice to use when generating the audio.</p>"},{"location":"reference/types/audio/speech_create_params/#src.openai.types.audio.speech_create_params.SpeechCreateParams.input","title":"input  <code>instance-attribute</code>","text":"<pre><code>input: Required[str]\n</code></pre> <p>The text to generate audio for. The maximum length is 4096 characters.</p>"},{"location":"reference/types/audio/speech_create_params/#src.openai.types.audio.speech_create_params.SpeechCreateParams.model","title":"model  <code>instance-attribute</code>","text":"<pre><code>model: Required[Union[str, Literal['tts-1', 'tts-1-hd']]]\n</code></pre> <p>One of the available TTS models: <code>tts-1</code> or <code>tts-1-hd</code></p>"},{"location":"reference/types/audio/speech_create_params/#src.openai.types.audio.speech_create_params.SpeechCreateParams.response_format","title":"response_format  <code>instance-attribute</code>","text":"<pre><code>response_format: Literal[\n    \"mp3\", \"opus\", \"aac\", \"flac\", \"wav\", \"pcm\"\n]\n</code></pre> <p>The format to audio in.</p> <p>Supported formats are <code>mp3</code>, <code>opus</code>, <code>aac</code>, <code>flac</code>, <code>wav</code>, and <code>pcm</code>.</p>"},{"location":"reference/types/audio/speech_create_params/#src.openai.types.audio.speech_create_params.SpeechCreateParams.speed","title":"speed  <code>instance-attribute</code>","text":"<pre><code>speed: float\n</code></pre> <p>The speed of the generated audio.</p> <p>Select a value from <code>0.25</code> to <code>4.0</code>. <code>1.0</code> is the default.</p>"},{"location":"reference/types/audio/speech_create_params/#src.openai.types.audio.speech_create_params.SpeechCreateParams.voice","title":"voice  <code>instance-attribute</code>","text":"<pre><code>voice: Required[\n    Literal[\n        \"alloy\", \"echo\", \"fable\", \"onyx\", \"nova\", \"shimmer\"\n    ]\n]\n</code></pre> <p>The voice to use when generating the audio.</p> <p>Supported voices are <code>alloy</code>, <code>echo</code>, <code>fable</code>, <code>onyx</code>, <code>nova</code>, and <code>shimmer</code>. Previews of the voices are available in the Text to speech guide.</p>"},{"location":"reference/types/audio/transcription/","title":"transcription","text":"<p>Classes:</p> Name Description <code>Transcription</code>"},{"location":"reference/types/audio/transcription/#src.openai.types.audio.transcription.Transcription","title":"Transcription","text":"<p>Attributes:</p> Name Type Description <code>text</code> <code>str</code> <p>The transcribed text.</p>"},{"location":"reference/types/audio/transcription/#src.openai.types.audio.transcription.Transcription.text","title":"text  <code>instance-attribute</code>","text":"<pre><code>text: str\n</code></pre> <p>The transcribed text.</p>"},{"location":"reference/types/audio/transcription_create_params/","title":"transcription_create_params","text":"<p>Classes:</p> Name Description <code>TranscriptionCreateParams</code>"},{"location":"reference/types/audio/transcription_create_params/#src.openai.types.audio.transcription_create_params.TranscriptionCreateParams","title":"TranscriptionCreateParams","text":"<p>Attributes:</p> Name Type Description <code>file</code> <code>Required[FileTypes]</code> <p>The audio file object (not file name) to transcribe, in one of these formats:</p> <code>language</code> <code>str</code> <p>The language of the input audio.</p> <code>model</code> <code>Required[Union[str, Literal['whisper-1']]]</code> <p>ID of the model to use.</p> <code>prompt</code> <code>str</code> <p>An optional text to guide the model's style or continue a previous audio</p> <code>response_format</code> <code>Literal['json', 'text', 'srt', 'verbose_json', 'vtt']</code> <p>The format of the transcript output, in one of these options: <code>json</code>, <code>text</code>,</p> <code>temperature</code> <code>float</code> <p>The sampling temperature, between 0 and 1.</p> <code>timestamp_granularities</code> <code>List[Literal['word', 'segment']]</code> <p>The timestamp granularities to populate for this transcription.</p>"},{"location":"reference/types/audio/transcription_create_params/#src.openai.types.audio.transcription_create_params.TranscriptionCreateParams.file","title":"file  <code>instance-attribute</code>","text":"<pre><code>file: Required[FileTypes]\n</code></pre> <p>The audio file object (not file name) to transcribe, in one of these formats: flac, mp3, mp4, mpeg, mpga, m4a, ogg, wav, or webm.</p>"},{"location":"reference/types/audio/transcription_create_params/#src.openai.types.audio.transcription_create_params.TranscriptionCreateParams.language","title":"language  <code>instance-attribute</code>","text":"<pre><code>language: str\n</code></pre> <p>The language of the input audio.</p> <p>Supplying the input language in ISO-639-1 format will improve accuracy and latency.</p>"},{"location":"reference/types/audio/transcription_create_params/#src.openai.types.audio.transcription_create_params.TranscriptionCreateParams.model","title":"model  <code>instance-attribute</code>","text":"<pre><code>model: Required[Union[str, Literal['whisper-1']]]\n</code></pre> <p>ID of the model to use.</p> <p>Only <code>whisper-1</code> (which is powered by our open source Whisper V2 model) is currently available.</p>"},{"location":"reference/types/audio/transcription_create_params/#src.openai.types.audio.transcription_create_params.TranscriptionCreateParams.prompt","title":"prompt  <code>instance-attribute</code>","text":"<pre><code>prompt: str\n</code></pre> <p>An optional text to guide the model's style or continue a previous audio segment.</p> <p>The prompt should match the audio language.</p>"},{"location":"reference/types/audio/transcription_create_params/#src.openai.types.audio.transcription_create_params.TranscriptionCreateParams.response_format","title":"response_format  <code>instance-attribute</code>","text":"<pre><code>response_format: Literal[\n    \"json\", \"text\", \"srt\", \"verbose_json\", \"vtt\"\n]\n</code></pre> <p>The format of the transcript output, in one of these options: <code>json</code>, <code>text</code>, <code>srt</code>, <code>verbose_json</code>, or <code>vtt</code>.</p>"},{"location":"reference/types/audio/transcription_create_params/#src.openai.types.audio.transcription_create_params.TranscriptionCreateParams.temperature","title":"temperature  <code>instance-attribute</code>","text":"<pre><code>temperature: float\n</code></pre> <p>The sampling temperature, between 0 and 1.</p> <p>Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. If set to 0, the model will use log probability to automatically increase the temperature until certain thresholds are hit.</p>"},{"location":"reference/types/audio/transcription_create_params/#src.openai.types.audio.transcription_create_params.TranscriptionCreateParams.timestamp_granularities","title":"timestamp_granularities  <code>instance-attribute</code>","text":"<pre><code>timestamp_granularities: List[Literal['word', 'segment']]\n</code></pre> <p>The timestamp granularities to populate for this transcription.</p> <p><code>response_format</code> must be set <code>verbose_json</code> to use timestamp granularities. Either or both of these options are supported: <code>word</code>, or <code>segment</code>. Note: There is no additional latency for segment timestamps, but generating word timestamps incurs additional latency.</p>"},{"location":"reference/types/audio/translation/","title":"translation","text":"<p>Classes:</p> Name Description <code>Translation</code>"},{"location":"reference/types/audio/translation/#src.openai.types.audio.translation.Translation","title":"Translation","text":"<p>Attributes:</p> Name Type Description <code>text</code> <code>str</code>"},{"location":"reference/types/audio/translation/#src.openai.types.audio.translation.Translation.text","title":"text  <code>instance-attribute</code>","text":"<pre><code>text: str\n</code></pre>"},{"location":"reference/types/audio/translation_create_params/","title":"translation_create_params","text":"<p>Classes:</p> Name Description <code>TranslationCreateParams</code>"},{"location":"reference/types/audio/translation_create_params/#src.openai.types.audio.translation_create_params.TranslationCreateParams","title":"TranslationCreateParams","text":"<p>Attributes:</p> Name Type Description <code>file</code> <code>Required[FileTypes]</code> <p>The audio file object (not file name) translate, in one of these formats: flac,</p> <code>model</code> <code>Required[Union[str, Literal['whisper-1']]]</code> <p>ID of the model to use.</p> <code>prompt</code> <code>str</code> <p>An optional text to guide the model's style or continue a previous audio</p> <code>response_format</code> <code>str</code> <p>The format of the transcript output, in one of these options: <code>json</code>, <code>text</code>,</p> <code>temperature</code> <code>float</code> <p>The sampling temperature, between 0 and 1.</p>"},{"location":"reference/types/audio/translation_create_params/#src.openai.types.audio.translation_create_params.TranslationCreateParams.file","title":"file  <code>instance-attribute</code>","text":"<pre><code>file: Required[FileTypes]\n</code></pre> <p>The audio file object (not file name) translate, in one of these formats: flac, mp3, mp4, mpeg, mpga, m4a, ogg, wav, or webm.</p>"},{"location":"reference/types/audio/translation_create_params/#src.openai.types.audio.translation_create_params.TranslationCreateParams.model","title":"model  <code>instance-attribute</code>","text":"<pre><code>model: Required[Union[str, Literal['whisper-1']]]\n</code></pre> <p>ID of the model to use.</p> <p>Only <code>whisper-1</code> (which is powered by our open source Whisper V2 model) is currently available.</p>"},{"location":"reference/types/audio/translation_create_params/#src.openai.types.audio.translation_create_params.TranslationCreateParams.prompt","title":"prompt  <code>instance-attribute</code>","text":"<pre><code>prompt: str\n</code></pre> <p>An optional text to guide the model's style or continue a previous audio segment.</p> <p>The prompt should be in English.</p>"},{"location":"reference/types/audio/translation_create_params/#src.openai.types.audio.translation_create_params.TranslationCreateParams.response_format","title":"response_format  <code>instance-attribute</code>","text":"<pre><code>response_format: str\n</code></pre> <p>The format of the transcript output, in one of these options: <code>json</code>, <code>text</code>, <code>srt</code>, <code>verbose_json</code>, or <code>vtt</code>.</p>"},{"location":"reference/types/audio/translation_create_params/#src.openai.types.audio.translation_create_params.TranslationCreateParams.temperature","title":"temperature  <code>instance-attribute</code>","text":"<pre><code>temperature: float\n</code></pre> <p>The sampling temperature, between 0 and 1.</p> <p>Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. If set to 0, the model will use log probability to automatically increase the temperature until certain thresholds are hit.</p>"},{"location":"reference/types/beta/","title":"src.openai.types.beta","text":"<p>Modules:</p> Name Description <code>assistant</code> <code>assistant_create_params</code> <code>assistant_deleted</code> <code>assistant_list_params</code> <code>assistant_update_params</code> <code>assistants</code> <code>chat</code> <code>thread</code> <code>thread_create_and_run_params</code> <code>thread_create_params</code> <code>thread_deleted</code> <code>thread_update_params</code> <code>threads</code>"},{"location":"reference/types/beta/assistant/","title":"assistant","text":"<p>Classes:</p> Name Description <code>Assistant</code> <code>ToolCodeInterpreter</code> <code>ToolFunction</code> <code>ToolRetrieval</code> <p>Attributes:</p> Name Type Description <code>Tool</code>"},{"location":"reference/types/beta/assistant/#src.openai.types.beta.assistant.Tool","title":"Tool  <code>module-attribute</code>","text":"<pre><code>Tool = Union[\n    ToolCodeInterpreter, ToolRetrieval, ToolFunction\n]\n</code></pre>"},{"location":"reference/types/beta/assistant/#src.openai.types.beta.assistant.Assistant","title":"Assistant","text":"<p>Attributes:</p> Name Type Description <code>created_at</code> <code>int</code> <p>The Unix timestamp (in seconds) for when the assistant was created.</p> <code>description</code> <code>Optional[str]</code> <p>The description of the assistant. The maximum length is 512 characters.</p> <code>file_ids</code> <code>List[str]</code> <p>A list of file IDs</p> <code>id</code> <code>str</code> <p>The identifier, which can be referenced in API endpoints.</p> <code>instructions</code> <code>Optional[str]</code> <p>The system instructions that the assistant uses.</p> <code>metadata</code> <code>Optional[object]</code> <p>Set of 16 key-value pairs that can be attached to an object.</p> <code>model</code> <code>str</code> <p>ID of the model to use.</p> <code>name</code> <code>Optional[str]</code> <p>The name of the assistant. The maximum length is 256 characters.</p> <code>object</code> <code>Literal['assistant']</code> <p>The object type, which is always <code>assistant</code>.</p> <code>tools</code> <code>List[Tool]</code> <p>A list of tool enabled on the assistant.</p>"},{"location":"reference/types/beta/assistant/#src.openai.types.beta.assistant.Assistant.created_at","title":"created_at  <code>instance-attribute</code>","text":"<pre><code>created_at: int\n</code></pre> <p>The Unix timestamp (in seconds) for when the assistant was created.</p>"},{"location":"reference/types/beta/assistant/#src.openai.types.beta.assistant.Assistant.description","title":"description  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>description: Optional[str] = None\n</code></pre> <p>The description of the assistant. The maximum length is 512 characters.</p>"},{"location":"reference/types/beta/assistant/#src.openai.types.beta.assistant.Assistant.file_ids","title":"file_ids  <code>instance-attribute</code>","text":"<pre><code>file_ids: List[str]\n</code></pre> <p>A list of file IDs attached to this assistant. There can be a maximum of 20 files attached to the assistant. Files are ordered by their creation date in ascending order.</p>"},{"location":"reference/types/beta/assistant/#src.openai.types.beta.assistant.Assistant.id","title":"id  <code>instance-attribute</code>","text":"<pre><code>id: str\n</code></pre> <p>The identifier, which can be referenced in API endpoints.</p>"},{"location":"reference/types/beta/assistant/#src.openai.types.beta.assistant.Assistant.instructions","title":"instructions  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>instructions: Optional[str] = None\n</code></pre> <p>The system instructions that the assistant uses.</p> <p>The maximum length is 32768 characters.</p>"},{"location":"reference/types/beta/assistant/#src.openai.types.beta.assistant.Assistant.metadata","title":"metadata  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>metadata: Optional[object] = None\n</code></pre> <p>Set of 16 key-value pairs that can be attached to an object.</p> <p>This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.</p>"},{"location":"reference/types/beta/assistant/#src.openai.types.beta.assistant.Assistant.model","title":"model  <code>instance-attribute</code>","text":"<pre><code>model: str\n</code></pre> <p>ID of the model to use.</p> <p>You can use the List models API to see all of your available models, or see our Model overview for descriptions of them.</p>"},{"location":"reference/types/beta/assistant/#src.openai.types.beta.assistant.Assistant.name","title":"name  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>name: Optional[str] = None\n</code></pre> <p>The name of the assistant. The maximum length is 256 characters.</p>"},{"location":"reference/types/beta/assistant/#src.openai.types.beta.assistant.Assistant.object","title":"object  <code>instance-attribute</code>","text":"<pre><code>object: Literal['assistant']\n</code></pre> <p>The object type, which is always <code>assistant</code>.</p>"},{"location":"reference/types/beta/assistant/#src.openai.types.beta.assistant.Assistant.tools","title":"tools  <code>instance-attribute</code>","text":"<pre><code>tools: List[Tool]\n</code></pre> <p>A list of tool enabled on the assistant.</p> <p>There can be a maximum of 128 tools per assistant. Tools can be of types <code>code_interpreter</code>, <code>retrieval</code>, or <code>function</code>.</p>"},{"location":"reference/types/beta/assistant/#src.openai.types.beta.assistant.ToolCodeInterpreter","title":"ToolCodeInterpreter","text":"<p>Attributes:</p> Name Type Description <code>type</code> <code>Literal['code_interpreter']</code> <p>The type of tool being defined: <code>code_interpreter</code></p>"},{"location":"reference/types/beta/assistant/#src.openai.types.beta.assistant.ToolCodeInterpreter.type","title":"type  <code>instance-attribute</code>","text":"<pre><code>type: Literal['code_interpreter']\n</code></pre> <p>The type of tool being defined: <code>code_interpreter</code></p>"},{"location":"reference/types/beta/assistant/#src.openai.types.beta.assistant.ToolFunction","title":"ToolFunction","text":"<p>Attributes:</p> Name Type Description <code>function</code> <code>FunctionDefinition</code> <code>type</code> <code>Literal['function']</code> <p>The type of tool being defined: <code>function</code></p>"},{"location":"reference/types/beta/assistant/#src.openai.types.beta.assistant.ToolFunction.function","title":"function  <code>instance-attribute</code>","text":"<pre><code>function: FunctionDefinition\n</code></pre>"},{"location":"reference/types/beta/assistant/#src.openai.types.beta.assistant.ToolFunction.type","title":"type  <code>instance-attribute</code>","text":"<pre><code>type: Literal['function']\n</code></pre> <p>The type of tool being defined: <code>function</code></p>"},{"location":"reference/types/beta/assistant/#src.openai.types.beta.assistant.ToolRetrieval","title":"ToolRetrieval","text":"<p>Attributes:</p> Name Type Description <code>type</code> <code>Literal['retrieval']</code> <p>The type of tool being defined: <code>retrieval</code></p>"},{"location":"reference/types/beta/assistant/#src.openai.types.beta.assistant.ToolRetrieval.type","title":"type  <code>instance-attribute</code>","text":"<pre><code>type: Literal['retrieval']\n</code></pre> <p>The type of tool being defined: <code>retrieval</code></p>"},{"location":"reference/types/beta/assistant_create_params/","title":"assistant_create_params","text":"<p>Classes:</p> Name Description <code>AssistantCreateParams</code> <code>ToolAssistantToolsCode</code> <code>ToolAssistantToolsFunction</code> <code>ToolAssistantToolsRetrieval</code> <p>Attributes:</p> Name Type Description <code>Tool</code>"},{"location":"reference/types/beta/assistant_create_params/#src.openai.types.beta.assistant_create_params.Tool","title":"Tool  <code>module-attribute</code>","text":"<pre><code>Tool = Union[\n    ToolAssistantToolsCode,\n    ToolAssistantToolsRetrieval,\n    ToolAssistantToolsFunction,\n]\n</code></pre>"},{"location":"reference/types/beta/assistant_create_params/#src.openai.types.beta.assistant_create_params.AssistantCreateParams","title":"AssistantCreateParams","text":"<p>Attributes:</p> Name Type Description <code>description</code> <code>Optional[str]</code> <p>The description of the assistant. The maximum length is 512 characters.</p> <code>file_ids</code> <code>List[str]</code> <p>A list of file IDs</p> <code>instructions</code> <code>Optional[str]</code> <p>The system instructions that the assistant uses.</p> <code>metadata</code> <code>Optional[object]</code> <p>Set of 16 key-value pairs that can be attached to an object.</p> <code>model</code> <code>Required[str]</code> <p>ID of the model to use.</p> <code>name</code> <code>Optional[str]</code> <p>The name of the assistant. The maximum length is 256 characters.</p> <code>tools</code> <code>Iterable[Tool]</code> <p>A list of tool enabled on the assistant.</p>"},{"location":"reference/types/beta/assistant_create_params/#src.openai.types.beta.assistant_create_params.AssistantCreateParams.description","title":"description  <code>instance-attribute</code>","text":"<pre><code>description: Optional[str]\n</code></pre> <p>The description of the assistant. The maximum length is 512 characters.</p>"},{"location":"reference/types/beta/assistant_create_params/#src.openai.types.beta.assistant_create_params.AssistantCreateParams.file_ids","title":"file_ids  <code>instance-attribute</code>","text":"<pre><code>file_ids: List[str]\n</code></pre> <p>A list of file IDs attached to this assistant. There can be a maximum of 20 files attached to the assistant. Files are ordered by their creation date in ascending order.</p>"},{"location":"reference/types/beta/assistant_create_params/#src.openai.types.beta.assistant_create_params.AssistantCreateParams.instructions","title":"instructions  <code>instance-attribute</code>","text":"<pre><code>instructions: Optional[str]\n</code></pre> <p>The system instructions that the assistant uses.</p> <p>The maximum length is 32768 characters.</p>"},{"location":"reference/types/beta/assistant_create_params/#src.openai.types.beta.assistant_create_params.AssistantCreateParams.metadata","title":"metadata  <code>instance-attribute</code>","text":"<pre><code>metadata: Optional[object]\n</code></pre> <p>Set of 16 key-value pairs that can be attached to an object.</p> <p>This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.</p>"},{"location":"reference/types/beta/assistant_create_params/#src.openai.types.beta.assistant_create_params.AssistantCreateParams.model","title":"model  <code>instance-attribute</code>","text":"<pre><code>model: Required[str]\n</code></pre> <p>ID of the model to use.</p> <p>You can use the List models API to see all of your available models, or see our Model overview for descriptions of them.</p>"},{"location":"reference/types/beta/assistant_create_params/#src.openai.types.beta.assistant_create_params.AssistantCreateParams.name","title":"name  <code>instance-attribute</code>","text":"<pre><code>name: Optional[str]\n</code></pre> <p>The name of the assistant. The maximum length is 256 characters.</p>"},{"location":"reference/types/beta/assistant_create_params/#src.openai.types.beta.assistant_create_params.AssistantCreateParams.tools","title":"tools  <code>instance-attribute</code>","text":"<pre><code>tools: Iterable[Tool]\n</code></pre> <p>A list of tool enabled on the assistant.</p> <p>There can be a maximum of 128 tools per assistant. Tools can be of types <code>code_interpreter</code>, <code>retrieval</code>, or <code>function</code>.</p>"},{"location":"reference/types/beta/assistant_create_params/#src.openai.types.beta.assistant_create_params.ToolAssistantToolsCode","title":"ToolAssistantToolsCode","text":"<p>Attributes:</p> Name Type Description <code>type</code> <code>Required[Literal['code_interpreter']]</code> <p>The type of tool being defined: <code>code_interpreter</code></p>"},{"location":"reference/types/beta/assistant_create_params/#src.openai.types.beta.assistant_create_params.ToolAssistantToolsCode.type","title":"type  <code>instance-attribute</code>","text":"<pre><code>type: Required[Literal['code_interpreter']]\n</code></pre> <p>The type of tool being defined: <code>code_interpreter</code></p>"},{"location":"reference/types/beta/assistant_create_params/#src.openai.types.beta.assistant_create_params.ToolAssistantToolsFunction","title":"ToolAssistantToolsFunction","text":"<p>Attributes:</p> Name Type Description <code>function</code> <code>Required[FunctionDefinition]</code> <code>type</code> <code>Required[Literal['function']]</code> <p>The type of tool being defined: <code>function</code></p>"},{"location":"reference/types/beta/assistant_create_params/#src.openai.types.beta.assistant_create_params.ToolAssistantToolsFunction.function","title":"function  <code>instance-attribute</code>","text":"<pre><code>function: Required[FunctionDefinition]\n</code></pre>"},{"location":"reference/types/beta/assistant_create_params/#src.openai.types.beta.assistant_create_params.ToolAssistantToolsFunction.type","title":"type  <code>instance-attribute</code>","text":"<pre><code>type: Required[Literal['function']]\n</code></pre> <p>The type of tool being defined: <code>function</code></p>"},{"location":"reference/types/beta/assistant_create_params/#src.openai.types.beta.assistant_create_params.ToolAssistantToolsRetrieval","title":"ToolAssistantToolsRetrieval","text":"<p>Attributes:</p> Name Type Description <code>type</code> <code>Required[Literal['retrieval']]</code> <p>The type of tool being defined: <code>retrieval</code></p>"},{"location":"reference/types/beta/assistant_create_params/#src.openai.types.beta.assistant_create_params.ToolAssistantToolsRetrieval.type","title":"type  <code>instance-attribute</code>","text":"<pre><code>type: Required[Literal['retrieval']]\n</code></pre> <p>The type of tool being defined: <code>retrieval</code></p>"},{"location":"reference/types/beta/assistant_deleted/","title":"assistant_deleted","text":"<p>Classes:</p> Name Description <code>AssistantDeleted</code>"},{"location":"reference/types/beta/assistant_deleted/#src.openai.types.beta.assistant_deleted.AssistantDeleted","title":"AssistantDeleted","text":"<p>Attributes:</p> Name Type Description <code>deleted</code> <code>bool</code> <code>id</code> <code>str</code> <code>object</code> <code>Literal['assistant.deleted']</code>"},{"location":"reference/types/beta/assistant_deleted/#src.openai.types.beta.assistant_deleted.AssistantDeleted.deleted","title":"deleted  <code>instance-attribute</code>","text":"<pre><code>deleted: bool\n</code></pre>"},{"location":"reference/types/beta/assistant_deleted/#src.openai.types.beta.assistant_deleted.AssistantDeleted.id","title":"id  <code>instance-attribute</code>","text":"<pre><code>id: str\n</code></pre>"},{"location":"reference/types/beta/assistant_deleted/#src.openai.types.beta.assistant_deleted.AssistantDeleted.object","title":"object  <code>instance-attribute</code>","text":"<pre><code>object: Literal['assistant.deleted']\n</code></pre>"},{"location":"reference/types/beta/assistant_list_params/","title":"assistant_list_params","text":"<p>Classes:</p> Name Description <code>AssistantListParams</code>"},{"location":"reference/types/beta/assistant_list_params/#src.openai.types.beta.assistant_list_params.AssistantListParams","title":"AssistantListParams","text":"<p>Attributes:</p> Name Type Description <code>after</code> <code>str</code> <p>A cursor for use in pagination.</p> <code>before</code> <code>str</code> <p>A cursor for use in pagination.</p> <code>limit</code> <code>int</code> <p>A limit on the number of objects to be returned.</p> <code>order</code> <code>Literal['asc', 'desc']</code> <p>Sort order by the <code>created_at</code> timestamp of the objects.</p>"},{"location":"reference/types/beta/assistant_list_params/#src.openai.types.beta.assistant_list_params.AssistantListParams.after","title":"after  <code>instance-attribute</code>","text":"<pre><code>after: str\n</code></pre> <p>A cursor for use in pagination.</p> <p><code>after</code> is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.</p>"},{"location":"reference/types/beta/assistant_list_params/#src.openai.types.beta.assistant_list_params.AssistantListParams.before","title":"before  <code>instance-attribute</code>","text":"<pre><code>before: str\n</code></pre> <p>A cursor for use in pagination.</p> <p><code>before</code> is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include before=obj_foo in order to fetch the previous page of the list.</p>"},{"location":"reference/types/beta/assistant_list_params/#src.openai.types.beta.assistant_list_params.AssistantListParams.limit","title":"limit  <code>instance-attribute</code>","text":"<pre><code>limit: int\n</code></pre> <p>A limit on the number of objects to be returned.</p> <p>Limit can range between 1 and 100, and the default is 20.</p>"},{"location":"reference/types/beta/assistant_list_params/#src.openai.types.beta.assistant_list_params.AssistantListParams.order","title":"order  <code>instance-attribute</code>","text":"<pre><code>order: Literal['asc', 'desc']\n</code></pre> <p>Sort order by the <code>created_at</code> timestamp of the objects.</p> <p><code>asc</code> for ascending order and <code>desc</code> for descending order.</p>"},{"location":"reference/types/beta/assistant_update_params/","title":"assistant_update_params","text":"<p>Classes:</p> Name Description <code>AssistantUpdateParams</code> <code>ToolAssistantToolsCode</code> <code>ToolAssistantToolsFunction</code> <code>ToolAssistantToolsRetrieval</code> <p>Attributes:</p> Name Type Description <code>Tool</code>"},{"location":"reference/types/beta/assistant_update_params/#src.openai.types.beta.assistant_update_params.Tool","title":"Tool  <code>module-attribute</code>","text":"<pre><code>Tool = Union[\n    ToolAssistantToolsCode,\n    ToolAssistantToolsRetrieval,\n    ToolAssistantToolsFunction,\n]\n</code></pre>"},{"location":"reference/types/beta/assistant_update_params/#src.openai.types.beta.assistant_update_params.AssistantUpdateParams","title":"AssistantUpdateParams","text":"<p>Attributes:</p> Name Type Description <code>description</code> <code>Optional[str]</code> <p>The description of the assistant. The maximum length is 512 characters.</p> <code>file_ids</code> <code>List[str]</code> <p>A list of File IDs</p> <code>instructions</code> <code>Optional[str]</code> <p>The system instructions that the assistant uses.</p> <code>metadata</code> <code>Optional[object]</code> <p>Set of 16 key-value pairs that can be attached to an object.</p> <code>model</code> <code>str</code> <p>ID of the model to use.</p> <code>name</code> <code>Optional[str]</code> <p>The name of the assistant. The maximum length is 256 characters.</p> <code>tools</code> <code>Iterable[Tool]</code> <p>A list of tool enabled on the assistant.</p>"},{"location":"reference/types/beta/assistant_update_params/#src.openai.types.beta.assistant_update_params.AssistantUpdateParams.description","title":"description  <code>instance-attribute</code>","text":"<pre><code>description: Optional[str]\n</code></pre> <p>The description of the assistant. The maximum length is 512 characters.</p>"},{"location":"reference/types/beta/assistant_update_params/#src.openai.types.beta.assistant_update_params.AssistantUpdateParams.file_ids","title":"file_ids  <code>instance-attribute</code>","text":"<pre><code>file_ids: List[str]\n</code></pre> <p>A list of File IDs attached to this assistant. There can be a maximum of 20 files attached to the assistant. Files are ordered by their creation date in ascending order. If a file was previously attached to the list but does not show up in the list, it will be deleted from the assistant.</p>"},{"location":"reference/types/beta/assistant_update_params/#src.openai.types.beta.assistant_update_params.AssistantUpdateParams.instructions","title":"instructions  <code>instance-attribute</code>","text":"<pre><code>instructions: Optional[str]\n</code></pre> <p>The system instructions that the assistant uses.</p> <p>The maximum length is 32768 characters.</p>"},{"location":"reference/types/beta/assistant_update_params/#src.openai.types.beta.assistant_update_params.AssistantUpdateParams.metadata","title":"metadata  <code>instance-attribute</code>","text":"<pre><code>metadata: Optional[object]\n</code></pre> <p>Set of 16 key-value pairs that can be attached to an object.</p> <p>This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.</p>"},{"location":"reference/types/beta/assistant_update_params/#src.openai.types.beta.assistant_update_params.AssistantUpdateParams.model","title":"model  <code>instance-attribute</code>","text":"<pre><code>model: str\n</code></pre> <p>ID of the model to use.</p> <p>You can use the List models API to see all of your available models, or see our Model overview for descriptions of them.</p>"},{"location":"reference/types/beta/assistant_update_params/#src.openai.types.beta.assistant_update_params.AssistantUpdateParams.name","title":"name  <code>instance-attribute</code>","text":"<pre><code>name: Optional[str]\n</code></pre> <p>The name of the assistant. The maximum length is 256 characters.</p>"},{"location":"reference/types/beta/assistant_update_params/#src.openai.types.beta.assistant_update_params.AssistantUpdateParams.tools","title":"tools  <code>instance-attribute</code>","text":"<pre><code>tools: Iterable[Tool]\n</code></pre> <p>A list of tool enabled on the assistant.</p> <p>There can be a maximum of 128 tools per assistant. Tools can be of types <code>code_interpreter</code>, <code>retrieval</code>, or <code>function</code>.</p>"},{"location":"reference/types/beta/assistant_update_params/#src.openai.types.beta.assistant_update_params.ToolAssistantToolsCode","title":"ToolAssistantToolsCode","text":"<p>Attributes:</p> Name Type Description <code>type</code> <code>Required[Literal['code_interpreter']]</code> <p>The type of tool being defined: <code>code_interpreter</code></p>"},{"location":"reference/types/beta/assistant_update_params/#src.openai.types.beta.assistant_update_params.ToolAssistantToolsCode.type","title":"type  <code>instance-attribute</code>","text":"<pre><code>type: Required[Literal['code_interpreter']]\n</code></pre> <p>The type of tool being defined: <code>code_interpreter</code></p>"},{"location":"reference/types/beta/assistant_update_params/#src.openai.types.beta.assistant_update_params.ToolAssistantToolsFunction","title":"ToolAssistantToolsFunction","text":"<p>Attributes:</p> Name Type Description <code>function</code> <code>Required[FunctionDefinition]</code> <code>type</code> <code>Required[Literal['function']]</code> <p>The type of tool being defined: <code>function</code></p>"},{"location":"reference/types/beta/assistant_update_params/#src.openai.types.beta.assistant_update_params.ToolAssistantToolsFunction.function","title":"function  <code>instance-attribute</code>","text":"<pre><code>function: Required[FunctionDefinition]\n</code></pre>"},{"location":"reference/types/beta/assistant_update_params/#src.openai.types.beta.assistant_update_params.ToolAssistantToolsFunction.type","title":"type  <code>instance-attribute</code>","text":"<pre><code>type: Required[Literal['function']]\n</code></pre> <p>The type of tool being defined: <code>function</code></p>"},{"location":"reference/types/beta/assistant_update_params/#src.openai.types.beta.assistant_update_params.ToolAssistantToolsRetrieval","title":"ToolAssistantToolsRetrieval","text":"<p>Attributes:</p> Name Type Description <code>type</code> <code>Required[Literal['retrieval']]</code> <p>The type of tool being defined: <code>retrieval</code></p>"},{"location":"reference/types/beta/assistant_update_params/#src.openai.types.beta.assistant_update_params.ToolAssistantToolsRetrieval.type","title":"type  <code>instance-attribute</code>","text":"<pre><code>type: Required[Literal['retrieval']]\n</code></pre> <p>The type of tool being defined: <code>retrieval</code></p>"},{"location":"reference/types/beta/thread/","title":"thread","text":"<p>Classes:</p> Name Description <code>Thread</code>"},{"location":"reference/types/beta/thread/#src.openai.types.beta.thread.Thread","title":"Thread","text":"<p>Attributes:</p> Name Type Description <code>created_at</code> <code>int</code> <p>The Unix timestamp (in seconds) for when the thread was created.</p> <code>id</code> <code>str</code> <p>The identifier, which can be referenced in API endpoints.</p> <code>metadata</code> <code>Optional[object]</code> <p>Set of 16 key-value pairs that can be attached to an object.</p> <code>object</code> <code>Literal['thread']</code> <p>The object type, which is always <code>thread</code>.</p>"},{"location":"reference/types/beta/thread/#src.openai.types.beta.thread.Thread.created_at","title":"created_at  <code>instance-attribute</code>","text":"<pre><code>created_at: int\n</code></pre> <p>The Unix timestamp (in seconds) for when the thread was created.</p>"},{"location":"reference/types/beta/thread/#src.openai.types.beta.thread.Thread.id","title":"id  <code>instance-attribute</code>","text":"<pre><code>id: str\n</code></pre> <p>The identifier, which can be referenced in API endpoints.</p>"},{"location":"reference/types/beta/thread/#src.openai.types.beta.thread.Thread.metadata","title":"metadata  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>metadata: Optional[object] = None\n</code></pre> <p>Set of 16 key-value pairs that can be attached to an object.</p> <p>This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.</p>"},{"location":"reference/types/beta/thread/#src.openai.types.beta.thread.Thread.object","title":"object  <code>instance-attribute</code>","text":"<pre><code>object: Literal['thread']\n</code></pre> <p>The object type, which is always <code>thread</code>.</p>"},{"location":"reference/types/beta/thread_create_and_run_params/","title":"thread_create_and_run_params","text":"<p>Classes:</p> Name Description <code>Thread</code> <code>ThreadCreateAndRunParams</code> <code>ThreadMessage</code> <code>ToolAssistantToolsCode</code> <code>ToolAssistantToolsFunction</code> <code>ToolAssistantToolsRetrieval</code> <p>Attributes:</p> Name Type Description <code>Tool</code>"},{"location":"reference/types/beta/thread_create_and_run_params/#src.openai.types.beta.thread_create_and_run_params.Tool","title":"Tool  <code>module-attribute</code>","text":"<pre><code>Tool = Union[\n    ToolAssistantToolsCode,\n    ToolAssistantToolsRetrieval,\n    ToolAssistantToolsFunction,\n]\n</code></pre>"},{"location":"reference/types/beta/thread_create_and_run_params/#src.openai.types.beta.thread_create_and_run_params.Thread","title":"Thread","text":"<p>Attributes:</p> Name Type Description <code>messages</code> <code>Iterable[ThreadMessage]</code> <p>A list of messages to</p> <code>metadata</code> <code>Optional[object]</code> <p>Set of 16 key-value pairs that can be attached to an object.</p>"},{"location":"reference/types/beta/thread_create_and_run_params/#src.openai.types.beta.thread_create_and_run_params.Thread.messages","title":"messages  <code>instance-attribute</code>","text":"<pre><code>messages: Iterable[ThreadMessage]\n</code></pre> <p>A list of messages to start the thread with.</p>"},{"location":"reference/types/beta/thread_create_and_run_params/#src.openai.types.beta.thread_create_and_run_params.Thread.metadata","title":"metadata  <code>instance-attribute</code>","text":"<pre><code>metadata: Optional[object]\n</code></pre> <p>Set of 16 key-value pairs that can be attached to an object.</p> <p>This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.</p>"},{"location":"reference/types/beta/thread_create_and_run_params/#src.openai.types.beta.thread_create_and_run_params.ThreadCreateAndRunParams","title":"ThreadCreateAndRunParams","text":"<p>Attributes:</p> Name Type Description <code>assistant_id</code> <code>Required[str]</code> <p>The ID of the</p> <code>instructions</code> <code>Optional[str]</code> <p>Override the default system message of the assistant.</p> <code>metadata</code> <code>Optional[object]</code> <p>Set of 16 key-value pairs that can be attached to an object.</p> <code>model</code> <code>Optional[str]</code> <p>The ID of the Model to</p> <code>thread</code> <code>Thread</code> <p>If no thread is provided, an empty thread will be created.</p> <code>tools</code> <code>Optional[Iterable[Tool]]</code> <p>Override the tools the assistant can use for this run.</p>"},{"location":"reference/types/beta/thread_create_and_run_params/#src.openai.types.beta.thread_create_and_run_params.ThreadCreateAndRunParams.assistant_id","title":"assistant_id  <code>instance-attribute</code>","text":"<pre><code>assistant_id: Required[str]\n</code></pre> <p>The ID of the assistant to use to execute this run.</p>"},{"location":"reference/types/beta/thread_create_and_run_params/#src.openai.types.beta.thread_create_and_run_params.ThreadCreateAndRunParams.instructions","title":"instructions  <code>instance-attribute</code>","text":"<pre><code>instructions: Optional[str]\n</code></pre> <p>Override the default system message of the assistant.</p> <p>This is useful for modifying the behavior on a per-run basis.</p>"},{"location":"reference/types/beta/thread_create_and_run_params/#src.openai.types.beta.thread_create_and_run_params.ThreadCreateAndRunParams.metadata","title":"metadata  <code>instance-attribute</code>","text":"<pre><code>metadata: Optional[object]\n</code></pre> <p>Set of 16 key-value pairs that can be attached to an object.</p> <p>This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.</p>"},{"location":"reference/types/beta/thread_create_and_run_params/#src.openai.types.beta.thread_create_and_run_params.ThreadCreateAndRunParams.model","title":"model  <code>instance-attribute</code>","text":"<pre><code>model: Optional[str]\n</code></pre> <p>The ID of the Model to be used to execute this run. If a value is provided here, it will override the model associated with the assistant. If not, the model associated with the assistant will be used.</p>"},{"location":"reference/types/beta/thread_create_and_run_params/#src.openai.types.beta.thread_create_and_run_params.ThreadCreateAndRunParams.thread","title":"thread  <code>instance-attribute</code>","text":"<pre><code>thread: Thread\n</code></pre> <p>If no thread is provided, an empty thread will be created.</p>"},{"location":"reference/types/beta/thread_create_and_run_params/#src.openai.types.beta.thread_create_and_run_params.ThreadCreateAndRunParams.tools","title":"tools  <code>instance-attribute</code>","text":"<pre><code>tools: Optional[Iterable[Tool]]\n</code></pre> <p>Override the tools the assistant can use for this run.</p> <p>This is useful for modifying the behavior on a per-run basis.</p>"},{"location":"reference/types/beta/thread_create_and_run_params/#src.openai.types.beta.thread_create_and_run_params.ThreadMessage","title":"ThreadMessage","text":"<p>Attributes:</p> Name Type Description <code>content</code> <code>Required[str]</code> <p>The content of the message.</p> <code>file_ids</code> <code>List[str]</code> <p>A list of File IDs that</p> <code>metadata</code> <code>Optional[object]</code> <p>Set of 16 key-value pairs that can be attached to an object.</p> <code>role</code> <code>Required[Literal['user']]</code> <p>The role of the entity that is creating the message.</p>"},{"location":"reference/types/beta/thread_create_and_run_params/#src.openai.types.beta.thread_create_and_run_params.ThreadMessage.content","title":"content  <code>instance-attribute</code>","text":"<pre><code>content: Required[str]\n</code></pre> <p>The content of the message.</p>"},{"location":"reference/types/beta/thread_create_and_run_params/#src.openai.types.beta.thread_create_and_run_params.ThreadMessage.file_ids","title":"file_ids  <code>instance-attribute</code>","text":"<pre><code>file_ids: List[str]\n</code></pre> <p>A list of File IDs that the message should use. There can be a maximum of 10 files attached to a message. Useful for tools like <code>retrieval</code> and <code>code_interpreter</code> that can access and use files.</p>"},{"location":"reference/types/beta/thread_create_and_run_params/#src.openai.types.beta.thread_create_and_run_params.ThreadMessage.metadata","title":"metadata  <code>instance-attribute</code>","text":"<pre><code>metadata: Optional[object]\n</code></pre> <p>Set of 16 key-value pairs that can be attached to an object.</p> <p>This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.</p>"},{"location":"reference/types/beta/thread_create_and_run_params/#src.openai.types.beta.thread_create_and_run_params.ThreadMessage.role","title":"role  <code>instance-attribute</code>","text":"<pre><code>role: Required[Literal['user']]\n</code></pre> <p>The role of the entity that is creating the message.</p> <p>Currently only <code>user</code> is supported.</p>"},{"location":"reference/types/beta/thread_create_and_run_params/#src.openai.types.beta.thread_create_and_run_params.ToolAssistantToolsCode","title":"ToolAssistantToolsCode","text":"<p>Attributes:</p> Name Type Description <code>type</code> <code>Required[Literal['code_interpreter']]</code> <p>The type of tool being defined: <code>code_interpreter</code></p>"},{"location":"reference/types/beta/thread_create_and_run_params/#src.openai.types.beta.thread_create_and_run_params.ToolAssistantToolsCode.type","title":"type  <code>instance-attribute</code>","text":"<pre><code>type: Required[Literal['code_interpreter']]\n</code></pre> <p>The type of tool being defined: <code>code_interpreter</code></p>"},{"location":"reference/types/beta/thread_create_and_run_params/#src.openai.types.beta.thread_create_and_run_params.ToolAssistantToolsFunction","title":"ToolAssistantToolsFunction","text":"<p>Attributes:</p> Name Type Description <code>function</code> <code>Required[FunctionDefinition]</code> <code>type</code> <code>Required[Literal['function']]</code> <p>The type of tool being defined: <code>function</code></p>"},{"location":"reference/types/beta/thread_create_and_run_params/#src.openai.types.beta.thread_create_and_run_params.ToolAssistantToolsFunction.function","title":"function  <code>instance-attribute</code>","text":"<pre><code>function: Required[FunctionDefinition]\n</code></pre>"},{"location":"reference/types/beta/thread_create_and_run_params/#src.openai.types.beta.thread_create_and_run_params.ToolAssistantToolsFunction.type","title":"type  <code>instance-attribute</code>","text":"<pre><code>type: Required[Literal['function']]\n</code></pre> <p>The type of tool being defined: <code>function</code></p>"},{"location":"reference/types/beta/thread_create_and_run_params/#src.openai.types.beta.thread_create_and_run_params.ToolAssistantToolsRetrieval","title":"ToolAssistantToolsRetrieval","text":"<p>Attributes:</p> Name Type Description <code>type</code> <code>Required[Literal['retrieval']]</code> <p>The type of tool being defined: <code>retrieval</code></p>"},{"location":"reference/types/beta/thread_create_and_run_params/#src.openai.types.beta.thread_create_and_run_params.ToolAssistantToolsRetrieval.type","title":"type  <code>instance-attribute</code>","text":"<pre><code>type: Required[Literal['retrieval']]\n</code></pre> <p>The type of tool being defined: <code>retrieval</code></p>"},{"location":"reference/types/beta/thread_create_params/","title":"thread_create_params","text":"<p>Classes:</p> Name Description <code>Message</code> <code>ThreadCreateParams</code>"},{"location":"reference/types/beta/thread_create_params/#src.openai.types.beta.thread_create_params.Message","title":"Message","text":"<p>Attributes:</p> Name Type Description <code>content</code> <code>Required[str]</code> <p>The content of the message.</p> <code>file_ids</code> <code>List[str]</code> <p>A list of File IDs that</p> <code>metadata</code> <code>Optional[object]</code> <p>Set of 16 key-value pairs that can be attached to an object.</p> <code>role</code> <code>Required[Literal['user']]</code> <p>The role of the entity that is creating the message.</p>"},{"location":"reference/types/beta/thread_create_params/#src.openai.types.beta.thread_create_params.Message.content","title":"content  <code>instance-attribute</code>","text":"<pre><code>content: Required[str]\n</code></pre> <p>The content of the message.</p>"},{"location":"reference/types/beta/thread_create_params/#src.openai.types.beta.thread_create_params.Message.file_ids","title":"file_ids  <code>instance-attribute</code>","text":"<pre><code>file_ids: List[str]\n</code></pre> <p>A list of File IDs that the message should use. There can be a maximum of 10 files attached to a message. Useful for tools like <code>retrieval</code> and <code>code_interpreter</code> that can access and use files.</p>"},{"location":"reference/types/beta/thread_create_params/#src.openai.types.beta.thread_create_params.Message.metadata","title":"metadata  <code>instance-attribute</code>","text":"<pre><code>metadata: Optional[object]\n</code></pre> <p>Set of 16 key-value pairs that can be attached to an object.</p> <p>This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.</p>"},{"location":"reference/types/beta/thread_create_params/#src.openai.types.beta.thread_create_params.Message.role","title":"role  <code>instance-attribute</code>","text":"<pre><code>role: Required[Literal['user']]\n</code></pre> <p>The role of the entity that is creating the message.</p> <p>Currently only <code>user</code> is supported.</p>"},{"location":"reference/types/beta/thread_create_params/#src.openai.types.beta.thread_create_params.ThreadCreateParams","title":"ThreadCreateParams","text":"<p>Attributes:</p> Name Type Description <code>messages</code> <code>Iterable[Message]</code> <p>A list of messages to</p> <code>metadata</code> <code>Optional[object]</code> <p>Set of 16 key-value pairs that can be attached to an object.</p>"},{"location":"reference/types/beta/thread_create_params/#src.openai.types.beta.thread_create_params.ThreadCreateParams.messages","title":"messages  <code>instance-attribute</code>","text":"<pre><code>messages: Iterable[Message]\n</code></pre> <p>A list of messages to start the thread with.</p>"},{"location":"reference/types/beta/thread_create_params/#src.openai.types.beta.thread_create_params.ThreadCreateParams.metadata","title":"metadata  <code>instance-attribute</code>","text":"<pre><code>metadata: Optional[object]\n</code></pre> <p>Set of 16 key-value pairs that can be attached to an object.</p> <p>This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.</p>"},{"location":"reference/types/beta/thread_deleted/","title":"thread_deleted","text":"<p>Classes:</p> Name Description <code>ThreadDeleted</code>"},{"location":"reference/types/beta/thread_deleted/#src.openai.types.beta.thread_deleted.ThreadDeleted","title":"ThreadDeleted","text":"<p>Attributes:</p> Name Type Description <code>deleted</code> <code>bool</code> <code>id</code> <code>str</code> <code>object</code> <code>Literal['thread.deleted']</code>"},{"location":"reference/types/beta/thread_deleted/#src.openai.types.beta.thread_deleted.ThreadDeleted.deleted","title":"deleted  <code>instance-attribute</code>","text":"<pre><code>deleted: bool\n</code></pre>"},{"location":"reference/types/beta/thread_deleted/#src.openai.types.beta.thread_deleted.ThreadDeleted.id","title":"id  <code>instance-attribute</code>","text":"<pre><code>id: str\n</code></pre>"},{"location":"reference/types/beta/thread_deleted/#src.openai.types.beta.thread_deleted.ThreadDeleted.object","title":"object  <code>instance-attribute</code>","text":"<pre><code>object: Literal['thread.deleted']\n</code></pre>"},{"location":"reference/types/beta/thread_update_params/","title":"thread_update_params","text":"<p>Classes:</p> Name Description <code>ThreadUpdateParams</code>"},{"location":"reference/types/beta/thread_update_params/#src.openai.types.beta.thread_update_params.ThreadUpdateParams","title":"ThreadUpdateParams","text":"<p>Attributes:</p> Name Type Description <code>metadata</code> <code>Optional[object]</code> <p>Set of 16 key-value pairs that can be attached to an object.</p>"},{"location":"reference/types/beta/thread_update_params/#src.openai.types.beta.thread_update_params.ThreadUpdateParams.metadata","title":"metadata  <code>instance-attribute</code>","text":"<pre><code>metadata: Optional[object]\n</code></pre> <p>Set of 16 key-value pairs that can be attached to an object.</p> <p>This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.</p>"},{"location":"reference/types/beta/assistants/","title":"Index","text":"<p>Modules:</p> Name Description <code>assistant_file</code> <code>file_create_params</code> <code>file_delete_response</code> <code>file_list_params</code>"},{"location":"reference/types/beta/assistants/assistant_file/","title":"assistant_file","text":"<p>Classes:</p> Name Description <code>AssistantFile</code>"},{"location":"reference/types/beta/assistants/assistant_file/#src.openai.types.beta.assistants.assistant_file.AssistantFile","title":"AssistantFile","text":"<p>Attributes:</p> Name Type Description <code>assistant_id</code> <code>str</code> <p>The assistant ID that the file is attached to.</p> <code>created_at</code> <code>int</code> <p>The Unix timestamp (in seconds) for when the assistant file was created.</p> <code>id</code> <code>str</code> <p>The identifier, which can be referenced in API endpoints.</p> <code>object</code> <code>Literal['assistant.file']</code> <p>The object type, which is always <code>assistant.file</code>.</p>"},{"location":"reference/types/beta/assistants/assistant_file/#src.openai.types.beta.assistants.assistant_file.AssistantFile.assistant_id","title":"assistant_id  <code>instance-attribute</code>","text":"<pre><code>assistant_id: str\n</code></pre> <p>The assistant ID that the file is attached to.</p>"},{"location":"reference/types/beta/assistants/assistant_file/#src.openai.types.beta.assistants.assistant_file.AssistantFile.created_at","title":"created_at  <code>instance-attribute</code>","text":"<pre><code>created_at: int\n</code></pre> <p>The Unix timestamp (in seconds) for when the assistant file was created.</p>"},{"location":"reference/types/beta/assistants/assistant_file/#src.openai.types.beta.assistants.assistant_file.AssistantFile.id","title":"id  <code>instance-attribute</code>","text":"<pre><code>id: str\n</code></pre> <p>The identifier, which can be referenced in API endpoints.</p>"},{"location":"reference/types/beta/assistants/assistant_file/#src.openai.types.beta.assistants.assistant_file.AssistantFile.object","title":"object  <code>instance-attribute</code>","text":"<pre><code>object: Literal['assistant.file']\n</code></pre> <p>The object type, which is always <code>assistant.file</code>.</p>"},{"location":"reference/types/beta/assistants/file_create_params/","title":"file_create_params","text":"<p>Classes:</p> Name Description <code>FileCreateParams</code>"},{"location":"reference/types/beta/assistants/file_create_params/#src.openai.types.beta.assistants.file_create_params.FileCreateParams","title":"FileCreateParams","text":"<p>Attributes:</p> Name Type Description <code>file_id</code> <code>Required[str]</code> <p>A File ID (with</p>"},{"location":"reference/types/beta/assistants/file_create_params/#src.openai.types.beta.assistants.file_create_params.FileCreateParams.file_id","title":"file_id  <code>instance-attribute</code>","text":"<pre><code>file_id: Required[str]\n</code></pre> <p>A File ID (with <code>purpose=\"assistants\"</code>) that the assistant should use. Useful for tools like <code>retrieval</code> and <code>code_interpreter</code> that can access files.</p>"},{"location":"reference/types/beta/assistants/file_delete_response/","title":"file_delete_response","text":"<p>Classes:</p> Name Description <code>FileDeleteResponse</code>"},{"location":"reference/types/beta/assistants/file_delete_response/#src.openai.types.beta.assistants.file_delete_response.FileDeleteResponse","title":"FileDeleteResponse","text":"<p>Attributes:</p> Name Type Description <code>deleted</code> <code>bool</code> <code>id</code> <code>str</code> <code>object</code> <code>Literal['assistant.file.deleted']</code>"},{"location":"reference/types/beta/assistants/file_delete_response/#src.openai.types.beta.assistants.file_delete_response.FileDeleteResponse.deleted","title":"deleted  <code>instance-attribute</code>","text":"<pre><code>deleted: bool\n</code></pre>"},{"location":"reference/types/beta/assistants/file_delete_response/#src.openai.types.beta.assistants.file_delete_response.FileDeleteResponse.id","title":"id  <code>instance-attribute</code>","text":"<pre><code>id: str\n</code></pre>"},{"location":"reference/types/beta/assistants/file_delete_response/#src.openai.types.beta.assistants.file_delete_response.FileDeleteResponse.object","title":"object  <code>instance-attribute</code>","text":"<pre><code>object: Literal['assistant.file.deleted']\n</code></pre>"},{"location":"reference/types/beta/assistants/file_list_params/","title":"file_list_params","text":"<p>Classes:</p> Name Description <code>FileListParams</code>"},{"location":"reference/types/beta/assistants/file_list_params/#src.openai.types.beta.assistants.file_list_params.FileListParams","title":"FileListParams","text":"<p>Attributes:</p> Name Type Description <code>after</code> <code>str</code> <p>A cursor for use in pagination.</p> <code>before</code> <code>str</code> <p>A cursor for use in pagination.</p> <code>limit</code> <code>int</code> <p>A limit on the number of objects to be returned.</p> <code>order</code> <code>Literal['asc', 'desc']</code> <p>Sort order by the <code>created_at</code> timestamp of the objects.</p>"},{"location":"reference/types/beta/assistants/file_list_params/#src.openai.types.beta.assistants.file_list_params.FileListParams.after","title":"after  <code>instance-attribute</code>","text":"<pre><code>after: str\n</code></pre> <p>A cursor for use in pagination.</p> <p><code>after</code> is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.</p>"},{"location":"reference/types/beta/assistants/file_list_params/#src.openai.types.beta.assistants.file_list_params.FileListParams.before","title":"before  <code>instance-attribute</code>","text":"<pre><code>before: str\n</code></pre> <p>A cursor for use in pagination.</p> <p><code>before</code> is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include before=obj_foo in order to fetch the previous page of the list.</p>"},{"location":"reference/types/beta/assistants/file_list_params/#src.openai.types.beta.assistants.file_list_params.FileListParams.limit","title":"limit  <code>instance-attribute</code>","text":"<pre><code>limit: int\n</code></pre> <p>A limit on the number of objects to be returned.</p> <p>Limit can range between 1 and 100, and the default is 20.</p>"},{"location":"reference/types/beta/assistants/file_list_params/#src.openai.types.beta.assistants.file_list_params.FileListParams.order","title":"order  <code>instance-attribute</code>","text":"<pre><code>order: Literal['asc', 'desc']\n</code></pre> <p>Sort order by the <code>created_at</code> timestamp of the objects.</p> <p><code>asc</code> for ascending order and <code>desc</code> for descending order.</p>"},{"location":"reference/types/beta/chat/","title":"chat","text":""},{"location":"reference/types/beta/threads/","title":"Index","text":"<p>Modules:</p> Name Description <code>message_content_image_file</code> <code>message_content_text</code> <code>message_create_params</code> <code>message_list_params</code> <code>message_update_params</code> <code>messages</code> <code>required_action_function_tool_call</code> <code>run</code> <code>run_create_params</code> <code>run_list_params</code> <code>run_status</code> <code>run_submit_tool_outputs_params</code> <code>run_update_params</code> <code>runs</code> <code>thread_message</code>"},{"location":"reference/types/beta/threads/message_content_image_file/","title":"message_content_image_file","text":"<p>Classes:</p> Name Description <code>ImageFile</code> <code>MessageContentImageFile</code>"},{"location":"reference/types/beta/threads/message_content_image_file/#src.openai.types.beta.threads.message_content_image_file.ImageFile","title":"ImageFile","text":"<p>Attributes:</p> Name Type Description <code>file_id</code> <code>str</code> <p>The File ID of the image</p>"},{"location":"reference/types/beta/threads/message_content_image_file/#src.openai.types.beta.threads.message_content_image_file.ImageFile.file_id","title":"file_id  <code>instance-attribute</code>","text":"<pre><code>file_id: str\n</code></pre> <p>The File ID of the image in the message content.</p>"},{"location":"reference/types/beta/threads/message_content_image_file/#src.openai.types.beta.threads.message_content_image_file.MessageContentImageFile","title":"MessageContentImageFile","text":"<p>Attributes:</p> Name Type Description <code>image_file</code> <code>ImageFile</code> <code>type</code> <code>Literal['image_file']</code> <p>Always <code>image_file</code>.</p>"},{"location":"reference/types/beta/threads/message_content_image_file/#src.openai.types.beta.threads.message_content_image_file.MessageContentImageFile.image_file","title":"image_file  <code>instance-attribute</code>","text":"<pre><code>image_file: ImageFile\n</code></pre>"},{"location":"reference/types/beta/threads/message_content_image_file/#src.openai.types.beta.threads.message_content_image_file.MessageContentImageFile.type","title":"type  <code>instance-attribute</code>","text":"<pre><code>type: Literal['image_file']\n</code></pre> <p>Always <code>image_file</code>.</p>"},{"location":"reference/types/beta/threads/message_content_text/","title":"message_content_text","text":"<p>Classes:</p> Name Description <code>MessageContentText</code> <code>Text</code> <code>TextAnnotationFileCitation</code> <code>TextAnnotationFileCitationFileCitation</code> <code>TextAnnotationFilePath</code> <code>TextAnnotationFilePathFilePath</code> <p>Attributes:</p> Name Type Description <code>TextAnnotation</code>"},{"location":"reference/types/beta/threads/message_content_text/#src.openai.types.beta.threads.message_content_text.TextAnnotation","title":"TextAnnotation  <code>module-attribute</code>","text":"<pre><code>TextAnnotation = Union[\n    TextAnnotationFileCitation, TextAnnotationFilePath\n]\n</code></pre>"},{"location":"reference/types/beta/threads/message_content_text/#src.openai.types.beta.threads.message_content_text.MessageContentText","title":"MessageContentText","text":"<p>Attributes:</p> Name Type Description <code>text</code> <code>Text</code> <code>type</code> <code>Literal['text']</code> <p>Always <code>text</code>.</p>"},{"location":"reference/types/beta/threads/message_content_text/#src.openai.types.beta.threads.message_content_text.MessageContentText.text","title":"text  <code>instance-attribute</code>","text":"<pre><code>text: Text\n</code></pre>"},{"location":"reference/types/beta/threads/message_content_text/#src.openai.types.beta.threads.message_content_text.MessageContentText.type","title":"type  <code>instance-attribute</code>","text":"<pre><code>type: Literal['text']\n</code></pre> <p>Always <code>text</code>.</p>"},{"location":"reference/types/beta/threads/message_content_text/#src.openai.types.beta.threads.message_content_text.Text","title":"Text","text":"<p>Attributes:</p> Name Type Description <code>annotations</code> <code>List[TextAnnotation]</code> <code>value</code> <code>str</code> <p>The data that makes up the text.</p>"},{"location":"reference/types/beta/threads/message_content_text/#src.openai.types.beta.threads.message_content_text.Text.annotations","title":"annotations  <code>instance-attribute</code>","text":"<pre><code>annotations: List[TextAnnotation]\n</code></pre>"},{"location":"reference/types/beta/threads/message_content_text/#src.openai.types.beta.threads.message_content_text.Text.value","title":"value  <code>instance-attribute</code>","text":"<pre><code>value: str\n</code></pre> <p>The data that makes up the text.</p>"},{"location":"reference/types/beta/threads/message_content_text/#src.openai.types.beta.threads.message_content_text.TextAnnotationFileCitation","title":"TextAnnotationFileCitation","text":"<p>Attributes:</p> Name Type Description <code>end_index</code> <code>int</code> <code>file_citation</code> <code>TextAnnotationFileCitationFileCitation</code> <code>start_index</code> <code>int</code> <code>text</code> <code>str</code> <p>The text in the message content that needs to be replaced.</p> <code>type</code> <code>Literal['file_citation']</code> <p>Always <code>file_citation</code>.</p>"},{"location":"reference/types/beta/threads/message_content_text/#src.openai.types.beta.threads.message_content_text.TextAnnotationFileCitation.end_index","title":"end_index  <code>instance-attribute</code>","text":"<pre><code>end_index: int\n</code></pre>"},{"location":"reference/types/beta/threads/message_content_text/#src.openai.types.beta.threads.message_content_text.TextAnnotationFileCitation.file_citation","title":"file_citation  <code>instance-attribute</code>","text":"<pre><code>file_citation: TextAnnotationFileCitationFileCitation\n</code></pre>"},{"location":"reference/types/beta/threads/message_content_text/#src.openai.types.beta.threads.message_content_text.TextAnnotationFileCitation.start_index","title":"start_index  <code>instance-attribute</code>","text":"<pre><code>start_index: int\n</code></pre>"},{"location":"reference/types/beta/threads/message_content_text/#src.openai.types.beta.threads.message_content_text.TextAnnotationFileCitation.text","title":"text  <code>instance-attribute</code>","text":"<pre><code>text: str\n</code></pre> <p>The text in the message content that needs to be replaced.</p>"},{"location":"reference/types/beta/threads/message_content_text/#src.openai.types.beta.threads.message_content_text.TextAnnotationFileCitation.type","title":"type  <code>instance-attribute</code>","text":"<pre><code>type: Literal['file_citation']\n</code></pre> <p>Always <code>file_citation</code>.</p>"},{"location":"reference/types/beta/threads/message_content_text/#src.openai.types.beta.threads.message_content_text.TextAnnotationFileCitationFileCitation","title":"TextAnnotationFileCitationFileCitation","text":"<p>Attributes:</p> Name Type Description <code>file_id</code> <code>str</code> <p>The ID of the specific File the citation is from.</p> <code>quote</code> <code>str</code> <p>The specific quote in the file.</p>"},{"location":"reference/types/beta/threads/message_content_text/#src.openai.types.beta.threads.message_content_text.TextAnnotationFileCitationFileCitation.file_id","title":"file_id  <code>instance-attribute</code>","text":"<pre><code>file_id: str\n</code></pre> <p>The ID of the specific File the citation is from.</p>"},{"location":"reference/types/beta/threads/message_content_text/#src.openai.types.beta.threads.message_content_text.TextAnnotationFileCitationFileCitation.quote","title":"quote  <code>instance-attribute</code>","text":"<pre><code>quote: str\n</code></pre> <p>The specific quote in the file.</p>"},{"location":"reference/types/beta/threads/message_content_text/#src.openai.types.beta.threads.message_content_text.TextAnnotationFilePath","title":"TextAnnotationFilePath","text":"<p>Attributes:</p> Name Type Description <code>end_index</code> <code>int</code> <code>file_path</code> <code>TextAnnotationFilePathFilePath</code> <code>start_index</code> <code>int</code> <code>text</code> <code>str</code> <p>The text in the message content that needs to be replaced.</p> <code>type</code> <code>Literal['file_path']</code> <p>Always <code>file_path</code>.</p>"},{"location":"reference/types/beta/threads/message_content_text/#src.openai.types.beta.threads.message_content_text.TextAnnotationFilePath.end_index","title":"end_index  <code>instance-attribute</code>","text":"<pre><code>end_index: int\n</code></pre>"},{"location":"reference/types/beta/threads/message_content_text/#src.openai.types.beta.threads.message_content_text.TextAnnotationFilePath.file_path","title":"file_path  <code>instance-attribute</code>","text":"<pre><code>file_path: TextAnnotationFilePathFilePath\n</code></pre>"},{"location":"reference/types/beta/threads/message_content_text/#src.openai.types.beta.threads.message_content_text.TextAnnotationFilePath.start_index","title":"start_index  <code>instance-attribute</code>","text":"<pre><code>start_index: int\n</code></pre>"},{"location":"reference/types/beta/threads/message_content_text/#src.openai.types.beta.threads.message_content_text.TextAnnotationFilePath.text","title":"text  <code>instance-attribute</code>","text":"<pre><code>text: str\n</code></pre> <p>The text in the message content that needs to be replaced.</p>"},{"location":"reference/types/beta/threads/message_content_text/#src.openai.types.beta.threads.message_content_text.TextAnnotationFilePath.type","title":"type  <code>instance-attribute</code>","text":"<pre><code>type: Literal['file_path']\n</code></pre> <p>Always <code>file_path</code>.</p>"},{"location":"reference/types/beta/threads/message_content_text/#src.openai.types.beta.threads.message_content_text.TextAnnotationFilePathFilePath","title":"TextAnnotationFilePathFilePath","text":"<p>Attributes:</p> Name Type Description <code>file_id</code> <code>str</code> <p>The ID of the file that was generated.</p>"},{"location":"reference/types/beta/threads/message_content_text/#src.openai.types.beta.threads.message_content_text.TextAnnotationFilePathFilePath.file_id","title":"file_id  <code>instance-attribute</code>","text":"<pre><code>file_id: str\n</code></pre> <p>The ID of the file that was generated.</p>"},{"location":"reference/types/beta/threads/message_create_params/","title":"message_create_params","text":"<p>Classes:</p> Name Description <code>MessageCreateParams</code>"},{"location":"reference/types/beta/threads/message_create_params/#src.openai.types.beta.threads.message_create_params.MessageCreateParams","title":"MessageCreateParams","text":"<p>Attributes:</p> Name Type Description <code>content</code> <code>Required[str]</code> <p>The content of the message.</p> <code>file_ids</code> <code>List[str]</code> <p>A list of File IDs that</p> <code>metadata</code> <code>Optional[object]</code> <p>Set of 16 key-value pairs that can be attached to an object.</p> <code>role</code> <code>Required[Literal['user']]</code> <p>The role of the entity that is creating the message.</p>"},{"location":"reference/types/beta/threads/message_create_params/#src.openai.types.beta.threads.message_create_params.MessageCreateParams.content","title":"content  <code>instance-attribute</code>","text":"<pre><code>content: Required[str]\n</code></pre> <p>The content of the message.</p>"},{"location":"reference/types/beta/threads/message_create_params/#src.openai.types.beta.threads.message_create_params.MessageCreateParams.file_ids","title":"file_ids  <code>instance-attribute</code>","text":"<pre><code>file_ids: List[str]\n</code></pre> <p>A list of File IDs that the message should use. There can be a maximum of 10 files attached to a message. Useful for tools like <code>retrieval</code> and <code>code_interpreter</code> that can access and use files.</p>"},{"location":"reference/types/beta/threads/message_create_params/#src.openai.types.beta.threads.message_create_params.MessageCreateParams.metadata","title":"metadata  <code>instance-attribute</code>","text":"<pre><code>metadata: Optional[object]\n</code></pre> <p>Set of 16 key-value pairs that can be attached to an object.</p> <p>This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.</p>"},{"location":"reference/types/beta/threads/message_create_params/#src.openai.types.beta.threads.message_create_params.MessageCreateParams.role","title":"role  <code>instance-attribute</code>","text":"<pre><code>role: Required[Literal['user']]\n</code></pre> <p>The role of the entity that is creating the message.</p> <p>Currently only <code>user</code> is supported.</p>"},{"location":"reference/types/beta/threads/message_list_params/","title":"message_list_params","text":"<p>Classes:</p> Name Description <code>MessageListParams</code>"},{"location":"reference/types/beta/threads/message_list_params/#src.openai.types.beta.threads.message_list_params.MessageListParams","title":"MessageListParams","text":"<p>Attributes:</p> Name Type Description <code>after</code> <code>str</code> <p>A cursor for use in pagination.</p> <code>before</code> <code>str</code> <p>A cursor for use in pagination.</p> <code>limit</code> <code>int</code> <p>A limit on the number of objects to be returned.</p> <code>order</code> <code>Literal['asc', 'desc']</code> <p>Sort order by the <code>created_at</code> timestamp of the objects.</p>"},{"location":"reference/types/beta/threads/message_list_params/#src.openai.types.beta.threads.message_list_params.MessageListParams.after","title":"after  <code>instance-attribute</code>","text":"<pre><code>after: str\n</code></pre> <p>A cursor for use in pagination.</p> <p><code>after</code> is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.</p>"},{"location":"reference/types/beta/threads/message_list_params/#src.openai.types.beta.threads.message_list_params.MessageListParams.before","title":"before  <code>instance-attribute</code>","text":"<pre><code>before: str\n</code></pre> <p>A cursor for use in pagination.</p> <p><code>before</code> is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include before=obj_foo in order to fetch the previous page of the list.</p>"},{"location":"reference/types/beta/threads/message_list_params/#src.openai.types.beta.threads.message_list_params.MessageListParams.limit","title":"limit  <code>instance-attribute</code>","text":"<pre><code>limit: int\n</code></pre> <p>A limit on the number of objects to be returned.</p> <p>Limit can range between 1 and 100, and the default is 20.</p>"},{"location":"reference/types/beta/threads/message_list_params/#src.openai.types.beta.threads.message_list_params.MessageListParams.order","title":"order  <code>instance-attribute</code>","text":"<pre><code>order: Literal['asc', 'desc']\n</code></pre> <p>Sort order by the <code>created_at</code> timestamp of the objects.</p> <p><code>asc</code> for ascending order and <code>desc</code> for descending order.</p>"},{"location":"reference/types/beta/threads/message_update_params/","title":"message_update_params","text":"<p>Classes:</p> Name Description <code>MessageUpdateParams</code>"},{"location":"reference/types/beta/threads/message_update_params/#src.openai.types.beta.threads.message_update_params.MessageUpdateParams","title":"MessageUpdateParams","text":"<p>Attributes:</p> Name Type Description <code>metadata</code> <code>Optional[object]</code> <p>Set of 16 key-value pairs that can be attached to an object.</p> <code>thread_id</code> <code>Required[str]</code>"},{"location":"reference/types/beta/threads/message_update_params/#src.openai.types.beta.threads.message_update_params.MessageUpdateParams.metadata","title":"metadata  <code>instance-attribute</code>","text":"<pre><code>metadata: Optional[object]\n</code></pre> <p>Set of 16 key-value pairs that can be attached to an object.</p> <p>This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.</p>"},{"location":"reference/types/beta/threads/message_update_params/#src.openai.types.beta.threads.message_update_params.MessageUpdateParams.thread_id","title":"thread_id  <code>instance-attribute</code>","text":"<pre><code>thread_id: Required[str]\n</code></pre>"},{"location":"reference/types/beta/threads/required_action_function_tool_call/","title":"required_action_function_tool_call","text":"<p>Classes:</p> Name Description <code>Function</code> <code>RequiredActionFunctionToolCall</code>"},{"location":"reference/types/beta/threads/required_action_function_tool_call/#src.openai.types.beta.threads.required_action_function_tool_call.Function","title":"Function","text":"<p>Attributes:</p> Name Type Description <code>arguments</code> <code>str</code> <p>The arguments that the model expects you to pass to the function.</p> <code>name</code> <code>str</code> <p>The name of the function.</p>"},{"location":"reference/types/beta/threads/required_action_function_tool_call/#src.openai.types.beta.threads.required_action_function_tool_call.Function.arguments","title":"arguments  <code>instance-attribute</code>","text":"<pre><code>arguments: str\n</code></pre> <p>The arguments that the model expects you to pass to the function.</p>"},{"location":"reference/types/beta/threads/required_action_function_tool_call/#src.openai.types.beta.threads.required_action_function_tool_call.Function.name","title":"name  <code>instance-attribute</code>","text":"<pre><code>name: str\n</code></pre> <p>The name of the function.</p>"},{"location":"reference/types/beta/threads/required_action_function_tool_call/#src.openai.types.beta.threads.required_action_function_tool_call.RequiredActionFunctionToolCall","title":"RequiredActionFunctionToolCall","text":"<p>Attributes:</p> Name Type Description <code>function</code> <code>Function</code> <p>The function definition.</p> <code>id</code> <code>str</code> <p>The ID of the tool call.</p> <code>type</code> <code>Literal['function']</code> <p>The type of tool call the output is required for.</p>"},{"location":"reference/types/beta/threads/required_action_function_tool_call/#src.openai.types.beta.threads.required_action_function_tool_call.RequiredActionFunctionToolCall.function","title":"function  <code>instance-attribute</code>","text":"<pre><code>function: Function\n</code></pre> <p>The function definition.</p>"},{"location":"reference/types/beta/threads/required_action_function_tool_call/#src.openai.types.beta.threads.required_action_function_tool_call.RequiredActionFunctionToolCall.id","title":"id  <code>instance-attribute</code>","text":"<pre><code>id: str\n</code></pre> <p>The ID of the tool call.</p> <p>This ID must be referenced when you submit the tool outputs in using the Submit tool outputs to run endpoint.</p>"},{"location":"reference/types/beta/threads/required_action_function_tool_call/#src.openai.types.beta.threads.required_action_function_tool_call.RequiredActionFunctionToolCall.type","title":"type  <code>instance-attribute</code>","text":"<pre><code>type: Literal['function']\n</code></pre> <p>The type of tool call the output is required for.</p> <p>For now, this is always <code>function</code>.</p>"},{"location":"reference/types/beta/threads/run/","title":"run","text":"<p>Classes:</p> Name Description <code>LastError</code> <code>RequiredAction</code> <code>RequiredActionSubmitToolOutputs</code> <code>Run</code> <code>ToolAssistantToolsCode</code> <code>ToolAssistantToolsFunction</code> <code>ToolAssistantToolsRetrieval</code> <code>Usage</code> <p>Attributes:</p> Name Type Description <code>Tool</code>"},{"location":"reference/types/beta/threads/run/#src.openai.types.beta.threads.run.Tool","title":"Tool  <code>module-attribute</code>","text":"<pre><code>Tool = Union[\n    ToolAssistantToolsCode,\n    ToolAssistantToolsRetrieval,\n    ToolAssistantToolsFunction,\n]\n</code></pre>"},{"location":"reference/types/beta/threads/run/#src.openai.types.beta.threads.run.LastError","title":"LastError","text":"<p>Attributes:</p> Name Type Description <code>code</code> <code>Literal['server_error', 'rate_limit_exceeded', 'invalid_prompt']</code> <p>One of <code>server_error</code>, <code>rate_limit_exceeded</code>, or <code>invalid_prompt</code>.</p> <code>message</code> <code>str</code> <p>A human-readable description of the error.</p>"},{"location":"reference/types/beta/threads/run/#src.openai.types.beta.threads.run.LastError.code","title":"code  <code>instance-attribute</code>","text":"<pre><code>code: Literal[\n    \"server_error\", \"rate_limit_exceeded\", \"invalid_prompt\"\n]\n</code></pre> <p>One of <code>server_error</code>, <code>rate_limit_exceeded</code>, or <code>invalid_prompt</code>.</p>"},{"location":"reference/types/beta/threads/run/#src.openai.types.beta.threads.run.LastError.message","title":"message  <code>instance-attribute</code>","text":"<pre><code>message: str\n</code></pre> <p>A human-readable description of the error.</p>"},{"location":"reference/types/beta/threads/run/#src.openai.types.beta.threads.run.RequiredAction","title":"RequiredAction","text":"<p>Attributes:</p> Name Type Description <code>submit_tool_outputs</code> <code>RequiredActionSubmitToolOutputs</code> <p>Details on the tool outputs needed for this run to continue.</p> <code>type</code> <code>Literal['submit_tool_outputs']</code> <p>For now, this is always <code>submit_tool_outputs</code>.</p>"},{"location":"reference/types/beta/threads/run/#src.openai.types.beta.threads.run.RequiredAction.submit_tool_outputs","title":"submit_tool_outputs  <code>instance-attribute</code>","text":"<pre><code>submit_tool_outputs: RequiredActionSubmitToolOutputs\n</code></pre> <p>Details on the tool outputs needed for this run to continue.</p>"},{"location":"reference/types/beta/threads/run/#src.openai.types.beta.threads.run.RequiredAction.type","title":"type  <code>instance-attribute</code>","text":"<pre><code>type: Literal['submit_tool_outputs']\n</code></pre> <p>For now, this is always <code>submit_tool_outputs</code>.</p>"},{"location":"reference/types/beta/threads/run/#src.openai.types.beta.threads.run.RequiredActionSubmitToolOutputs","title":"RequiredActionSubmitToolOutputs","text":"<p>Attributes:</p> Name Type Description <code>tool_calls</code> <code>List[RequiredActionFunctionToolCall]</code> <p>A list of the relevant tool calls.</p>"},{"location":"reference/types/beta/threads/run/#src.openai.types.beta.threads.run.RequiredActionSubmitToolOutputs.tool_calls","title":"tool_calls  <code>instance-attribute</code>","text":"<pre><code>tool_calls: List[RequiredActionFunctionToolCall]\n</code></pre> <p>A list of the relevant tool calls.</p>"},{"location":"reference/types/beta/threads/run/#src.openai.types.beta.threads.run.Run","title":"Run","text":"<p>Attributes:</p> Name Type Description <code>assistant_id</code> <code>str</code> <p>The ID of the</p> <code>cancelled_at</code> <code>Optional[int]</code> <p>The Unix timestamp (in seconds) for when the run was cancelled.</p> <code>completed_at</code> <code>Optional[int]</code> <p>The Unix timestamp (in seconds) for when the run was completed.</p> <code>created_at</code> <code>int</code> <p>The Unix timestamp (in seconds) for when the run was created.</p> <code>expires_at</code> <code>int</code> <p>The Unix timestamp (in seconds) for when the run will expire.</p> <code>failed_at</code> <code>Optional[int]</code> <p>The Unix timestamp (in seconds) for when the run failed.</p> <code>file_ids</code> <code>List[str]</code> <p>The list of File IDs the</p> <code>id</code> <code>str</code> <p>The identifier, which can be referenced in API endpoints.</p> <code>instructions</code> <code>str</code> <p>The instructions that the</p> <code>last_error</code> <code>Optional[LastError]</code> <p>The last error associated with this run. Will be <code>null</code> if there are no errors.</p> <code>metadata</code> <code>Optional[object]</code> <p>Set of 16 key-value pairs that can be attached to an object.</p> <code>model</code> <code>str</code> <p>The model that the</p> <code>object</code> <code>Literal['thread.run']</code> <p>The object type, which is always <code>thread.run</code>.</p> <code>required_action</code> <code>Optional[RequiredAction]</code> <p>Details on the action required to continue the run.</p> <code>started_at</code> <code>Optional[int]</code> <p>The Unix timestamp (in seconds) for when the run was started.</p> <code>status</code> <code>RunStatus</code> <p>The status of the run, which can be either <code>queued</code>, <code>in_progress</code>,</p> <code>thread_id</code> <code>str</code> <p>The ID of the thread</p> <code>tools</code> <code>List[Tool]</code> <p>The list of tools that the</p> <code>usage</code> <code>Optional[Usage]</code> <p>Usage statistics related to the run.</p>"},{"location":"reference/types/beta/threads/run/#src.openai.types.beta.threads.run.Run.assistant_id","title":"assistant_id  <code>instance-attribute</code>","text":"<pre><code>assistant_id: str\n</code></pre> <p>The ID of the assistant used for execution of this run.</p>"},{"location":"reference/types/beta/threads/run/#src.openai.types.beta.threads.run.Run.cancelled_at","title":"cancelled_at  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>cancelled_at: Optional[int] = None\n</code></pre> <p>The Unix timestamp (in seconds) for when the run was cancelled.</p>"},{"location":"reference/types/beta/threads/run/#src.openai.types.beta.threads.run.Run.completed_at","title":"completed_at  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>completed_at: Optional[int] = None\n</code></pre> <p>The Unix timestamp (in seconds) for when the run was completed.</p>"},{"location":"reference/types/beta/threads/run/#src.openai.types.beta.threads.run.Run.created_at","title":"created_at  <code>instance-attribute</code>","text":"<pre><code>created_at: int\n</code></pre> <p>The Unix timestamp (in seconds) for when the run was created.</p>"},{"location":"reference/types/beta/threads/run/#src.openai.types.beta.threads.run.Run.expires_at","title":"expires_at  <code>instance-attribute</code>","text":"<pre><code>expires_at: int\n</code></pre> <p>The Unix timestamp (in seconds) for when the run will expire.</p>"},{"location":"reference/types/beta/threads/run/#src.openai.types.beta.threads.run.Run.failed_at","title":"failed_at  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>failed_at: Optional[int] = None\n</code></pre> <p>The Unix timestamp (in seconds) for when the run failed.</p>"},{"location":"reference/types/beta/threads/run/#src.openai.types.beta.threads.run.Run.file_ids","title":"file_ids  <code>instance-attribute</code>","text":"<pre><code>file_ids: List[str]\n</code></pre> <p>The list of File IDs the assistant used for this run.</p>"},{"location":"reference/types/beta/threads/run/#src.openai.types.beta.threads.run.Run.id","title":"id  <code>instance-attribute</code>","text":"<pre><code>id: str\n</code></pre> <p>The identifier, which can be referenced in API endpoints.</p>"},{"location":"reference/types/beta/threads/run/#src.openai.types.beta.threads.run.Run.instructions","title":"instructions  <code>instance-attribute</code>","text":"<pre><code>instructions: str\n</code></pre> <p>The instructions that the assistant used for this run.</p>"},{"location":"reference/types/beta/threads/run/#src.openai.types.beta.threads.run.Run.last_error","title":"last_error  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>last_error: Optional[LastError] = None\n</code></pre> <p>The last error associated with this run. Will be <code>null</code> if there are no errors.</p>"},{"location":"reference/types/beta/threads/run/#src.openai.types.beta.threads.run.Run.metadata","title":"metadata  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>metadata: Optional[object] = None\n</code></pre> <p>Set of 16 key-value pairs that can be attached to an object.</p> <p>This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.</p>"},{"location":"reference/types/beta/threads/run/#src.openai.types.beta.threads.run.Run.model","title":"model  <code>instance-attribute</code>","text":"<pre><code>model: str\n</code></pre> <p>The model that the assistant used for this run.</p>"},{"location":"reference/types/beta/threads/run/#src.openai.types.beta.threads.run.Run.object","title":"object  <code>instance-attribute</code>","text":"<pre><code>object: Literal['thread.run']\n</code></pre> <p>The object type, which is always <code>thread.run</code>.</p>"},{"location":"reference/types/beta/threads/run/#src.openai.types.beta.threads.run.Run.required_action","title":"required_action  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>required_action: Optional[RequiredAction] = None\n</code></pre> <p>Details on the action required to continue the run.</p> <p>Will be <code>null</code> if no action is required.</p>"},{"location":"reference/types/beta/threads/run/#src.openai.types.beta.threads.run.Run.started_at","title":"started_at  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>started_at: Optional[int] = None\n</code></pre> <p>The Unix timestamp (in seconds) for when the run was started.</p>"},{"location":"reference/types/beta/threads/run/#src.openai.types.beta.threads.run.Run.status","title":"status  <code>instance-attribute</code>","text":"<pre><code>status: RunStatus\n</code></pre> <p>The status of the run, which can be either <code>queued</code>, <code>in_progress</code>, <code>requires_action</code>, <code>cancelling</code>, <code>cancelled</code>, <code>failed</code>, <code>completed</code>, or <code>expired</code>.</p>"},{"location":"reference/types/beta/threads/run/#src.openai.types.beta.threads.run.Run.thread_id","title":"thread_id  <code>instance-attribute</code>","text":"<pre><code>thread_id: str\n</code></pre> <p>The ID of the thread that was executed on as a part of this run.</p>"},{"location":"reference/types/beta/threads/run/#src.openai.types.beta.threads.run.Run.tools","title":"tools  <code>instance-attribute</code>","text":"<pre><code>tools: List[Tool]\n</code></pre> <p>The list of tools that the assistant used for this run.</p>"},{"location":"reference/types/beta/threads/run/#src.openai.types.beta.threads.run.Run.usage","title":"usage  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>usage: Optional[Usage] = None\n</code></pre> <p>Usage statistics related to the run.</p> <p>This value will be <code>null</code> if the run is not in a terminal state (i.e. <code>in_progress</code>, <code>queued</code>, etc.).</p>"},{"location":"reference/types/beta/threads/run/#src.openai.types.beta.threads.run.ToolAssistantToolsCode","title":"ToolAssistantToolsCode","text":"<p>Attributes:</p> Name Type Description <code>type</code> <code>Literal['code_interpreter']</code> <p>The type of tool being defined: <code>code_interpreter</code></p>"},{"location":"reference/types/beta/threads/run/#src.openai.types.beta.threads.run.ToolAssistantToolsCode.type","title":"type  <code>instance-attribute</code>","text":"<pre><code>type: Literal['code_interpreter']\n</code></pre> <p>The type of tool being defined: <code>code_interpreter</code></p>"},{"location":"reference/types/beta/threads/run/#src.openai.types.beta.threads.run.ToolAssistantToolsFunction","title":"ToolAssistantToolsFunction","text":"<p>Attributes:</p> Name Type Description <code>function</code> <code>FunctionDefinition</code> <code>type</code> <code>Literal['function']</code> <p>The type of tool being defined: <code>function</code></p>"},{"location":"reference/types/beta/threads/run/#src.openai.types.beta.threads.run.ToolAssistantToolsFunction.function","title":"function  <code>instance-attribute</code>","text":"<pre><code>function: FunctionDefinition\n</code></pre>"},{"location":"reference/types/beta/threads/run/#src.openai.types.beta.threads.run.ToolAssistantToolsFunction.type","title":"type  <code>instance-attribute</code>","text":"<pre><code>type: Literal['function']\n</code></pre> <p>The type of tool being defined: <code>function</code></p>"},{"location":"reference/types/beta/threads/run/#src.openai.types.beta.threads.run.ToolAssistantToolsRetrieval","title":"ToolAssistantToolsRetrieval","text":"<p>Attributes:</p> Name Type Description <code>type</code> <code>Literal['retrieval']</code> <p>The type of tool being defined: <code>retrieval</code></p>"},{"location":"reference/types/beta/threads/run/#src.openai.types.beta.threads.run.ToolAssistantToolsRetrieval.type","title":"type  <code>instance-attribute</code>","text":"<pre><code>type: Literal['retrieval']\n</code></pre> <p>The type of tool being defined: <code>retrieval</code></p>"},{"location":"reference/types/beta/threads/run/#src.openai.types.beta.threads.run.Usage","title":"Usage","text":"<p>Attributes:</p> Name Type Description <code>completion_tokens</code> <code>int</code> <p>Number of completion tokens used over the course of the run.</p> <code>prompt_tokens</code> <code>int</code> <p>Number of prompt tokens used over the course of the run.</p> <code>total_tokens</code> <code>int</code> <p>Total number of tokens used (prompt + completion).</p>"},{"location":"reference/types/beta/threads/run/#src.openai.types.beta.threads.run.Usage.completion_tokens","title":"completion_tokens  <code>instance-attribute</code>","text":"<pre><code>completion_tokens: int\n</code></pre> <p>Number of completion tokens used over the course of the run.</p>"},{"location":"reference/types/beta/threads/run/#src.openai.types.beta.threads.run.Usage.prompt_tokens","title":"prompt_tokens  <code>instance-attribute</code>","text":"<pre><code>prompt_tokens: int\n</code></pre> <p>Number of prompt tokens used over the course of the run.</p>"},{"location":"reference/types/beta/threads/run/#src.openai.types.beta.threads.run.Usage.total_tokens","title":"total_tokens  <code>instance-attribute</code>","text":"<pre><code>total_tokens: int\n</code></pre> <p>Total number of tokens used (prompt + completion).</p>"},{"location":"reference/types/beta/threads/run_create_params/","title":"run_create_params","text":"<p>Classes:</p> Name Description <code>RunCreateParams</code> <code>ToolAssistantToolsCode</code> <code>ToolAssistantToolsFunction</code> <code>ToolAssistantToolsRetrieval</code> <p>Attributes:</p> Name Type Description <code>Tool</code>"},{"location":"reference/types/beta/threads/run_create_params/#src.openai.types.beta.threads.run_create_params.Tool","title":"Tool  <code>module-attribute</code>","text":"<pre><code>Tool = Union[\n    ToolAssistantToolsCode,\n    ToolAssistantToolsRetrieval,\n    ToolAssistantToolsFunction,\n]\n</code></pre>"},{"location":"reference/types/beta/threads/run_create_params/#src.openai.types.beta.threads.run_create_params.RunCreateParams","title":"RunCreateParams","text":"<p>Attributes:</p> Name Type Description <code>additional_instructions</code> <code>Optional[str]</code> <p>Appends additional instructions at the end of the instructions for the run.</p> <code>assistant_id</code> <code>Required[str]</code> <p>The ID of the</p> <code>instructions</code> <code>Optional[str]</code> <p>Overrides the</p> <code>metadata</code> <code>Optional[object]</code> <p>Set of 16 key-value pairs that can be attached to an object.</p> <code>model</code> <code>Optional[str]</code> <p>The ID of the Model to</p> <code>tools</code> <code>Optional[Iterable[Tool]]</code> <p>Override the tools the assistant can use for this run.</p>"},{"location":"reference/types/beta/threads/run_create_params/#src.openai.types.beta.threads.run_create_params.RunCreateParams.additional_instructions","title":"additional_instructions  <code>instance-attribute</code>","text":"<pre><code>additional_instructions: Optional[str]\n</code></pre> <p>Appends additional instructions at the end of the instructions for the run.</p> <p>This is useful for modifying the behavior on a per-run basis without overriding other instructions.</p>"},{"location":"reference/types/beta/threads/run_create_params/#src.openai.types.beta.threads.run_create_params.RunCreateParams.assistant_id","title":"assistant_id  <code>instance-attribute</code>","text":"<pre><code>assistant_id: Required[str]\n</code></pre> <p>The ID of the assistant to use to execute this run.</p>"},{"location":"reference/types/beta/threads/run_create_params/#src.openai.types.beta.threads.run_create_params.RunCreateParams.instructions","title":"instructions  <code>instance-attribute</code>","text":"<pre><code>instructions: Optional[str]\n</code></pre> <p>Overrides the instructions of the assistant. This is useful for modifying the behavior on a per-run basis.</p>"},{"location":"reference/types/beta/threads/run_create_params/#src.openai.types.beta.threads.run_create_params.RunCreateParams.metadata","title":"metadata  <code>instance-attribute</code>","text":"<pre><code>metadata: Optional[object]\n</code></pre> <p>Set of 16 key-value pairs that can be attached to an object.</p> <p>This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.</p>"},{"location":"reference/types/beta/threads/run_create_params/#src.openai.types.beta.threads.run_create_params.RunCreateParams.model","title":"model  <code>instance-attribute</code>","text":"<pre><code>model: Optional[str]\n</code></pre> <p>The ID of the Model to be used to execute this run. If a value is provided here, it will override the model associated with the assistant. If not, the model associated with the assistant will be used.</p>"},{"location":"reference/types/beta/threads/run_create_params/#src.openai.types.beta.threads.run_create_params.RunCreateParams.tools","title":"tools  <code>instance-attribute</code>","text":"<pre><code>tools: Optional[Iterable[Tool]]\n</code></pre> <p>Override the tools the assistant can use for this run.</p> <p>This is useful for modifying the behavior on a per-run basis.</p>"},{"location":"reference/types/beta/threads/run_create_params/#src.openai.types.beta.threads.run_create_params.ToolAssistantToolsCode","title":"ToolAssistantToolsCode","text":"<p>Attributes:</p> Name Type Description <code>type</code> <code>Required[Literal['code_interpreter']]</code> <p>The type of tool being defined: <code>code_interpreter</code></p>"},{"location":"reference/types/beta/threads/run_create_params/#src.openai.types.beta.threads.run_create_params.ToolAssistantToolsCode.type","title":"type  <code>instance-attribute</code>","text":"<pre><code>type: Required[Literal['code_interpreter']]\n</code></pre> <p>The type of tool being defined: <code>code_interpreter</code></p>"},{"location":"reference/types/beta/threads/run_create_params/#src.openai.types.beta.threads.run_create_params.ToolAssistantToolsFunction","title":"ToolAssistantToolsFunction","text":"<p>Attributes:</p> Name Type Description <code>function</code> <code>Required[FunctionDefinition]</code> <code>type</code> <code>Required[Literal['function']]</code> <p>The type of tool being defined: <code>function</code></p>"},{"location":"reference/types/beta/threads/run_create_params/#src.openai.types.beta.threads.run_create_params.ToolAssistantToolsFunction.function","title":"function  <code>instance-attribute</code>","text":"<pre><code>function: Required[FunctionDefinition]\n</code></pre>"},{"location":"reference/types/beta/threads/run_create_params/#src.openai.types.beta.threads.run_create_params.ToolAssistantToolsFunction.type","title":"type  <code>instance-attribute</code>","text":"<pre><code>type: Required[Literal['function']]\n</code></pre> <p>The type of tool being defined: <code>function</code></p>"},{"location":"reference/types/beta/threads/run_create_params/#src.openai.types.beta.threads.run_create_params.ToolAssistantToolsRetrieval","title":"ToolAssistantToolsRetrieval","text":"<p>Attributes:</p> Name Type Description <code>type</code> <code>Required[Literal['retrieval']]</code> <p>The type of tool being defined: <code>retrieval</code></p>"},{"location":"reference/types/beta/threads/run_create_params/#src.openai.types.beta.threads.run_create_params.ToolAssistantToolsRetrieval.type","title":"type  <code>instance-attribute</code>","text":"<pre><code>type: Required[Literal['retrieval']]\n</code></pre> <p>The type of tool being defined: <code>retrieval</code></p>"},{"location":"reference/types/beta/threads/run_list_params/","title":"run_list_params","text":"<p>Classes:</p> Name Description <code>RunListParams</code>"},{"location":"reference/types/beta/threads/run_list_params/#src.openai.types.beta.threads.run_list_params.RunListParams","title":"RunListParams","text":"<p>Attributes:</p> Name Type Description <code>after</code> <code>str</code> <p>A cursor for use in pagination.</p> <code>before</code> <code>str</code> <p>A cursor for use in pagination.</p> <code>limit</code> <code>int</code> <p>A limit on the number of objects to be returned.</p> <code>order</code> <code>Literal['asc', 'desc']</code> <p>Sort order by the <code>created_at</code> timestamp of the objects.</p>"},{"location":"reference/types/beta/threads/run_list_params/#src.openai.types.beta.threads.run_list_params.RunListParams.after","title":"after  <code>instance-attribute</code>","text":"<pre><code>after: str\n</code></pre> <p>A cursor for use in pagination.</p> <p><code>after</code> is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.</p>"},{"location":"reference/types/beta/threads/run_list_params/#src.openai.types.beta.threads.run_list_params.RunListParams.before","title":"before  <code>instance-attribute</code>","text":"<pre><code>before: str\n</code></pre> <p>A cursor for use in pagination.</p> <p><code>before</code> is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include before=obj_foo in order to fetch the previous page of the list.</p>"},{"location":"reference/types/beta/threads/run_list_params/#src.openai.types.beta.threads.run_list_params.RunListParams.limit","title":"limit  <code>instance-attribute</code>","text":"<pre><code>limit: int\n</code></pre> <p>A limit on the number of objects to be returned.</p> <p>Limit can range between 1 and 100, and the default is 20.</p>"},{"location":"reference/types/beta/threads/run_list_params/#src.openai.types.beta.threads.run_list_params.RunListParams.order","title":"order  <code>instance-attribute</code>","text":"<pre><code>order: Literal['asc', 'desc']\n</code></pre> <p>Sort order by the <code>created_at</code> timestamp of the objects.</p> <p><code>asc</code> for ascending order and <code>desc</code> for descending order.</p>"},{"location":"reference/types/beta/threads/run_submit_tool_outputs_params/","title":"run_submit_tool_outputs_params","text":"<p>Classes:</p> Name Description <code>RunSubmitToolOutputsParams</code> <code>ToolOutput</code>"},{"location":"reference/types/beta/threads/run_submit_tool_outputs_params/#src.openai.types.beta.threads.run_submit_tool_outputs_params.RunSubmitToolOutputsParams","title":"RunSubmitToolOutputsParams","text":"<p>Attributes:</p> Name Type Description <code>thread_id</code> <code>Required[str]</code> <code>tool_outputs</code> <code>Required[Iterable[ToolOutput]]</code> <p>A list of tools for which the outputs are being submitted.</p>"},{"location":"reference/types/beta/threads/run_submit_tool_outputs_params/#src.openai.types.beta.threads.run_submit_tool_outputs_params.RunSubmitToolOutputsParams.thread_id","title":"thread_id  <code>instance-attribute</code>","text":"<pre><code>thread_id: Required[str]\n</code></pre>"},{"location":"reference/types/beta/threads/run_submit_tool_outputs_params/#src.openai.types.beta.threads.run_submit_tool_outputs_params.RunSubmitToolOutputsParams.tool_outputs","title":"tool_outputs  <code>instance-attribute</code>","text":"<pre><code>tool_outputs: Required[Iterable[ToolOutput]]\n</code></pre> <p>A list of tools for which the outputs are being submitted.</p>"},{"location":"reference/types/beta/threads/run_submit_tool_outputs_params/#src.openai.types.beta.threads.run_submit_tool_outputs_params.ToolOutput","title":"ToolOutput","text":"<p>Attributes:</p> Name Type Description <code>output</code> <code>str</code> <p>The output of the tool call to be submitted to continue the run.</p> <code>tool_call_id</code> <code>str</code> <p>The ID of the tool call in the <code>required_action</code> object within the run object</p>"},{"location":"reference/types/beta/threads/run_submit_tool_outputs_params/#src.openai.types.beta.threads.run_submit_tool_outputs_params.ToolOutput.output","title":"output  <code>instance-attribute</code>","text":"<pre><code>output: str\n</code></pre> <p>The output of the tool call to be submitted to continue the run.</p>"},{"location":"reference/types/beta/threads/run_submit_tool_outputs_params/#src.openai.types.beta.threads.run_submit_tool_outputs_params.ToolOutput.tool_call_id","title":"tool_call_id  <code>instance-attribute</code>","text":"<pre><code>tool_call_id: str\n</code></pre> <p>The ID of the tool call in the <code>required_action</code> object within the run object the output is being submitted for.</p>"},{"location":"reference/types/beta/threads/run_update_params/","title":"run_update_params","text":"<p>Classes:</p> Name Description <code>RunUpdateParams</code>"},{"location":"reference/types/beta/threads/run_update_params/#src.openai.types.beta.threads.run_update_params.RunUpdateParams","title":"RunUpdateParams","text":"<p>Attributes:</p> Name Type Description <code>metadata</code> <code>Optional[object]</code> <p>Set of 16 key-value pairs that can be attached to an object.</p> <code>thread_id</code> <code>Required[str]</code>"},{"location":"reference/types/beta/threads/run_update_params/#src.openai.types.beta.threads.run_update_params.RunUpdateParams.metadata","title":"metadata  <code>instance-attribute</code>","text":"<pre><code>metadata: Optional[object]\n</code></pre> <p>Set of 16 key-value pairs that can be attached to an object.</p> <p>This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.</p>"},{"location":"reference/types/beta/threads/run_update_params/#src.openai.types.beta.threads.run_update_params.RunUpdateParams.thread_id","title":"thread_id  <code>instance-attribute</code>","text":"<pre><code>thread_id: Required[str]\n</code></pre>"},{"location":"reference/types/beta/threads/thread_message/","title":"thread_message","text":"<p>Classes:</p> Name Description <code>ThreadMessage</code> <p>Attributes:</p> Name Type Description <code>Content</code>"},{"location":"reference/types/beta/threads/thread_message/#src.openai.types.beta.threads.thread_message.Content","title":"Content  <code>module-attribute</code>","text":"<pre><code>Content = Union[MessageContentImageFile, MessageContentText]\n</code></pre>"},{"location":"reference/types/beta/threads/thread_message/#src.openai.types.beta.threads.thread_message.ThreadMessage","title":"ThreadMessage","text":"<p>Attributes:</p> Name Type Description <code>assistant_id</code> <code>Optional[str]</code> <p>If applicable, the ID of the</p> <code>content</code> <code>List[Content]</code> <p>The content of the message in array of text and/or images.</p> <code>created_at</code> <code>int</code> <p>The Unix timestamp (in seconds) for when the message was created.</p> <code>file_ids</code> <code>List[str]</code> <p>A list of file IDs that</p> <code>id</code> <code>str</code> <p>The identifier, which can be referenced in API endpoints.</p> <code>metadata</code> <code>Optional[object]</code> <p>Set of 16 key-value pairs that can be attached to an object.</p> <code>object</code> <code>Literal['thread.message']</code> <p>The object type, which is always <code>thread.message</code>.</p> <code>role</code> <code>Literal['user', 'assistant']</code> <p>The entity that produced the message. One of <code>user</code> or <code>assistant</code>.</p> <code>run_id</code> <code>Optional[str]</code> <p>If applicable, the ID of the</p> <code>thread_id</code> <code>str</code> <p>The thread ID that</p>"},{"location":"reference/types/beta/threads/thread_message/#src.openai.types.beta.threads.thread_message.ThreadMessage.assistant_id","title":"assistant_id  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>assistant_id: Optional[str] = None\n</code></pre> <p>If applicable, the ID of the assistant that authored this message.</p>"},{"location":"reference/types/beta/threads/thread_message/#src.openai.types.beta.threads.thread_message.ThreadMessage.content","title":"content  <code>instance-attribute</code>","text":"<pre><code>content: List[Content]\n</code></pre> <p>The content of the message in array of text and/or images.</p>"},{"location":"reference/types/beta/threads/thread_message/#src.openai.types.beta.threads.thread_message.ThreadMessage.created_at","title":"created_at  <code>instance-attribute</code>","text":"<pre><code>created_at: int\n</code></pre> <p>The Unix timestamp (in seconds) for when the message was created.</p>"},{"location":"reference/types/beta/threads/thread_message/#src.openai.types.beta.threads.thread_message.ThreadMessage.file_ids","title":"file_ids  <code>instance-attribute</code>","text":"<pre><code>file_ids: List[str]\n</code></pre> <p>A list of file IDs that the assistant should use. Useful for tools like retrieval and code_interpreter that can access files. A maximum of 10 files can be attached to a message.</p>"},{"location":"reference/types/beta/threads/thread_message/#src.openai.types.beta.threads.thread_message.ThreadMessage.id","title":"id  <code>instance-attribute</code>","text":"<pre><code>id: str\n</code></pre> <p>The identifier, which can be referenced in API endpoints.</p>"},{"location":"reference/types/beta/threads/thread_message/#src.openai.types.beta.threads.thread_message.ThreadMessage.metadata","title":"metadata  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>metadata: Optional[object] = None\n</code></pre> <p>Set of 16 key-value pairs that can be attached to an object.</p> <p>This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.</p>"},{"location":"reference/types/beta/threads/thread_message/#src.openai.types.beta.threads.thread_message.ThreadMessage.object","title":"object  <code>instance-attribute</code>","text":"<pre><code>object: Literal['thread.message']\n</code></pre> <p>The object type, which is always <code>thread.message</code>.</p>"},{"location":"reference/types/beta/threads/thread_message/#src.openai.types.beta.threads.thread_message.ThreadMessage.role","title":"role  <code>instance-attribute</code>","text":"<pre><code>role: Literal['user', 'assistant']\n</code></pre> <p>The entity that produced the message. One of <code>user</code> or <code>assistant</code>.</p>"},{"location":"reference/types/beta/threads/thread_message/#src.openai.types.beta.threads.thread_message.ThreadMessage.run_id","title":"run_id  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>run_id: Optional[str] = None\n</code></pre> <p>If applicable, the ID of the run associated with the authoring of this message.</p>"},{"location":"reference/types/beta/threads/thread_message/#src.openai.types.beta.threads.thread_message.ThreadMessage.thread_id","title":"thread_id  <code>instance-attribute</code>","text":"<pre><code>thread_id: str\n</code></pre> <p>The thread ID that this message belongs to.</p>"},{"location":"reference/types/beta/threads/messages/","title":"Index","text":"<p>Modules:</p> Name Description <code>file_list_params</code> <code>message_file</code>"},{"location":"reference/types/beta/threads/messages/file_list_params/","title":"file_list_params","text":"<p>Classes:</p> Name Description <code>FileListParams</code>"},{"location":"reference/types/beta/threads/messages/file_list_params/#src.openai.types.beta.threads.messages.file_list_params.FileListParams","title":"FileListParams","text":"<p>Attributes:</p> Name Type Description <code>after</code> <code>str</code> <p>A cursor for use in pagination.</p> <code>before</code> <code>str</code> <p>A cursor for use in pagination.</p> <code>limit</code> <code>int</code> <p>A limit on the number of objects to be returned.</p> <code>order</code> <code>Literal['asc', 'desc']</code> <p>Sort order by the <code>created_at</code> timestamp of the objects.</p> <code>thread_id</code> <code>Required[str]</code>"},{"location":"reference/types/beta/threads/messages/file_list_params/#src.openai.types.beta.threads.messages.file_list_params.FileListParams.after","title":"after  <code>instance-attribute</code>","text":"<pre><code>after: str\n</code></pre> <p>A cursor for use in pagination.</p> <p><code>after</code> is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.</p>"},{"location":"reference/types/beta/threads/messages/file_list_params/#src.openai.types.beta.threads.messages.file_list_params.FileListParams.before","title":"before  <code>instance-attribute</code>","text":"<pre><code>before: str\n</code></pre> <p>A cursor for use in pagination.</p> <p><code>before</code> is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include before=obj_foo in order to fetch the previous page of the list.</p>"},{"location":"reference/types/beta/threads/messages/file_list_params/#src.openai.types.beta.threads.messages.file_list_params.FileListParams.limit","title":"limit  <code>instance-attribute</code>","text":"<pre><code>limit: int\n</code></pre> <p>A limit on the number of objects to be returned.</p> <p>Limit can range between 1 and 100, and the default is 20.</p>"},{"location":"reference/types/beta/threads/messages/file_list_params/#src.openai.types.beta.threads.messages.file_list_params.FileListParams.order","title":"order  <code>instance-attribute</code>","text":"<pre><code>order: Literal['asc', 'desc']\n</code></pre> <p>Sort order by the <code>created_at</code> timestamp of the objects.</p> <p><code>asc</code> for ascending order and <code>desc</code> for descending order.</p>"},{"location":"reference/types/beta/threads/messages/file_list_params/#src.openai.types.beta.threads.messages.file_list_params.FileListParams.thread_id","title":"thread_id  <code>instance-attribute</code>","text":"<pre><code>thread_id: Required[str]\n</code></pre>"},{"location":"reference/types/beta/threads/messages/message_file/","title":"message_file","text":"<p>Classes:</p> Name Description <code>MessageFile</code>"},{"location":"reference/types/beta/threads/messages/message_file/#src.openai.types.beta.threads.messages.message_file.MessageFile","title":"MessageFile","text":"<p>Attributes:</p> Name Type Description <code>created_at</code> <code>int</code> <p>The Unix timestamp (in seconds) for when the message file was created.</p> <code>id</code> <code>str</code> <p>The identifier, which can be referenced in API endpoints.</p> <code>message_id</code> <code>str</code> <p>The ID of the message</p> <code>object</code> <code>Literal['thread.message.file']</code> <p>The object type, which is always <code>thread.message.file</code>.</p>"},{"location":"reference/types/beta/threads/messages/message_file/#src.openai.types.beta.threads.messages.message_file.MessageFile.created_at","title":"created_at  <code>instance-attribute</code>","text":"<pre><code>created_at: int\n</code></pre> <p>The Unix timestamp (in seconds) for when the message file was created.</p>"},{"location":"reference/types/beta/threads/messages/message_file/#src.openai.types.beta.threads.messages.message_file.MessageFile.id","title":"id  <code>instance-attribute</code>","text":"<pre><code>id: str\n</code></pre> <p>The identifier, which can be referenced in API endpoints.</p>"},{"location":"reference/types/beta/threads/messages/message_file/#src.openai.types.beta.threads.messages.message_file.MessageFile.message_id","title":"message_id  <code>instance-attribute</code>","text":"<pre><code>message_id: str\n</code></pre> <p>The ID of the message that the File is attached to.</p>"},{"location":"reference/types/beta/threads/messages/message_file/#src.openai.types.beta.threads.messages.message_file.MessageFile.object","title":"object  <code>instance-attribute</code>","text":"<pre><code>object: Literal['thread.message.file']\n</code></pre> <p>The object type, which is always <code>thread.message.file</code>.</p>"},{"location":"reference/types/beta/threads/runs/","title":"Index","text":"<p>Modules:</p> Name Description <code>code_tool_call</code> <code>function_tool_call</code> <code>message_creation_step_details</code> <code>retrieval_tool_call</code> <code>run_step</code> <code>step_list_params</code> <code>tool_calls_step_details</code>"},{"location":"reference/types/beta/threads/runs/code_tool_call/","title":"code_tool_call","text":"<p>Classes:</p> Name Description <code>CodeInterpreter</code> <code>CodeInterpreterOutputImage</code> <code>CodeInterpreterOutputImageImage</code> <code>CodeInterpreterOutputLogs</code> <code>CodeToolCall</code> <p>Attributes:</p> Name Type Description <code>CodeInterpreterOutput</code>"},{"location":"reference/types/beta/threads/runs/code_tool_call/#src.openai.types.beta.threads.runs.code_tool_call.CodeInterpreterOutput","title":"CodeInterpreterOutput  <code>module-attribute</code>","text":"<pre><code>CodeInterpreterOutput = Union[\n    CodeInterpreterOutputLogs, CodeInterpreterOutputImage\n]\n</code></pre>"},{"location":"reference/types/beta/threads/runs/code_tool_call/#src.openai.types.beta.threads.runs.code_tool_call.CodeInterpreter","title":"CodeInterpreter","text":"<p>Attributes:</p> Name Type Description <code>input</code> <code>str</code> <p>The input to the Code Interpreter tool call.</p> <code>outputs</code> <code>List[CodeInterpreterOutput]</code> <p>The outputs from the Code Interpreter tool call.</p>"},{"location":"reference/types/beta/threads/runs/code_tool_call/#src.openai.types.beta.threads.runs.code_tool_call.CodeInterpreter.input","title":"input  <code>instance-attribute</code>","text":"<pre><code>input: str\n</code></pre> <p>The input to the Code Interpreter tool call.</p>"},{"location":"reference/types/beta/threads/runs/code_tool_call/#src.openai.types.beta.threads.runs.code_tool_call.CodeInterpreter.outputs","title":"outputs  <code>instance-attribute</code>","text":"<pre><code>outputs: List[CodeInterpreterOutput]\n</code></pre> <p>The outputs from the Code Interpreter tool call.</p> <p>Code Interpreter can output one or more items, including text (<code>logs</code>) or images (<code>image</code>). Each of these are represented by a different object type.</p>"},{"location":"reference/types/beta/threads/runs/code_tool_call/#src.openai.types.beta.threads.runs.code_tool_call.CodeInterpreterOutputImage","title":"CodeInterpreterOutputImage","text":"<p>Attributes:</p> Name Type Description <code>image</code> <code>CodeInterpreterOutputImageImage</code> <code>type</code> <code>Literal['image']</code> <p>Always <code>image</code>.</p>"},{"location":"reference/types/beta/threads/runs/code_tool_call/#src.openai.types.beta.threads.runs.code_tool_call.CodeInterpreterOutputImage.image","title":"image  <code>instance-attribute</code>","text":"<pre><code>image: CodeInterpreterOutputImageImage\n</code></pre>"},{"location":"reference/types/beta/threads/runs/code_tool_call/#src.openai.types.beta.threads.runs.code_tool_call.CodeInterpreterOutputImage.type","title":"type  <code>instance-attribute</code>","text":"<pre><code>type: Literal['image']\n</code></pre> <p>Always <code>image</code>.</p>"},{"location":"reference/types/beta/threads/runs/code_tool_call/#src.openai.types.beta.threads.runs.code_tool_call.CodeInterpreterOutputImageImage","title":"CodeInterpreterOutputImageImage","text":"<p>Attributes:</p> Name Type Description <code>file_id</code> <code>str</code> <p>The file ID of the</p>"},{"location":"reference/types/beta/threads/runs/code_tool_call/#src.openai.types.beta.threads.runs.code_tool_call.CodeInterpreterOutputImageImage.file_id","title":"file_id  <code>instance-attribute</code>","text":"<pre><code>file_id: str\n</code></pre> <p>The file ID of the image.</p>"},{"location":"reference/types/beta/threads/runs/code_tool_call/#src.openai.types.beta.threads.runs.code_tool_call.CodeInterpreterOutputLogs","title":"CodeInterpreterOutputLogs","text":"<p>Attributes:</p> Name Type Description <code>logs</code> <code>str</code> <p>The text output from the Code Interpreter tool call.</p> <code>type</code> <code>Literal['logs']</code> <p>Always <code>logs</code>.</p>"},{"location":"reference/types/beta/threads/runs/code_tool_call/#src.openai.types.beta.threads.runs.code_tool_call.CodeInterpreterOutputLogs.logs","title":"logs  <code>instance-attribute</code>","text":"<pre><code>logs: str\n</code></pre> <p>The text output from the Code Interpreter tool call.</p>"},{"location":"reference/types/beta/threads/runs/code_tool_call/#src.openai.types.beta.threads.runs.code_tool_call.CodeInterpreterOutputLogs.type","title":"type  <code>instance-attribute</code>","text":"<pre><code>type: Literal['logs']\n</code></pre> <p>Always <code>logs</code>.</p>"},{"location":"reference/types/beta/threads/runs/code_tool_call/#src.openai.types.beta.threads.runs.code_tool_call.CodeToolCall","title":"CodeToolCall","text":"<p>Attributes:</p> Name Type Description <code>code_interpreter</code> <code>CodeInterpreter</code> <p>The Code Interpreter tool call definition.</p> <code>id</code> <code>str</code> <p>The ID of the tool call.</p> <code>type</code> <code>Literal['code_interpreter']</code> <p>The type of tool call.</p>"},{"location":"reference/types/beta/threads/runs/code_tool_call/#src.openai.types.beta.threads.runs.code_tool_call.CodeToolCall.code_interpreter","title":"code_interpreter  <code>instance-attribute</code>","text":"<pre><code>code_interpreter: CodeInterpreter\n</code></pre> <p>The Code Interpreter tool call definition.</p>"},{"location":"reference/types/beta/threads/runs/code_tool_call/#src.openai.types.beta.threads.runs.code_tool_call.CodeToolCall.id","title":"id  <code>instance-attribute</code>","text":"<pre><code>id: str\n</code></pre> <p>The ID of the tool call.</p>"},{"location":"reference/types/beta/threads/runs/code_tool_call/#src.openai.types.beta.threads.runs.code_tool_call.CodeToolCall.type","title":"type  <code>instance-attribute</code>","text":"<pre><code>type: Literal['code_interpreter']\n</code></pre> <p>The type of tool call.</p> <p>This is always going to be <code>code_interpreter</code> for this type of tool call.</p>"},{"location":"reference/types/beta/threads/runs/function_tool_call/","title":"function_tool_call","text":"<p>Classes:</p> Name Description <code>Function</code> <code>FunctionToolCall</code>"},{"location":"reference/types/beta/threads/runs/function_tool_call/#src.openai.types.beta.threads.runs.function_tool_call.Function","title":"Function","text":"<p>Attributes:</p> Name Type Description <code>arguments</code> <code>str</code> <p>The arguments passed to the function.</p> <code>name</code> <code>str</code> <p>The name of the function.</p> <code>output</code> <code>Optional[str]</code> <p>The output of the function.</p>"},{"location":"reference/types/beta/threads/runs/function_tool_call/#src.openai.types.beta.threads.runs.function_tool_call.Function.arguments","title":"arguments  <code>instance-attribute</code>","text":"<pre><code>arguments: str\n</code></pre> <p>The arguments passed to the function.</p>"},{"location":"reference/types/beta/threads/runs/function_tool_call/#src.openai.types.beta.threads.runs.function_tool_call.Function.name","title":"name  <code>instance-attribute</code>","text":"<pre><code>name: str\n</code></pre> <p>The name of the function.</p>"},{"location":"reference/types/beta/threads/runs/function_tool_call/#src.openai.types.beta.threads.runs.function_tool_call.Function.output","title":"output  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>output: Optional[str] = None\n</code></pre> <p>The output of the function.</p> <p>This will be <code>null</code> if the outputs have not been submitted yet.</p>"},{"location":"reference/types/beta/threads/runs/function_tool_call/#src.openai.types.beta.threads.runs.function_tool_call.FunctionToolCall","title":"FunctionToolCall","text":"<p>Attributes:</p> Name Type Description <code>function</code> <code>Function</code> <p>The definition of the function that was called.</p> <code>id</code> <code>str</code> <p>The ID of the tool call object.</p> <code>type</code> <code>Literal['function']</code> <p>The type of tool call.</p>"},{"location":"reference/types/beta/threads/runs/function_tool_call/#src.openai.types.beta.threads.runs.function_tool_call.FunctionToolCall.function","title":"function  <code>instance-attribute</code>","text":"<pre><code>function: Function\n</code></pre> <p>The definition of the function that was called.</p>"},{"location":"reference/types/beta/threads/runs/function_tool_call/#src.openai.types.beta.threads.runs.function_tool_call.FunctionToolCall.id","title":"id  <code>instance-attribute</code>","text":"<pre><code>id: str\n</code></pre> <p>The ID of the tool call object.</p>"},{"location":"reference/types/beta/threads/runs/function_tool_call/#src.openai.types.beta.threads.runs.function_tool_call.FunctionToolCall.type","title":"type  <code>instance-attribute</code>","text":"<pre><code>type: Literal['function']\n</code></pre> <p>The type of tool call.</p> <p>This is always going to be <code>function</code> for this type of tool call.</p>"},{"location":"reference/types/beta/threads/runs/message_creation_step_details/","title":"message_creation_step_details","text":"<p>Classes:</p> Name Description <code>MessageCreation</code> <code>MessageCreationStepDetails</code>"},{"location":"reference/types/beta/threads/runs/message_creation_step_details/#src.openai.types.beta.threads.runs.message_creation_step_details.MessageCreation","title":"MessageCreation","text":"<p>Attributes:</p> Name Type Description <code>message_id</code> <code>str</code> <p>The ID of the message that was created by this run step.</p>"},{"location":"reference/types/beta/threads/runs/message_creation_step_details/#src.openai.types.beta.threads.runs.message_creation_step_details.MessageCreation.message_id","title":"message_id  <code>instance-attribute</code>","text":"<pre><code>message_id: str\n</code></pre> <p>The ID of the message that was created by this run step.</p>"},{"location":"reference/types/beta/threads/runs/message_creation_step_details/#src.openai.types.beta.threads.runs.message_creation_step_details.MessageCreationStepDetails","title":"MessageCreationStepDetails","text":"<p>Attributes:</p> Name Type Description <code>message_creation</code> <code>MessageCreation</code> <code>type</code> <code>Literal['message_creation']</code> <p>Always <code>message_creation</code>.</p>"},{"location":"reference/types/beta/threads/runs/message_creation_step_details/#src.openai.types.beta.threads.runs.message_creation_step_details.MessageCreationStepDetails.message_creation","title":"message_creation  <code>instance-attribute</code>","text":"<pre><code>message_creation: MessageCreation\n</code></pre>"},{"location":"reference/types/beta/threads/runs/message_creation_step_details/#src.openai.types.beta.threads.runs.message_creation_step_details.MessageCreationStepDetails.type","title":"type  <code>instance-attribute</code>","text":"<pre><code>type: Literal['message_creation']\n</code></pre> <p>Always <code>message_creation</code>.</p>"},{"location":"reference/types/beta/threads/runs/retrieval_tool_call/","title":"retrieval_tool_call","text":"<p>Classes:</p> Name Description <code>RetrievalToolCall</code>"},{"location":"reference/types/beta/threads/runs/retrieval_tool_call/#src.openai.types.beta.threads.runs.retrieval_tool_call.RetrievalToolCall","title":"RetrievalToolCall","text":"<p>Attributes:</p> Name Type Description <code>id</code> <code>str</code> <p>The ID of the tool call object.</p> <code>retrieval</code> <code>object</code> <p>For now, this is always going to be an empty object.</p> <code>type</code> <code>Literal['retrieval']</code> <p>The type of tool call.</p>"},{"location":"reference/types/beta/threads/runs/retrieval_tool_call/#src.openai.types.beta.threads.runs.retrieval_tool_call.RetrievalToolCall.id","title":"id  <code>instance-attribute</code>","text":"<pre><code>id: str\n</code></pre> <p>The ID of the tool call object.</p>"},{"location":"reference/types/beta/threads/runs/retrieval_tool_call/#src.openai.types.beta.threads.runs.retrieval_tool_call.RetrievalToolCall.retrieval","title":"retrieval  <code>instance-attribute</code>","text":"<pre><code>retrieval: object\n</code></pre> <p>For now, this is always going to be an empty object.</p>"},{"location":"reference/types/beta/threads/runs/retrieval_tool_call/#src.openai.types.beta.threads.runs.retrieval_tool_call.RetrievalToolCall.type","title":"type  <code>instance-attribute</code>","text":"<pre><code>type: Literal['retrieval']\n</code></pre> <p>The type of tool call.</p> <p>This is always going to be <code>retrieval</code> for this type of tool call.</p>"},{"location":"reference/types/beta/threads/runs/run_step/","title":"run_step","text":"<p>Classes:</p> Name Description <code>LastError</code> <code>RunStep</code> <code>Usage</code> <p>Attributes:</p> Name Type Description <code>StepDetails</code>"},{"location":"reference/types/beta/threads/runs/run_step/#src.openai.types.beta.threads.runs.run_step.StepDetails","title":"StepDetails  <code>module-attribute</code>","text":"<pre><code>StepDetails = Union[\n    MessageCreationStepDetails, ToolCallsStepDetails\n]\n</code></pre>"},{"location":"reference/types/beta/threads/runs/run_step/#src.openai.types.beta.threads.runs.run_step.LastError","title":"LastError","text":"<p>Attributes:</p> Name Type Description <code>code</code> <code>Literal['server_error', 'rate_limit_exceeded']</code> <p>One of <code>server_error</code> or <code>rate_limit_exceeded</code>.</p> <code>message</code> <code>str</code> <p>A human-readable description of the error.</p>"},{"location":"reference/types/beta/threads/runs/run_step/#src.openai.types.beta.threads.runs.run_step.LastError.code","title":"code  <code>instance-attribute</code>","text":"<pre><code>code: Literal['server_error', 'rate_limit_exceeded']\n</code></pre> <p>One of <code>server_error</code> or <code>rate_limit_exceeded</code>.</p>"},{"location":"reference/types/beta/threads/runs/run_step/#src.openai.types.beta.threads.runs.run_step.LastError.message","title":"message  <code>instance-attribute</code>","text":"<pre><code>message: str\n</code></pre> <p>A human-readable description of the error.</p>"},{"location":"reference/types/beta/threads/runs/run_step/#src.openai.types.beta.threads.runs.run_step.RunStep","title":"RunStep","text":"<p>Attributes:</p> Name Type Description <code>assistant_id</code> <code>str</code> <p>The ID of the</p> <code>cancelled_at</code> <code>Optional[int]</code> <p>The Unix timestamp (in seconds) for when the run step was cancelled.</p> <code>completed_at</code> <code>Optional[int]</code> <p>The Unix timestamp (in seconds) for when the run step completed.</p> <code>created_at</code> <code>int</code> <p>The Unix timestamp (in seconds) for when the run step was created.</p> <code>expired_at</code> <code>Optional[int]</code> <p>The Unix timestamp (in seconds) for when the run step expired.</p> <code>failed_at</code> <code>Optional[int]</code> <p>The Unix timestamp (in seconds) for when the run step failed.</p> <code>id</code> <code>str</code> <p>The identifier of the run step, which can be referenced in API endpoints.</p> <code>last_error</code> <code>Optional[LastError]</code> <p>The last error associated with this run step.</p> <code>metadata</code> <code>Optional[object]</code> <p>Set of 16 key-value pairs that can be attached to an object.</p> <code>object</code> <code>Literal['thread.run.step']</code> <p>The object type, which is always <code>thread.run.step</code>.</p> <code>run_id</code> <code>str</code> <p>The ID of the run that</p> <code>status</code> <code>Literal['in_progress', 'cancelled', 'failed', 'completed', 'expired']</code> <p>The status of the run step, which can be either <code>in_progress</code>, <code>cancelled</code>,</p> <code>step_details</code> <code>StepDetails</code> <p>The details of the run step.</p> <code>thread_id</code> <code>str</code> <p>The ID of the thread</p> <code>type</code> <code>Literal['message_creation', 'tool_calls']</code> <p>The type of run step, which can be either <code>message_creation</code> or <code>tool_calls</code>.</p> <code>usage</code> <code>Optional[Usage]</code> <p>Usage statistics related to the run step.</p>"},{"location":"reference/types/beta/threads/runs/run_step/#src.openai.types.beta.threads.runs.run_step.RunStep.assistant_id","title":"assistant_id  <code>instance-attribute</code>","text":"<pre><code>assistant_id: str\n</code></pre> <p>The ID of the assistant associated with the run step.</p>"},{"location":"reference/types/beta/threads/runs/run_step/#src.openai.types.beta.threads.runs.run_step.RunStep.cancelled_at","title":"cancelled_at  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>cancelled_at: Optional[int] = None\n</code></pre> <p>The Unix timestamp (in seconds) for when the run step was cancelled.</p>"},{"location":"reference/types/beta/threads/runs/run_step/#src.openai.types.beta.threads.runs.run_step.RunStep.completed_at","title":"completed_at  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>completed_at: Optional[int] = None\n</code></pre> <p>The Unix timestamp (in seconds) for when the run step completed.</p>"},{"location":"reference/types/beta/threads/runs/run_step/#src.openai.types.beta.threads.runs.run_step.RunStep.created_at","title":"created_at  <code>instance-attribute</code>","text":"<pre><code>created_at: int\n</code></pre> <p>The Unix timestamp (in seconds) for when the run step was created.</p>"},{"location":"reference/types/beta/threads/runs/run_step/#src.openai.types.beta.threads.runs.run_step.RunStep.expired_at","title":"expired_at  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>expired_at: Optional[int] = None\n</code></pre> <p>The Unix timestamp (in seconds) for when the run step expired.</p> <p>A step is considered expired if the parent run is expired.</p>"},{"location":"reference/types/beta/threads/runs/run_step/#src.openai.types.beta.threads.runs.run_step.RunStep.failed_at","title":"failed_at  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>failed_at: Optional[int] = None\n</code></pre> <p>The Unix timestamp (in seconds) for when the run step failed.</p>"},{"location":"reference/types/beta/threads/runs/run_step/#src.openai.types.beta.threads.runs.run_step.RunStep.id","title":"id  <code>instance-attribute</code>","text":"<pre><code>id: str\n</code></pre> <p>The identifier of the run step, which can be referenced in API endpoints.</p>"},{"location":"reference/types/beta/threads/runs/run_step/#src.openai.types.beta.threads.runs.run_step.RunStep.last_error","title":"last_error  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>last_error: Optional[LastError] = None\n</code></pre> <p>The last error associated with this run step.</p> <p>Will be <code>null</code> if there are no errors.</p>"},{"location":"reference/types/beta/threads/runs/run_step/#src.openai.types.beta.threads.runs.run_step.RunStep.metadata","title":"metadata  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>metadata: Optional[object] = None\n</code></pre> <p>Set of 16 key-value pairs that can be attached to an object.</p> <p>This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.</p>"},{"location":"reference/types/beta/threads/runs/run_step/#src.openai.types.beta.threads.runs.run_step.RunStep.object","title":"object  <code>instance-attribute</code>","text":"<pre><code>object: Literal['thread.run.step']\n</code></pre> <p>The object type, which is always <code>thread.run.step</code>.</p>"},{"location":"reference/types/beta/threads/runs/run_step/#src.openai.types.beta.threads.runs.run_step.RunStep.run_id","title":"run_id  <code>instance-attribute</code>","text":"<pre><code>run_id: str\n</code></pre> <p>The ID of the run that this run step is a part of.</p>"},{"location":"reference/types/beta/threads/runs/run_step/#src.openai.types.beta.threads.runs.run_step.RunStep.status","title":"status  <code>instance-attribute</code>","text":"<pre><code>status: Literal[\n    \"in_progress\",\n    \"cancelled\",\n    \"failed\",\n    \"completed\",\n    \"expired\",\n]\n</code></pre> <p>The status of the run step, which can be either <code>in_progress</code>, <code>cancelled</code>, <code>failed</code>, <code>completed</code>, or <code>expired</code>.</p>"},{"location":"reference/types/beta/threads/runs/run_step/#src.openai.types.beta.threads.runs.run_step.RunStep.step_details","title":"step_details  <code>instance-attribute</code>","text":"<pre><code>step_details: StepDetails\n</code></pre> <p>The details of the run step.</p>"},{"location":"reference/types/beta/threads/runs/run_step/#src.openai.types.beta.threads.runs.run_step.RunStep.thread_id","title":"thread_id  <code>instance-attribute</code>","text":"<pre><code>thread_id: str\n</code></pre> <p>The ID of the thread that was run.</p>"},{"location":"reference/types/beta/threads/runs/run_step/#src.openai.types.beta.threads.runs.run_step.RunStep.type","title":"type  <code>instance-attribute</code>","text":"<pre><code>type: Literal['message_creation', 'tool_calls']\n</code></pre> <p>The type of run step, which can be either <code>message_creation</code> or <code>tool_calls</code>.</p>"},{"location":"reference/types/beta/threads/runs/run_step/#src.openai.types.beta.threads.runs.run_step.RunStep.usage","title":"usage  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>usage: Optional[Usage] = None\n</code></pre> <p>Usage statistics related to the run step.</p> <p>This value will be <code>null</code> while the run step's status is <code>in_progress</code>.</p>"},{"location":"reference/types/beta/threads/runs/run_step/#src.openai.types.beta.threads.runs.run_step.Usage","title":"Usage","text":"<p>Attributes:</p> Name Type Description <code>completion_tokens</code> <code>int</code> <p>Number of completion tokens used over the course of the run step.</p> <code>prompt_tokens</code> <code>int</code> <p>Number of prompt tokens used over the course of the run step.</p> <code>total_tokens</code> <code>int</code> <p>Total number of tokens used (prompt + completion).</p>"},{"location":"reference/types/beta/threads/runs/run_step/#src.openai.types.beta.threads.runs.run_step.Usage.completion_tokens","title":"completion_tokens  <code>instance-attribute</code>","text":"<pre><code>completion_tokens: int\n</code></pre> <p>Number of completion tokens used over the course of the run step.</p>"},{"location":"reference/types/beta/threads/runs/run_step/#src.openai.types.beta.threads.runs.run_step.Usage.prompt_tokens","title":"prompt_tokens  <code>instance-attribute</code>","text":"<pre><code>prompt_tokens: int\n</code></pre> <p>Number of prompt tokens used over the course of the run step.</p>"},{"location":"reference/types/beta/threads/runs/run_step/#src.openai.types.beta.threads.runs.run_step.Usage.total_tokens","title":"total_tokens  <code>instance-attribute</code>","text":"<pre><code>total_tokens: int\n</code></pre> <p>Total number of tokens used (prompt + completion).</p>"},{"location":"reference/types/beta/threads/runs/step_list_params/","title":"step_list_params","text":"<p>Classes:</p> Name Description <code>StepListParams</code>"},{"location":"reference/types/beta/threads/runs/step_list_params/#src.openai.types.beta.threads.runs.step_list_params.StepListParams","title":"StepListParams","text":"<p>Attributes:</p> Name Type Description <code>after</code> <code>str</code> <p>A cursor for use in pagination.</p> <code>before</code> <code>str</code> <p>A cursor for use in pagination.</p> <code>limit</code> <code>int</code> <p>A limit on the number of objects to be returned.</p> <code>order</code> <code>Literal['asc', 'desc']</code> <p>Sort order by the <code>created_at</code> timestamp of the objects.</p> <code>thread_id</code> <code>Required[str]</code>"},{"location":"reference/types/beta/threads/runs/step_list_params/#src.openai.types.beta.threads.runs.step_list_params.StepListParams.after","title":"after  <code>instance-attribute</code>","text":"<pre><code>after: str\n</code></pre> <p>A cursor for use in pagination.</p> <p><code>after</code> is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.</p>"},{"location":"reference/types/beta/threads/runs/step_list_params/#src.openai.types.beta.threads.runs.step_list_params.StepListParams.before","title":"before  <code>instance-attribute</code>","text":"<pre><code>before: str\n</code></pre> <p>A cursor for use in pagination.</p> <p><code>before</code> is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include before=obj_foo in order to fetch the previous page of the list.</p>"},{"location":"reference/types/beta/threads/runs/step_list_params/#src.openai.types.beta.threads.runs.step_list_params.StepListParams.limit","title":"limit  <code>instance-attribute</code>","text":"<pre><code>limit: int\n</code></pre> <p>A limit on the number of objects to be returned.</p> <p>Limit can range between 1 and 100, and the default is 20.</p>"},{"location":"reference/types/beta/threads/runs/step_list_params/#src.openai.types.beta.threads.runs.step_list_params.StepListParams.order","title":"order  <code>instance-attribute</code>","text":"<pre><code>order: Literal['asc', 'desc']\n</code></pre> <p>Sort order by the <code>created_at</code> timestamp of the objects.</p> <p><code>asc</code> for ascending order and <code>desc</code> for descending order.</p>"},{"location":"reference/types/beta/threads/runs/step_list_params/#src.openai.types.beta.threads.runs.step_list_params.StepListParams.thread_id","title":"thread_id  <code>instance-attribute</code>","text":"<pre><code>thread_id: Required[str]\n</code></pre>"},{"location":"reference/types/beta/threads/runs/tool_calls_step_details/","title":"tool_calls_step_details","text":"<p>Classes:</p> Name Description <code>ToolCallsStepDetails</code> <p>Attributes:</p> Name Type Description <code>ToolCall</code>"},{"location":"reference/types/beta/threads/runs/tool_calls_step_details/#src.openai.types.beta.threads.runs.tool_calls_step_details.ToolCall","title":"ToolCall  <code>module-attribute</code>","text":"<pre><code>ToolCall = Union[\n    CodeToolCall, RetrievalToolCall, FunctionToolCall\n]\n</code></pre>"},{"location":"reference/types/beta/threads/runs/tool_calls_step_details/#src.openai.types.beta.threads.runs.tool_calls_step_details.ToolCallsStepDetails","title":"ToolCallsStepDetails","text":"<p>Attributes:</p> Name Type Description <code>tool_calls</code> <code>List[ToolCall]</code> <p>An array of tool calls the run step was involved in.</p> <code>type</code> <code>Literal['tool_calls']</code> <p>Always <code>tool_calls</code>.</p>"},{"location":"reference/types/beta/threads/runs/tool_calls_step_details/#src.openai.types.beta.threads.runs.tool_calls_step_details.ToolCallsStepDetails.tool_calls","title":"tool_calls  <code>instance-attribute</code>","text":"<pre><code>tool_calls: List[ToolCall]\n</code></pre> <p>An array of tool calls the run step was involved in.</p> <p>These can be associated with one of three types of tools: <code>code_interpreter</code>, <code>retrieval</code>, or <code>function</code>.</p>"},{"location":"reference/types/beta/threads/runs/tool_calls_step_details/#src.openai.types.beta.threads.runs.tool_calls_step_details.ToolCallsStepDetails.type","title":"type  <code>instance-attribute</code>","text":"<pre><code>type: Literal['tool_calls']\n</code></pre> <p>Always <code>tool_calls</code>.</p>"},{"location":"reference/types/chat/","title":"Index","text":"<p>Modules:</p> Name Description <code>chat_completion</code> <code>chat_completion_assistant_message_param</code> <code>chat_completion_chunk</code> <code>chat_completion_content_part_image_param</code> <code>chat_completion_content_part_param</code> <code>chat_completion_content_part_text_param</code> <code>chat_completion_function_call_option_param</code> <code>chat_completion_function_message_param</code> <code>chat_completion_message</code> <code>chat_completion_message_param</code> <code>chat_completion_message_tool_call</code> <code>chat_completion_message_tool_call_param</code> <code>chat_completion_named_tool_choice_param</code> <code>chat_completion_role</code> <code>chat_completion_system_message_param</code> <code>chat_completion_token_logprob</code> <code>chat_completion_tool_choice_option_param</code> <code>chat_completion_tool_message_param</code> <code>chat_completion_tool_param</code> <code>chat_completion_user_message_param</code> <code>completion_create_params</code>"},{"location":"reference/types/chat/chat_completion/","title":"chat_completion","text":"<p>Classes:</p> Name Description <code>ChatCompletion</code> <code>Choice</code> <code>ChoiceLogprobs</code>"},{"location":"reference/types/chat/chat_completion/#src.openai.types.chat.chat_completion.ChatCompletion","title":"ChatCompletion","text":"<p>Attributes:</p> Name Type Description <code>choices</code> <code>List[Choice]</code> <p>A list of chat completion choices.</p> <code>created</code> <code>int</code> <p>The Unix timestamp (in seconds) of when the chat completion was created.</p> <code>id</code> <code>str</code> <p>A unique identifier for the chat completion.</p> <code>model</code> <code>str</code> <p>The model used for the chat completion.</p> <code>object</code> <code>Literal['chat.completion']</code> <p>The object type, which is always <code>chat.completion</code>.</p> <code>system_fingerprint</code> <code>Optional[str]</code> <p>This fingerprint represents the backend configuration that the model runs with.</p> <code>usage</code> <code>Optional[CompletionUsage]</code> <p>Usage statistics for the completion request.</p>"},{"location":"reference/types/chat/chat_completion/#src.openai.types.chat.chat_completion.ChatCompletion.choices","title":"choices  <code>instance-attribute</code>","text":"<pre><code>choices: List[Choice]\n</code></pre> <p>A list of chat completion choices.</p> <p>Can be more than one if <code>n</code> is greater than 1.</p>"},{"location":"reference/types/chat/chat_completion/#src.openai.types.chat.chat_completion.ChatCompletion.created","title":"created  <code>instance-attribute</code>","text":"<pre><code>created: int\n</code></pre> <p>The Unix timestamp (in seconds) of when the chat completion was created.</p>"},{"location":"reference/types/chat/chat_completion/#src.openai.types.chat.chat_completion.ChatCompletion.id","title":"id  <code>instance-attribute</code>","text":"<pre><code>id: str\n</code></pre> <p>A unique identifier for the chat completion.</p>"},{"location":"reference/types/chat/chat_completion/#src.openai.types.chat.chat_completion.ChatCompletion.model","title":"model  <code>instance-attribute</code>","text":"<pre><code>model: str\n</code></pre> <p>The model used for the chat completion.</p>"},{"location":"reference/types/chat/chat_completion/#src.openai.types.chat.chat_completion.ChatCompletion.object","title":"object  <code>instance-attribute</code>","text":"<pre><code>object: Literal['chat.completion']\n</code></pre> <p>The object type, which is always <code>chat.completion</code>.</p>"},{"location":"reference/types/chat/chat_completion/#src.openai.types.chat.chat_completion.ChatCompletion.system_fingerprint","title":"system_fingerprint  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>system_fingerprint: Optional[str] = None\n</code></pre> <p>This fingerprint represents the backend configuration that the model runs with.</p> <p>Can be used in conjunction with the <code>seed</code> request parameter to understand when backend changes have been made that might impact determinism.</p>"},{"location":"reference/types/chat/chat_completion/#src.openai.types.chat.chat_completion.ChatCompletion.usage","title":"usage  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>usage: Optional[CompletionUsage] = None\n</code></pre> <p>Usage statistics for the completion request.</p>"},{"location":"reference/types/chat/chat_completion/#src.openai.types.chat.chat_completion.Choice","title":"Choice","text":"<p>Attributes:</p> Name Type Description <code>finish_reason</code> <code>Literal['stop', 'length', 'tool_calls', 'content_filter', 'function_call']</code> <p>The reason the model stopped generating tokens.</p> <code>index</code> <code>int</code> <p>The index of the choice in the list of choices.</p> <code>logprobs</code> <code>Optional[ChoiceLogprobs]</code> <p>Log probability information for the choice.</p> <code>message</code> <code>ChatCompletionMessage</code> <p>A chat completion message generated by the model.</p>"},{"location":"reference/types/chat/chat_completion/#src.openai.types.chat.chat_completion.Choice.finish_reason","title":"finish_reason  <code>instance-attribute</code>","text":"<pre><code>finish_reason: Literal[\n    \"stop\",\n    \"length\",\n    \"tool_calls\",\n    \"content_filter\",\n    \"function_call\",\n]\n</code></pre> <p>The reason the model stopped generating tokens.</p> <p>This will be <code>stop</code> if the model hit a natural stop point or a provided stop sequence, <code>length</code> if the maximum number of tokens specified in the request was reached, <code>content_filter</code> if content was omitted due to a flag from our content filters, <code>tool_calls</code> if the model called a tool, or <code>function_call</code> (deprecated) if the model called a function.</p>"},{"location":"reference/types/chat/chat_completion/#src.openai.types.chat.chat_completion.Choice.index","title":"index  <code>instance-attribute</code>","text":"<pre><code>index: int\n</code></pre> <p>The index of the choice in the list of choices.</p>"},{"location":"reference/types/chat/chat_completion/#src.openai.types.chat.chat_completion.Choice.logprobs","title":"logprobs  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>logprobs: Optional[ChoiceLogprobs] = None\n</code></pre> <p>Log probability information for the choice.</p>"},{"location":"reference/types/chat/chat_completion/#src.openai.types.chat.chat_completion.Choice.message","title":"message  <code>instance-attribute</code>","text":"<pre><code>message: ChatCompletionMessage\n</code></pre> <p>A chat completion message generated by the model.</p>"},{"location":"reference/types/chat/chat_completion/#src.openai.types.chat.chat_completion.ChoiceLogprobs","title":"ChoiceLogprobs","text":"<p>Attributes:</p> Name Type Description <code>content</code> <code>Optional[List[ChatCompletionTokenLogprob]]</code> <p>A list of message content tokens with log probability information.</p>"},{"location":"reference/types/chat/chat_completion/#src.openai.types.chat.chat_completion.ChoiceLogprobs.content","title":"content  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>content: Optional[List[ChatCompletionTokenLogprob]] = None\n</code></pre> <p>A list of message content tokens with log probability information.</p>"},{"location":"reference/types/chat/chat_completion_assistant_message_param/","title":"chat_completion_assistant_message_param","text":"<p>Classes:</p> Name Description <code>ChatCompletionAssistantMessageParam</code> <code>FunctionCall</code>"},{"location":"reference/types/chat/chat_completion_assistant_message_param/#src.openai.types.chat.chat_completion_assistant_message_param.ChatCompletionAssistantMessageParam","title":"ChatCompletionAssistantMessageParam","text":"<p>Attributes:</p> Name Type Description <code>content</code> <code>Optional[str]</code> <p>The contents of the assistant message.</p> <code>function_call</code> <code>FunctionCall</code> <p>Deprecated and replaced by <code>tool_calls</code>.</p> <code>name</code> <code>str</code> <p>An optional name for the participant.</p> <code>role</code> <code>Required[Literal['assistant']]</code> <p>The role of the messages author, in this case <code>assistant</code>.</p> <code>tool_calls</code> <code>Iterable[ChatCompletionMessageToolCallParam]</code> <p>The tool calls generated by the model, such as function calls.</p>"},{"location":"reference/types/chat/chat_completion_assistant_message_param/#src.openai.types.chat.chat_completion_assistant_message_param.ChatCompletionAssistantMessageParam.content","title":"content  <code>instance-attribute</code>","text":"<pre><code>content: Optional[str]\n</code></pre> <p>The contents of the assistant message.</p> <p>Required unless <code>tool_calls</code> or <code>function_call</code> is specified.</p>"},{"location":"reference/types/chat/chat_completion_assistant_message_param/#src.openai.types.chat.chat_completion_assistant_message_param.ChatCompletionAssistantMessageParam.function_call","title":"function_call  <code>instance-attribute</code>","text":"<pre><code>function_call: FunctionCall\n</code></pre> <p>Deprecated and replaced by <code>tool_calls</code>.</p> <p>The name and arguments of a function that should be called, as generated by the model.</p>"},{"location":"reference/types/chat/chat_completion_assistant_message_param/#src.openai.types.chat.chat_completion_assistant_message_param.ChatCompletionAssistantMessageParam.name","title":"name  <code>instance-attribute</code>","text":"<pre><code>name: str\n</code></pre> <p>An optional name for the participant.</p> <p>Provides the model information to differentiate between participants of the same role.</p>"},{"location":"reference/types/chat/chat_completion_assistant_message_param/#src.openai.types.chat.chat_completion_assistant_message_param.ChatCompletionAssistantMessageParam.role","title":"role  <code>instance-attribute</code>","text":"<pre><code>role: Required[Literal['assistant']]\n</code></pre> <p>The role of the messages author, in this case <code>assistant</code>.</p>"},{"location":"reference/types/chat/chat_completion_assistant_message_param/#src.openai.types.chat.chat_completion_assistant_message_param.ChatCompletionAssistantMessageParam.tool_calls","title":"tool_calls  <code>instance-attribute</code>","text":"<pre><code>tool_calls: Iterable[ChatCompletionMessageToolCallParam]\n</code></pre> <p>The tool calls generated by the model, such as function calls.</p>"},{"location":"reference/types/chat/chat_completion_assistant_message_param/#src.openai.types.chat.chat_completion_assistant_message_param.FunctionCall","title":"FunctionCall","text":"<p>Attributes:</p> Name Type Description <code>arguments</code> <code>Required[str]</code> <p>The arguments to call the function with, as generated by the model in JSON</p> <code>name</code> <code>Required[str]</code> <p>The name of the function to call.</p>"},{"location":"reference/types/chat/chat_completion_assistant_message_param/#src.openai.types.chat.chat_completion_assistant_message_param.FunctionCall.arguments","title":"arguments  <code>instance-attribute</code>","text":"<pre><code>arguments: Required[str]\n</code></pre> <p>The arguments to call the function with, as generated by the model in JSON format. Note that the model does not always generate valid JSON, and may hallucinate parameters not defined by your function schema. Validate the arguments in your code before calling your function.</p>"},{"location":"reference/types/chat/chat_completion_assistant_message_param/#src.openai.types.chat.chat_completion_assistant_message_param.FunctionCall.name","title":"name  <code>instance-attribute</code>","text":"<pre><code>name: Required[str]\n</code></pre> <p>The name of the function to call.</p>"},{"location":"reference/types/chat/chat_completion_chunk/","title":"chat_completion_chunk","text":"<p>Classes:</p> Name Description <code>ChatCompletionChunk</code> <code>Choice</code> <code>ChoiceDelta</code> <code>ChoiceDeltaFunctionCall</code> <code>ChoiceDeltaToolCall</code> <code>ChoiceDeltaToolCallFunction</code> <code>ChoiceLogprobs</code>"},{"location":"reference/types/chat/chat_completion_chunk/#src.openai.types.chat.chat_completion_chunk.ChatCompletionChunk","title":"ChatCompletionChunk","text":"<p>Attributes:</p> Name Type Description <code>choices</code> <code>List[Choice]</code> <p>A list of chat completion choices.</p> <code>created</code> <code>int</code> <p>The Unix timestamp (in seconds) of when the chat completion was created.</p> <code>id</code> <code>str</code> <p>A unique identifier for the chat completion. Each chunk has the same ID.</p> <code>model</code> <code>str</code> <p>The model to generate the completion.</p> <code>object</code> <code>Literal['chat.completion.chunk']</code> <p>The object type, which is always <code>chat.completion.chunk</code>.</p> <code>system_fingerprint</code> <code>Optional[str]</code> <p>This fingerprint represents the backend configuration that the model runs with.</p>"},{"location":"reference/types/chat/chat_completion_chunk/#src.openai.types.chat.chat_completion_chunk.ChatCompletionChunk.choices","title":"choices  <code>instance-attribute</code>","text":"<pre><code>choices: List[Choice]\n</code></pre> <p>A list of chat completion choices.</p> <p>Can be more than one if <code>n</code> is greater than 1.</p>"},{"location":"reference/types/chat/chat_completion_chunk/#src.openai.types.chat.chat_completion_chunk.ChatCompletionChunk.created","title":"created  <code>instance-attribute</code>","text":"<pre><code>created: int\n</code></pre> <p>The Unix timestamp (in seconds) of when the chat completion was created.</p> <p>Each chunk has the same timestamp.</p>"},{"location":"reference/types/chat/chat_completion_chunk/#src.openai.types.chat.chat_completion_chunk.ChatCompletionChunk.id","title":"id  <code>instance-attribute</code>","text":"<pre><code>id: str\n</code></pre> <p>A unique identifier for the chat completion. Each chunk has the same ID.</p>"},{"location":"reference/types/chat/chat_completion_chunk/#src.openai.types.chat.chat_completion_chunk.ChatCompletionChunk.model","title":"model  <code>instance-attribute</code>","text":"<pre><code>model: str\n</code></pre> <p>The model to generate the completion.</p>"},{"location":"reference/types/chat/chat_completion_chunk/#src.openai.types.chat.chat_completion_chunk.ChatCompletionChunk.object","title":"object  <code>instance-attribute</code>","text":"<pre><code>object: Literal['chat.completion.chunk']\n</code></pre> <p>The object type, which is always <code>chat.completion.chunk</code>.</p>"},{"location":"reference/types/chat/chat_completion_chunk/#src.openai.types.chat.chat_completion_chunk.ChatCompletionChunk.system_fingerprint","title":"system_fingerprint  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>system_fingerprint: Optional[str] = None\n</code></pre> <p>This fingerprint represents the backend configuration that the model runs with. Can be used in conjunction with the <code>seed</code> request parameter to understand when backend changes have been made that might impact determinism.</p>"},{"location":"reference/types/chat/chat_completion_chunk/#src.openai.types.chat.chat_completion_chunk.Choice","title":"Choice","text":"<p>Attributes:</p> Name Type Description <code>delta</code> <code>ChoiceDelta</code> <p>A chat completion delta generated by streamed model responses.</p> <code>finish_reason</code> <code>Optional[Literal['stop', 'length', 'tool_calls', 'content_filter', 'function_call']]</code> <p>The reason the model stopped generating tokens.</p> <code>index</code> <code>int</code> <p>The index of the choice in the list of choices.</p> <code>logprobs</code> <code>Optional[ChoiceLogprobs]</code> <p>Log probability information for the choice.</p>"},{"location":"reference/types/chat/chat_completion_chunk/#src.openai.types.chat.chat_completion_chunk.Choice.delta","title":"delta  <code>instance-attribute</code>","text":"<pre><code>delta: ChoiceDelta\n</code></pre> <p>A chat completion delta generated by streamed model responses.</p>"},{"location":"reference/types/chat/chat_completion_chunk/#src.openai.types.chat.chat_completion_chunk.Choice.finish_reason","title":"finish_reason  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>finish_reason: Optional[\n    Literal[\n        \"stop\",\n        \"length\",\n        \"tool_calls\",\n        \"content_filter\",\n        \"function_call\",\n    ]\n] = None\n</code></pre> <p>The reason the model stopped generating tokens.</p> <p>This will be <code>stop</code> if the model hit a natural stop point or a provided stop sequence, <code>length</code> if the maximum number of tokens specified in the request was reached, <code>content_filter</code> if content was omitted due to a flag from our content filters, <code>tool_calls</code> if the model called a tool, or <code>function_call</code> (deprecated) if the model called a function.</p>"},{"location":"reference/types/chat/chat_completion_chunk/#src.openai.types.chat.chat_completion_chunk.Choice.index","title":"index  <code>instance-attribute</code>","text":"<pre><code>index: int\n</code></pre> <p>The index of the choice in the list of choices.</p>"},{"location":"reference/types/chat/chat_completion_chunk/#src.openai.types.chat.chat_completion_chunk.Choice.logprobs","title":"logprobs  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>logprobs: Optional[ChoiceLogprobs] = None\n</code></pre> <p>Log probability information for the choice.</p>"},{"location":"reference/types/chat/chat_completion_chunk/#src.openai.types.chat.chat_completion_chunk.ChoiceDelta","title":"ChoiceDelta","text":"<p>Attributes:</p> Name Type Description <code>content</code> <code>Optional[str]</code> <p>The contents of the chunk message.</p> <code>function_call</code> <code>Optional[ChoiceDeltaFunctionCall]</code> <p>Deprecated and replaced by <code>tool_calls</code>.</p> <code>role</code> <code>Optional[Literal['system', 'user', 'assistant', 'tool']]</code> <p>The role of the author of this message.</p> <code>tool_calls</code> <code>Optional[List[ChoiceDeltaToolCall]]</code>"},{"location":"reference/types/chat/chat_completion_chunk/#src.openai.types.chat.chat_completion_chunk.ChoiceDelta.content","title":"content  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>content: Optional[str] = None\n</code></pre> <p>The contents of the chunk message.</p>"},{"location":"reference/types/chat/chat_completion_chunk/#src.openai.types.chat.chat_completion_chunk.ChoiceDelta.function_call","title":"function_call  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>function_call: Optional[ChoiceDeltaFunctionCall] = None\n</code></pre> <p>Deprecated and replaced by <code>tool_calls</code>.</p> <p>The name and arguments of a function that should be called, as generated by the model.</p>"},{"location":"reference/types/chat/chat_completion_chunk/#src.openai.types.chat.chat_completion_chunk.ChoiceDelta.role","title":"role  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>role: Optional[\n    Literal[\"system\", \"user\", \"assistant\", \"tool\"]\n] = None\n</code></pre> <p>The role of the author of this message.</p>"},{"location":"reference/types/chat/chat_completion_chunk/#src.openai.types.chat.chat_completion_chunk.ChoiceDelta.tool_calls","title":"tool_calls  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>tool_calls: Optional[List[ChoiceDeltaToolCall]] = None\n</code></pre>"},{"location":"reference/types/chat/chat_completion_chunk/#src.openai.types.chat.chat_completion_chunk.ChoiceDeltaFunctionCall","title":"ChoiceDeltaFunctionCall","text":"<p>Attributes:</p> Name Type Description <code>arguments</code> <code>Optional[str]</code> <p>The arguments to call the function with, as generated by the model in JSON</p> <code>name</code> <code>Optional[str]</code> <p>The name of the function to call.</p>"},{"location":"reference/types/chat/chat_completion_chunk/#src.openai.types.chat.chat_completion_chunk.ChoiceDeltaFunctionCall.arguments","title":"arguments  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>arguments: Optional[str] = None\n</code></pre> <p>The arguments to call the function with, as generated by the model in JSON format. Note that the model does not always generate valid JSON, and may hallucinate parameters not defined by your function schema. Validate the arguments in your code before calling your function.</p>"},{"location":"reference/types/chat/chat_completion_chunk/#src.openai.types.chat.chat_completion_chunk.ChoiceDeltaFunctionCall.name","title":"name  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>name: Optional[str] = None\n</code></pre> <p>The name of the function to call.</p>"},{"location":"reference/types/chat/chat_completion_chunk/#src.openai.types.chat.chat_completion_chunk.ChoiceDeltaToolCall","title":"ChoiceDeltaToolCall","text":"<p>Attributes:</p> Name Type Description <code>function</code> <code>Optional[ChoiceDeltaToolCallFunction]</code> <code>id</code> <code>Optional[str]</code> <p>The ID of the tool call.</p> <code>index</code> <code>int</code> <code>type</code> <code>Optional[Literal['function']]</code> <p>The type of the tool. Currently, only <code>function</code> is supported.</p>"},{"location":"reference/types/chat/chat_completion_chunk/#src.openai.types.chat.chat_completion_chunk.ChoiceDeltaToolCall.function","title":"function  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>function: Optional[ChoiceDeltaToolCallFunction] = None\n</code></pre>"},{"location":"reference/types/chat/chat_completion_chunk/#src.openai.types.chat.chat_completion_chunk.ChoiceDeltaToolCall.id","title":"id  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>id: Optional[str] = None\n</code></pre> <p>The ID of the tool call.</p>"},{"location":"reference/types/chat/chat_completion_chunk/#src.openai.types.chat.chat_completion_chunk.ChoiceDeltaToolCall.index","title":"index  <code>instance-attribute</code>","text":"<pre><code>index: int\n</code></pre>"},{"location":"reference/types/chat/chat_completion_chunk/#src.openai.types.chat.chat_completion_chunk.ChoiceDeltaToolCall.type","title":"type  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>type: Optional[Literal['function']] = None\n</code></pre> <p>The type of the tool. Currently, only <code>function</code> is supported.</p>"},{"location":"reference/types/chat/chat_completion_chunk/#src.openai.types.chat.chat_completion_chunk.ChoiceDeltaToolCallFunction","title":"ChoiceDeltaToolCallFunction","text":"<p>Attributes:</p> Name Type Description <code>arguments</code> <code>Optional[str]</code> <p>The arguments to call the function with, as generated by the model in JSON</p> <code>name</code> <code>Optional[str]</code> <p>The name of the function to call.</p>"},{"location":"reference/types/chat/chat_completion_chunk/#src.openai.types.chat.chat_completion_chunk.ChoiceDeltaToolCallFunction.arguments","title":"arguments  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>arguments: Optional[str] = None\n</code></pre> <p>The arguments to call the function with, as generated by the model in JSON format. Note that the model does not always generate valid JSON, and may hallucinate parameters not defined by your function schema. Validate the arguments in your code before calling your function.</p>"},{"location":"reference/types/chat/chat_completion_chunk/#src.openai.types.chat.chat_completion_chunk.ChoiceDeltaToolCallFunction.name","title":"name  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>name: Optional[str] = None\n</code></pre> <p>The name of the function to call.</p>"},{"location":"reference/types/chat/chat_completion_chunk/#src.openai.types.chat.chat_completion_chunk.ChoiceLogprobs","title":"ChoiceLogprobs","text":"<p>Attributes:</p> Name Type Description <code>content</code> <code>Optional[List[ChatCompletionTokenLogprob]]</code> <p>A list of message content tokens with log probability information.</p>"},{"location":"reference/types/chat/chat_completion_chunk/#src.openai.types.chat.chat_completion_chunk.ChoiceLogprobs.content","title":"content  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>content: Optional[List[ChatCompletionTokenLogprob]] = None\n</code></pre> <p>A list of message content tokens with log probability information.</p>"},{"location":"reference/types/chat/chat_completion_content_part_image_param/","title":"chat_completion_content_part_image_param","text":"<p>Classes:</p> Name Description <code>ChatCompletionContentPartImageParam</code> <code>ImageURL</code>"},{"location":"reference/types/chat/chat_completion_content_part_image_param/#src.openai.types.chat.chat_completion_content_part_image_param.ChatCompletionContentPartImageParam","title":"ChatCompletionContentPartImageParam","text":"<p>Attributes:</p> Name Type Description <code>image_url</code> <code>Required[ImageURL]</code> <code>type</code> <code>Required[Literal['image_url']]</code> <p>The type of the content part.</p>"},{"location":"reference/types/chat/chat_completion_content_part_image_param/#src.openai.types.chat.chat_completion_content_part_image_param.ChatCompletionContentPartImageParam.image_url","title":"image_url  <code>instance-attribute</code>","text":"<pre><code>image_url: Required[ImageURL]\n</code></pre>"},{"location":"reference/types/chat/chat_completion_content_part_image_param/#src.openai.types.chat.chat_completion_content_part_image_param.ChatCompletionContentPartImageParam.type","title":"type  <code>instance-attribute</code>","text":"<pre><code>type: Required[Literal['image_url']]\n</code></pre> <p>The type of the content part.</p>"},{"location":"reference/types/chat/chat_completion_content_part_image_param/#src.openai.types.chat.chat_completion_content_part_image_param.ImageURL","title":"ImageURL","text":"<p>Attributes:</p> Name Type Description <code>detail</code> <code>Literal['auto', 'low', 'high']</code> <p>Specifies the detail level of the image.</p> <code>url</code> <code>Required[str]</code> <p>Either a URL of the image or the base64 encoded image data.</p>"},{"location":"reference/types/chat/chat_completion_content_part_image_param/#src.openai.types.chat.chat_completion_content_part_image_param.ImageURL.detail","title":"detail  <code>instance-attribute</code>","text":"<pre><code>detail: Literal['auto', 'low', 'high']\n</code></pre> <p>Specifies the detail level of the image.</p> <p>Learn more in the Vision guide.</p>"},{"location":"reference/types/chat/chat_completion_content_part_image_param/#src.openai.types.chat.chat_completion_content_part_image_param.ImageURL.url","title":"url  <code>instance-attribute</code>","text":"<pre><code>url: Required[str]\n</code></pre> <p>Either a URL of the image or the base64 encoded image data.</p>"},{"location":"reference/types/chat/chat_completion_content_part_param/","title":"chat_completion_content_part_param","text":"<p>Attributes:</p> Name Type Description <code>ChatCompletionContentPartParam</code>"},{"location":"reference/types/chat/chat_completion_content_part_param/#src.openai.types.chat.chat_completion_content_part_param.ChatCompletionContentPartParam","title":"ChatCompletionContentPartParam  <code>module-attribute</code>","text":"<pre><code>ChatCompletionContentPartParam = Union[\n    ChatCompletionContentPartTextParam,\n    ChatCompletionContentPartImageParam,\n]\n</code></pre>"},{"location":"reference/types/chat/chat_completion_content_part_text_param/","title":"chat_completion_content_part_text_param","text":"<p>Classes:</p> Name Description <code>ChatCompletionContentPartTextParam</code>"},{"location":"reference/types/chat/chat_completion_content_part_text_param/#src.openai.types.chat.chat_completion_content_part_text_param.ChatCompletionContentPartTextParam","title":"ChatCompletionContentPartTextParam","text":"<p>Attributes:</p> Name Type Description <code>text</code> <code>Required[str]</code> <p>The text content.</p> <code>type</code> <code>Required[Literal['text']]</code> <p>The type of the content part.</p>"},{"location":"reference/types/chat/chat_completion_content_part_text_param/#src.openai.types.chat.chat_completion_content_part_text_param.ChatCompletionContentPartTextParam.text","title":"text  <code>instance-attribute</code>","text":"<pre><code>text: Required[str]\n</code></pre> <p>The text content.</p>"},{"location":"reference/types/chat/chat_completion_content_part_text_param/#src.openai.types.chat.chat_completion_content_part_text_param.ChatCompletionContentPartTextParam.type","title":"type  <code>instance-attribute</code>","text":"<pre><code>type: Required[Literal['text']]\n</code></pre> <p>The type of the content part.</p>"},{"location":"reference/types/chat/chat_completion_function_call_option_param/","title":"chat_completion_function_call_option_param","text":"<p>Classes:</p> Name Description <code>ChatCompletionFunctionCallOptionParam</code>"},{"location":"reference/types/chat/chat_completion_function_call_option_param/#src.openai.types.chat.chat_completion_function_call_option_param.ChatCompletionFunctionCallOptionParam","title":"ChatCompletionFunctionCallOptionParam","text":"<p>Attributes:</p> Name Type Description <code>name</code> <code>Required[str]</code> <p>The name of the function to call.</p>"},{"location":"reference/types/chat/chat_completion_function_call_option_param/#src.openai.types.chat.chat_completion_function_call_option_param.ChatCompletionFunctionCallOptionParam.name","title":"name  <code>instance-attribute</code>","text":"<pre><code>name: Required[str]\n</code></pre> <p>The name of the function to call.</p>"},{"location":"reference/types/chat/chat_completion_function_message_param/","title":"chat_completion_function_message_param","text":"<p>Classes:</p> Name Description <code>ChatCompletionFunctionMessageParam</code>"},{"location":"reference/types/chat/chat_completion_function_message_param/#src.openai.types.chat.chat_completion_function_message_param.ChatCompletionFunctionMessageParam","title":"ChatCompletionFunctionMessageParam","text":"<p>Attributes:</p> Name Type Description <code>content</code> <code>Required[Optional[str]]</code> <p>The contents of the function message.</p> <code>name</code> <code>Required[str]</code> <p>The name of the function to call.</p> <code>role</code> <code>Required[Literal['function']]</code> <p>The role of the messages author, in this case <code>function</code>.</p>"},{"location":"reference/types/chat/chat_completion_function_message_param/#src.openai.types.chat.chat_completion_function_message_param.ChatCompletionFunctionMessageParam.content","title":"content  <code>instance-attribute</code>","text":"<pre><code>content: Required[Optional[str]]\n</code></pre> <p>The contents of the function message.</p>"},{"location":"reference/types/chat/chat_completion_function_message_param/#src.openai.types.chat.chat_completion_function_message_param.ChatCompletionFunctionMessageParam.name","title":"name  <code>instance-attribute</code>","text":"<pre><code>name: Required[str]\n</code></pre> <p>The name of the function to call.</p>"},{"location":"reference/types/chat/chat_completion_function_message_param/#src.openai.types.chat.chat_completion_function_message_param.ChatCompletionFunctionMessageParam.role","title":"role  <code>instance-attribute</code>","text":"<pre><code>role: Required[Literal['function']]\n</code></pre> <p>The role of the messages author, in this case <code>function</code>.</p>"},{"location":"reference/types/chat/chat_completion_message/","title":"chat_completion_message","text":"<p>Classes:</p> Name Description <code>ChatCompletionMessage</code> <code>FunctionCall</code>"},{"location":"reference/types/chat/chat_completion_message/#src.openai.types.chat.chat_completion_message.ChatCompletionMessage","title":"ChatCompletionMessage","text":"<p>Attributes:</p> Name Type Description <code>content</code> <code>Optional[str]</code> <p>The contents of the message.</p> <code>function_call</code> <code>Optional[FunctionCall]</code> <p>Deprecated and replaced by <code>tool_calls</code>.</p> <code>role</code> <code>Literal['assistant']</code> <p>The role of the author of this message.</p> <code>tool_calls</code> <code>Optional[List[ChatCompletionMessageToolCall]]</code> <p>The tool calls generated by the model, such as function calls.</p>"},{"location":"reference/types/chat/chat_completion_message/#src.openai.types.chat.chat_completion_message.ChatCompletionMessage.content","title":"content  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>content: Optional[str] = None\n</code></pre> <p>The contents of the message.</p>"},{"location":"reference/types/chat/chat_completion_message/#src.openai.types.chat.chat_completion_message.ChatCompletionMessage.function_call","title":"function_call  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>function_call: Optional[FunctionCall] = None\n</code></pre> <p>Deprecated and replaced by <code>tool_calls</code>.</p> <p>The name and arguments of a function that should be called, as generated by the model.</p>"},{"location":"reference/types/chat/chat_completion_message/#src.openai.types.chat.chat_completion_message.ChatCompletionMessage.role","title":"role  <code>instance-attribute</code>","text":"<pre><code>role: Literal['assistant']\n</code></pre> <p>The role of the author of this message.</p>"},{"location":"reference/types/chat/chat_completion_message/#src.openai.types.chat.chat_completion_message.ChatCompletionMessage.tool_calls","title":"tool_calls  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>tool_calls: Optional[\n    List[ChatCompletionMessageToolCall]\n] = None\n</code></pre> <p>The tool calls generated by the model, such as function calls.</p>"},{"location":"reference/types/chat/chat_completion_message/#src.openai.types.chat.chat_completion_message.FunctionCall","title":"FunctionCall","text":"<p>Attributes:</p> Name Type Description <code>arguments</code> <code>str</code> <p>The arguments to call the function with, as generated by the model in JSON</p> <code>name</code> <code>str</code> <p>The name of the function to call.</p>"},{"location":"reference/types/chat/chat_completion_message/#src.openai.types.chat.chat_completion_message.FunctionCall.arguments","title":"arguments  <code>instance-attribute</code>","text":"<pre><code>arguments: str\n</code></pre> <p>The arguments to call the function with, as generated by the model in JSON format. Note that the model does not always generate valid JSON, and may hallucinate parameters not defined by your function schema. Validate the arguments in your code before calling your function.</p>"},{"location":"reference/types/chat/chat_completion_message/#src.openai.types.chat.chat_completion_message.FunctionCall.name","title":"name  <code>instance-attribute</code>","text":"<pre><code>name: str\n</code></pre> <p>The name of the function to call.</p>"},{"location":"reference/types/chat/chat_completion_message_param/","title":"chat_completion_message_param","text":"<p>Attributes:</p> Name Type Description <code>ChatCompletionMessageParam</code>"},{"location":"reference/types/chat/chat_completion_message_param/#src.openai.types.chat.chat_completion_message_param.ChatCompletionMessageParam","title":"ChatCompletionMessageParam  <code>module-attribute</code>","text":"<pre><code>ChatCompletionMessageParam = Union[\n    ChatCompletionSystemMessageParam,\n    ChatCompletionUserMessageParam,\n    ChatCompletionAssistantMessageParam,\n    ChatCompletionToolMessageParam,\n    ChatCompletionFunctionMessageParam,\n]\n</code></pre>"},{"location":"reference/types/chat/chat_completion_message_tool_call/","title":"chat_completion_message_tool_call","text":"<p>Classes:</p> Name Description <code>ChatCompletionMessageToolCall</code> <code>Function</code>"},{"location":"reference/types/chat/chat_completion_message_tool_call/#src.openai.types.chat.chat_completion_message_tool_call.ChatCompletionMessageToolCall","title":"ChatCompletionMessageToolCall","text":"<p>Attributes:</p> Name Type Description <code>function</code> <code>Function</code> <p>The function that the model called.</p> <code>id</code> <code>str</code> <p>The ID of the tool call.</p> <code>type</code> <code>Literal['function']</code> <p>The type of the tool. Currently, only <code>function</code> is supported.</p>"},{"location":"reference/types/chat/chat_completion_message_tool_call/#src.openai.types.chat.chat_completion_message_tool_call.ChatCompletionMessageToolCall.function","title":"function  <code>instance-attribute</code>","text":"<pre><code>function: Function\n</code></pre> <p>The function that the model called.</p>"},{"location":"reference/types/chat/chat_completion_message_tool_call/#src.openai.types.chat.chat_completion_message_tool_call.ChatCompletionMessageToolCall.id","title":"id  <code>instance-attribute</code>","text":"<pre><code>id: str\n</code></pre> <p>The ID of the tool call.</p>"},{"location":"reference/types/chat/chat_completion_message_tool_call/#src.openai.types.chat.chat_completion_message_tool_call.ChatCompletionMessageToolCall.type","title":"type  <code>instance-attribute</code>","text":"<pre><code>type: Literal['function']\n</code></pre> <p>The type of the tool. Currently, only <code>function</code> is supported.</p>"},{"location":"reference/types/chat/chat_completion_message_tool_call/#src.openai.types.chat.chat_completion_message_tool_call.Function","title":"Function","text":"<p>Attributes:</p> Name Type Description <code>arguments</code> <code>str</code> <p>The arguments to call the function with, as generated by the model in JSON</p> <code>name</code> <code>str</code> <p>The name of the function to call.</p>"},{"location":"reference/types/chat/chat_completion_message_tool_call/#src.openai.types.chat.chat_completion_message_tool_call.Function.arguments","title":"arguments  <code>instance-attribute</code>","text":"<pre><code>arguments: str\n</code></pre> <p>The arguments to call the function with, as generated by the model in JSON format. Note that the model does not always generate valid JSON, and may hallucinate parameters not defined by your function schema. Validate the arguments in your code before calling your function.</p>"},{"location":"reference/types/chat/chat_completion_message_tool_call/#src.openai.types.chat.chat_completion_message_tool_call.Function.name","title":"name  <code>instance-attribute</code>","text":"<pre><code>name: str\n</code></pre> <p>The name of the function to call.</p>"},{"location":"reference/types/chat/chat_completion_message_tool_call_param/","title":"chat_completion_message_tool_call_param","text":"<p>Classes:</p> Name Description <code>ChatCompletionMessageToolCallParam</code> <code>Function</code>"},{"location":"reference/types/chat/chat_completion_message_tool_call_param/#src.openai.types.chat.chat_completion_message_tool_call_param.ChatCompletionMessageToolCallParam","title":"ChatCompletionMessageToolCallParam","text":"<p>Attributes:</p> Name Type Description <code>function</code> <code>Required[Function]</code> <p>The function that the model called.</p> <code>id</code> <code>Required[str]</code> <p>The ID of the tool call.</p> <code>type</code> <code>Required[Literal['function']]</code> <p>The type of the tool. Currently, only <code>function</code> is supported.</p>"},{"location":"reference/types/chat/chat_completion_message_tool_call_param/#src.openai.types.chat.chat_completion_message_tool_call_param.ChatCompletionMessageToolCallParam.function","title":"function  <code>instance-attribute</code>","text":"<pre><code>function: Required[Function]\n</code></pre> <p>The function that the model called.</p>"},{"location":"reference/types/chat/chat_completion_message_tool_call_param/#src.openai.types.chat.chat_completion_message_tool_call_param.ChatCompletionMessageToolCallParam.id","title":"id  <code>instance-attribute</code>","text":"<pre><code>id: Required[str]\n</code></pre> <p>The ID of the tool call.</p>"},{"location":"reference/types/chat/chat_completion_message_tool_call_param/#src.openai.types.chat.chat_completion_message_tool_call_param.ChatCompletionMessageToolCallParam.type","title":"type  <code>instance-attribute</code>","text":"<pre><code>type: Required[Literal['function']]\n</code></pre> <p>The type of the tool. Currently, only <code>function</code> is supported.</p>"},{"location":"reference/types/chat/chat_completion_message_tool_call_param/#src.openai.types.chat.chat_completion_message_tool_call_param.Function","title":"Function","text":"<p>Attributes:</p> Name Type Description <code>arguments</code> <code>Required[str]</code> <p>The arguments to call the function with, as generated by the model in JSON</p> <code>name</code> <code>Required[str]</code> <p>The name of the function to call.</p>"},{"location":"reference/types/chat/chat_completion_message_tool_call_param/#src.openai.types.chat.chat_completion_message_tool_call_param.Function.arguments","title":"arguments  <code>instance-attribute</code>","text":"<pre><code>arguments: Required[str]\n</code></pre> <p>The arguments to call the function with, as generated by the model in JSON format. Note that the model does not always generate valid JSON, and may hallucinate parameters not defined by your function schema. Validate the arguments in your code before calling your function.</p>"},{"location":"reference/types/chat/chat_completion_message_tool_call_param/#src.openai.types.chat.chat_completion_message_tool_call_param.Function.name","title":"name  <code>instance-attribute</code>","text":"<pre><code>name: Required[str]\n</code></pre> <p>The name of the function to call.</p>"},{"location":"reference/types/chat/chat_completion_named_tool_choice_param/","title":"chat_completion_named_tool_choice_param","text":"<p>Classes:</p> Name Description <code>ChatCompletionNamedToolChoiceParam</code> <code>Function</code>"},{"location":"reference/types/chat/chat_completion_named_tool_choice_param/#src.openai.types.chat.chat_completion_named_tool_choice_param.ChatCompletionNamedToolChoiceParam","title":"ChatCompletionNamedToolChoiceParam","text":"<p>Attributes:</p> Name Type Description <code>function</code> <code>Required[Function]</code> <code>type</code> <code>Required[Literal['function']]</code> <p>The type of the tool. Currently, only <code>function</code> is supported.</p>"},{"location":"reference/types/chat/chat_completion_named_tool_choice_param/#src.openai.types.chat.chat_completion_named_tool_choice_param.ChatCompletionNamedToolChoiceParam.function","title":"function  <code>instance-attribute</code>","text":"<pre><code>function: Required[Function]\n</code></pre>"},{"location":"reference/types/chat/chat_completion_named_tool_choice_param/#src.openai.types.chat.chat_completion_named_tool_choice_param.ChatCompletionNamedToolChoiceParam.type","title":"type  <code>instance-attribute</code>","text":"<pre><code>type: Required[Literal['function']]\n</code></pre> <p>The type of the tool. Currently, only <code>function</code> is supported.</p>"},{"location":"reference/types/chat/chat_completion_named_tool_choice_param/#src.openai.types.chat.chat_completion_named_tool_choice_param.Function","title":"Function","text":"<p>Attributes:</p> Name Type Description <code>name</code> <code>Required[str]</code> <p>The name of the function to call.</p>"},{"location":"reference/types/chat/chat_completion_named_tool_choice_param/#src.openai.types.chat.chat_completion_named_tool_choice_param.Function.name","title":"name  <code>instance-attribute</code>","text":"<pre><code>name: Required[str]\n</code></pre> <p>The name of the function to call.</p>"},{"location":"reference/types/chat/chat_completion_role/","title":"chat_completion_role","text":"<p>Attributes:</p> Name Type Description <code>ChatCompletionRole</code>"},{"location":"reference/types/chat/chat_completion_role/#src.openai.types.chat.chat_completion_role.ChatCompletionRole","title":"ChatCompletionRole  <code>module-attribute</code>","text":"<pre><code>ChatCompletionRole = Literal[\n    \"system\", \"user\", \"assistant\", \"tool\", \"function\"\n]\n</code></pre>"},{"location":"reference/types/chat/chat_completion_system_message_param/","title":"chat_completion_system_message_param","text":"<p>Classes:</p> Name Description <code>ChatCompletionSystemMessageParam</code>"},{"location":"reference/types/chat/chat_completion_system_message_param/#src.openai.types.chat.chat_completion_system_message_param.ChatCompletionSystemMessageParam","title":"ChatCompletionSystemMessageParam","text":"<p>Attributes:</p> Name Type Description <code>content</code> <code>Required[str]</code> <p>The contents of the system message.</p> <code>name</code> <code>str</code> <p>An optional name for the participant.</p> <code>role</code> <code>Required[Literal['system']]</code> <p>The role of the messages author, in this case <code>system</code>.</p>"},{"location":"reference/types/chat/chat_completion_system_message_param/#src.openai.types.chat.chat_completion_system_message_param.ChatCompletionSystemMessageParam.content","title":"content  <code>instance-attribute</code>","text":"<pre><code>content: Required[str]\n</code></pre> <p>The contents of the system message.</p>"},{"location":"reference/types/chat/chat_completion_system_message_param/#src.openai.types.chat.chat_completion_system_message_param.ChatCompletionSystemMessageParam.name","title":"name  <code>instance-attribute</code>","text":"<pre><code>name: str\n</code></pre> <p>An optional name for the participant.</p> <p>Provides the model information to differentiate between participants of the same role.</p>"},{"location":"reference/types/chat/chat_completion_system_message_param/#src.openai.types.chat.chat_completion_system_message_param.ChatCompletionSystemMessageParam.role","title":"role  <code>instance-attribute</code>","text":"<pre><code>role: Required[Literal['system']]\n</code></pre> <p>The role of the messages author, in this case <code>system</code>.</p>"},{"location":"reference/types/chat/chat_completion_token_logprob/","title":"chat_completion_token_logprob","text":"<p>Classes:</p> Name Description <code>ChatCompletionTokenLogprob</code> <code>TopLogprob</code>"},{"location":"reference/types/chat/chat_completion_token_logprob/#src.openai.types.chat.chat_completion_token_logprob.ChatCompletionTokenLogprob","title":"ChatCompletionTokenLogprob","text":"<p>Attributes:</p> Name Type Description <code>bytes</code> <code>Optional[List[int]]</code> <p>A list of integers representing the UTF-8 bytes representation of the token.</p> <code>logprob</code> <code>float</code> <p>The log probability of this token, if it is within the top 20 most likely</p> <code>token</code> <code>str</code> <p>The token.</p> <code>top_logprobs</code> <code>List[TopLogprob]</code> <p>List of the most likely tokens and their log probability, at this token</p>"},{"location":"reference/types/chat/chat_completion_token_logprob/#src.openai.types.chat.chat_completion_token_logprob.ChatCompletionTokenLogprob.bytes","title":"bytes  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>bytes: Optional[List[int]] = None\n</code></pre> <p>A list of integers representing the UTF-8 bytes representation of the token.</p> <p>Useful in instances where characters are represented by multiple tokens and their byte representations must be combined to generate the correct text representation. Can be <code>null</code> if there is no bytes representation for the token.</p>"},{"location":"reference/types/chat/chat_completion_token_logprob/#src.openai.types.chat.chat_completion_token_logprob.ChatCompletionTokenLogprob.logprob","title":"logprob  <code>instance-attribute</code>","text":"<pre><code>logprob: float\n</code></pre> <p>The log probability of this token, if it is within the top 20 most likely tokens.</p> <p>Otherwise, the value <code>-9999.0</code> is used to signify that the token is very unlikely.</p>"},{"location":"reference/types/chat/chat_completion_token_logprob/#src.openai.types.chat.chat_completion_token_logprob.ChatCompletionTokenLogprob.token","title":"token  <code>instance-attribute</code>","text":"<pre><code>token: str\n</code></pre> <p>The token.</p>"},{"location":"reference/types/chat/chat_completion_token_logprob/#src.openai.types.chat.chat_completion_token_logprob.ChatCompletionTokenLogprob.top_logprobs","title":"top_logprobs  <code>instance-attribute</code>","text":"<pre><code>top_logprobs: List[TopLogprob]\n</code></pre> <p>List of the most likely tokens and their log probability, at this token position.</p> <p>In rare cases, there may be fewer than the number of requested <code>top_logprobs</code> returned.</p>"},{"location":"reference/types/chat/chat_completion_token_logprob/#src.openai.types.chat.chat_completion_token_logprob.TopLogprob","title":"TopLogprob","text":"<p>Attributes:</p> Name Type Description <code>bytes</code> <code>Optional[List[int]]</code> <p>A list of integers representing the UTF-8 bytes representation of the token.</p> <code>logprob</code> <code>float</code> <p>The log probability of this token, if it is within the top 20 most likely</p> <code>token</code> <code>str</code> <p>The token.</p>"},{"location":"reference/types/chat/chat_completion_token_logprob/#src.openai.types.chat.chat_completion_token_logprob.TopLogprob.bytes","title":"bytes  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>bytes: Optional[List[int]] = None\n</code></pre> <p>A list of integers representing the UTF-8 bytes representation of the token.</p> <p>Useful in instances where characters are represented by multiple tokens and their byte representations must be combined to generate the correct text representation. Can be <code>null</code> if there is no bytes representation for the token.</p>"},{"location":"reference/types/chat/chat_completion_token_logprob/#src.openai.types.chat.chat_completion_token_logprob.TopLogprob.logprob","title":"logprob  <code>instance-attribute</code>","text":"<pre><code>logprob: float\n</code></pre> <p>The log probability of this token, if it is within the top 20 most likely tokens.</p> <p>Otherwise, the value <code>-9999.0</code> is used to signify that the token is very unlikely.</p>"},{"location":"reference/types/chat/chat_completion_token_logprob/#src.openai.types.chat.chat_completion_token_logprob.TopLogprob.token","title":"token  <code>instance-attribute</code>","text":"<pre><code>token: str\n</code></pre> <p>The token.</p>"},{"location":"reference/types/chat/chat_completion_tool_choice_option_param/","title":"chat_completion_tool_choice_option_param","text":"<p>Attributes:</p> Name Type Description <code>ChatCompletionToolChoiceOptionParam</code>"},{"location":"reference/types/chat/chat_completion_tool_choice_option_param/#src.openai.types.chat.chat_completion_tool_choice_option_param.ChatCompletionToolChoiceOptionParam","title":"ChatCompletionToolChoiceOptionParam  <code>module-attribute</code>","text":"<pre><code>ChatCompletionToolChoiceOptionParam = Union[\n    Literal[\"none\", \"auto\"],\n    ChatCompletionNamedToolChoiceParam,\n]\n</code></pre>"},{"location":"reference/types/chat/chat_completion_tool_message_param/","title":"chat_completion_tool_message_param","text":"<p>Classes:</p> Name Description <code>ChatCompletionToolMessageParam</code>"},{"location":"reference/types/chat/chat_completion_tool_message_param/#src.openai.types.chat.chat_completion_tool_message_param.ChatCompletionToolMessageParam","title":"ChatCompletionToolMessageParam","text":"<p>Attributes:</p> Name Type Description <code>content</code> <code>Required[str]</code> <p>The contents of the tool message.</p> <code>role</code> <code>Required[Literal['tool']]</code> <p>The role of the messages author, in this case <code>tool</code>.</p> <code>tool_call_id</code> <code>Required[str]</code> <p>Tool call that this message is responding to.</p>"},{"location":"reference/types/chat/chat_completion_tool_message_param/#src.openai.types.chat.chat_completion_tool_message_param.ChatCompletionToolMessageParam.content","title":"content  <code>instance-attribute</code>","text":"<pre><code>content: Required[str]\n</code></pre> <p>The contents of the tool message.</p>"},{"location":"reference/types/chat/chat_completion_tool_message_param/#src.openai.types.chat.chat_completion_tool_message_param.ChatCompletionToolMessageParam.role","title":"role  <code>instance-attribute</code>","text":"<pre><code>role: Required[Literal['tool']]\n</code></pre> <p>The role of the messages author, in this case <code>tool</code>.</p>"},{"location":"reference/types/chat/chat_completion_tool_message_param/#src.openai.types.chat.chat_completion_tool_message_param.ChatCompletionToolMessageParam.tool_call_id","title":"tool_call_id  <code>instance-attribute</code>","text":"<pre><code>tool_call_id: Required[str]\n</code></pre> <p>Tool call that this message is responding to.</p>"},{"location":"reference/types/chat/chat_completion_tool_param/","title":"chat_completion_tool_param","text":"<p>Classes:</p> Name Description <code>ChatCompletionToolParam</code>"},{"location":"reference/types/chat/chat_completion_tool_param/#src.openai.types.chat.chat_completion_tool_param.ChatCompletionToolParam","title":"ChatCompletionToolParam","text":"<p>Attributes:</p> Name Type Description <code>function</code> <code>Required[FunctionDefinition]</code> <code>type</code> <code>Required[Literal['function']]</code> <p>The type of the tool. Currently, only <code>function</code> is supported.</p>"},{"location":"reference/types/chat/chat_completion_tool_param/#src.openai.types.chat.chat_completion_tool_param.ChatCompletionToolParam.function","title":"function  <code>instance-attribute</code>","text":"<pre><code>function: Required[FunctionDefinition]\n</code></pre>"},{"location":"reference/types/chat/chat_completion_tool_param/#src.openai.types.chat.chat_completion_tool_param.ChatCompletionToolParam.type","title":"type  <code>instance-attribute</code>","text":"<pre><code>type: Required[Literal['function']]\n</code></pre> <p>The type of the tool. Currently, only <code>function</code> is supported.</p>"},{"location":"reference/types/chat/chat_completion_user_message_param/","title":"chat_completion_user_message_param","text":"<p>Classes:</p> Name Description <code>ChatCompletionUserMessageParam</code>"},{"location":"reference/types/chat/chat_completion_user_message_param/#src.openai.types.chat.chat_completion_user_message_param.ChatCompletionUserMessageParam","title":"ChatCompletionUserMessageParam","text":"<p>Attributes:</p> Name Type Description <code>content</code> <code>Required[Union[str, Iterable[ChatCompletionContentPartParam]]]</code> <p>The contents of the user message.</p> <code>name</code> <code>str</code> <p>An optional name for the participant.</p> <code>role</code> <code>Required[Literal['user']]</code> <p>The role of the messages author, in this case <code>user</code>.</p>"},{"location":"reference/types/chat/chat_completion_user_message_param/#src.openai.types.chat.chat_completion_user_message_param.ChatCompletionUserMessageParam.content","title":"content  <code>instance-attribute</code>","text":"<pre><code>content: Required[\n    Union[str, Iterable[ChatCompletionContentPartParam]]\n]\n</code></pre> <p>The contents of the user message.</p>"},{"location":"reference/types/chat/chat_completion_user_message_param/#src.openai.types.chat.chat_completion_user_message_param.ChatCompletionUserMessageParam.name","title":"name  <code>instance-attribute</code>","text":"<pre><code>name: str\n</code></pre> <p>An optional name for the participant.</p> <p>Provides the model information to differentiate between participants of the same role.</p>"},{"location":"reference/types/chat/chat_completion_user_message_param/#src.openai.types.chat.chat_completion_user_message_param.ChatCompletionUserMessageParam.role","title":"role  <code>instance-attribute</code>","text":"<pre><code>role: Required[Literal['user']]\n</code></pre> <p>The role of the messages author, in this case <code>user</code>.</p>"},{"location":"reference/types/chat/completion_create_params/","title":"completion_create_params","text":"<p>Classes:</p> Name Description <code>CompletionCreateParamsBase</code> <code>CompletionCreateParamsNonStreaming</code> <code>CompletionCreateParamsStreaming</code> <code>Function</code> <code>ResponseFormat</code> <p>Attributes:</p> Name Type Description <code>CompletionCreateParams</code> <code>FunctionCall</code>"},{"location":"reference/types/chat/completion_create_params/#src.openai.types.chat.completion_create_params.CompletionCreateParams","title":"CompletionCreateParams  <code>module-attribute</code>","text":"<pre><code>CompletionCreateParams = Union[\n    CompletionCreateParamsNonStreaming,\n    CompletionCreateParamsStreaming,\n]\n</code></pre>"},{"location":"reference/types/chat/completion_create_params/#src.openai.types.chat.completion_create_params.FunctionCall","title":"FunctionCall  <code>module-attribute</code>","text":"<pre><code>FunctionCall = Union[\n    Literal[\"none\", \"auto\"],\n    ChatCompletionFunctionCallOptionParam,\n]\n</code></pre>"},{"location":"reference/types/chat/completion_create_params/#src.openai.types.chat.completion_create_params.CompletionCreateParamsBase","title":"CompletionCreateParamsBase","text":"<p>Attributes:</p> Name Type Description <code>frequency_penalty</code> <code>Optional[float]</code> <p>Number between -2.0 and 2.0.</p> <code>function_call</code> <code>FunctionCall</code> <p>Deprecated in favor of <code>tool_choice</code>.</p> <code>functions</code> <code>Iterable[Function]</code> <p>Deprecated in favor of <code>tools</code>.</p> <code>logit_bias</code> <code>Optional[Dict[str, int]]</code> <p>Modify the likelihood of specified tokens appearing in the completion.</p> <code>logprobs</code> <code>Optional[bool]</code> <p>Whether to return log probabilities of the output tokens or not.</p> <code>max_tokens</code> <code>Optional[int]</code> <p>The maximum number of tokens that can be generated in the chat</p> <code>messages</code> <code>Required[Iterable[ChatCompletionMessageParam]]</code> <p>A list of messages comprising the conversation so far.</p> <code>model</code> <code>Required[Union[str, Literal['gpt-4-0125-preview', 'gpt-4-turbo-preview', 'gpt-4-1106-preview', 'gpt-4-vision-preview', 'gpt-4', 'gpt-4-0314', 'gpt-4-0613', 'gpt-4-32k', 'gpt-4-32k-0314', 'gpt-4-32k-0613', 'gpt-3.5-turbo', 'gpt-3.5-turbo-16k', 'gpt-3.5-turbo-0301', 'gpt-3.5-turbo-0613', 'gpt-3.5-turbo-1106', 'gpt-3.5-turbo-0125', 'gpt-3.5-turbo-16k-0613']]]</code> <p>ID of the model to use.</p> <code>n</code> <code>Optional[int]</code> <p>How many chat completion choices to generate for each input message.</p> <code>presence_penalty</code> <code>Optional[float]</code> <p>Number between -2.0 and 2.0.</p> <code>response_format</code> <code>ResponseFormat</code> <p>An object specifying the format that the model must output.</p> <code>seed</code> <code>Optional[int]</code> <p>This feature is in Beta. If specified, our system will make a best effort to</p> <code>stop</code> <code>Union[Optional[str], List[str]]</code> <p>Up to 4 sequences where the API will stop generating further tokens.</p> <code>temperature</code> <code>Optional[float]</code> <p>What sampling temperature to use, between 0 and 2.</p> <code>tool_choice</code> <code>ChatCompletionToolChoiceOptionParam</code> <p>Controls which (if any) function is called by the model. <code>none</code> means the model</p> <code>tools</code> <code>Iterable[ChatCompletionToolParam]</code> <p>A list of tools the model may call.</p> <code>top_logprobs</code> <code>Optional[int]</code> <p>An integer between 0 and 20 specifying the number of most likely tokens to</p> <code>top_p</code> <code>Optional[float]</code> <p>An alternative to sampling with temperature, called nucleus sampling, where the</p> <code>user</code> <code>str</code> <p>A unique identifier representing your end-user, which can help OpenAI to monitor</p>"},{"location":"reference/types/chat/completion_create_params/#src.openai.types.chat.completion_create_params.CompletionCreateParamsBase.frequency_penalty","title":"frequency_penalty  <code>instance-attribute</code>","text":"<pre><code>frequency_penalty: Optional[float]\n</code></pre> <p>Number between -2.0 and 2.0.</p> <p>Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim.</p> <p>See more information about frequency and presence penalties.</p>"},{"location":"reference/types/chat/completion_create_params/#src.openai.types.chat.completion_create_params.CompletionCreateParamsBase.function_call","title":"function_call  <code>instance-attribute</code>","text":"<pre><code>function_call: FunctionCall\n</code></pre> <p>Deprecated in favor of <code>tool_choice</code>.</p> <p>Controls which (if any) function is called by the model. <code>none</code> means the model will not call a function and instead generates a message. <code>auto</code> means the model can pick between generating a message or calling a function. Specifying a particular function via <code>{\"name\": \"my_function\"}</code> forces the model to call that function.</p> <p><code>none</code> is the default when no functions are present. <code>auto</code> is the default if functions are present.</p>"},{"location":"reference/types/chat/completion_create_params/#src.openai.types.chat.completion_create_params.CompletionCreateParamsBase.functions","title":"functions  <code>instance-attribute</code>","text":"<pre><code>functions: Iterable[Function]\n</code></pre> <p>Deprecated in favor of <code>tools</code>.</p> <p>A list of functions the model may generate JSON inputs for.</p>"},{"location":"reference/types/chat/completion_create_params/#src.openai.types.chat.completion_create_params.CompletionCreateParamsBase.logit_bias","title":"logit_bias  <code>instance-attribute</code>","text":"<pre><code>logit_bias: Optional[Dict[str, int]]\n</code></pre> <p>Modify the likelihood of specified tokens appearing in the completion.</p> <p>Accepts a JSON object that maps tokens (specified by their token ID in the tokenizer) to an associated bias value from -100 to 100. Mathematically, the bias is added to the logits generated by the model prior to sampling. The exact effect will vary per model, but values between -1 and 1 should decrease or increase likelihood of selection; values like -100 or 100 should result in a ban or exclusive selection of the relevant token.</p>"},{"location":"reference/types/chat/completion_create_params/#src.openai.types.chat.completion_create_params.CompletionCreateParamsBase.logprobs","title":"logprobs  <code>instance-attribute</code>","text":"<pre><code>logprobs: Optional[bool]\n</code></pre> <p>Whether to return log probabilities of the output tokens or not.</p> <p>If true, returns the log probabilities of each output token returned in the <code>content</code> of <code>message</code>. This option is currently not available on the <code>gpt-4-vision-preview</code> model.</p>"},{"location":"reference/types/chat/completion_create_params/#src.openai.types.chat.completion_create_params.CompletionCreateParamsBase.max_tokens","title":"max_tokens  <code>instance-attribute</code>","text":"<pre><code>max_tokens: Optional[int]\n</code></pre> <p>The maximum number of tokens that can be generated in the chat completion.</p> <p>The total length of input tokens and generated tokens is limited by the model's context length. Example Python code for counting tokens.</p>"},{"location":"reference/types/chat/completion_create_params/#src.openai.types.chat.completion_create_params.CompletionCreateParamsBase.messages","title":"messages  <code>instance-attribute</code>","text":"<pre><code>messages: Required[Iterable[ChatCompletionMessageParam]]\n</code></pre> <p>A list of messages comprising the conversation so far.</p> <p>Example Python code.</p>"},{"location":"reference/types/chat/completion_create_params/#src.openai.types.chat.completion_create_params.CompletionCreateParamsBase.model","title":"model  <code>instance-attribute</code>","text":"<pre><code>model: Required[\n    Union[\n        str,\n        Literal[\n            \"gpt-4-0125-preview\",\n            \"gpt-4-turbo-preview\",\n            \"gpt-4-1106-preview\",\n            \"gpt-4-vision-preview\",\n            \"gpt-4\",\n            \"gpt-4-0314\",\n            \"gpt-4-0613\",\n            \"gpt-4-32k\",\n            \"gpt-4-32k-0314\",\n            \"gpt-4-32k-0613\",\n            \"gpt-3.5-turbo\",\n            \"gpt-3.5-turbo-16k\",\n            \"gpt-3.5-turbo-0301\",\n            \"gpt-3.5-turbo-0613\",\n            \"gpt-3.5-turbo-1106\",\n            \"gpt-3.5-turbo-0125\",\n            \"gpt-3.5-turbo-16k-0613\",\n        ],\n    ]\n]\n</code></pre> <p>ID of the model to use.</p> <p>See the model endpoint compatibility table for details on which models work with the Chat API.</p>"},{"location":"reference/types/chat/completion_create_params/#src.openai.types.chat.completion_create_params.CompletionCreateParamsBase.n","title":"n  <code>instance-attribute</code>","text":"<pre><code>n: Optional[int]\n</code></pre> <p>How many chat completion choices to generate for each input message.</p> <p>Note that you will be charged based on the number of generated tokens across all of the choices. Keep <code>n</code> as <code>1</code> to minimize costs.</p>"},{"location":"reference/types/chat/completion_create_params/#src.openai.types.chat.completion_create_params.CompletionCreateParamsBase.presence_penalty","title":"presence_penalty  <code>instance-attribute</code>","text":"<pre><code>presence_penalty: Optional[float]\n</code></pre> <p>Number between -2.0 and 2.0.</p> <p>Positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics.</p> <p>See more information about frequency and presence penalties.</p>"},{"location":"reference/types/chat/completion_create_params/#src.openai.types.chat.completion_create_params.CompletionCreateParamsBase.response_format","title":"response_format  <code>instance-attribute</code>","text":"<pre><code>response_format: ResponseFormat\n</code></pre> <p>An object specifying the format that the model must output.</p> <p>Compatible with GPT-4 Turbo and all GPT-3.5 Turbo models newer than <code>gpt-3.5-turbo-1106</code>.</p> <p>Setting to <code>{ \"type\": \"json_object\" }</code> enables JSON mode, which guarantees the message the model generates is valid JSON.</p> <p>Important: when using JSON mode, you must also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly \"stuck\" request. Also note that the message content may be partially cut off if <code>finish_reason=\"length\"</code>, which indicates the generation exceeded <code>max_tokens</code> or the conversation exceeded the max context length.</p>"},{"location":"reference/types/chat/completion_create_params/#src.openai.types.chat.completion_create_params.CompletionCreateParamsBase.seed","title":"seed  <code>instance-attribute</code>","text":"<pre><code>seed: Optional[int]\n</code></pre> <p>This feature is in Beta. If specified, our system will make a best effort to sample deterministically, such that repeated requests with the same <code>seed</code> and parameters should return the same result. Determinism is not guaranteed, and you should refer to the <code>system_fingerprint</code> response parameter to monitor changes in the backend.</p>"},{"location":"reference/types/chat/completion_create_params/#src.openai.types.chat.completion_create_params.CompletionCreateParamsBase.stop","title":"stop  <code>instance-attribute</code>","text":"<pre><code>stop: Union[Optional[str], List[str]]\n</code></pre> <p>Up to 4 sequences where the API will stop generating further tokens.</p>"},{"location":"reference/types/chat/completion_create_params/#src.openai.types.chat.completion_create_params.CompletionCreateParamsBase.temperature","title":"temperature  <code>instance-attribute</code>","text":"<pre><code>temperature: Optional[float]\n</code></pre> <p>What sampling temperature to use, between 0 and 2.</p> <p>Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.</p> <p>We generally recommend altering this or <code>top_p</code> but not both.</p>"},{"location":"reference/types/chat/completion_create_params/#src.openai.types.chat.completion_create_params.CompletionCreateParamsBase.tool_choice","title":"tool_choice  <code>instance-attribute</code>","text":"<pre><code>tool_choice: ChatCompletionToolChoiceOptionParam\n</code></pre> <p>Controls which (if any) function is called by the model. <code>none</code> means the model will not call a function and instead generates a message. <code>auto</code> means the model can pick between generating a message or calling a function. Specifying a particular function via <code>{\"type\": \"function\", \"function\": {\"name\": \"my_function\"}}</code> forces the model to call that function.</p> <p><code>none</code> is the default when no functions are present. <code>auto</code> is the default if functions are present.</p>"},{"location":"reference/types/chat/completion_create_params/#src.openai.types.chat.completion_create_params.CompletionCreateParamsBase.tools","title":"tools  <code>instance-attribute</code>","text":"<pre><code>tools: Iterable[ChatCompletionToolParam]\n</code></pre> <p>A list of tools the model may call.</p> <p>Currently, only functions are supported as a tool. Use this to provide a list of functions the model may generate JSON inputs for.</p>"},{"location":"reference/types/chat/completion_create_params/#src.openai.types.chat.completion_create_params.CompletionCreateParamsBase.top_logprobs","title":"top_logprobs  <code>instance-attribute</code>","text":"<pre><code>top_logprobs: Optional[int]\n</code></pre> <p>An integer between 0 and 20 specifying the number of most likely tokens to return at each token position, each with an associated log probability. <code>logprobs</code> must be set to <code>true</code> if this parameter is used.</p>"},{"location":"reference/types/chat/completion_create_params/#src.openai.types.chat.completion_create_params.CompletionCreateParamsBase.top_p","title":"top_p  <code>instance-attribute</code>","text":"<pre><code>top_p: Optional[float]\n</code></pre> <p>An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.</p> <p>We generally recommend altering this or <code>temperature</code> but not both.</p>"},{"location":"reference/types/chat/completion_create_params/#src.openai.types.chat.completion_create_params.CompletionCreateParamsBase.user","title":"user  <code>instance-attribute</code>","text":"<pre><code>user: str\n</code></pre> <p>A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. Learn more.</p>"},{"location":"reference/types/chat/completion_create_params/#src.openai.types.chat.completion_create_params.CompletionCreateParamsNonStreaming","title":"CompletionCreateParamsNonStreaming","text":"<p>Attributes:</p> Name Type Description <code>stream</code> <code>Optional[Literal[False]]</code> <p>If set, partial message deltas will be sent, like in ChatGPT.</p>"},{"location":"reference/types/chat/completion_create_params/#src.openai.types.chat.completion_create_params.CompletionCreateParamsNonStreaming.stream","title":"stream  <code>instance-attribute</code>","text":"<pre><code>stream: Optional[Literal[False]]\n</code></pre> <p>If set, partial message deltas will be sent, like in ChatGPT.</p> <p>Tokens will be sent as data-only server-sent events as they become available, with the stream terminated by a <code>data: [DONE]</code> message. Example Python code.</p>"},{"location":"reference/types/chat/completion_create_params/#src.openai.types.chat.completion_create_params.CompletionCreateParamsStreaming","title":"CompletionCreateParamsStreaming","text":"<p>Attributes:</p> Name Type Description <code>stream</code> <code>Required[Literal[True]]</code> <p>If set, partial message deltas will be sent, like in ChatGPT.</p>"},{"location":"reference/types/chat/completion_create_params/#src.openai.types.chat.completion_create_params.CompletionCreateParamsStreaming.stream","title":"stream  <code>instance-attribute</code>","text":"<pre><code>stream: Required[Literal[True]]\n</code></pre> <p>If set, partial message deltas will be sent, like in ChatGPT.</p> <p>Tokens will be sent as data-only server-sent events as they become available, with the stream terminated by a <code>data: [DONE]</code> message. Example Python code.</p>"},{"location":"reference/types/chat/completion_create_params/#src.openai.types.chat.completion_create_params.Function","title":"Function","text":"<p>Attributes:</p> Name Type Description <code>description</code> <code>str</code> <p>A description of what the function does, used by the model to choose when and</p> <code>name</code> <code>Required[str]</code> <p>The name of the function to be called.</p> <code>parameters</code> <code>FunctionParameters</code> <p>The parameters the functions accepts, described as a JSON Schema object.</p>"},{"location":"reference/types/chat/completion_create_params/#src.openai.types.chat.completion_create_params.Function.description","title":"description  <code>instance-attribute</code>","text":"<pre><code>description: str\n</code></pre> <p>A description of what the function does, used by the model to choose when and how to call the function.</p>"},{"location":"reference/types/chat/completion_create_params/#src.openai.types.chat.completion_create_params.Function.name","title":"name  <code>instance-attribute</code>","text":"<pre><code>name: Required[str]\n</code></pre> <p>The name of the function to be called.</p> <p>Must be a-z, A-Z, 0-9, or contain underscores and dashes, with a maximum length of 64.</p>"},{"location":"reference/types/chat/completion_create_params/#src.openai.types.chat.completion_create_params.Function.parameters","title":"parameters  <code>instance-attribute</code>","text":"<pre><code>parameters: FunctionParameters\n</code></pre> <p>The parameters the functions accepts, described as a JSON Schema object.</p> <p>See the guide for examples, and the JSON Schema reference for documentation about the format.</p> <p>Omitting <code>parameters</code> defines a function with an empty parameter list.</p>"},{"location":"reference/types/chat/completion_create_params/#src.openai.types.chat.completion_create_params.ResponseFormat","title":"ResponseFormat","text":"<p>Attributes:</p> Name Type Description <code>type</code> <code>Literal['text', 'json_object']</code> <p>Must be one of <code>text</code> or <code>json_object</code>.</p>"},{"location":"reference/types/chat/completion_create_params/#src.openai.types.chat.completion_create_params.ResponseFormat.type","title":"type  <code>instance-attribute</code>","text":"<pre><code>type: Literal['text', 'json_object']\n</code></pre> <p>Must be one of <code>text</code> or <code>json_object</code>.</p>"},{"location":"reference/types/fine_tuning/","title":"openai.types.fine_tuning","text":"<p>Modules:</p> Name Description <code>fine_tuning_job</code> <code>fine_tuning_job_event</code> <code>job_create_params</code> <code>job_list_events_params</code> <code>job_list_params</code>"},{"location":"reference/types/fine_tuning/fine_tuning_job/","title":"fine_tuning_job","text":"<p>Classes:</p> Name Description <code>Error</code> <code>FineTuningJob</code> <code>Hyperparameters</code>"},{"location":"reference/types/fine_tuning/fine_tuning_job/#src.openai.types.fine_tuning.fine_tuning_job.Error","title":"Error","text":"<p>Attributes:</p> Name Type Description <code>code</code> <code>str</code> <p>A machine-readable error code.</p> <code>message</code> <code>str</code> <p>A human-readable error message.</p> <code>param</code> <code>Optional[str]</code> <p>The parameter that was invalid, usually <code>training_file</code> or <code>validation_file</code>.</p>"},{"location":"reference/types/fine_tuning/fine_tuning_job/#src.openai.types.fine_tuning.fine_tuning_job.Error.code","title":"code  <code>instance-attribute</code>","text":"<pre><code>code: str\n</code></pre> <p>A machine-readable error code.</p>"},{"location":"reference/types/fine_tuning/fine_tuning_job/#src.openai.types.fine_tuning.fine_tuning_job.Error.message","title":"message  <code>instance-attribute</code>","text":"<pre><code>message: str\n</code></pre> <p>A human-readable error message.</p>"},{"location":"reference/types/fine_tuning/fine_tuning_job/#src.openai.types.fine_tuning.fine_tuning_job.Error.param","title":"param  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>param: Optional[str] = None\n</code></pre> <p>The parameter that was invalid, usually <code>training_file</code> or <code>validation_file</code>.</p> <p>This field will be null if the failure was not parameter-specific.</p>"},{"location":"reference/types/fine_tuning/fine_tuning_job/#src.openai.types.fine_tuning.fine_tuning_job.FineTuningJob","title":"FineTuningJob","text":"<p>Attributes:</p> Name Type Description <code>created_at</code> <code>int</code> <p>The Unix timestamp (in seconds) for when the fine-tuning job was created.</p> <code>error</code> <code>Optional[Error]</code> <p>For fine-tuning jobs that have <code>failed</code>, this will contain more information on</p> <code>fine_tuned_model</code> <code>Optional[str]</code> <p>The name of the fine-tuned model that is being created.</p> <code>finished_at</code> <code>Optional[int]</code> <p>The Unix timestamp (in seconds) for when the fine-tuning job was finished.</p> <code>hyperparameters</code> <code>Hyperparameters</code> <p>The hyperparameters used for the fine-tuning job.</p> <code>id</code> <code>str</code> <p>The object identifier, which can be referenced in the API endpoints.</p> <code>model</code> <code>str</code> <p>The base model that is being fine-tuned.</p> <code>object</code> <code>Literal['fine_tuning.job']</code> <p>The object type, which is always \"fine_tuning.job\".</p> <code>organization_id</code> <code>str</code> <p>The organization that owns the fine-tuning job.</p> <code>result_files</code> <code>List[str]</code> <p>The compiled results file ID(s) for the fine-tuning job.</p> <code>status</code> <code>Literal['validating_files', 'queued', 'running', 'succeeded', 'failed', 'cancelled']</code> <p>The current status of the fine-tuning job, which can be either</p> <code>trained_tokens</code> <code>Optional[int]</code> <p>The total number of billable tokens processed by this fine-tuning job.</p> <code>training_file</code> <code>str</code> <p>The file ID used for training.</p> <code>validation_file</code> <code>Optional[str]</code> <p>The file ID used for validation.</p>"},{"location":"reference/types/fine_tuning/fine_tuning_job/#src.openai.types.fine_tuning.fine_tuning_job.FineTuningJob.created_at","title":"created_at  <code>instance-attribute</code>","text":"<pre><code>created_at: int\n</code></pre> <p>The Unix timestamp (in seconds) for when the fine-tuning job was created.</p>"},{"location":"reference/types/fine_tuning/fine_tuning_job/#src.openai.types.fine_tuning.fine_tuning_job.FineTuningJob.error","title":"error  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>error: Optional[Error] = None\n</code></pre> <p>For fine-tuning jobs that have <code>failed</code>, this will contain more information on the cause of the failure.</p>"},{"location":"reference/types/fine_tuning/fine_tuning_job/#src.openai.types.fine_tuning.fine_tuning_job.FineTuningJob.fine_tuned_model","title":"fine_tuned_model  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>fine_tuned_model: Optional[str] = None\n</code></pre> <p>The name of the fine-tuned model that is being created.</p> <p>The value will be null if the fine-tuning job is still running.</p>"},{"location":"reference/types/fine_tuning/fine_tuning_job/#src.openai.types.fine_tuning.fine_tuning_job.FineTuningJob.finished_at","title":"finished_at  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>finished_at: Optional[int] = None\n</code></pre> <p>The Unix timestamp (in seconds) for when the fine-tuning job was finished.</p> <p>The value will be null if the fine-tuning job is still running.</p>"},{"location":"reference/types/fine_tuning/fine_tuning_job/#src.openai.types.fine_tuning.fine_tuning_job.FineTuningJob.hyperparameters","title":"hyperparameters  <code>instance-attribute</code>","text":"<pre><code>hyperparameters: Hyperparameters\n</code></pre> <p>The hyperparameters used for the fine-tuning job.</p> <p>See the fine-tuning guide for more details.</p>"},{"location":"reference/types/fine_tuning/fine_tuning_job/#src.openai.types.fine_tuning.fine_tuning_job.FineTuningJob.id","title":"id  <code>instance-attribute</code>","text":"<pre><code>id: str\n</code></pre> <p>The object identifier, which can be referenced in the API endpoints.</p>"},{"location":"reference/types/fine_tuning/fine_tuning_job/#src.openai.types.fine_tuning.fine_tuning_job.FineTuningJob.model","title":"model  <code>instance-attribute</code>","text":"<pre><code>model: str\n</code></pre> <p>The base model that is being fine-tuned.</p>"},{"location":"reference/types/fine_tuning/fine_tuning_job/#src.openai.types.fine_tuning.fine_tuning_job.FineTuningJob.object","title":"object  <code>instance-attribute</code>","text":"<pre><code>object: Literal['fine_tuning.job']\n</code></pre> <p>The object type, which is always \"fine_tuning.job\".</p>"},{"location":"reference/types/fine_tuning/fine_tuning_job/#src.openai.types.fine_tuning.fine_tuning_job.FineTuningJob.organization_id","title":"organization_id  <code>instance-attribute</code>","text":"<pre><code>organization_id: str\n</code></pre> <p>The organization that owns the fine-tuning job.</p>"},{"location":"reference/types/fine_tuning/fine_tuning_job/#src.openai.types.fine_tuning.fine_tuning_job.FineTuningJob.result_files","title":"result_files  <code>instance-attribute</code>","text":"<pre><code>result_files: List[str]\n</code></pre> <p>The compiled results file ID(s) for the fine-tuning job.</p> <p>You can retrieve the results with the Files API.</p>"},{"location":"reference/types/fine_tuning/fine_tuning_job/#src.openai.types.fine_tuning.fine_tuning_job.FineTuningJob.status","title":"status  <code>instance-attribute</code>","text":"<pre><code>status: Literal[\n    \"validating_files\",\n    \"queued\",\n    \"running\",\n    \"succeeded\",\n    \"failed\",\n    \"cancelled\",\n]\n</code></pre> <p>The current status of the fine-tuning job, which can be either <code>validating_files</code>, <code>queued</code>, <code>running</code>, <code>succeeded</code>, <code>failed</code>, or <code>cancelled</code>.</p>"},{"location":"reference/types/fine_tuning/fine_tuning_job/#src.openai.types.fine_tuning.fine_tuning_job.FineTuningJob.trained_tokens","title":"trained_tokens  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>trained_tokens: Optional[int] = None\n</code></pre> <p>The total number of billable tokens processed by this fine-tuning job.</p> <p>The value will be null if the fine-tuning job is still running.</p>"},{"location":"reference/types/fine_tuning/fine_tuning_job/#src.openai.types.fine_tuning.fine_tuning_job.FineTuningJob.training_file","title":"training_file  <code>instance-attribute</code>","text":"<pre><code>training_file: str\n</code></pre> <p>The file ID used for training.</p> <p>You can retrieve the training data with the Files API.</p>"},{"location":"reference/types/fine_tuning/fine_tuning_job/#src.openai.types.fine_tuning.fine_tuning_job.FineTuningJob.validation_file","title":"validation_file  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>validation_file: Optional[str] = None\n</code></pre> <p>The file ID used for validation.</p> <p>You can retrieve the validation results with the Files API.</p>"},{"location":"reference/types/fine_tuning/fine_tuning_job/#src.openai.types.fine_tuning.fine_tuning_job.Hyperparameters","title":"Hyperparameters","text":"<p>Attributes:</p> Name Type Description <code>n_epochs</code> <code>Union[Literal['auto'], int]</code> <p>The number of epochs to train the model for.</p>"},{"location":"reference/types/fine_tuning/fine_tuning_job/#src.openai.types.fine_tuning.fine_tuning_job.Hyperparameters.n_epochs","title":"n_epochs  <code>instance-attribute</code>","text":"<pre><code>n_epochs: Union[Literal['auto'], int]\n</code></pre> <p>The number of epochs to train the model for.</p> <p>An epoch refers to one full cycle through the training dataset. \"auto\" decides the optimal number of epochs based on the size of the dataset. If setting the number manually, we support any number between 1 and 50 epochs.</p>"},{"location":"reference/types/fine_tuning/fine_tuning_job_event/","title":"fine_tuning_job_event","text":"<p>Classes:</p> Name Description <code>FineTuningJobEvent</code>"},{"location":"reference/types/fine_tuning/fine_tuning_job_event/#src.openai.types.fine_tuning.fine_tuning_job_event.FineTuningJobEvent","title":"FineTuningJobEvent","text":"<p>Attributes:</p> Name Type Description <code>created_at</code> <code>int</code> <code>id</code> <code>str</code> <code>level</code> <code>Literal['info', 'warn', 'error']</code> <code>message</code> <code>str</code> <code>object</code> <code>Literal['fine_tuning.job.event']</code>"},{"location":"reference/types/fine_tuning/fine_tuning_job_event/#src.openai.types.fine_tuning.fine_tuning_job_event.FineTuningJobEvent.created_at","title":"created_at  <code>instance-attribute</code>","text":"<pre><code>created_at: int\n</code></pre>"},{"location":"reference/types/fine_tuning/fine_tuning_job_event/#src.openai.types.fine_tuning.fine_tuning_job_event.FineTuningJobEvent.id","title":"id  <code>instance-attribute</code>","text":"<pre><code>id: str\n</code></pre>"},{"location":"reference/types/fine_tuning/fine_tuning_job_event/#src.openai.types.fine_tuning.fine_tuning_job_event.FineTuningJobEvent.level","title":"level  <code>instance-attribute</code>","text":"<pre><code>level: Literal['info', 'warn', 'error']\n</code></pre>"},{"location":"reference/types/fine_tuning/fine_tuning_job_event/#src.openai.types.fine_tuning.fine_tuning_job_event.FineTuningJobEvent.message","title":"message  <code>instance-attribute</code>","text":"<pre><code>message: str\n</code></pre>"},{"location":"reference/types/fine_tuning/fine_tuning_job_event/#src.openai.types.fine_tuning.fine_tuning_job_event.FineTuningJobEvent.object","title":"object  <code>instance-attribute</code>","text":"<pre><code>object: Literal['fine_tuning.job.event']\n</code></pre>"},{"location":"reference/types/fine_tuning/job_create_params/","title":"job_create_params","text":"<p>Classes:</p> Name Description <code>Hyperparameters</code> <code>JobCreateParams</code>"},{"location":"reference/types/fine_tuning/job_create_params/#src.openai.types.fine_tuning.job_create_params.Hyperparameters","title":"Hyperparameters","text":"<p>Attributes:</p> Name Type Description <code>batch_size</code> <code>Union[Literal['auto'], int]</code> <p>Number of examples in each batch.</p> <code>learning_rate_multiplier</code> <code>Union[Literal['auto'], float]</code> <p>Scaling factor for the learning rate.</p> <code>n_epochs</code> <code>Union[Literal['auto'], int]</code> <p>The number of epochs to train the model for.</p>"},{"location":"reference/types/fine_tuning/job_create_params/#src.openai.types.fine_tuning.job_create_params.Hyperparameters.batch_size","title":"batch_size  <code>instance-attribute</code>","text":"<pre><code>batch_size: Union[Literal['auto'], int]\n</code></pre> <p>Number of examples in each batch.</p> <p>A larger batch size means that model parameters are updated less frequently, but with lower variance.</p>"},{"location":"reference/types/fine_tuning/job_create_params/#src.openai.types.fine_tuning.job_create_params.Hyperparameters.learning_rate_multiplier","title":"learning_rate_multiplier  <code>instance-attribute</code>","text":"<pre><code>learning_rate_multiplier: Union[Literal['auto'], float]\n</code></pre> <p>Scaling factor for the learning rate.</p> <p>A smaller learning rate may be useful to avoid overfitting.</p>"},{"location":"reference/types/fine_tuning/job_create_params/#src.openai.types.fine_tuning.job_create_params.Hyperparameters.n_epochs","title":"n_epochs  <code>instance-attribute</code>","text":"<pre><code>n_epochs: Union[Literal['auto'], int]\n</code></pre> <p>The number of epochs to train the model for.</p> <p>An epoch refers to one full cycle through the training dataset.</p>"},{"location":"reference/types/fine_tuning/job_create_params/#src.openai.types.fine_tuning.job_create_params.JobCreateParams","title":"JobCreateParams","text":"<p>Attributes:</p> Name Type Description <code>hyperparameters</code> <code>Hyperparameters</code> <p>The hyperparameters used for the fine-tuning job.</p> <code>model</code> <code>Required[Union[str, Literal['babbage-002', 'davinci-002', 'gpt-3.5-turbo']]]</code> <p>The name of the model to fine-tune.</p> <code>suffix</code> <code>Optional[str]</code> <p>A string of up to 18 characters that will be added to your fine-tuned model</p> <code>training_file</code> <code>Required[str]</code> <p>The ID of an uploaded file that contains training data.</p> <code>validation_file</code> <code>Optional[str]</code> <p>The ID of an uploaded file that contains validation data.</p>"},{"location":"reference/types/fine_tuning/job_create_params/#src.openai.types.fine_tuning.job_create_params.JobCreateParams.hyperparameters","title":"hyperparameters  <code>instance-attribute</code>","text":"<pre><code>hyperparameters: Hyperparameters\n</code></pre> <p>The hyperparameters used for the fine-tuning job.</p>"},{"location":"reference/types/fine_tuning/job_create_params/#src.openai.types.fine_tuning.job_create_params.JobCreateParams.model","title":"model  <code>instance-attribute</code>","text":"<pre><code>model: Required[\n    Union[\n        str,\n        Literal[\n            \"babbage-002\", \"davinci-002\", \"gpt-3.5-turbo\"\n        ],\n    ]\n]\n</code></pre> <p>The name of the model to fine-tune.</p> <p>You can select one of the supported models.</p>"},{"location":"reference/types/fine_tuning/job_create_params/#src.openai.types.fine_tuning.job_create_params.JobCreateParams.suffix","title":"suffix  <code>instance-attribute</code>","text":"<pre><code>suffix: Optional[str]\n</code></pre> <p>A string of up to 18 characters that will be added to your fine-tuned model name.</p> <p>For example, a <code>suffix</code> of \"custom-model-name\" would produce a model name like <code>ft:gpt-3.5-turbo:openai:custom-model-name:7p4lURel</code>.</p>"},{"location":"reference/types/fine_tuning/job_create_params/#src.openai.types.fine_tuning.job_create_params.JobCreateParams.training_file","title":"training_file  <code>instance-attribute</code>","text":"<pre><code>training_file: Required[str]\n</code></pre> <p>The ID of an uploaded file that contains training data.</p> <p>See upload file for how to upload a file.</p> <p>Your dataset must be formatted as a JSONL file. Additionally, you must upload your file with the purpose <code>fine-tune</code>.</p> <p>See the fine-tuning guide for more details.</p>"},{"location":"reference/types/fine_tuning/job_create_params/#src.openai.types.fine_tuning.job_create_params.JobCreateParams.validation_file","title":"validation_file  <code>instance-attribute</code>","text":"<pre><code>validation_file: Optional[str]\n</code></pre> <p>The ID of an uploaded file that contains validation data.</p> <p>If you provide this file, the data is used to generate validation metrics periodically during fine-tuning. These metrics can be viewed in the fine-tuning results file. The same data should not be present in both train and validation files.</p> <p>Your dataset must be formatted as a JSONL file. You must upload your file with the purpose <code>fine-tune</code>.</p> <p>See the fine-tuning guide for more details.</p>"},{"location":"reference/types/fine_tuning/job_list_events_params/","title":"job_list_events_params","text":"<p>Classes:</p> Name Description <code>JobListEventsParams</code>"},{"location":"reference/types/fine_tuning/job_list_events_params/#src.openai.types.fine_tuning.job_list_events_params.JobListEventsParams","title":"JobListEventsParams","text":"<p>Attributes:</p> Name Type Description <code>after</code> <code>str</code> <p>Identifier for the last event from the previous pagination request.</p> <code>limit</code> <code>int</code> <p>Number of events to retrieve.</p>"},{"location":"reference/types/fine_tuning/job_list_events_params/#src.openai.types.fine_tuning.job_list_events_params.JobListEventsParams.after","title":"after  <code>instance-attribute</code>","text":"<pre><code>after: str\n</code></pre> <p>Identifier for the last event from the previous pagination request.</p>"},{"location":"reference/types/fine_tuning/job_list_events_params/#src.openai.types.fine_tuning.job_list_events_params.JobListEventsParams.limit","title":"limit  <code>instance-attribute</code>","text":"<pre><code>limit: int\n</code></pre> <p>Number of events to retrieve.</p>"},{"location":"reference/types/fine_tuning/job_list_params/","title":"job_list_params","text":"<p>Classes:</p> Name Description <code>JobListParams</code>"},{"location":"reference/types/fine_tuning/job_list_params/#src.openai.types.fine_tuning.job_list_params.JobListParams","title":"JobListParams","text":"<p>Attributes:</p> Name Type Description <code>after</code> <code>str</code> <p>Identifier for the last job from the previous pagination request.</p> <code>limit</code> <code>int</code> <p>Number of fine-tuning jobs to retrieve.</p>"},{"location":"reference/types/fine_tuning/job_list_params/#src.openai.types.fine_tuning.job_list_params.JobListParams.after","title":"after  <code>instance-attribute</code>","text":"<pre><code>after: str\n</code></pre> <p>Identifier for the last job from the previous pagination request.</p>"},{"location":"reference/types/fine_tuning/job_list_params/#src.openai.types.fine_tuning.job_list_params.JobListParams.limit","title":"limit  <code>instance-attribute</code>","text":"<pre><code>limit: int\n</code></pre> <p>Number of fine-tuning jobs to retrieve.</p>"},{"location":"reference/types/shared/","title":"openai.types.shared","text":"<p>Modules:</p> Name Description <code>function_definition</code> <code>function_parameters</code>"},{"location":"reference/types/shared/function_definition/","title":"function_definition","text":"<p>Classes:</p> Name Description <code>FunctionDefinition</code>"},{"location":"reference/types/shared/function_definition/#src.openai.types.shared.function_definition.FunctionDefinition","title":"FunctionDefinition","text":"<p>Attributes:</p> Name Type Description <code>description</code> <code>Optional[str]</code> <p>A description of what the function does, used by the model to choose when and</p> <code>name</code> <code>str</code> <p>The name of the function to be called.</p> <code>parameters</code> <code>Optional[FunctionParameters]</code> <p>The parameters the functions accepts, described as a JSON Schema object.</p>"},{"location":"reference/types/shared/function_definition/#src.openai.types.shared.function_definition.FunctionDefinition.description","title":"description  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>description: Optional[str] = None\n</code></pre> <p>A description of what the function does, used by the model to choose when and how to call the function.</p>"},{"location":"reference/types/shared/function_definition/#src.openai.types.shared.function_definition.FunctionDefinition.name","title":"name  <code>instance-attribute</code>","text":"<pre><code>name: str\n</code></pre> <p>The name of the function to be called.</p> <p>Must be a-z, A-Z, 0-9, or contain underscores and dashes, with a maximum length of 64.</p>"},{"location":"reference/types/shared/function_definition/#src.openai.types.shared.function_definition.FunctionDefinition.parameters","title":"parameters  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>parameters: Optional[FunctionParameters] = None\n</code></pre> <p>The parameters the functions accepts, described as a JSON Schema object.</p> <p>See the guide for examples, and the JSON Schema reference for documentation about the format.</p> <p>Omitting <code>parameters</code> defines a function with an empty parameter list.</p>"},{"location":"reference/types/shared/function_parameters/","title":"function_parameters","text":"<p>Attributes:</p> Name Type Description <code>FunctionParameters</code>"},{"location":"reference/types/shared/function_parameters/#src.openai.types.shared.function_parameters.FunctionParameters","title":"FunctionParameters  <code>module-attribute</code>","text":"<pre><code>FunctionParameters = Dict[str, object]\n</code></pre>"},{"location":"reference/types/shared_params/","title":"openai.types.shared_params","text":"<p>Modules:</p> Name Description <code>function_definition</code> <code>function_parameters</code>"},{"location":"reference/types/shared_params/function_definition/","title":"function_definition","text":"<p>Classes:</p> Name Description <code>FunctionDefinition</code>"},{"location":"reference/types/shared_params/function_definition/#src.openai.types.shared_params.function_definition.FunctionDefinition","title":"FunctionDefinition","text":"<p>Attributes:</p> Name Type Description <code>description</code> <code>str</code> <p>A description of what the function does, used by the model to choose when and</p> <code>name</code> <code>Required[str]</code> <p>The name of the function to be called.</p> <code>parameters</code> <code>FunctionParameters</code> <p>The parameters the functions accepts, described as a JSON Schema object.</p>"},{"location":"reference/types/shared_params/function_definition/#src.openai.types.shared_params.function_definition.FunctionDefinition.description","title":"description  <code>instance-attribute</code>","text":"<pre><code>description: str\n</code></pre> <p>A description of what the function does, used by the model to choose when and how to call the function.</p>"},{"location":"reference/types/shared_params/function_definition/#src.openai.types.shared_params.function_definition.FunctionDefinition.name","title":"name  <code>instance-attribute</code>","text":"<pre><code>name: Required[str]\n</code></pre> <p>The name of the function to be called.</p> <p>Must be a-z, A-Z, 0-9, or contain underscores and dashes, with a maximum length of 64.</p>"},{"location":"reference/types/shared_params/function_definition/#src.openai.types.shared_params.function_definition.FunctionDefinition.parameters","title":"parameters  <code>instance-attribute</code>","text":"<pre><code>parameters: FunctionParameters\n</code></pre> <p>The parameters the functions accepts, described as a JSON Schema object.</p> <p>See the guide for examples, and the JSON Schema reference for documentation about the format.</p> <p>Omitting <code>parameters</code> defines a function with an empty parameter list.</p>"},{"location":"reference/types/shared_params/function_parameters/","title":"function_parameters","text":"<p>Attributes:</p> Name Type Description <code>FunctionParameters</code>"},{"location":"reference/types/shared_params/function_parameters/#src.openai.types.shared_params.function_parameters.FunctionParameters","title":"FunctionParameters  <code>module-attribute</code>","text":"<pre><code>FunctionParameters = Dict[str, object]\n</code></pre>"}]}